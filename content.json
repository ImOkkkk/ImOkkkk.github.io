{"meta":{"title":"liuwy1998 BLOG","subtitle":"When they go low,we go high.","description":"Java开发, 后端开发","author":"liuwy1998","url":"http://tonymua.top","root":"/"},"pages":[{"title":"about","date":"2020-04-30T00:02:54.000Z","updated":"2020-04-30T00:03:10.835Z","comments":true,"path":"about/index.html","permalink":"http://tonymua.top/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-04-30T00:00:45.000Z","updated":"2020-04-30T00:01:46.812Z","comments":true,"path":"categories/index.html","permalink":"http://tonymua.top/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-30T00:00:30.000Z","updated":"2020-04-30T00:01:25.532Z","comments":true,"path":"tags/index.html","permalink":"http://tonymua.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"计算机网络","slug":"计算机网络","date":"2021-06-15T14:42:33.436Z","updated":"2021-06-20T13:48:51.466Z","comments":true,"path":"computernetwork/","link":"","permalink":"http://tonymua.top/computernetwork/","excerpt":"1.TCP 为什么握手是 3 次、挥手是 4 次？ 如果一个Host主动向另一个Host发起连接，称为SYN，请求同步； 如果一个Host主动断开请求，称为FIN，请求完成； 如果一个Host给另一个Host发送数据，称为PSH，数据推送。","text":"1.TCP 为什么握手是 3 次、挥手是 4 次？ 如果一个Host主动向另一个Host发起连接，称为SYN，请求同步； 如果一个Host主动断开请求，称为FIN，请求完成； 如果一个Host给另一个Host发送数据，称为PSH，数据推送。 TCP是一个双工协议，建立连接的时候，连接双方都需要向对方发送SYN和ACK。握手阶段没有繁琐的工作，因此一方向另一方发起同步(SYN)之后，另一方可以将自己的ACK和SYN打包作为一条消息回复，因此是3次握手。 挥手阶段，双方都可能有未完成的工作。收到挥手请求的一方，必须马上响应(ACK)，表示收到了挥手请求。最后等所有工作结束，再发送请求中断连接(FIN)，因此是4次挥手。 2.TCP协议是如何恢复数据的顺序，TCP拆包和粘包的作用是什么？TCP拆包：将任务拆分处理，降低整体任务出错的概率，以及减小底层网络处理的压力。拆包过程中需要保证数据经过网络传输，又能恢复到原始的顺序。TCP利用发送字节数(Sequence Number)和接收字节数(Acknowledgement Number)的唯一性来确定封包之间的顺序关系(无论是Seq还是ACK，都是针对对方而言的。是对方发送的数据和对方接受的数据)。粘包是为了防止数据量过小，导致大量的传输，而将多个TCP段合并成一个发送。 3.滑动窗口和流速控制深绿色：已经收到了ACK的段 浅绿色：发送了，但是没有收到ACK的段 白色：没有发送的段 紫色：暂时不能发送的段。 有两个封包到达，标记为绿色。 滑动窗口可以向右滑动 重传 如果部分数据没能收到ACK，如段4迟迟没有收到ACK。 此时滑动窗口只能右移一个位置 如果段4重传成功(接收到ACK)，那么窗口就会继续右移。如果段4发送失败，还是没能收到ACK，那么接收方也会抛弃段5、6、7。这样从段4开始之后的数据都需要重发。 快速重传 例如段1、2、4到了，但是3没到。接收方可以发送多次3的ACK(不发段4的ACK)。如果发送方收到多个3的ACK，就会重发段3。这和超时重发不同，是一种催促机制，接收方希望催促发送方尽快补全某个TCP段。 实际操作中，每个TCP段的大小不同，限制数量会让接收方的缓冲区不好操作，因此实际操作中滑动窗口的大小单位是字节数。 总结 滑动窗口是TCP协议控制可靠性的核心。发送方将数据拆包，变成多个分组。然后将数据放入一个拥有滑动窗口的数组，依次发出，仍然遵循先入先出的顺序，但是窗口中的分组会一次性发送。窗口中序号最大的分组如果收到ACK，窗口就会发生滑动；如果有分组为收到ACK，则会滑动到该窗口。 在多次传输中，网络的平均延迟往往是相对固定的，这样TCP协议可以通过发送方和接收方协商窗口大小控制流速。 4.TCP和UDP的区别UDP UDP，目标是在传输层提供直接发送报文的能力。Datagram是数据传输的最小单位，UDP协议不会帮助拆分数据，它的目标只有一个，就是能发送报文。 UDP的可靠性仅仅就是通过Checksum保证。如果一个数据封包Datagram发生了数据损坏，UDP可以通过Checksum纠错或者修复。 UDP与TCP的区别 目的差异 TCP：提供可靠的网络传输。 UDP：提供报文交换能力基础上尽可能的简化协议。 可靠性差异 TCP：可靠，收到的数据会进行排序。 UDP：不可靠，只管发送数据包。 连接vs无连接 TCP：面向连接，会有握手的过程，传输数据必须先建立连接。 UDP：无连接协议，数据随时都可以发送，只提供发送封包的能力。 流控技术 TCP在发送缓冲区中存储数据，并在接收缓冲区中接收数据，如果接收缓冲区已满，接收方无法处理更多数据，并将其丢弃。UDP没有提供类似的能力。 传输速度 UDP协议简化，封包小，没有连接、可靠性检查等，因此单纯从速度上讲，UDP更快。 理论上，任何一个用TCP协议构造的成熟应用层协议，都可以UDP重构。想要把网络优化到极致，就会用UDP作为底层技术，然后在UDP基础上解决可靠性。 TCP场景： 远程控制(SSH) File Transfer Protocol(FTP) 邮件(SMTP、IMAP等) 点对点文件传输(微信等) UDP场景 网络游戏 音视频传输 DNS ping 直播 模糊地带 HTTP(目前以TCP为主) 文件传输 TCP最核心的价值就是提供封装好的一套解决可靠性的优秀方案。UDP最核心的价值是灵活、轻量、传输速度快。场景不同选择不同。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://tonymua.top/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://tonymua.top/tags/计算机网络/"},{"name":"HTTP","slug":"HTTP","permalink":"http://tonymua.top/tags/HTTP/"},{"name":"TCP","slug":"TCP","permalink":"http://tonymua.top/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://tonymua.top/tags/UDP/"}]},{"title":"MySQL","slug":"MySQL","date":"2021-06-06T08:06:55.156Z","updated":"2021-06-20T15:04:32.301Z","comments":true,"path":"mysql/","link":"","permalink":"http://tonymua.top/mysql/","excerpt":"1.基础篇1.1 一条SQL查询语句是如何执行的？ Server层 连接器、查询缓存、分析器、优化器、执行器等。涵盖MySQL的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能在这一层实现，如存储过程、触发器、视图等。","text":"1.基础篇1.1 一条SQL查询语句是如何执行的？ Server层 连接器、查询缓存、分析器、优化器、执行器等。涵盖MySQL的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能在这一层实现，如存储过程、触发器、视图等。 存储引擎层 负责数据的存储和提取。支持InnoDB、MyISAM、Memory等多个存储引擎。MySQL5.5.5版本后默认使用InnoDB。 连接器 连接器负责与客户端建立连接、获取权限、维持和管理连接。 1mysql -h&#123;ip&#125; -P&#123;port&#125; -u&#123;user&#125; -p 一个用户成功建立连接后，即使使用管理员账户对该用户的权限做了修改，也不会影响已经存在的连接权限，只有新建的连接才会使用新的权限设置。 show processlist 可以查看各连接状态 “Sleep”表示空闲连接，如果客户端太长时间没动静(wait_timeout，默认8小时)，连接器自动断开。 数据库长连接指连接成功后，客户端持续有请求，则一直使用同一个连接；短连接指每次执行完几次查询后就断开连接，下次查询再重新建立。MySQL在执行过程中临时使用的内存是管理在连接对象里的，如果长连接累积下来，会导致内存占用过大。 解决办法： 定期断开长连接 MySQL5.7及以后，可以在每次执行一个比较大的操作后，执行mysql_reset_connection来将连接恢复到刚刚创建完的状态(不需要重连和权限验证)。 查询缓存 之前查询过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。但只要有对一个表的更新，那么这个表上的查询缓存就会被全部清除。MySQL8.0版本将查询缓存模块删除掉了。 MySQL提供了”按需使用”的方式，将参数query_cache_type设置为DEMAND，这样对于默认的SQL不使用查询缓存。使用SQL_CACHE显式指定： 1mysql&gt; select SQL_CACHE * from T where ID=10； 分析器 如果没有命中查询缓存，就要开真正开始执行语句。 词法分析 把”select”关键字识别出来，把字符串”T”识别为”表名T”，把字符串”ID”识别为”列ID”。 语法分析 123mysql&gt; elect * from t where ID=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1 优化器 在表里有多个索引的时候，决定使用哪个索引；或者一个语句有多表关联(join)的时候，决定各个表的连接顺序。 执行器 开始执行语句，先判断对这个表T是否有权限(如果命中查询缓存，会在查询缓存返回结果时做权限校验)。如果有权限，就开始执行语句。 调用InnoDB引擎接口取这个表的第一行，判断ID是否为10，如果不是则跳过，如果是则将这行存在结果集。 调用引擎接口取”下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 将结果集返回给客户端。 对于有索引的表，第一次调用的是”满足条件的第一行”这个接口，之后循环取”满足条件的下一行”接口。 1.2 日志系统：一条SQL更新语句是如何执行的12mysql&gt; create table T(ID int primary key, c int);mysql&gt; update T set c=c+1 where ID=2; 重要的日志模块：redo log WAL(Write-Ahead Logging)：先写日志，再写磁盘。当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做的。 InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB。从头开始写，写到末尾就又回到开头循环写。 write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos和checkpoint之间空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，这时不能再执行新的更新，得擦掉一些记录，把checkpoint推进一下。 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 重要的日志模块：binlog MySQL整体看包括两块：一块是Server层，它主要做的是MySQL功能层面的事情；还一块是引擎层，负责存储相关的具体事宜。redo log是InnoDB(重做日志)引擎特有的日志，而Server层也有自己的日志，称为binlog(归档日志) 为什么会有两份日志？ 因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎MyIASM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是以插件形式引入MySQL的，使用另外一套日志系统-redo log来实现crash-safe能力。 这两种日志有以下三点不同： redo log是InnoDB引擎特有的，binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是”在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如”给ID=2这一行的c字段加1”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的，binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 InnoDB引擎内部执行流程 执行器先找引擎取ID=2这一行。(ID是主键，引擎直接用树搜索到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。) 执行器拿到引擎给的行数据，把这个值加1，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成commit状态，更新完成。 浅色表示在InnoDB内部进行，深色表示在执行器中执行。 1.3 事务隔离事务：保证一组数据库操作，要么全部成功，要么全部失败。 ACID(原子性、一致性、隔离性、持久性) 当数据库上有多个事务同时执行的时候，可能会出现脏读、不可重复读、幻读的问题。SQL标准的事务隔离级别包括： 读未提交：一个事务还没提交，它做的变更就能被其他事务看到。 读提交：一个事务提交之后，它做的变更才会被其他事务看到。 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化：对于同一行记录，”写”会加”写锁”，”读”会加”读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 读未提交：V1 = 2，V2、V3 = 2 读提交：V1 = 1，V2 = 2，V3 = 2 可重复读：V1、V2 = 1，V3 = 2；之所以V2还是1，是因为：事务在执行期间看到的数据前后必须一致 串行化：在事务B执行”将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以V1、V2 = 1，V3 = 2 事务隔离的实现 数据库里会创建一个视图，访问的时候以视图的逻辑结果为准。”可重复读”，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图；”读提交”，这个视图是在每个SQL语句开始执行的时候创建的。”读未提交”，直接返回记录上的最新值，没有视图概念；”串行化”，直接用加锁的方式来避免并发访问。 MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，都可以得到前一个状态。当系统里没有比这个回滚日志更早的read-view的时候，回滚日志会被删除。 长事务意味着系统里会存在很老的事务视图，这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这会导致占用大量存储空间。 事务的启动方式 显式启动事务语句，begin或start transaction。配套的语句是commit或者rollback。 set autocommit = 0，将这个线程的自动提交关掉。意味着如果执行一个select语句，这个事务就启动了，而且不会自动提交。这个事务持续存在直到主动执行commit或者rollback，或者断开连接。 1.4 索引索引的常见模型 哈希表 以键-值(key-value)存储数据的结构。多个key经过哈希函数换算，会出现同一个值的情况，此时会拉出一个链表。因为不是有序的，所以哈希索引做区间查询的速度很慢。适用于只有等值查询的场景。 有序数组 支持范围查询，但在插入数据和删除数据时必须挪动后面所有的记录，成本太高。适用于静态存储查询，这类不会再修改的数据。 二叉搜索树 二叉搜索树的特点：父节点左子树所有节点小于父节点的值，右子树所有的节点大于父节点的值。 多叉树就是每个节点有多个儿子，儿子的大小保证从左到右递增。索引不止在内存中，还要写到磁盘上。为了尽可能少的读磁盘，就必须让查询过程访问尽量少的数据块。”N叉树”的”N”取决于数据块的大小。 InnoDB的索引模型 每一个索引在InnoDB中对应一棵B+树。 12345mysql&gt; create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB; 表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。 索引类型分为主键索引和非主键索引。 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也称为聚簇索引。 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引。 基于主键索引和普通索引的查询有什么区别？ select * from T where ID = 500 即主键查询方式，则只需要搜索ID这棵B+树 select * from T where k = 5 即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次，这个过程称为回表。 索引维护 B+树为了维护索引有序性，在插入新值时需要做必要的维护。以上图为例，如果插入新的行ID值为700，则只需要在R5后面插入一个新记录。如果新插入的ID为400，需要逻辑上挪动后面的数据，空出位置。如果R5所在的数据页已满，根据B+树的算法，需要申请一个新的数据页，然后挪动部分数据过去，这个过程称为页分裂，性能会下降。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。 当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。 自增主键：NOT NULL PRIMARY KEY AUTO_INCREMENT。每次插入一条新纪录，都是追加操作，都不涉及挪动记录，也不会触发叶子节点的分裂。 由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约２０个字节，而如果用整形做主键，则只需要４个字节。主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 覆盖索引 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。 最左前缀原则 索引项是按照索引定义里面出现的字段顺序排序的。当查询所有名字是”张三”的人时，可以快速定位到ID4，然后向后遍历。 不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。 如果通过调整顺序，可以少维护一个索引，那么往往优先考虑这个顺序。 索引下推 1select * from tuser where name like '张 %' and age=10 and ismale=1; MySQL5.6之前，只能从ID3开始一个个回表，到主键索引上找出数据行，再对比字段值。 MySQL5.6之后引入索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的数据，减少回表次数。 无索引下推：回表4次 有索引下推：在(name，age)索引内部就判断了age是否等于10，对于不等于10的记录，直接判断并跳过，只需回表2次。 1.5 全局锁和表锁数据库锁设计的初衷是处理并发问题。 全局锁 全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局锁的方法，命令是Flush tables with read lock(FTWRL)。当需要让整个库处于只读状态(不止DML，还包括DDL)时，可以使用该命令。使用场景是，全库逻辑备份的时候。 InnoDB引擎的库推荐使用一致性读(single-transcation)参数，对应用会更友好，全局锁一般在数据库引擎不支持事务时使用。 为什么不使用set global readonly=true？ readonly的值会被用作其他逻辑，如判断主库备库。 异常处理机制有差别，执行FTWRL后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。readonly，如果客户端发生异常，则数据库就会一直保持readonly状态。 表级锁 MySQL里面的表级别锁有两种：一种是表锁，一种是元数据锁(meta data lock，MDL) 表锁 表锁的语法是lock tables..read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。lock tables不仅会限制别的线程的读写外，也限定了本线程接下来的操作对象。 某个线程A执行lock tables t1 read，t2 write；则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作，连写t1都不允许，自然也不能访问其他表。 元数据锁DML 不需要显示的使用，在访问一个表的时候会被自动加上，保证读写的正确性。 给一个表加字段，或者修改字段，或者加索引。需要扫描全表的数据。 如何安全地给小表加字段？ 首先解决长事务的问题，事务不提交，就会一直占着MDL锁。在alter table语句里面设定等待时间，如果在这个指定的等待时间内未拿到MDL锁，则会放弃，不阻塞后面的业务。之后再通过重试命令重复这个过程。 12ALTER TABLE tb1_name NOWAIT add column ...ALTER TABLE tb1_name WAIT N add column ...","categories":[{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://tonymua.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"}]},{"title":"代理模式(JDK Proxy与CGLIB Proxy)","slug":"代理模式","date":"2021-05-23T14:15:34.269Z","updated":"2021-05-23T14:36:45.692Z","comments":true,"path":"proxymode/","link":"","permalink":"http://tonymua.top/proxymode/","excerpt":"1.静态代理 售卖香水接口 123456/* * 定义真实对象和代理对象的公共接口 */public interface SellPerfume &#123; void sellPerfume(double price);&#125; 定义香水提供商，实现接口 123456public class ChanelFactory implements SellPerfume &#123; @Override public void sellPerfume(double price) &#123; System.out.println(\"成功购买香奈儿品牌的香水，价格是：\" + price + \"元！\"); &#125;&#125;","text":"1.静态代理 售卖香水接口 123456/* * 定义真实对象和代理对象的公共接口 */public interface SellPerfume &#123; void sellPerfume(double price);&#125; 定义香水提供商，实现接口 123456public class ChanelFactory implements SellPerfume &#123; @Override public void sellPerfume(double price) &#123; System.out.println(\"成功购买香奈儿品牌的香水，价格是：\" + price + \"元！\"); &#125;&#125; 定义代理类 123456789101112131415161718192021222324public class XiaoHongSellProxy implements SellPerfume &#123; /* * 代理对象内部保存对真实目标对象的引用，控制其它对象对目标对象的访问。 */ private ChanelFactory chanelFactory; public XiaoHongSellProxy(ChanelFactory chanelFactory) &#123; this.chanelFactory = chanelFactory; &#125; @Override public void sellPerfume(double price) &#123; doSomethingBeforeSell(); chanelFactory.sellPerfume(price); doSomethingAfterSell(); &#125; private void doSomethingBeforeSell() &#123; System.out.println(\"小红代理购买香水前的额外操作...\"); &#125; private void doSomethingAfterSell() &#123; System.out.println(\"小红代理购买香水后的额外操作...\"); &#125;&#125; 购买香水 123456789101112131415161718/* * 访问者仅能通过代理对象访问真实目标对象，不可直接访问目标对象 */public class XiaoMing &#123; public static void main(String[] args) &#123; ChanelFactory chanelFactory = new ChanelFactory(); XiaoHongSellProxy xiaoHongSellProxy = new XiaoHongSellProxy(chanelFactory); /* * 代理对象并不是真正提供服务的对象，它只是替访问者访问目标对象的一个中间人， * 真正提供服务的还是目标对象，而代理对象的作用就是在目标对象提供服务之前或之后能够执行额外的逻辑 */ xiaoHongSellProxy.sellPerfume(100); &#125;&#125;小红代理购买香水前的额外操作...成功购买香奈儿品牌的香水，价格是：100.0元！小红代理购买香水后的额外操作... 代理模式的定义：给目标对象提供一个代理对象，代理对象包含该目标对象，并控制对该目标对象的访问。 代理模式的目的：通过代理对象的隔离，可以在对目标对象的访问前后增加额外的业务逻辑，实现功能增强；通过代理对象访问目标对象，可以防止系统大量的直接对目标对象进行不正确的访问。 2.静态代理与动态代理共同点：都能实现代理模式；代理对象和目标对象都需要实现一个公共接口。 不同点： 动态代理产生代理对象的时机是运行时动态生成，它没有Java源文件，直接生成字节码文件实例化代理对象，而静态代理的代理对象，在程序编译时已经写好了Java文件，直接new一个代理对象即可。 动态代理比静态代理更加稳健，对程序的可维护性和扩展性更加友好。 3.动态代理面对新的需求时，不需要修改代理对象的代码，只需要新增接口对象，在客户端调用即可完成新的代理。 3.1 JDK ProxyJDK提供的一个动态代理机制，涉及到Proxy和InvocationHandler两个核心类。 代理对象是在程序运行过程中，有代理工厂动态生成，代理对象本身不存在Java源文件。 代理工厂需要实现InvocationHanlder接口并实现invoke()方法 1234567891011121314151617181920212223242526272829public class SellProxyFactory implements InvocationHandler &#123; // 代理的真实对象 private Object object; public SellProxyFactory(Object object) &#123; this.object = object; &#125; private void doSomethingAfter() &#123; System.out.println(\"执行代理后的额外操作...\"); &#125; private void doSomethingBefore() &#123; System.out.println(\"执行代理前的额外操作...\"); &#125; /** * @param proxy 代理对象 * @param method 真正执行的方法 * @param args 调用第二个参数method时传入的参数列表值 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; doSomethingBefore(); Object invokeObject = method.invoke(object, args); doSomethingAfter(); return invokeObject; &#125;&#125; 生成代理对象需要用到Proxy类，里面的静态方法newProxyInstance可以生成任意一个代理对象 123456 /** * @param loader 加载动态代理的类的类加载器 * @param method 代理类实现的接口，可以传入多个接口 * @param args 指定代理类的调用处理程序，即调用接口中的方法时，会找到该代理工厂h，执行invoke()方法 */Proxy.newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h) 新增红酒代理功能： 创建新的红酒供应商和售卖红酒接口 123456789/* * 红酒供应商 */public class RedWineFactory implements SellWine &#123; @Override public void SellWine(double price) &#123; System.out.println(\"成功售卖一瓶红酒，价格：\" + price + \"元\"); &#125;&#125; 123456/* * 售卖红酒接口 */public interface SellWine &#123; void SellWine(double price);&#125; 在客户端实例化一个代理对象，然后向该代理对象购买红酒 1234567891011121314151617181920212223242526public class XiaoMing &#123; public static void main(String[] args) &#123; // buyChannel(); buyRedWine(); &#125; static void buyChannel() &#123; ChanelFactory chanelFactory = new ChanelFactory(); SellProxyFactory sellProxyFactory = new SellProxyFactory(chanelFactory); SellPerfume sellPerfume = (SellPerfume)Proxy.newProxyInstance(chanelFactory.getClass().getClassLoader(), chanelFactory.getClass().getInterfaces(), sellProxyFactory); sellPerfume.sellPerfume(100); &#125; static void buyRedWine() &#123; // 实例化一个红酒供应商 RedWineFactory redWineFactory = new RedWineFactory(); // 实例化代理工厂，传入红酒供应商引用控制对其的访问 SellProxyFactory sellProxyFactory = new SellProxyFactory(redWineFactory); // 实例化代理对象 SellWine sellWine = (SellWine)Proxy.newProxyInstance(redWineFactory.getClass().getClassLoader(), redWineFactory.getClass().getInterfaces(), sellProxyFactory); // 代理售卖红酒 sellWine.SellWine(100); &#125;&#125; 总结： JDK动态代理的使用方法 代理工厂需要实现InvocationHandle接口，调用代理方法会转向执行invoke()方法。 生成代理对象需要使用Proxy对象中的newProxyInsatnce()方法，返回对象可强转成传入的其中一个接口，然后调用接口方法即可实现代理。 JDK动态代理的特点 目标对象强制需要实现一个接口，否则无法使用JDK动态代理。 3.2 CGLIBCGLIB不是JDK自带的动态代理，它需要导入第三方依赖，它是一个字节码生成类库，能够在运行时动态生成代理类对Java类和Java接口扩展。CGLIB不仅能够为Java接口做代理，而且能够为普通的Java类做代理，而JDK Proxy只能为实现了接口的Java类做代理。 CGLIB可以代理没有实现接口的Java类 导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; CGLIB代理中有两个核心的类：MetondInterceptor接口和Enhancer类，前者是实现一个代理工厂的根接口，后者是创建动态代理对象的类。 定义代理工厂 1234567891011121314151617181920212223242526272829303132333435363738394041public class SellProxyFactory implements MethodInterceptor &#123; // 关联真实对象，控制真实对象的访问 private Object object; // 从代理工厂获取一个代理对象实例，等价于创建小红代理 public Object getProxyInstance(Object object) &#123; this.object = object; Enhancer enhancer = new Enhancer(); // 设置需要增强类的类加载器 enhancer.setClassLoader(object.getClass().getClassLoader()); // 设置被代理类，真实对象 enhancer.setSuperclass(object.getClass()); // 设置方法拦截器，代理工厂 enhancer.setCallback(this); // 创建代理类 return enhancer.create(); &#125; private void doSomethingBefore() &#123; System.out.println(\"执行方法前额外的操作...\"); &#125; private void doSomethingAfter() &#123; System.out.println(\"执行方法后额外的操作...\"); &#125; /** * @param o 被代理对象 * @param method 被拦截的方法 * @param objects 被拦截方法的所有入参值 * @param methodProxy 方法代理，用于调用原始的方法 */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; doSomethingBefore(); Object invokeSuperObject = methodProxy.invokeSuper(o, objects); doSomethingAfter(); return invokeSuperObject; &#125;&#125; 12345678public class XiaoMing &#123; public static void main(String[] args) &#123; SellProxyFactory sellProxyFactory = new SellProxyFactory(); //获取一个代理实例 ChanelFactory chanelFactoryInstance = (ChanelFactory) sellProxyFactory.getProxyInstance(new ChanelFactory()); chanelFactoryInstance.sellPerfume(100); &#125;&#125; 总结： CGLIB的使用方法 代理工厂需要实现MethodInterceptor接口，并重写方法，内部关联真实对象，控制第三者对真实对象的访问；代理工厂内部暴露getInstance(Object object)方法，用于从代理工厂中获取一个代理对象实例。 Enhancer类用于从代理工厂中实例化一个代理对象，给调用者提供代理服务。 JDK Proxy和CGLIB的对比 JDK Proxy CGLIB 代理工厂实现接口 InvocationHandler MethodInterceptor 构造代理对象给Client服务 Proxy Enhancer 不同点： CGLIB可以代理大部分类；而JDK Proxy仅能够代理实现了接口的类 CGLIB采用动态创建被代理类的子类实现方法拦截的方法，所以CGLIB不能代理被final关键字修饰的类和方法。 4.动态代理的实际运用AOP允许我们将重复的代码逻辑抽取出来形成一个单独的覆盖层，在执行代码时可以将覆盖层嵌入到原代码逻辑里面去。 如下图，method1和method2都需要在方法执行前后记录日志，AOP可以将大量重复的Log.info代码包装到额外的一层，监听方法的执行，当方法被调用时，通用的日志记录层会拦截掉该方法，在该方法调用前后记录日志，这样可以让方法专注于自己的业务逻辑而无需关注其它不必要的信息。 Spring AOP有许多功能：提供缓存、提供日志环绕、事务处理…… 事务 @Transactional 每个有关数据库的操作都有保证一个事务内的所有操作，要么全部执行成功，要么全部执行失败，传统的事务失败回滚和成功提交是使用try…catch代码块完成的 1234567891011121314SqlSession session = null;try&#123; session = getSqlSessionFactory().openSession(false); session.update(\"...\", new Object()); // 事务提交 session.commit();&#125;catch(Exception e)&#123; // 事务回滚 session.rollback(); throw e;&#125;finally&#123; // 关闭事务 session.close();&#125; 如果多个方法都需要写这一段逻辑非常冗余，所以Spring封装了一个注解@Transactional，使用它后，调用方法时会监视方法，如果方法上含有该注解，就会自动把数据库相关操作的代码包裹起来，类似上面一段代码。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/categories/Spring/"}],"tags":[{"name":"代理模式","slug":"代理模式","permalink":"http://tonymua.top/tags/代理模式/"}]},{"title":"通用Mapper入门","slug":"通用Mapper入门","date":"2021-05-08T13:19:59.251Z","updated":"2020-04-29T02:44:38.016Z","comments":true,"path":"2400/","link":"","permalink":"http://tonymua.top/2400/","excerpt":"1.为什么使用通用mapper​ 通用 Mapper4 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及Example 相关的单表操作。通用 Mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。 2.快速入门","text":"1.为什么使用通用mapper​ 通用 Mapper4 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及Example 相关的单表操作。通用 Mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。 2.快速入门 2.1 添加依赖12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt; 2.2 创建实体类12345678910@Data@Table(name = \"employee\")public class Employee implements Serializable &#123; @Id @KeySql(useGeneratedKeys = true) private Integer id; private String name; private String gender; private String email;&#125; 2.3 创建相关数据表123456789101112131415DROP TABLE IF EXISTS `employee`;CREATE TABLE `employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '姓名', `gender` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '性别', `email` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '邮箱', PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 4 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of employee-- ----------------------------INSERT INTO `employee` VALUES (1, '许威威', '男', 'xuweiwei@qq.com');INSERT INTO `employee` VALUES (2, '孙夏萍', '女', 'sunxiaping@qq,com');INSERT INTO `employee` VALUES (3, '杜国庆', '男', 'duguoqing@qq.com'); 2.4 创建Mapper接口12public interface EmployeeMapper extends Mapper&lt;Employee&gt; &#123;&#125; 拓展:自定义通用Mapper 123@RegisterMapperpublic interface BaseMapper&lt;T&gt; extends Mapper&lt;T&gt;, IdListMapper&lt;T,Long&gt;, InsertListMapper&lt;T&gt; &#123;&#125; 2.5 配置通用Mapper为了让上述方法可以直接使用，还需要配置通用 Mapper，让项目在启动的时候，把上述方法都自动生成好，这样在运行时就可以使用上面所有的方法。 根据不同的开发环境，需要不同的配置方式，完整的内容可以 集成通用 Mapper，我们这里以最常见的 Spring 和 MyBatis 集成为例。 在集成 Spring 的环境中使用 MyBatis 接口方式时，需要配置 MapperScannerConfigurer，在这种情况下使用通用 Mapper，只需要修改配置如下： 1234&lt;bean class=\"tk.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"扫描包名\"/&gt; &lt;!-- 其他配置 --&gt;&lt;/bean&gt; 2.6 简单使用12345678910111213141516@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath*:applicationContext.xml\")public class MapperTest &#123; @Autowired private DataSource dataSource; @Autowired private EmployeeMapper emloyeeMapper; @Test public void testDemo()&#123; List&lt;Employee&gt; employees = emloyeeMapper.selectAll(); for (Employee employee : employees) &#123; System.out.println(employee); &#125; &#125;&#125; 3.相关方法123456789101112131415161718192021222324252627282930313233343536//根据实体类不为null的字段进行查询,条件全部使用=号and条件List&lt;T&gt; select(T record); //根据实体类不为null的字段查询总数,条件全部使用=号and条件int selectCount(T record); //根据主键进行查询,必须保证结果唯一//单个字段做主键时,可以直接写主键的值//联合主键时,key可以是实体类,也可以是MapT selectByPrimaryKey(Object key); //插入一条数据//支持Oracle序列,UUID,类似Mysql的INDENTITY自动增长(自动回写)//优先使用传入的参数值,参数值空时,才会使用序列、UUID,自动增长int insert(T record); //插入一条数据,只插入不为null的字段,不会影响有默认值的字段//支持Oracle序列,UUID,类似Mysql的INDENTITY自动增长(自动回写)//优先使用传入的参数值,参数值空时,才会使用序列、UUID,自动增长int insertSelective(T record); //根据实体类中字段不为null的条件进行删除,条件全部使用=号and条件int delete(T key); //通过主键进行删除,这里最多只会删除一条数据//单个字段做主键时,可以直接写主键的值//联合主键时,key可以是实体类,也可以是Mapint deleteByPrimaryKey(Object key); //根据主键进行更新,这里最多只会更新一条数据//参数为实体类int updateByPrimaryKey(T record); //根据主键进行更新//只会更新不是null的数据int updateByPrimaryKeySelective(T record); Example方法 方法：List&lt;T&gt; selectByExample(Object example)说明：根据Example条件进行查询重点：这个查询支持通过Example类指定查询列，通过selectProperties方法指定查询列 方法：int selectCountByExample(Object example)说明：根据Example条件进行查询总数 方法：int updateByExample(T record,Object example)说明：根据Example条件更新实体record包含的全部属性，null值会被更新 方法：int updateByExampleSelective(T record, Object example)说明：根据Example条件更新实体record包含的不是null的属性值 方法：int deleteByExample(Object example)说明：根据Example条件删除数据 Demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath*:applicationContext.xml\")public class MapperTest &#123; @Autowired private DataSource dataSource; @Autowired private EmployeeMapper emloyeeMapper; @Test public void testDemo()&#123; List&lt;Employee&gt; employees = emloyeeMapper.selectAll(); for (Employee employee : employees) &#123; System.out.println(employee); &#125; &#125; @Test public void testSelect()&#123; /*Employee employee=new Employee(); employee.setId(2); List&lt;Employee&gt; select = emloyeeMapper.select(employee);*/ Employee employee=new Employee(); employee.setGender(\"男\"); int count = emloyeeMapper.selectCount(employee); Employee select = emloyeeMapper.selectByPrimaryKey(2); System.out.println(count); System.out.println(select); &#125; @Test public void testInsert()&#123; Employee employee=new Employee(); employee.setGender(\"男\"); employee.setName(\"小王\"); employee.setEmail(\"111@qq.com\"); int count = emloyeeMapper.insert(employee); System.out.println(count); &#125; @Test public void testDelete()&#123; /*Employee employee=new Employee(); employee.setGender(\"男\"); int count = emloyeeMapper.delete(employee);*/ int count = emloyeeMapper.deleteByPrimaryKey(2); System.out.println(count); &#125; @Test public void testUpdate()&#123; Employee employee=new Employee(); employee.setId(6); employee.setEmail(\"333.@qq.com\"); employee.setGender(\"女\"); int count = emloyeeMapper.updateByPrimaryKeySelective(employee); System.out.println(count); &#125;","categories":[],"tags":[{"name":"javaee","slug":"javaee","permalink":"http://tonymua.top/tags/javaee/"}]},{"title":"计算机网络与网络编程","slug":"计算机网络与网络编程","date":"2021-05-08T13:19:59.249Z","updated":"2020-04-29T02:44:38.098Z","comments":true,"path":"65346/","link":"","permalink":"http://tonymua.top/65346/","excerpt":"1.软件结构1.1 C/S结构全称为Client/Server结构，是指客户端和服务器结构。常见程序有ＱＱ、迅雷等软件。 1.2 B/S结构全称为Browser/Server结构，是指浏览器和服务器结构。常见浏览器有谷歌、火狐等。","text":"1.软件结构1.1 C/S结构全称为Client/Server结构，是指客户端和服务器结构。常见程序有ＱＱ、迅雷等软件。 1.2 B/S结构全称为Browser/Server结构，是指浏览器和服务器结构。常见浏览器有谷歌、火狐等。 两种架构各有优势，但是无论哪种架构，都离不开网络的支持。网络编程，就是在一定的协议下，实现两台计算机的通信的程序。 2.网络通信协议 网络通信协议：通过计算机网络可以使多台计算机实现连接，位于同一个网络中的计算机在进行连接和通信时需要遵守一定的规则，这就好比在道路中行驶的汽车一定要遵守交通规则一样。在计算机网络中，这些连接和通信的规则被称为网络通信协议，它对数据的传输格式、传输速率、传输步骤等做了统一规定，通信双方必须同时遵守才能完成数据交换。 TCP/IP协议： 传输控制协议/因特网互联协议( Transmission Control Protocol/Internet Protocol)，是Internet最基本、最广泛的协议。它定义了计算机如何连入因特网，以及数据如何在它们之间传输的标准。它的内部包含一系列的用于处理数据通信的协议，并采用了4层的分层模型，每一层都呼叫它的下一层所提供的协议来完成自己的需求。上图中，TCP/IP协议中的四层分别是应用层、传输层、网络层和链路层，每层分别负责不同的通信功能。链路层：链路层是用于定义物理传输通道，通常是对某些网络连接设备的驱动协议，例如针对光纤、网线提供的驱动。网络层：网络层是整个TCP/IP协议的核心，它主要用于将传输的数据进行分组，将分组数据发送到目标计算机或者网络。运输层：主要使网络程序进行通信，在进行网络通信时，可以采用TCP协议，也可以采用UDP协议。应用层：主要负责应用程序的协议，例如HTTP协议、FTP协议等。 OSI七层模型: 应用层 负责对软件提供接口时程序能使用网络服务 表示层 应用程序和网络之间的翻译官 会话层 负责在网络中的两节点之间建立和维持通信 传输层 建立端到端之间的连接，数据的分段和重组 网络层 将网络地址翻译成对应的mac地址，指导数据包的转发 数据链路层 将网络层接收到的数据包封装为特定的数据帧，使其在不可靠的物理链路上进行可靠的数据传递 物理层 建立、维护、断开物理连接。（由底层网络定义协议） 3.UDP与TCP协议3.1 UDP协议​ UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。由于使用UDP协议消耗资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输例如视频会议都使用UDP协议，因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。但是在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议。UDP的交换过程如下图所示。 3.2 TCP协议​ TCP协议是面向连接的通信协议，即在传输数据前先在发送端和接收端建立逻辑连接，然后再传输数据，它提供了两台计算机之间可靠无差错的数据传输。每次连接的创建都需要经过“三次握手”。 第一次握手，客户端向服务器端发出连接请求，等待服务器确认 第二次握手，服务器端向客户端回送一个响应，通知客户端收到了连接请求 第三次握手，客户端再次向服务器端发送确认信息，确认连接。整个交互过程如下图所示由于TCP协议的面向连接特性，它可以保证传输数据的安全性，所以是一个被广泛采用的协议，例如在下载文件时，如果数据接收不完整，将会导致文件数据丢失而不能被打开，因此，下载文件时必须采用TCP协议。 4.相关面试题 TCP断开连接的四次挥手第一次挥手：客户端发送一个FIN包（seq=x），进入FIN_WAIT（结束等待）状态第二次挥手：服务器收到FIN包，发回一个ACK包(ack=x+1)，进入CLOSE_WAIT（关闭等待）状态第三次挥手：服务器关闭客户端的连接，并发送一个FIN包(seq=y)，进入LAST_ACK（最后确认）状态第四次挥手：客户端发回ACK(ack=y+1)包确认，发送完毕后，连接断开 需要三次握手的原因为了防止失效的连接请求报文突然又传送到服务器产生错误。假如不三次握手，客户端发送连接确认给服务端就立即建立连接，如果有个连接请求阻塞了很久才到服务端，而此时本来已经关闭了连接的又重新建立了连接，然而等了很久都没有数据发送，这就会白白浪费资源 Http协议与Https协议 Http协议即超文本传输协议，是一种基于TCP的应用层协议，还是一种无状态协议。用于服务器和客户端的数据传输，客户端和服务器使用URL来建立连接和传输数据。客户端发送Http请求给服务器，服务器根据请求返回Html、文本或多媒体文件给客户端 Https协议是一种安全的Http协议。Http协议是一种明文传输的协议，存在被窃听，信息篡改等安全隐患，在Http协议的基础上加入了SSL或TLS协议，实现了数据的加密传输。因为加上了加密的协议，所以Https的响应速度会比Http慢很多。并不是所有情况下都需要使用Https协议，对于隐私的，重要的信息最好用Https协议，不重要的或者可以公开的信息就没有必要用Https协议 Http请求报文和响应报文 请求报文包括请求行，请求头，空行和请求体（GET请求没有请求体） 响应报文包括状态行，响应头，空行和响应体 Http请求常见状态码 200 OK，请求成功 404 Not Found，对应的URL上不存在资源 405 Method Not Allowed，请求不被允许，即请求方式错误 500 Internal Server Error，服务器内部错误，发现严重BUG，要及时修复 GET请求与POST请求的区别 GET请求一般用于获取服务器上的资源，是幂等的。POST请求一般用于对服务器上资源进行更新，非幂等的（幂等即每次请求返回结果一样） GET请求没有请求体，请求参数跟是在URL后面的，所以使用GET请求时请求参数用户是可以直接看到的。POST请求有请求体，请求参数放在请求体，对用户是不可见的。相对来说POST请求比GET请求更安全 GET请求的参数长度有限制，这是因为URL长度有限导致的。POST请求的参数长度可以认为是无限制的 TCP 和 UDP的区别 TCP是一种面向连接的可靠传输协议，UDP是面向无连接的不可靠传输协议 TCP支持报文传输，还支持字节流的传输。而UDP协议只支持传输报文 TCP数据报格式比较复杂，传输过程数据不容易丢失和出错，而UDP数据报格式较为简单，容易丢失 TCP传输在接收端会进行重排，所以是有序的，UDP则不保证有序 TCP速度慢，UDP速度快 TCP有流量控制和拥塞控制，而UDP没有 应用层协议有哪些 DNS协议，域名解析系统。基于TCP和UDP的协议，通过DNS可以将域名转换成IP地址 SMTP协议，电子邮件协议。基于TCP的协议，通过SMTP协议可以发送电子邮件，SMTP通信的过程建立连接、邮件传送、连接释放 Telnet协议，远程终端协议。基于TCP的协议，通过Telnet协议可以对远程的终端进行控制 Http协议，超文本传输协议。基于TCP的协议，通过Http协议实现客户端和服务端的数据传输 FTP协议，文件传输协议。基于TCP的协议，通过FTP协议达到相互传输文件的效果 OSI参考模型与TCP/IP参考模型(1) OSI参考模型由7层组成：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层(2) TCP/IP参考模型由4层组成：主机-网络层、网际层、传输层、应用层(3) 对应关系中，OSI参考模型的物理层、数据链路层对应TCP/IP的主机-网络层，网络层对应网际层，传输层对应传输层，会话层、表示层、应用层对应应用层 cookie 和 session的区别(1) cookie由于把信息保存在客户端中。session把信息保存在服务器中(2) cookie性能更高一点，速度较快，用户的信息存在各自的浏览器中，可以分担服务器的一部分存储工作。session速度较慢，所有用户的信息都存在服务器中，在高并发时必然影响服务器性能(3) cookie有限制大小，在4K以内。session没有限制(4) cookie对用户是透明的，安全性低，不重要的或者可以公开的信息保存在cookie。session对用户是不可见的，安全性高，重要信息应该保存在session forward 和 redirect的区别(1) forward为转发，进行forward操作后，请求URL不发生变化，并且会把请求的数据携带到下一个请求中。redirect是重定向，进行redirect操作后，请求URL是发生变化的(2) forward是服务器内部请求转发，不可以请求到其它站点，redirect是服务器通知客户端重新请求，可以请求到其它站点(3) forward速度快，redirect速度慢 DNS劫持和DNS污染(1) DNS劫持：指用户访问一个域名时，DNS服务器故意将此地址指向一个错误的IP地址的行为。比如进入一个网站显示的却是另外一个网站的内容(2) DNS污染：指用户访问一个域名时，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。比如国内不能访问Google、YouTube等 5.TCP通信程序5.1 简单的TCP网络程序TCP通信分析图解 【服务端】启动,创建ServerSocket对象，等待连接。 【客户端】启动,创建Socket对象，请求连接。 【服务端】接收连接,调用accept方法，并返回一个Socket对象。 【客户端】Socket对象，获取OutputStream，向服务端写出数据。 【服务端】Scoket对象，获取InputStream，读取客户端发送的数据。 到此，客户端向服务端发送数据成功。自此，服务端向客户端回写数据。 【服务端】Socket对象，获取OutputStream，向客户端回写数据。 【客户端】Scoket对象，获取InputStream，解析回写数据。 【客户端】释放资源，断开连接。 服务端实现： 12345678910111213141516171819202122232425262728public class ServerTCP &#123; public static void main(String[] args) throws IOException &#123; System.out.println(\"服务端启动 , 等待连接 .... \"); // 1.创建 ServerSocket对象，绑定端口，开始等待连接 ServerSocket ss = new ServerSocket(6666); // 2.接收连接 accept 方法, 返回 socket 对象. Socket server = ss.accept(); // 3.通过socket 获取输入流 InputStream is = server.getInputStream(); // 4.一次性读取数据 // 4.1 创建字节数组 byte[] b = new byte[1024]; // 4.2 据读取到字节数组中. int len = is.read(b)； // 4.3 解析数组,打印字符串信息 String msg = new String(b, 0, len); System.out.println(msg); // =================回写数据======================= // 5. 通过 socket 获取输出流 OutputStream out = server.getOutputStream(); // 6. 回写数据 out.write(\"我很好,谢谢你\".getBytes()); // 7.关闭资源. out.close(); is.close(); server.close(); &#125;&#125; 客户端实现： 12345678910111213141516171819202122public class ClientTCP &#123; public static void main(String[] args) throws Exception &#123; System.out.println(\"客户端 发送数据\"); // 1.创建 Socket ( ip , port ) , 确定连接到哪里. Socket client = new Socket(\"localhost\", 6666); // 2.通过Scoket,获取输出流对象 OutputStream os = client.getOutputStream(); // 3.写出数据. os.write(\"你好么? tcp ,我来了\".getBytes()); // ==============解析回写========================= // 4. 通过Scoket,获取 输入流对象 InputStream in = client.getInputStream(); // 5. 读取数据数据 byte[] b = new byte[100]; int len = in.read(b); System.out.println(new String(b, 0, len)); // 6. 关闭资源 . in.close(); os.close(); client.close(); &#125;&#125; 5.2 文件上传文件上传分析图解 【客户端】输入流，从硬盘读取文件数据到程序中。 【客户端】输出流，写出文件数据到服务端。 【服务端】输入流，读取文件数据到服务端程序。 【服务端】输出流，写出文件数据到服务器硬盘中。 【服务端】获取输出流，回写数据。 【客户端】获取输入流，解析回写数据。 服务端实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class FileUpload_Server &#123; public static void main(String[] args) throws IOException &#123; System.out.println(\"服务器 启动..... \"); // 1. 创建服务端ServerSocket ServerSocket serverSocket = new ServerSocket(6666); // 2. 循环接收,建立连接 while (true) &#123; Socket accept = serverSocket.accept(); /* 3. socket对象交给子线程处理,进行读写操作 Runnable接口中,只有一个run方法,使用lambda表达式简化格式 */ new Thread(() -&gt; &#123; try ( //3.1 获取输入流对象 BufferedInputStream bis = new BufferedInputStream(accept.getInputStream()); //3.2 创建输出流对象, 保存到本地 . FileOutputStream fis = new FileOutputStream(System.currentTimeMillis() + \".jpg\"); BufferedOutputStream bos = new BufferedOutputStream(fis); ) &#123; // 3.3 读写数据 byte[] b = new byte[1024 * 8]; int len; while ((len = bis.read(b)) != -1) &#123; bos.write(b, 0, len); &#125; // 4.=======信息回写=========================== System.out.println(\"back ........\"); OutputStream out = accept.getOutputStream(); out.write(\"上传成功\".getBytes()); out.close(); //================================ //5. 关闭 资源 bos.close(); bis.close(); accept.close(); System.out.println(\"文件上传已保存\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125;&#125; 客户端实现： 12345678910111213141516171819202122232425262728293031public class FileUpload_Client &#123; public static void main(String[] args) throws IOException &#123; // 1.创建流对象 // 1.1 创建输入流,读取本地文件 BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\"test.jpg\")); // 1.2 创建输出流,写到服务端 Socket socket = new Socket(\"localhost\", 6666); BufferedOutputStream bos = new BufferedOutputStream(socket.getOutputStream()); //2.写出数据. byte[] b = new byte[1024 * 8 ]; int len ; while (( len = bis.read(b))!=-1) &#123; bos.write(b, 0, len); &#125; // 关闭输出流,通知服务端,写出数据完毕 socket.shutdownOutput(); System.out.println(\"文件发送完毕\"); // 3. =====解析回写============ InputStream in = socket.getInputStream(); byte[] back = new byte[20]; in.read(back); System.out.println(new String(back)); in.close(); // ============================ // 4.释放资源 socket.close(); bis.close(); &#125;&#125;","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"}]},{"title":"线程池","slug":"线程池","date":"2021-05-08T13:19:59.242Z","updated":"2020-11-03T12:25:05.495Z","comments":true,"path":"ThreadPool/","link":"","permalink":"http://tonymua.top/ThreadPool/","excerpt":"线程池1.概述","text":"线程池1.概述 原理：当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为 corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果阻塞队列满了，那就创建新的线程执行当前任务；直到线程池中的线程数达到 maxPoolSize，这时再有任务来，只能执行 reject() 处理该任务。优点： 降低资源消耗； 提高响应速度； 提高线程的可管理性。 缺点：TODO 1.1 四种常用ExecutorService特性 类型 核心线程数 最大线程数 KeepAlive时间(存活时间) 任务队列 拒绝策略 newCachedThreadPool(可缓存线程池) 0 Integer.MAX_VALUE 60s SynchronousQueue 线程池无限大，当执行第二个任务已经完成，会复用执行第一个任务的线程。 newFixedThreadPool(定长线程池) 指定大小 指定大小(与核心线程数相同) 0 LinkedBlockingQueue 线程池大小固定，没有可用的线程的时候，任务会放在队列等待，队列的长度无限制。 newSingleThreadExexutor 1 1 0 LinkedBlockingQueue 单线程化的线程池，适用于业务逻辑上只允许1个线程进行处理的场景，保证所有任务按照指定顺序FIFO(先进先出)，LIFO(后进先出)，优先级执行。 newScheduledThreadPool 指定大小 Integer.MAX_VALUE 0 DelayedWordQueue 定长线程池，支持定时及周期性任务执行。 1.2 ThreadPoolExecutor《阿里巴巴 Java 开发手册》中规定线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。而且线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式。这样的处理方式能够更加明确线程池的运行规则，规避资源耗尽的风险。 1234567ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数：corePoolSize：核心线程数，指定了线程池中的线程池数量，它的数量决定了添加的任务是开辟新的线程去执行，还是放到workQueue任务队列中； maximumPoolSize：指定了线程池中的最大线程数量，这个参数会根据使用的workQueue任务队列的类型，决定线程池会开辟的最大线程数量。 核心和最大线程数大小仅在构建时设置，但也可以使用 setCorePoolSize() 和 setMaximumPoolSize() 进行动态更改。keepAliveTime：当线程池中的空闲线程数量超过corePoolSize时，多余的线程会在多长时间内被销毁。如果线程池在以后会变得更加活跃，则应构建线程或者使用setKeepAliveTime(long, TimeUnit)方法。 unit：keepAliveTime的单位 workQueue：阻塞队列(用来保存等待被执行的任务) ArrayBlockingQueue：基于数组结构的有界任务队列，按照FIFO排序任务。若有新的任务需要执行时，线程会创建新的线程，直到创建的线程数量达到corePoolSize时，则会将新的任务加入到等待队列中。若等待队列已满，即超过ArrayBlockingQueue初始化的容量，则继续创建线程数量达到maximumPoolSize，则执行拒绝策略。这种情况下，线程数量的上限与有界任务队列的状态有直接关系，如果有界任务队列的初始容量比较大或者没有达到超负荷状态，线程数将会一直维持在corePoolSize以下，反之，则会以maximumPoolSize为最大线程数上限。 没有预定义容量的LinkedBlockingQueue：基于链表结构的无界任务队列，按照FIFO排序任务。使用无界任务队列，线程池的任务队列可以无限制的添加新的任务，当线程数达到corePoolSize后就不会再增加了。使用无界任务队列将导致新任务在队列中等待，从而导致maximumPoolSize的值没有任何作用。当使用这种任务队列模式时，一定要注意任务提交与处理之间的协调与控制，不然会出现队列中的任务由于无法及时处理导致一直增长，直到最后资源耗尽的问题。这种队列方式可以用于平滑瞬时大量请求。 SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于ArrayBlockingQueue。直接握手队列：它将任务交给线程而不需要保留，如果没有线程立即可用来运行它，那么排队任务的尝试将失败，因此构建新的线程，如果达到maximumPoolSize设置的最大值，则根据设置的handler执行拒绝策略。在这种情况下，需要对程序的并发量有个准确的评估，才能设置合适的maximumPoolSize数量避免执行拒绝策略。应注意，当任务持续以平均提交速度大于平均处理速度时，会导致线程数量会无限增长问题。 PriorityBlockingQueue：具有优先级的无界任务队列。优先任务队列：特殊的无界任务队列，无论添加了多少个任务，线程数量都不会超过corePoolSize。其它队列一般是按照FIFO(先进先出)的规则处理任务，而PriorityBlockingQueue队列可以自定义规则根据任务的优先级顺序先后执行。 threadFactory：线程工程，用于创建线程。如果未另行指定，则使用Executors.defaultThreadFactory默认工厂，使其全部位于同一个ThreadGroup中，并具有相同的NORM_PRIORITY优先级和非守护进程状态。通过不同的ThreadFactory可以更改线程的名称，线程组，优先级，守护进程状态等。privilegedThreadFactory：继承自defaultThreadFactory，主要添加了访问权限校验。 handler：拒绝策略，创建线程池时，为防止资源被耗尽，任务队列都会选择创建有界任务队列，但如果出现任务队列已满且线程池创建的线程数达到maximumPoolSize时，这时就需要指定ThreadPoolExecutor的RejectedExecutionHandler参数即合理的拒绝策略，来处理线程池”超载”的情况。ThreadPoolExecutor自带的拒绝策略如下： AbortPolicy：默认策略，丢掉任务直接抛出RejectedExecutionException异常，阻止系统正常工作。 CallerRunsPolicy：如果线程池的线程池的线程数量达到上限，该策略会把拒绝的任务放在调用者线程当中运行，如果执行程序已关闭，则会丢弃该任务。 DiscardPolicy：该策略会默默丢弃无法处理的任务，不会抛出任何异常，使用此策略，业务场景中需允许任务的丢失。 DiscardOldestPolicy：该策略会丢弃任务队列中最老的一个任务，也就是当前任务队列中最先被添加进去的。即每次移除队头元素后再尝试入队。 2.使用12345678910111213141516171819public class TestThreadPool &#123; private static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(8, 16, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(100), new ThreadPoolExecutor.AbortPolicy()); private static class testTask implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125; public static void main(String[] args) &#123; testTask testTask = new testTask(); for (int i = 0; i &lt; 50; i++) &#123; threadPoolExecutor.submit(testTask); &#125; threadPoolExecutor.shutdown(); &#125;&#125;","categories":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/tags/多线程/"},{"name":"并发编程","slug":"并发编程","permalink":"http://tonymua.top/tags/并发编程/"}]},{"title":"微信公众号开发(四)处理语音消息","slug":"微信公众号开发(四)处理语音消息","date":"2021-05-08T13:19:59.224Z","updated":"2020-04-29T02:44:38.015Z","comments":true,"path":"35386/","link":"","permalink":"http://tonymua.top/35386/","excerpt":"1.语音识别接口为了实现微信公众号与用户的多样化交互, 本章进行处理用户语音消息的开发. 开发者进入微信公众平台 https://mp.weixin.qq.com/ —接口权限—对话服务—接受消息—打开接收语音识别结果接口权限","text":"1.语音识别接口为了实现微信公众号与用户的多样化交互, 本章进行处理用户语音消息的开发. 开发者进入微信公众平台 https://mp.weixin.qq.com/ —接口权限—对话服务—接受消息—打开接收语音识别结果接口权限 2.获取语音识别结果请注意，开通语音识别后，用户每次发送语音给公众号时，微信会在推送的语音消息XML数据包中，增加一个Recognition字段（注：由于客户端缓存，开发者开启或者关闭语音识别功能，对新关注者立刻生效，对已关注用户需要24小时生效。开发者可以重新关注此帐号进行测试）。 开启语音识别后的语音XML数据包如下： 12345678910&lt;xml&gt; &lt;ToUserName&gt;&lt; ![CDATA[toUser] ]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt; ![CDATA[fromUser] ]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1357290913&lt;/CreateTime&gt; &lt;MsgType&gt;&lt; ![CDATA[voice] ]&gt;&lt;/MsgType&gt; &lt;MediaId&gt;&lt; ![CDATA[media_id] ]&gt;&lt;/MediaId&gt; &lt;Format&gt;&lt; ![CDATA[Format] ]&gt;&lt;/Format&gt; &lt;Recognition&gt;&lt; ![CDATA[腾讯微信团队] ]&gt;&lt;/Recognition&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 语音消息参数说明 开通语音识别功能以后，用户每次发送语音给微信公众号，微信会在推送语音消息XML数据包中添加一个Recongnition字段，该字段为语音识别出的文本内容. 3.功能实现实体类VoiceMessage 1234@Datapublic class VoiceMessage extends BaseMessage&#123; private String Recognition;&#125; MessageUtil 1234public static String voiceMessageToXml(VoiceMessage voiceMessage) &#123; xstream.alias(\"xml\", voiceMessage.getClass()); return xstream.toXML(voiceMessage);&#125; MsgService 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Servicepublic class MsgService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(MsgService.class); public String processRequest(HttpServletRequest request) &#123; String respMessage = null; System.out.println(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); try &#123; // xml请求解析 Map&lt;String, String&gt; requestMap = MessageUtil.xmlToMap(request); // 发送方帐号（open_id） String fromUserName = requestMap.get(\"FromUserName\"); // 公众帐号 String toUserName = requestMap.get(\"ToUserName\"); // 消息类型 String msgType = requestMap.get(\"MsgType\"); // 消息内容 String content = requestMap.get(\"Content\"); String recognition = requestMap.get(\"Recognition\"); LOGGER.info(\"FromUserName is:\" + fromUserName + \", ToUserName is:\" + toUserName + \", MsgType is:\" + msgType); if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_VOICE))&#123; System.out.println(recognition); if(recognition.indexOf(\"环境信息\")!=-1)&#123; Map map = IoTPopApiUtil.IoTpop(); Map ioTpop = JSON.parseObject(JSONObject.toJSONString(map), Map.class); Object data = ioTpop.get(\"data\"); String str = data.toString(); int index=str.indexOf(\"[\"); String result=str.substring(index); String jsonStr = result.substring(0, result.length() - 1); JSONArray array = JSONArray.parseArray(jsonStr); List&lt;Pi&gt; pi = JSONObject.parseArray(array.toJSONString(),Pi.class); String returnText=\"当前温度:\"+pi.get(3).getValue()+\"°C\"+\"\\n\" +\"当前湿度:\"+pi.get(2).getValue()+\"%\"+\"\\n\" +\"当前光照强度:\"+pi.get(4).getValue()+\"Lux\"+\"\\n\" +\"当前气压:\"+pi.get(1).getValue()+\"hPa\"+\"\\n\" +\"当前海拔:\"+pi.get(0).getValue()+\"m\"+\"\\n\" +\"降雨情况:\"+(pi.get(5).getValue()==1?\"降雨\":\"未降雨\"); //文本消息 TextMessage text = new TextMessage(); text.setContent(returnText); text.setToUserName(fromUserName); text.setFromUserName(toUserName); text.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); text.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_TEXT); respMessage = MessageUtil.textMessageToXml(text); &#125; if(recognition.indexOf(\"天气\")!=-1)&#123; //自动回复 NewsMessage newmsg = new NewsMessage(); newmsg.setToUserName(fromUserName); newmsg.setFromUserName(toUserName); newmsg.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); newmsg.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_NEWS); newmsg.setFuncFlag(0); List&lt;Article&gt; articleList = new ArrayList&lt;&gt;(); Article article = new Article(); article.setTitle(\"天气预报\"); article.setDescription(\"点击了解未来天气详情...\"); article.setPicUrl(\"https://xxxx.oss-cn-beijing.aliyuncs.com/ep.png\"); article.setUrl(\"https://widget-page.heweather.net/h5/index.html?bg=1&amp;md=0123456&amp;lc=accu&amp;key=4bdfe35a67bb4b53bee844f6ce7a4b5c\"); articleList.add(article); // 设置图文消息个数 newmsg.setArticleCount(articleList.size()); // 设置图文消息包含的图文集合 newmsg.setArticles(articleList); // 将图文消息对象转换成xml字符串 respMessage = MessageUtil.newsMessageToXml(newmsg); &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.error(\"error......\"); &#125; return respMessage; &#125;&#125; 4.测试","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"微信公众号开发(五)部署项目到阿里云服务器","slug":"微信公众号开发(五)部署项目到阿里云服务器","date":"2021-05-08T13:19:59.223Z","updated":"2020-05-28T02:18:40.540Z","comments":true,"path":"deployment/","link":"","permalink":"http://tonymua.top/deployment/","excerpt":"1.准备工作 可以正常运行提供服务的项目 一台云服务器 2.项目打包首先将我们在IDEA下的项目进行打包，这边基于的是maven项目的打包。点击菜单栏 File → Project Structure → Artifacts 添加一个jar","text":"1.准备工作 可以正常运行提供服务的项目 一台云服务器 2.项目打包首先将我们在IDEA下的项目进行打包，这边基于的是maven项目的打包。点击菜单栏 File → Project Structure → Artifacts 添加一个jar 之后，对添加的jar进行配置 点击右侧竖排菜单栏的maven project 然后点开Lifecycle，先clean再package，注意在打包之前，要将项目的启动端口号改为80，8080端口是本机端口，不适用于服务器。 当下方控制器显示BUILD SUCCESS时说明打包成功 这时候我们可以在项目的文件目录下看到多了个target目录，点开目录移动到最下方我们可以看到项目jar包,我们可以从电脑磁盘中将放置该项目的文件夹打开并找到该项目文件。 3.导入服务器使用FTP工具负责构建完成的项目jar包到云服务器 4.运行项目4.1 配置Java运行环境 查看yum库中的Java安装包 1yum -y list java* 以yum库中java-1.8.0为例, “*”表示将java-1.8.0的所有相关Java程序都安装上 1yum -y install java-1.8.0-openjdk* 检查是否安装成功输入 java -version javac 4.2 启动项目查询一下80端口是否已开放，开放了80端口后我们就可以启动我们的项目了，通过输入指令：Java -jar [jar包的完整文件名(.jar别忘了加)] 如下图所示。这样我们的项目就开始启动了 1java -jar WeChat-1.0-SNAPSHOT.jar","categories":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/categories/项目/"}],"tags":[{"name":"项目部署","slug":"项目部署","permalink":"http://tonymua.top/tags/项目部署/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://tonymua.top/tags/Spring-Boot/"},{"name":"微信公众号","slug":"微信公众号","permalink":"http://tonymua.top/tags/微信公众号/"}]},{"title":"微信公众号开发(二)自动回复功能实现简单的天气查询","slug":"微信公众号开发(二)自动回复功能实现简单的天气查询","date":"2021-05-08T13:19:59.221Z","updated":"2020-04-29T02:44:38.058Z","comments":true,"path":"39972/","link":"","permalink":"http://tonymua.top/39972/","excerpt":"1.前言微信公众平台服务器配置通过后，就能进行下面的开发啦 首先可以查看官方的说明文档：https://developers.weixin.qq.com/doc/offiaccount/Getting_Started/Overview.html 普通消息的类型分为7种：","text":"1.前言微信公众平台服务器配置通过后，就能进行下面的开发啦 首先可以查看官方的说明文档：https://developers.weixin.qq.com/doc/offiaccount/Getting_Started/Overview.html 普通消息的类型分为7种： 文本消息 图片消息 语音消息 视频消息 小视频消息 地理位置消息 链接消息 本文使用的是文本消息与图片消息 2.图文消息的自动回复2.1 文本消息文本消息的XML结构是： 12345678&lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[this is a test]]&gt;&lt;/Content&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 参数包含： 定义一个BaseMessage，消息基类，封装通用属性： 123456789101112131415161718192021/** * 消息基类（普通用户 -&gt; 公众帐号） * */@Datapublic class BaseMessage &#123; // 开发者微信号 private String ToUserName; // 发送方帐号（一个OpenID） private String FromUserName; // 消息创建时间 （整型） private String CreateTime; // 消息类型（text/image/location/link） private String MsgType; // 消息id，64位整型 private long MsgId; /** * 位0x0001被标志时，星标刚收到的消息 */ private int FuncFlag;&#125; 接下来定义文本消息属性TextMessage： 12345678/** * 文本消息 */@Datapublic class TextMessage extends BaseMessage&#123; // 消息内容 private String Content;&#125; 2.2 图片消息图片消息的XML结构是： 123456789&lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[image]]&gt;&lt;/MsgType&gt; &lt;PicUrl&gt;&lt;![CDATA[this is a url]]&gt;&lt;/PicUrl&gt; &lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 参数包含： 123@Datapublic class ImageMessage extends BaseMessage&#123;&#125; 2.3 图文消息1234567891011121314151617181920@Datapublic class Article &#123; /** * 图文消息描述 */ private String Description; /** * 图片链接，支持JPG、PNG格式，&lt;br&gt; * 较好的效果为大图640*320，小图80*80 */ private String PicUrl; /** * 图文消息名称 */ private String Title; /** * 点击图文消息跳转链接 */ private String Url;&#125; 123456789101112131415/** * &lt;p&gt; 图文消息 &lt;/p&gt; */@Setter@Getterpublic class NewsMessage extends BaseMessage&#123; /** * 图文消息个数，限制为10条以内 */ private Integer ArticleCount; /** * 多条图文消息信息，默认第一个item为大图 */ private List&lt;Article&gt; Articles;&#125; 3.功能实现3.1 工具类MessageUtil 解析微信发来的请求（xml） 将响应消息的Java对象转换成xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180public class MessageUtil &#123; /** * 返回消息类型：文本 */ public static final String RESP_MESSAGE_TYPE_TEXT = \"text\"; /** * 返回消息类型：音乐 */ public static final String RESP_MESSAGE_TYPE_MUSIC = \"music\"; /** * 返回消息类型：图文 */ public static final String RESP_MESSAGE_TYPE_NEWS = \"news\"; /** * 请求消息类型：文本 */ public static final String REQ_MESSAGE_TYPE_TEXT = \"text\"; /** * 请求消息类型：图片 */ public static final String REQ_MESSAGE_TYPE_IMAGE = \"image\"; /** * 请求消息类型：链接 */ public static final String REQ_MESSAGE_TYPE_LINK = \"link\"; /** * 请求消息类型：地理位置 */ public static final String REQ_MESSAGE_TYPE_LOCATION = \"location\"; /** * 请求消息类型：音频 */ public static final String REQ_MESSAGE_TYPE_VOICE = \"voice\"; /** * 请求消息类型：推送 */ public static final String REQ_MESSAGE_TYPE_EVENT = \"event\"; /** * 事件类型：subscribe(订阅) */ public static final String EVENT_TYPE_SUBSCRIBE = \"subscribe\"; /** * 事件类型：unsubscribe(取消订阅) */ public static final String EVENT_TYPE_UNSUBSCRIBE = \"unsubscribe\"; /** * 事件类型：CLICK(自定义菜单点击事件) */ public static final String EVENT_TYPE_CLICK = \"CLICK\"; /** * xml转换为map * @param request * @return * @throws IOException */ public static Map&lt;String, String&gt; xmlToMap(HttpServletRequest request) throws IOException &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); SAXReader reader = new SAXReader(); InputStream ins = null; try &#123; ins = request.getInputStream(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; Document doc = null; try &#123; doc = reader.read(ins); Element root = doc.getRootElement(); List&lt;Element&gt; list = root.elements(); for (Element e : list) &#123; map.put(e.getName(), e.getText()); &#125; return map; &#125; catch (DocumentException e1) &#123; e1.printStackTrace(); &#125;finally&#123; ins.close(); &#125; return null; &#125; /** * @Description: 解析微信发来的请求（XML） * @param @param request * @param @return * @param @throws Exception * @author dapengniao * @date 2016年3月7日 上午10:04:02 */ public static Map&lt;String, String&gt; parseXml(HttpServletRequest request) throws Exception &#123; // 将解析结果存储在HashMap中 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 从request中取得输入流 InputStream inputStream = request.getInputStream(); // 读取输入流 SAXReader reader = new SAXReader(); Document document = reader.read(inputStream); // 得到xml根元素 Element root = document.getRootElement(); // 得到根元素的所有子节点 List&lt;Element&gt; elementList = root.elements(); // 遍历所有子节点 for (Element e : elementList) &#123; map.put(e.getName(), e.getText()); &#125; // 释放资源 inputStream.close(); inputStream = null; return map; &#125;// public static XStream xstream = new XStream(); /** * 文本消息对象转换成xml * * @param textMessage 文本消息对象 * @return xml */ public static String textMessageToXml(TextMessage textMessage)&#123;// XStream xstream = new XStream(); xstream.alias(\"xml\", textMessage.getClass()); return xstream.toXML(textMessage); &#125; /** * @Description: 图文消息对象转换成xml * @param @param newsMessage * @param @return * @author dapengniao * @date 2016年3月8日 下午4:14:09 */ public static String newsMessageToXml(NewsMessage newsMessage) &#123; xstream.alias(\"xml\", newsMessage.getClass()); xstream.alias(\"item\", new Article().getClass()); return xstream.toXML(newsMessage); &#125; /** * @Description: 图片消息对象转换成xml * @param @param imageMessage * @param @return * @author dapengniao * @date 2016年3月9日 上午9:25:51 */ public static String imageMessageToXml(ImageMessage imageMessage) &#123; xstream.alias(\"xml\", imageMessage.getClass()); return xstream.toXML(imageMessage); &#125; /** * 对象到xml的处理 */ private static XStream xstream = new XStream(new XppDriver() &#123; public HierarchicalStreamWriter createWriter(Writer out) &#123; return new PrettyPrintWriter(out) &#123; // 对所有xml节点的转换都增加CDATA标记 boolean cdata = true; @SuppressWarnings(\"rawtypes\") public void startNode(String name, Class clazz) &#123; super.startNode(name, clazz); &#125; protected void writeText(QuickWriter writer, String text) &#123; if (cdata) &#123; writer.write(\"&lt;![CDATA[\"); writer.write(text); writer.write(\"]]&gt;\"); &#125; else &#123; writer.write(text); &#125; &#125; &#125;; &#125; &#125;);&#125; 3.2 实现当用户发送消息给公众号时（或某些特定的用户操作引发的事件推送时），会产生一个POST请求，开发者可以在响应包（Get）中返回特定XML结构，来对该消息进行响应（现支持回复文本、图片、图文、语音、视频、音乐）。 上一篇文章，已经创建了IndexController ，里面的GET方法用来验证token，下面直接加一个POST方法，用于进行消息管理。消息接收POST和微信认证GET是同一个接口（开发者填写的URL） Controller 12345678910111213141516171819202122@PostMappingpublic void msgProcess(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; try &#123; request.setCharacterEncoding(\"UTF-8\"); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; response.setCharacterEncoding(\"UTF-8\"); // 调用核心业务类接收消息、处理消息 String respMessage = msgService.processRequest(request); // 响应消息 PrintWriter out = null; try &#123; out = response.getWriter(); out.print(respMessage); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; out.close(); out = null; &#125;&#125; Service 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Servicepublic class MsgService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(MsgService.class); public String processRequest(HttpServletRequest request) &#123; String respMessage = null; System.out.println(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); try &#123; // xml请求解析 Map&lt;String, String&gt; requestMap = MessageUtil.xmlToMap(request); // 发送方帐号（open_id） String fromUserName = requestMap.get(\"FromUserName\"); // 公众帐号 String toUserName = requestMap.get(\"ToUserName\"); // 消息类型 String msgType = requestMap.get(\"MsgType\"); // 消息内容 String content = requestMap.get(\"Content\"); LOGGER.info(\"FromUserName is:\" + fromUserName + \", ToUserName is:\" + toUserName + \", MsgType is:\" + msgType); // 文本消息 if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_TEXT)) &#123; //这里根据关键字执行相应的逻辑，只有你想不到的，没有做不到的 if (content.indexOf(\"天气\")!=-1) &#123; //自动回复 NewsMessage newmsg = new NewsMessage(); newmsg.setToUserName(fromUserName); newmsg.setFromUserName(toUserName); newmsg.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); newmsg.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_NEWS); newmsg.setFuncFlag(0); List&lt;Article&gt; articleList = new ArrayList&lt;&gt;(); Article article = new Article(); article.setTitle(\"天气预报\"); article.setDescription(\"点击了解未来天气详情...\"); article.setPicUrl(\"https://lwy-image.oss-cn-beijing.aliyuncs.com/ep.png\"); article.setUrl(\"https://widget-page.heweather.net/h5/index.html?bg=1&amp;md=0123456&amp;lc=auto&amp;key=f1688db9422246fc969a6ba559075097\"); articleList.add(article); // 设置图文消息个数 newmsg.setArticleCount(articleList.size()); // 设置图文消息包含的图文集合 newmsg.setArticles(articleList); // 将图文消息对象转换成xml字符串 respMessage = MessageUtil.newsMessageToXml(newmsg); &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.error(\"error......\"); &#125; return respMessage; &#125;&#125; 测试 源码参考 https://github.com/zhouminpz/wechatPublicAccount-","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"微信公众号开发(三)快递信息查询","slug":"微信公众号开发(三)快递信息查询","date":"2021-05-08T13:19:59.220Z","updated":"2020-04-29T02:44:38.057Z","comments":true,"path":"12221/","link":"","permalink":"http://tonymua.top/12221/","excerpt":"1.快递查询API这里使用的是阿里云全国快递物流查询-快递查询接口:https://market.aliyun.com/products/56928004/cmapi021863.html 该接口支持只通过快递运单号查询物流信息, 不需要在额外设置参数. 该种方式95%能自动识别, 填写查询速度会更快, 已经满足一般开发的需求, 并能极大方便开发者的使用.","text":"1.快递查询API这里使用的是阿里云全国快递物流查询-快递查询接口:https://market.aliyun.com/products/56928004/cmapi021863.html 该接口支持只通过快递运单号查询物流信息, 不需要在额外设置参数. 该种方式95%能自动识别, 填写查询速度会更快, 已经满足一般开发的需求, 并能极大方便开发者的使用. 请求参数说明 返回结果说明 官方提供的示例代码: 1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) &#123; String host = \"https://wuliu.market.alicloudapi.com\"; String path = \"/kdi\"; String method = \"GET\"; System.out.println(\"请先替换成自己的AppCode\"); String appcode = \"833509fd73fe1124838xxxxxxxx\"; // !!!替换填写自己的AppCode 在买家中心查看 Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(); headers.put(\"Authorization\", \"APPCODE \" + appcode); //格式为:Authorization:APPCODE 83359fd73fe11248385f570e3c139xxx Map&lt;String, String&gt; querys = new HashMap&lt;String, String&gt;(); querys.put(\"no\", \"462587770684\");// !!! 请求参数 querys.put(\"type\", \"zto\");// !!! 请求参数 //JDK 1.8示例代码请在这里下载： http://code.fegine.com/Tools.zip try &#123; /** * 重要提示如下: * HttpUtils请从 * https://github.com/aliyun/api-gateway-demo-sign-java/blob/master/src/main/java/com/aliyun/api/gateway/demo/util/HttpUtils.java * 或者直接下载： * http://code.fegine.com/HttpUtils.zip * 下载 * * 相应的依赖请参照 * https://github.com/aliyun/api-gateway-demo-sign-java/blob/master/pom.xml * 相关jar包（非pom）直接下载： * http://code.fegine.com/aliyun-jar.zip */ HttpResponse response = HttpUtils.doGet(host, path, method, headers, querys); //System.out.println(response.toString());如不输出json, 请打开这行代码，打印调试头部状态码。 //状态码: 200 正常；400 URL无效；401 appCode错误； 403 次数用完； 500 API网管错误 //获取response的body System.out.println(EntityUtils.toString(response.getEntity())); //输出json &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 正常返回示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; \"status\": \"0\",/* status 0:正常查询 201:快递单号错误 203:快递公司不存在 204:快递公司识别失败 205:没有信息 207:该单号被限制，错误单号 */ \"msg\": \"ok\", \"result\": &#123; \"number\": \"780098068058\", \"type\": \"zto\", \"list\": [&#123; \"time\": \"2018-03-09 11:59:26\", \"status\": \"【石家庄市】快件已在【长安三部】 签收,签收人: 本人,感谢使用中通快递,期待再次为您服务!\" &#125;, &#123; \"time\": \"2018-03-09 09:03:10\", \"status\": \"【石家庄市】 快件已到达 【长安三部】（0311-85344265）,业务员 容晓光（13081105270） 正在第1次派件, 请保持电话畅通,并耐心等待\" &#125;, &#123; \"time\": \"2018-03-08 23:43:44\", \"status\": \"【石家庄市】 快件离开 【石家庄】 发往 【长安三部】\" &#125;, &#123; \"time\": \"2018-03-08 21:00:44\", \"status\": \"【石家庄市】 快件到达 【石家庄】\" &#125;, &#123; \"time\": \"2018-03-07 01:38:45\", \"status\": \"【广州市】 快件离开 【广州中心】 发往 【石家庄】\" &#125;, &#123; \"time\": \"2018-03-07 01:36:53\", \"status\": \"【广州市】 快件到达 【广州中心】\" &#125;, &#123; \"time\": \"2018-03-07 00:40:57\", \"status\": \"【广州市】 快件离开 【广州花都】 发往 【石家庄中转】\" &#125;, &#123; \"time\": \"2018-03-07 00:01:55\", \"status\": \"【广州市】 【广州花都】（020-37738523） 的 马溪 （18998345739） 已揽收\" &#125;], \"deliverystatus\": \"3\", /* 0：快递收件(揽件)1.在途中 2.正在派件 3.已签收 4.派送失败 5.疑难件 6.退件签收 */ \"issign\": \"1\", /* 1.是否签收 */ \"expName\": \"中通快递\", /* 快递公司名称 */ \"expSite\": \"www.zto.com\", /* 快递公司官网 */ \"expPhone\": \"95311\", /* 快递公司电话 */ \"courier\": \"容晓光\", /* 快递员 或 快递站(没有则为空)*/ \"courierPhone\":\"13081105270\", /* 快递员电话 (没有则为空) */ \"updateTime\":\"2019-08-27 13:56:19\", /* 快递轨迹信息最新时间 */ \"takeTime\":\"2天20小时14分\", /* 发货到收货消耗时长 (截止最新轨迹) */ \"logo\":\"http://img3.fegine.com/express/zto.jpg\" /* 快递公司LOGO */ &#125;&#125; 失败返回示例: 123456789&#123; \"status\": \"205\", /* status状态码见产品详情 */ \"msg\": \"没有信息\", \"result\": &#123; \"number\": \"1111ADECD1234\", \"type\": \"AUTO\", \"list\": [] &#125;&#125; 错误码定义: 错误码 错误信息 描述 201 快递单号错误 status：快递单号错误 203 快递公司不存在 status：快递公司不存在 204 快递公司识别失败 status：快递公司识别失败 205 没有信息 status：没有信息 207 该单号被限制，错误单号 status：该单号被限制，错误单号；一个单号对应多个快递公司，请求须指定快递公司 0 正常 status：正常查询 2.核心代码工具类: HttpUtils(官方提供) 下载地址 http://code.fegine.com/HttpUtils.zip TextUtil 用于判断输入发送的消息是否为英文字母+数字或纯数字(即符合快递运单号基本规则) 1234567public class TextUtil &#123; public static boolean DecText(String text)&#123; Pattern p=Pattern.compile(\"^[A-Za-z0-9]+$\"); //正则表达式 Matcher matcher = p.matcher(text); return matcher.matches(); &#125;&#125; ExpressUtil 调用API查询物流信息 1234567891011121314151617181920212223public class ExpressUtil &#123; public static String QueryExpress(String num) throws Exception &#123; String host = \"https://wuliu.market.alicloudapi.com\"; String path = \"/kdi\"; String method = \"GET\"; String appcode = \"06a9e928218141bxxxxxxx\"; // !!!替换填写自己的AppCode 在买家中心查看 Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(); headers.put(\"Authorization\", \"APPCODE \" + appcode); //格式为:Authorization:APPCODE 83359fd73fe11248385f570e3c139xxx Map&lt;String, String&gt; querys = new HashMap&lt;String, String&gt;(); querys.put(\"no\", num);// !!! 请求参数 HttpResponse response = HttpUtils.doGet(host, path, method, headers, querys); //System.out.println(response.toString()); //获取response的body String str = EntityUtils.toString(response.getEntity());//输出json JSONObject jsonObject = JSONObject.parseObject(str); // 获取到key为result的值 String result = jsonObject.getString(\"result\"); jsonObject = JSONObject.parseObject(result); // 获取到key为list的值 String list = jsonObject.getString(\"list\"); return list; &#125;&#125; 此时返回的数据为: 12345678910111213141516171819202122[&#123; \"time\": \"2020-02-29 19:45:12\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何海桃】\"&#125;, &#123; \"time\": \"2020-02-29 19:45:12\", \"status\": \"快件在【浙江嘉善公司】进行装车，扫描员【何海桃】，车签号【】\"&#125;, &#123; \"time\": \"2020-02-29 19:42:13\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何德文】\"&#125;, &#123; \"time\": \"2020-02-29 19:42:13\", \"status\": \"快件在【浙江嘉善公司】进行装包，扫描员【何德文】，袋号【9005261902881】\"&#125;, &#123; \"time\": \"2020-02-29 19:41:07\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何德文】\"&#125;, &#123; \"time\": \"2020-02-29 19:29:40\", \"status\": \"【浙江嘉善公司】的【公司称重（)】已收件，扫描员【公司出港1】\"&#125;, &#123; \"time\": \"2020-02-29 18:32:52\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何德文】\"&#125;] MsgService 1234567891011121314151617181920212223if (TextUtil.DecText(content)==true)&#123; String str = ExpressUtil.QueryExpress(content); List&lt;HashMap&gt; r = JSON.parseArray(str, HashMap.class); StringBuilder stringBuilder = new StringBuilder(); for (int i = r.size() - 1; i &gt;= 0; i--) &#123; System.out.println(r.get(i).get(\"time\") + \":\" + r.get(i).get(\"status\")); String string = r.get(i).get(\"time\") + \":\" + r.get(i).get(\"status\"); if (i == 0) &#123; stringBuilder.append(string); &#125; else &#123; stringBuilder.append(string).append(\"\\n\"); &#125; &#125; System.out.println(stringBuilder); //文本消息 TextMessage text = new TextMessage(); text.setContent(stringBuilder+\"\"); text.setToUserName(fromUserName); text.setFromUserName(toUserName); text.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); text.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_TEXT); respMessage = MessageUtil.textMessageToXml(text); &#125; 3.功能测试","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"微信公众号开发(一)开发者接入微信公众号","slug":"微信公众号开发(一)开发者接入微信公众号","date":"2021-05-08T13:19:59.218Z","updated":"2020-04-29T02:44:38.014Z","comments":true,"path":"38103/","link":"","permalink":"http://tonymua.top/38103/","excerpt":"微信公众号开发(一)开发者接入微信公众号1.前言该文章基于JDK1.8 springboot2.1.7.RELEASE环境 实现开发者第一次接入微信公众号后台的需求 2.准备工作2.1 进入微信公众平台注册账号 https://mp.weixin.qq.com/ 个人用户建议注册订阅号","text":"微信公众号开发(一)开发者接入微信公众号1.前言该文章基于JDK1.8 springboot2.1.7.RELEASE环境 实现开发者第一次接入微信公众号后台的需求 2.准备工作2.1 进入微信公众平台注册账号 https://mp.weixin.qq.com/ 个人用户建议注册订阅号 2.2 内网穿透因为要直接用内网本机开发调试，微信网页授权在回调时要访问本机，所以直接做个内网穿透，可以直接在外网访问到本机，做法如下： 登录 https://natapp.cn/ （我用的natapp.cn，你可以用其他类似的，个人感觉这个不错） 购买隧道：购买后使用方式: 参考官方教程：https://natapp.cn/article/natapp_newbie 使用后会得到natapp分配的网址，如 xxx.natapp.cn，这个地址就可以访问到开发本机。 下载并配置config.ini, 运行natapp 3.接入认证成为开发者 可参考微信官方开发文档 https://developers.weixin.qq.com/doc/offiaccount/Basic_Information/Access_Overview.html 3.1 填写服务器配置登录微信公众号开发平台:https://mp.weixin.qq.com/ 开发—开发者工具—公众平台测试账号 Tips: 微信公众号接口必须以http://或https://开头，分别支持80端口和443端口！ 这里的url可以选择自己买的服务器地址，记得必须开放80端口去使用！ 或者使用内网映射外网工具生成一个域名地址供给你开发使用，此方法自行百度，如下就是其中一种使用~ 目前提交是无法配置成功的, 不要着急 3.2 提交验证URL有效性3.2.1 搭建SpingBoot工程项目结构 pom.xml 123456789101112131415161718192021&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.binarywang&lt;/groupId&gt; &lt;artifactId&gt;weixin-java-mp&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yaml 123456wechat: mpAppId: xxxxxxxx #公众平台测试账号---测试号信息, 目前可以不填 mpAppSecret: xxxxxx #公众平台测试账号---测试号信息, 目前可以不填 mpToken: xxxxx #与前面在公众平台测试账号---接口配置信息所填写保持一致server: port: 80 #端口号 sha1加密工具类 1234567891011121314151617181920public class SecurityUtil &#123; public static String sha1(String str) &#123; try &#123; StringBuilder sb = new StringBuilder(); MessageDigest digest = MessageDigest.getInstance(\"sha1\"); // 放入加密字符串 digest.update(str.getBytes()); // 进行加密 byte[] digestMsg = digest.digest(); // byte转换16进制 for (byte b : digestMsg) &#123; sb.append(String.format(\"%02x\", b)); &#125; return sb.toString(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return str; &#125;&#125; 12345678@Data@Component@ConfigurationProperties(prefix = \"wechat\")public class WechatAccountConfig &#123; private String mpAppId; private String mpAppSecret; private String mpToken;&#125; Controller 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Slf4j@RestController@RequestMapping(\"/wechat/index\")public class IndexController &#123; @Autowired private WechatAccountConfig wechatAccountConfig; /** * 处理微信认证：验证服务器地址的有效性，get提交 * signature: 微信加密签名，signature结合了开发者填写的token参数和请求中的timestamp参数、nonce参数。 * timestamp 时间戳 * nonce: 随机数 * echostr: 随机字符串 */ @GetMapping public void checkSignature(HttpServletRequest request, HttpServletResponse response) throws IOException, IOException &#123; System.out.println(\"============= 处理微信认证 ===============\"); // 拿到微信的请求参数 String signature = request.getParameter(\"signature\"); String timestamp = request.getParameter(\"timestamp\"); String nonce = request.getParameter(\"nonce\"); String echostr = request.getParameter(\"echostr\"); // TODO 这里的token是微信公众平台上自己所配的！ String token = wechatAccountConfig.getMpToken(); // ① 将token、timestamp、nonce三个参数进行字典序排序 b a d c h ==&gt;a b c d h String[] strArr = &#123;token, timestamp, nonce&#125;; // 字典排序 Arrays.sort(strArr); // ② 将三个参数字符串拼接成一个字符串进行sha1加密 StringBuffer sb = new StringBuffer(); // 字符串拼接 for (String str : strArr) &#123; sb.append(str); &#125; // 加密 String sha1Str = SecurityUtil.sha1(sb.toString()); // ③ 开发者获得加密后的字符串可与signature对比，标识该请求来源于微信 if (sha1Str.equals(signature)) &#123; // 如果相等，就是来自微信请求 // 若确认此次GET请求来自微信服务器，原样返回echostr参数内容，则接入生效 response.getWriter().println(echostr); &#125; &#125;&#125; 启动类 123456@SpringBootApplicationpublic class WeChatService &#123; public static void main(String[] args) &#123; SpringApplication.run(WeChatService.class); &#125;&#125; 3.2.2 测试 启动该SpringBoot项目 回到公众平台测试账号—接口配置信息, 点击提交即可","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"常用设计模式","slug":"常用设计模式","date":"2021-05-08T13:19:59.217Z","updated":"2020-04-29T02:44:38.055Z","comments":true,"path":"14808/","link":"","permalink":"http://tonymua.top/14808/","excerpt":"Java 中一般认为有23种设计模式, 下面介绍几种常见的设计模式。总体来说设计模式分为三大类： 创建型模式, 共5五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共7种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。","text":"Java 中一般认为有23种设计模式, 下面介绍几种常见的设计模式。总体来说设计模式分为三大类： 创建型模式, 共5五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共7种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 1.单例模式所谓的单例设计指的是一个类只允许产生一个实例化对象。最好理解的一种设计模式，分为懒汉式和饿汉式。 饿汉式: 构造方法私有化，外部无法产生新的实例化对象，只能通过static方法取得实例化对象 123456789101112131415161718class Singleton &#123; /** * 在类的内部可以访问私有结构，所以可以在类的内部产生实例化对象 */ private static Singleton instance = new Singleton(); /** * private 声明构造 */ private Singleton() &#123; &#125; /** * 返回对象实例 */ public static Singleton getInstance() &#123; return instance; &#125;&#125; 懒汉式: 当第一次去使用Singleton对象的时候才会为其产生实例化对象的操作 123456789101112131415161718192021222324class Singleton &#123; /** * 声明变量 */ private static volatile Singleton singleton = null; /** * 私有构造方法 */ private Singleton() &#123; &#125; public static Singleton getInstance() &#123; // 还未实例化 if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; ​ 当多个线程并发执行 getInstance() 方法时，懒汉式会存在线程安全问题，所以用到了 synchronized 来实现线程的同步，当一个线程获得锁的时候其他线程就只能在外等待其执行完毕。而饿汉式则不存在线程安全的问题。 适用场景： 单例模式只允许创建一个对象，因此节省内存，加快对象访问速度，因此对象需要被公用的场合适合使用，如多个模块使用同一个数据源连接对象等等。如： (1) 需要频繁实例化然后销毁的对象。 (2) 创建对象时耗时过多或者耗资源过多，但又经常用到的对象。 (3) 有状态的工具类对象。 (4) 频繁访问数据库或文件的对象。以下都是单例模式的经典使用场景： (1) 资源共享的情况下，避免由于资源操作时导致的性能或损耗等。如上述中的日志文件，应用配置。 (2) 控制资源的情况下，方便资源之间的互相通信。如线程池等。 2.观察者模式一个对象(subject)被其他多个对象(observer)所依赖。则当一个对象变化时，发出通知，其它依赖该对象的对象都会收到通知，并且随着变化。 3.装饰者模式对已有的业务逻辑进一步的封装, 使其增加额外的功能, 要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例。 适用环境: ​ (1) 在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。 ​ (2) 处理那些可以撤消的职责。 ​ (3) 当不能采用生成子类的方法进行扩充时。一种情况是，可能有大量独立的扩展，为支持每一种组合将产生大量的 子类，使得子类数目呈爆炸性增长。另一种情况可能是因为类定义被隐藏，或类定义不能用于生成子类。 4.适配器模式适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 5.工厂模式5.1 简单工厂模式简单工厂模式就是把对类的创建初始化全都交给一个工厂来执行，而用户不需要去关心创建的过程是什么样的，只用告诉工厂我想要什么就行了。而这种方法的缺点也很明显，违背了设计模式的开闭原则，因为如果你要增加工厂可以初始化的类的时候，你必须对工厂进行改建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 抽象产品类abstract class Car &#123; public void run(); public void stop();&#125; // 具体实现类class Benz implements Car &#123; public void run() &#123; System.out.println(\"Benz开始启动了。。。。。\"); &#125; public void stop() &#123; System.out.println(\"Benz停车了。。。。。\"); &#125;&#125; class Ford implements Car &#123; public void run() &#123; System.out.println(\"Ford开始启动了。。。\"); &#125; public void stop() &#123; System.out.println(\"Ford停车了。。。。\"); &#125;&#125; // 工厂类class Factory &#123; public static Car getCarInstance(String type) &#123; Car c = null; if (\"Benz\".equals(type)) &#123; c = new Benz(); &#125; if (\"Ford\".equals(type)) &#123; c = new Ford(); &#125; return c; &#125;&#125; public class Test &#123; public static void main(String[] args) &#123; Car c = Factory.getCarInstance(\"Benz\"); if (c != null) &#123; c.run(); c.stop(); &#125; else &#123; System.out.println(\"造不了这种汽车。。。\"); &#125; &#125; 5.2 工厂方法模式设计一个工厂的接口，你想要什么东西，就写个类继承于这个工厂，这样就不用修改什么，直接添加就行了。就相当于，我这个工厂是用来生汽车的，而要什么品牌的汽车具体分到了每个车间，如果新多了一种品牌的汽车，直接新增一个车间就行了。那么问题又来了，如果想要生产大炮怎么办？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 抽象产品角色public interface Moveable &#123; void run();&#125; // 具体产品角色public class Plane implements Moveable &#123; @Override public void run() &#123; System.out.println(\"plane....\"); &#125;&#125; public class Broom implements Moveable &#123; @Override public void run() &#123; System.out.println(\"broom.....\"); &#125;&#125; // 抽象工厂public abstract class VehicleFactory &#123; abstract Moveable create();&#125; // 具体工厂public class PlaneFactory extends VehicleFactory &#123; public Moveable create() &#123; return new Plane(); &#125;&#125; public class BroomFactory extends VehicleFactory &#123; public Moveable create() &#123; return new Broom(); &#125;&#125; // 测试类public class Test &#123; public static void main(String[] args) &#123; VehicleFactory factory = new BroomFactory(); Moveable m = factory.create(); m.run(); &#125;&#125; 5.3 抽象工厂模式与工厂方法模式不同的是，工厂方法模式中的工厂只生产单一的产品，而抽象工厂模式中的工厂生产多个产品 123456789101112131415161718192021222324252627282930313233//抽象工厂类public abstract class AbstractFactory &#123; public abstract Vehicle createVehicle(); public abstract Weapon createWeapon(); public abstract Food createFood();&#125;//具体工厂类，其中Food,Vehicle，Weapon是抽象类，public class DefaultFactory extends AbstractFactory&#123; @Override public Food createFood() &#123; return new Apple(); &#125; @Override public Vehicle createVehicle() &#123; return new Car(); &#125; @Override public Weapon createWeapon() &#123; return new AK47(); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; AbstractFactory f = new DefaultFactory(); Vehicle v = f.createVehicle(); v.run(); Weapon w = f.createWeapon(); w.shoot(); Food a = f.createFood(); a.printName(); &#125;&#125;","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"}]},{"title":"四种常见的排序算法","slug":"四种常见的排序算法","date":"2021-05-08T13:19:59.192Z","updated":"2020-04-29T02:44:38.011Z","comments":true,"path":"23116/","link":"","permalink":"http://tonymua.top/23116/","excerpt":"1.冒泡排序思想: 每一趟将待排序序列中最大元素移到最后，剩下的为新的待排序序列, 重复上述步骤直到排完所有元素。这只是冒泡排序的一种, 当然也可以从后往前排 平均时间复杂度: O(n^2)","text":"1.冒泡排序思想: 每一趟将待排序序列中最大元素移到最后，剩下的为新的待排序序列, 重复上述步骤直到排完所有元素。这只是冒泡排序的一种, 当然也可以从后往前排 平均时间复杂度: O(n^2) 1234567891011121314151617181920public class Demo &#123; public void bubbleSort(int arr[]) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] arr=&#123;4, 8, 7, 5, 6, 3, 1&#125;; Demo d = new Demo(); d.selectSort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 2.选择排序思想: 每一趟从待排序序列选择一个最小的元素放在已排好序列的末尾, 剩下的为待排序序列, 重复上述步骤直至完成排序 平均时间复杂度: O(n^2) 123456789101112131415161718192021public void selectSort(int arr[]) &#123; //选择 for (int i = 0; i &lt; arr.length; i++) &#123; //默认第一个是最小的。 int min = arr[i]; //记录最小的下标 int index = i; //通过与后面的数据进行比较得出，最小值和下标 for (int j = i + 1; j &lt; arr.length; j++) &#123; if (min &gt; arr[j]) &#123; min = arr[j]; index = j; &#125; &#125; //然后将最小值与本次循环的，开始值交换 int temp = arr[i]; arr[i] = min; arr[index] = temp; //说明：将i前面的数据看成一个排好的队列，i后面的看成一个无序队列。每次只需要找无需的最小值，做替换 &#125;&#125; 3.插入排序思想: 1. 默认从第二个数据开始比较。 2.如果第二个数据比第一个小，则交换。然后在用第三个数据比较，如果比前面小，则插入（狡猾）。否则，退出循环 3.说明：默认将第一数据看成有序列表，后面无序的列表循环每一个数据，如果比前面的数据小则插入（交换）。否则退出 平均时间复杂度: O(n^2) 1234567891011121314151617public void insertSort(int arr[]) &#123; //插入排序 for (int i = 1; i &lt; arr.length; i++) &#123; //外层循环，从第二个开始比较 for (int j = i; j &gt; 0; j--) &#123; //内存循环，与前面排好序的数据比较，如果后面的数据小于前面的则交换 if (arr[j] &lt; arr[j - 1]) &#123; int temp = arr[j - 1]; arr[j - 1] = arr[j]; arr[j] = temp; &#125; else &#123; //如果不小于，说明插入完毕，退出内层循环 break; &#125; &#125; &#125;&#125; 4.快速排序采用分治法的思想：首先设置一个轴值pivot，然后以这个轴值为划分基准将待排序序列分成比pivot大和比pivot小的两部分，接下来对划分完的子序列进行快排直到子序列为一个元素为止。 平均时间复杂度: O(n*log(n)) 123456789101112131415161718192021222324252627282930public class Demo &#123; public void quickSort(int arr[], int low, int high) &#123; //pivot:位索引;p_pos:轴值 int pivot, p_pos, i, temp; if (low &lt; high) &#123; p_pos = low; pivot = arr[p_pos]; for (i = low + 1; i &lt;= high; i++) &#123; if (arr[i] &gt; pivot) &#123; p_pos++; temp = arr[p_pos]; arr[p_pos] = arr[i]; arr[i] = temp; &#125; &#125; temp = arr[low]; arr[low] = arr[p_pos]; arr[p_pos] = temp; //分而治之 quickSort(arr, low, p_pos - 1);//排序左半部分 quickSort(arr, p_pos + 1, high);//排序右半部分 &#125; &#125; public static void main(String[] args) &#123; int[] arr = &#123;4, 8, 7, 5, 6, 3, 1&#125;; Demo d = new Demo(); d.quickSort(arr, 0, arr.length - 1); System.out.println(Arrays.toString(arr)); &#125;&#125; 注: 各排序时间复杂度 排序方法 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n^2) O(n) O(n^2) O(1) 稳定 选择排序 O(n^2) O(n^2) O(n^2) O(1) 不稳定 插入排序 O(n^2) O(n) O(n^2) O(1) 稳定 希尔排序O(n*log(n))~O(n^2) O(n^1.3) O(n^2) O(1) 不稳定 堆排序 O(nlog(n)) O(nlog(n)) O(n*log(n)) O(1) 不稳定 归并排序 O(nlog(n)) O(nlog(n)) O(n*log(n)) O(n) 稳定 快速排序 O(nlog(n)) O(nlog(n)) O(n^2) O(1) 不稳定","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"初始ElasticSearch集群","slug":"初始ElasticSearch集群","date":"2021-05-08T13:19:59.191Z","updated":"2020-04-29T02:44:38.009Z","comments":true,"path":"31824/","link":"","permalink":"http://tonymua.top/31824/","excerpt":"1.集群管理1.1 集群结构ES通常以集群方式工作，这样做不仅能够提高ES的搜索能力还可以处理大数据搜索的能力，同时也增加了系统的 容错能力及高可用，ES可以实现PB级数据的搜索。","text":"1.集群管理1.1 集群结构ES通常以集群方式工作，这样做不仅能够提高ES的搜索能力还可以处理大数据搜索的能力，同时也增加了系统的 容错能力及高可用，ES可以实现PB级数据的搜索。 下图是ES集群结构的示意图： 从上图总结以下概念： 结点 ES集群由多个服务器组成，每个服务器即为一个Node结点(该服务只部署了一个ES进程)。 分片 当我们的文档量很大时，由于内存和硬盘的限制，同时也为了提高ES的处理能力、容错能力及高可用能力，我们将索引分成若干分片，每个分片可以放在不同的服务器，这样就实现了多个服务器共同对外提供索引及搜索服务。一个搜索请求过来，会分别从各各分片去查询，后将查询到的数据合并返回给用户。 副本 为了提高ES的高可用同时也为了提高搜索的吞吐量，我们将分片复制一份或多份存储在其它的服务器，这样即使当前的服务器挂掉了，拥有副本的服务器照常可以提供服务。 主结点 一个集群中会有一个或多个主结点，主结点的作用是集群管理，比如增加节点，移除节点等，主结点挂掉后ES会重新选一个主结点。 结点转发 每个结点都知道其它结点的信息，我们可以对任意一个结点发起请求，接收请求的结点会转发给其它结点查询数据。 1.2 搭建集群下边的例子实现创建一个2结点的集群，并且索引的分片我们设置2片，每片一个副本。 1.2.1 结点的三个角色主结点：master节点主要用于集群的管理及索引比如新增结点、分片分配、索引的新增和删除等。数据结点： data 节点上保存了数据分片，它负责索引和搜索操作。客户端结点：client 节点仅作为请求客户端存在，client的作用也作为负载均衡器，client 节点不存数据，只是将请求均衡转发到其它结点。 通过下边两项参数来配置结点的功能：node.master: #是否允许为主结点node.data: #允许存储数据作为数据结点node.ingest: #是否允许成为协调节点四种组合方式：master=true，data=true：即是主结点又是数据结点master=false，data=true：仅是数据结点master=true，data=false：仅是主结点，不存储数据master=false，data=false：即不是主结点也不是数据结点，此时可设置ingest为true表示它是一个客户端。 1.2.2 创建结点 1解压elasticsearch-6.2.1.zip 到 F:\\devenv\\elasticsearch\\es-cloud-1\\elasticsearch-6.2.1结点1对外服务的http端口是：9200集群管理端口是9300配置elasticsearch.yml 结点名：xc_node_1elasticsearch.yml内容如下 12345678910111213cluster.name: xuecheng node.name: xc_node_1 network.host: 0.0.0.0 http.port: 9200 transport.tcp.port: 9300 node.master: true node.data: true discovery.zen.ping.unicast.hosts: [\"0.0.0.0:9300\", \"0.0.0.0:9301\"] discovery.zen.minimum_master_nodes: 1 node.ingest: true node.max_local_storage_nodes: 2 path.data: D:\\ElasticSearch\\elasticsearch‐6.2.1‐1\\data path.logs: D:\\ElasticSearch\\elasticsearch‐6.2.1‐1\\logs http.cors.enabled: true http.cors.allow‐origin: /.*/ 启动结点1 1.2.3 创建结点 2解压elasticsearch-6.2.1.zip 到 F:\\devenv\\elasticsearch\\es-cloud-2\\elasticsearch-6.2.1结点2对外服务的http端口是：9201集群管理端口是9302结点名：xc_node_2elasticsearch.yml内容如下 12345678910111213cluster.name: xuecheng node.name: xc_node_2 network.host: 0.0.0.0 http.port: 9201 transport.tcp.port: 9301 node.master: true node.data: true discovery.zen.ping.unicast.hosts: [\"0.0.0.0:9300\", \"0.0.0.0:9301\"] discovery.zen.minimum_master_nodes: 1 node.ingest: true node.max_local_storage_nodes: 2 path.data: D:\\ElasticSearch\\elasticsearch‐6.2.1‐2\\data path.logs: D:\\ElasticSearch\\elasticsearch‐6.2.1‐2\\logs http.cors.enabled: true http.cors.allow‐origin: /.*/ 启动结点2 1.2.4 创建索引库 使用head连上其中一个结点 下边创建索引库，共2个分片，每个分片一个副本。 上图可以看到共有4个分片，其中两个分片是副本。 每个结点安装IK分词器 1.2.5 集群的健康通过访问 GET /_cluster/health 来查看Elasticsearch的集群健康情况。用三种颜色来展示健康状态： green 、 yellow 或者 red 。 green：所有的主分片和副本分片都正常运行。yellow：所有的主分片都正常运行，但有些副本分片运行不正常。red：存在主分片运行不正常。 Get请求：http://localhost:9200/_cluster/health 1.3 测试 创建映射并写入文档连接其中任意一台结点，创建映射写入文档。Post http://localhost:9200/xc_course/doc/3 12345&#123; \"name\": \"spring开发基础\", \"description\": \"spring 在java领域非常流行，java软件开发人员都在用。\", \"studymodel\": \"201001\", \"price\":66.6 &#125; 搜索向其它一个结点发起搜索请求，查询全部数据。 关闭一个结点ES会重新选中一个主结点（前提在配置结点时允许它可以为主结点）此时向活的结点发起搜索请求，仍然正常。 添加一个结点添加结点3，端口设置为： http端口是：9202 集群管理端口是9302 结点名：xc_node_3此结点的配置：node.master: false node.data: true启动结点3，刷新head，下图显示ES将分片分在了3个结点向结点3发起搜索请求： Get： http://127.0.0.1:9202/xc_course/doc/_search 全部数据可被正常搜索到。","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"分布式文件系统 FastDFS研究","slug":"分布式文件系统-FastDFS研究","date":"2021-05-08T13:19:59.190Z","updated":"2020-04-29T02:44:38.051Z","comments":true,"path":"22469/","link":"","permalink":"http://tonymua.top/22469/","excerpt":"1.什么是分布式文件系统1.1 技术应用场景分布式文件系统解决了海量文件存储及传输访问的瓶颈问题，对海量视频的管理、对海量图片的管理等。 1.2 什么是分布式文件系统引用“百度百科”中的描述：","text":"1.什么是分布式文件系统1.1 技术应用场景分布式文件系统解决了海量文件存储及传输访问的瓶颈问题，对海量视频的管理、对海量图片的管理等。 1.2 什么是分布式文件系统引用“百度百科”中的描述： 为什么会有分布文件系统呢？ 分布式文件系统是面对互联网的需求而产生，互联网时代对海量数据如何存储？靠简单的增加硬盘的个数已经满足不了我们的要求，因为硬盘传输速度有限但是数据在急剧增长，另外我们还要要做好数据备份、数据安全等。 采用分布式文件系统可以将多个地点的文件系统通过网络连接起来，组成一个文件系统网络，结点之间通过网络进 行通信，一台文件系统的存储和传输能力有限，我们让文件在多台计算机上存储，通过多台计算机共同传输。如下 图： 好处: 一台计算机的文件系统处理能力扩充到多台计算机同时处理 一台计算机挂了还有另外副本计算机提供数据 每台计算机可以放在不同的地域，这样用户就可以就近访问，提高访问速度 1.3 主流的分布式文件系统(1) NFS ​ NFS是基于UDP/IP协议的应用，其实现主要是采用远程过程调用RPC机制，RPC提供了一组与机器、操作系统以及低层传送协议无关的存取远程文件的操作。RPC采用了XDR的支持。XDR是一种与机器无关的数据描述编码的协议，他以独立与任意机器体系结构的格式对网上传送的数据进行编码和解码，支持在异构系统之间数据的传送。 1）在客户端上映射NFS服务器的驱动器。2）客户端通过网络访问NFS服务器的硬盘完全透明。 (2) GFS ​ GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，并提供容错功能。它可以给大量的用户提供总体性能较高的服务。 1）GFS采用主从结构，一个GFS集群由一个master和大量的chunkserver组成。2）master存储了数据文件的元数据，一个文件被分成了若干块存储在多个chunkserver中。 3）用户从master中获取数据元信息，从chunkserver存储数据。 (3) HDFS 1）HDFS采用主从结构，一个HDFS集群由一个名称结点和若干数据结点组成 名称结点存储数据的元信息，一个完整的数据文件分成若干块存储在数据结点。2）客户端从名称结点获取数据的元信息及数据分块的信息，得到信息客户端即可从数据块来存取数据。 1.4 分布式文件服务提供商1）阿里的OSS2）七牛云存储3）百度云存储 2.什么是FastDFS2.1 FastDSF介绍FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联 网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很 容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 为什么要使用fastDFS呢？ 上边介绍的NFS、GFS都是通用的分布式文件系统，通用的分布式文件系统的优点的是开发体验好，但是系统复杂性高、性能一般，而专用的分布式文件系统虽然开发体验性差，但是系统复杂性低并且性能高。FastDFS非常适合存储图片等那些小文件，FastDFS不对文件进行分块，所以它就没有分块合并的开销，FastDFS网络通信采用 socket，通信速度很快。 2.2 FastDSF工作原理2.2.1 FastDSF架构FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Tracker server调度最终由Storage server完成文件上传和下载。 如下图： 1）TrackerTracker Server作用是负载均衡和调度，通过Tracker server在文件上传时可以根据一些策略找到Storage server提 供文件上传服务。可以将tracker称为追踪服务器或调度服务器。 FastDFS集群中的Tracker server可以有多台，Tracker server之间是相互平等关系同时提供服务，Tracker server 不存在单点故障。客户端请求Tracker server采用轮询方式，如果请求的tracker无法提供服务则换另一个tracker。 2）StorageStorage Server作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storage server没有实现自己 的文件系统而是使用操作系统的文件系统来管理文件。可以将storage称为存储服务器。 Storage集群采用了分组存储方式。storage集群由一个或多个组构成，集群存储总容量为集群中所有组的存储容 量之和。一个组由一台或多台存储服务器组成，组内的Storage server之间是平等关系，不同组的Storage server 之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步，从而保证同组内每个storage上的文件完全一致的。一个组的存储容量为该组内的存储服务器容量最小的那个，由此可见组内存储服务器的软硬件配置最好是一致的。 采用分组存储方式的好处是灵活、可控性较强。比如上传文件时，可以由客户端直接指定上传到的组也可以由 tracker进行调度选择。一个分组的存储服务器访问压力较大时，可以在该组增加存储服务器来扩充服务能力（纵向扩容）。当系统容量不足时，可以增加组来扩充存储容量（横向扩容）。 3）Storage状态收集 Storage server会连接集群中所有的Tracker server，定时向他们报告自己的状态，包括磁盘剩余空间、文件同步 状况、文件上传下载次数等统计信息。 2.2.2 文件上传流程客户端上传文件后存储服务器将文件ID返回给客户端，此文件ID用于以后访问该文件的索引信息。文件索引信息 包括：组名，虚拟磁盘路径，数据两级目录，文件名。 http://192.168.179.101/group1/M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png 组名：文件上传后所在的storage组名称，在文件上传成功后有storage服务器返回，需要客户端自行保存。 虚拟磁盘路径：storage配置的虚拟路径，与磁盘选项store_path*对应。如果配置了store_path0则是M00， 如果配置了store_path1则是M01，以此类推。 数据两级目录：storage服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件。 文件名：与文件上传时不同。是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创 建时间戳、文件大小、随机数和文件拓展名等信息。 2.2.3 文件下载流程tracker根据请求的文件路径即文件ID 来快速定义文件。比如请求下边的文件： http://192.168.179.101/group1/M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png (1) 通过组名tracker能够很快的定位到客户端需要访问的存储服务器组是group1，并选择合适的存储服务器提供客户端访问。(2) 存储服务器根据“文件存储虚拟磁盘路径”和“数据文件两级目录”可以很快定位到文件所在目录，并根据文件名找到客户端需要访问的文件。 3.fastDFS入门3.1 文件上传下载测试3.1.1 搭建环境这里我们使用javaApi测试文件的上传，java版本的fastdfs-client地址在： https://github.com/happyﬁsh100/fastdfs-client-java，参考此工程编写测试用例。 1）创建maven工程 1234567891011121314151617181920212223242526272829&lt;parent&gt; &lt;artifactId&gt;xc-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../xc-framework-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;test-fastdfs&lt;/artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2) 配置文件 在classpath:conﬁg下创建fastdfs-client.properties文件 1234fastdfs.connect_timeout_in_seconds = 5fastdfs.network_timeout_in_seconds = 30fastdfs.charset = UTF-8fastdfs.tracker_servers = 192.168.179.101:22122 3.1.2 文件上传1234567891011121314151617181920212223242526272829//上传文件@Testpublic void testUpload() &#123; try &#123; ClientGlobal.initByProperties(\"config/fastdfs-client.properties\"); System.out.println(\"network_timeout=\"+ClientGlobal.g_network_timeout+\"ms\"); System.out.println(\"charset=\"+ClientGlobal.g_charset); //创建客户端 TrackerClient trackerClient=new TrackerClient(); //连接tracker Server TrackerServer trackerServer = trackerClient.getConnection(); if (trackerServer==null)&#123; System.out.println(\"getConnection return null\"); &#125; //获取一个storage server StorageServer storageServer = trackerClient.getStoreStorage(trackerServer); if (storageServer==null)&#123; System.out.println(\"getStoreStorage return null\"); &#125; //创建一个storage存储客户端 StorageClient1 storageClient1=new StorageClient1(trackerServer,storageServer); NameValuePair[] meta_list=null; //new NameValuePair[0]; String item=\"E:\\\\test.png\"; String fileid=(storageClient1.upload_file1(item,\"png\",meta_list)); System.out.println(\"Upload local file\"+item+\"ok,fileid=\"+fileid); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 3.1.3 文件查询123456789101112131415//查询文件@Testpublic void testQueryFile()&#123; try &#123; ClientGlobal.initByProperties(\"config/fastdfs-client.properties\"); TrackerClient trackerClient=new TrackerClient(); TrackerServer trackerServer=trackerClient.getConnection(); StorageServer storageServer=null; StorageClient storageClient=new StorageClient(trackerServer,storageServer); FileInfo fileInfo = storageClient.query_file_info(\"group1\", \"M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png\"); System.out.println(fileInfo); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 3.1.4 文件下载123456789101112131415161718//下载文件@Testpublic void testDownload() &#123; try &#123; ClientGlobal.initByProperties(\"config/fastdfs-client.properties\"); TrackerClient trackerClient=new TrackerClient(); TrackerServer trackerServer = trackerClient.getConnection(); StorageServer storageServer=null; StorageClient1 storageClient1=new StorageClient1(trackerServer,storageServer); byte[] result = storageClient1.download_file1(\"M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png\"); File file=new File(\"E:/1.png\"); FileOutputStream fileOutputStream=new FileOutputStream(file); fileOutputStream.write(result); fileOutputStream.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"使用tree命令导出文件夹/文件的目录树","slug":"使用tree命令导出文件夹或文件的目录树","date":"2021-05-08T13:19:59.188Z","updated":"2020-05-01T13:37:12.901Z","comments":true,"path":"shell_tree/","link":"","permalink":"http://tonymua.top/shell_tree/","excerpt":"Windows和Linux都有tree命令，主要功能是创建文件列表，将所有文件以树的形式列出来 1.Windows的tree命令使用tree命令导出windows的文件夹/文件的目录树","text":"Windows和Linux都有tree命令，主要功能是创建文件列表，将所有文件以树的形式列出来 1.Windows的tree命令使用tree命令导出windows的文件夹/文件的目录树 1234TREE [drive:][path] [/F] [/A]/F 显示每个文件夹中文件的名称。（带扩展名）/A 使用 ASCII 字符，而不使用扩展字符。(如果要显示中文，例如 tree /f /A &gt;tree.txt)tree /f &gt; list.txt 将带扩展名的文件目录输出到list.txt文件中 2.Linux的tree命令Linux下的tree就比较强大了，但一般系统并不自带这个命令，需要手动下载安装：sudo apt-get install tree 。 1234567891011121314151617181920-a 显示所有文件和目录。-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。-C 在文件和目录清单加上色彩，便于区分各种类型。-d 显示目录名称而非内容。-D 列出文件或目录的更改时间。-f 在每个文件或目录之前，显示完整的相对路径名称。-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上\"*\",\"/\",\"=\",\"@\",\"|\"号。-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。-i 不以阶梯状列出文件或目录名称。-I 不显示符合范本样式的文件或目录名称。-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。-n 不在文件和目录清单加上色彩。-N 直接列出文件和目录名称，包括控制字符。-p 列出权限标示。-P 只显示符合范本样式的文件或目录名称。-q 用\"?\"号取代控制字符，列出文件和目录名称。-s 列出文件或目录大小。-t 用文件和目录的更改时间排序。-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。 3.测试执行命令行tree /f &gt; tree.txt","categories":[{"name":"shell","slug":"shell","permalink":"http://tonymua.top/categories/shell/"}],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Vue开发常用命令","slug":"Vue开发常用命令","date":"2021-05-08T13:19:59.186Z","updated":"2020-05-28T06:27:34.810Z","comments":true,"path":"Vue_shell/","link":"","permalink":"http://tonymua.top/Vue_shell/","excerpt":"1.创建vue脚手架项目 1vue init webpack 项目名 2.axios 安装axios 1npm install axios --save-dev 配置main.js中引入axios","text":"1.创建vue脚手架项目 1vue init webpack 项目名 2.axios 安装axios 1npm install axios --save-dev 配置main.js中引入axios 123import axios from 'axios';Vue.prototype.$http=axios; 使用axios在需要发送异步请求的位置:123456this.$http.get( \"url\" ) .then(res =&gt; &#123; &#125;); 3.ElementUI 安装ElementUI 1npm i element-ui -S 配置main.js中引入ElementUI 12345import ElementUI from 'element-ui';import 'element-ui/lib/theme-chalk/index.css';//在vue脚手架中使用elementuiVue.use(ElementUI) 4.项目打包 打包在项目根目录中执行如下命令: 1npm run build 注意:vue脚手架打包的项目必须在服务器上运行不能直接双击运行 打包之后当前项目中变化在打包之后项目中出现dist目录,dist目录就是vue脚手架项目生产目录或者说是直接部署目录 与后端合并部署复制dist目录到Java工程resource下的static文件夹,index.html中修改路径 1234&lt;link href=/dist/static/css/app...../&gt;...&lt;script type=text/javascript src=/dist/static/js/ma....&gt;&lt;/script&gt;... 访问项目浏览器访问: http://localhost:8080/dist/index.html","categories":[{"name":"前端","slug":"前端","permalink":"http://tonymua.top/categories/前端/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://tonymua.top/tags/Vue/"}]},{"title":"top K问题的优化解法","slug":"top-K问题的优化解法","date":"2021-05-08T13:19:59.185Z","updated":"2020-04-29T02:44:38.006Z","comments":true,"path":"1060/","link":"","permalink":"http://tonymua.top/1060/","excerpt":"top K问题的优化解法​ 在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。","text":"top K问题的优化解法​ 在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。 100亿数据找出最大的1000个数字 对于海量数据处理，思路基本上是：必须分块处理，然后再合并起来。 1.局部淘汰法​ 用一个容器保存前1000个数，然后将剩余的所有数字一一与容器内的最小数字相比，如果所有后续的元素都比容器内的1000个数还小，那么容器内这个1000个数就是最大1000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O(n+m^2)，其中m为容器的大小。 ​ 这个容器可以用（小顶堆）最小堆来实现。我们知道完全二叉树有几个非常重要的特性，就是假如该二叉树中总共有N个节点，那么该二叉树的深度就是log2N，对于小顶堆来说移动根元素到底部或者移动底部元素到根部只需要log2N，相比N来说时间复杂度优化太多了（1亿的logN值是26-27的一个浮点数）。基本的思路就是先从文件中取出1000个元素构建一个小顶堆数组k，然后依次对剩下的100亿-1000个数字进行遍历m，如果m大于小顶堆的根元素，即k[0]，那么用m取代k[0]，对新的数组进行重新构建组成一个新的小顶堆。这个算法的时间复杂度是O((100亿-1000)log(1000))，即O((N-M)logM)，空间复杂度是M 这个算法优点是性能尚可，空间复杂度低，IO读取比较频繁，对系统压力大。 2.分治法(1) 将100亿个数据分为1000个大分区，每个区1000万个数据 (2) 每个大分区再细分成100个小分区。总共就有1000*100=10万个分区 (3) 计算每个小分区上最大的1000个数 (4) 合并每个大分区细分出来的小分区。每个大分区有100个小分区，我们已经找出了每个小分区的前1000个数。将这100个分区的1000*100个数合并，找出每个大分区的前1000个数 (5) 合并大分区。我们有1000个大分区，上一步已找出每个大分区的前1000个数。我们将这1000*1000个数合并，找出前1000.这1000个数就是所有数据中最大的1000个数 3.Hash法​ 如果这1亿个数据里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的1000个数。","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"http://tonymua.top/tags/算法/"}]},{"title":"SVN, AdminLTE","slug":"SVN, AdminLTE","date":"2021-05-08T13:19:59.184Z","updated":"2020-04-29T06:03:28.172Z","comments":true,"path":"36764/","link":"","permalink":"http://tonymua.top/36764/","excerpt":"1.SVN介绍​ SVN是Subversion的简称，是一个自由开源的版本控制系统。 Subversion将文件存放在中心版本库里，这个版本库很像一个普通的文件服务器，不同的是，它可以记录每一次文 件和目录的修改情况，这样就可以借此将数据恢复到以前的版本，并可以查看数据的更改细节早期版本控制使用的是CVS,后来SVN替代了CVS,随着android兴起，出现Git版本控制工具 1.1 SVN基本概念","text":"1.SVN介绍​ SVN是Subversion的简称，是一个自由开源的版本控制系统。 Subversion将文件存放在中心版本库里，这个版本库很像一个普通的文件服务器，不同的是，它可以记录每一次文 件和目录的修改情况，这样就可以借此将数据恢复到以前的版本，并可以查看数据的更改细节早期版本控制使用的是CVS,后来SVN替代了CVS,随着android兴起，出现Git版本控制工具 1.1 SVN基本概念 问题: 怎样让系统允许用户共享信息，而不会让他们因意外而互相干扰？ 复制-修改-合并方案(Subversion默认的模式) ​ 在这种模型里，每一个客户读取项目配置库建立一个私有工作副本——版本库中文件和目录的本地映射。用户并行工作，修改各自的工作副本，终，各个私有的复制合并在一起，成为终的版本，这种系统通常可以辅助合并操 作，但是终要靠人工去确定正误。 *锁定-修改-解锁方案 * 在这样的模型里，在一个时间段里配置库的一个文件只允许被一个人修改。 此模式不适合软件开发这种工作。 2.IDEA下SVN使用​ SVN是一种集中式管理代码的版本控制系统，原理就是把代码都保存到一个固定的位置（仓库），每次从这个位置 拷贝更新代码，进行编辑；再把修改后的代码提交到该目录中。多人协作开发也是如此。因此需要一个类似Oracle 或者Mysql的服务器用于保存和管理库文件（要保存的代码等文件）的服务端——VisualSVN Server。还需要一个 用户的操作端，用于提交更新检出代码，常用的有idea的Svn插件，以及TortoiseSVN（小乌龟）。SubVersion 官网：http://subversion.apache.org/ 2.1 IDEA下svn配置前提是我们的电脑上已经安装了TortoiseSVN. 1.Update Project 更新项目 2.Commit changes 提交项目上所有变化文件 3.Compare with the Same Repository Version 当前文件与服务器上该文件通版本的内容进行比较。如果当前编辑 的文件没有修改，则是灰色不可点击。 4.Show history 显示当前文件的历史记录 5.Revert 还原当前被修改的文件到违背修改的版本状态下 1.Local Changes 本地修改过的文件都会出现在这里 2.Repository svn仓库所有提交记录 3.Incoming 本地还没有更新的别人提交的代码 2.2 IDEA下SVN使用2.2.1 share project 2.2.2 checkout 2.2.3 add commit update 2.2.4 ignor 2.2.5 解决冲突3.SVN规范3.1 SVN目录规范在visualSVN中创建仓库时，可以选择svn目录结构 ​ Trunk 主干目录，此目录下的文件为基准文件 ​ Branches 用于开发的分支目录 Tags 用于发布的版本目录 ​ 假设有一个项目OA,我们完成了1.0版本，这时就可以打一个tags 后续我们在OA项目上添加一个新的模块(及时通讯),我们就可以开一个分支,又有一个公司需要在我们OA基础上添加 财务管理模块，我们又可以打一个分支.我们后续针对OA的1.0版本在升级，我们不需要原来附加功能,就可以在原来的主干上继续开发，形成OA2.0版本， 开发完成后就可以在打一个tags 3.2 分支与标记分支的定义规则: Project name+日期时间+功能点 Tags的定义规则 Project name+版本号 版本号定义为三段数字 编号 xxx.xxx.xxx 第一个:革命性的产品升级版 第二个:新功能版 第三个:修正bug Tags一般是只读，它代表的是发布的版本，所以我们不要进行改变。 3.3 主干与分支或标记的合并主干合并到分支 首先保证主干是新的(先update)，在分支这边进行操作 4.AdminLTE快速入门​ AdminLTE是一款建立在bootstrap和jquery之上的开源的模板主题工具，它提供了一系列响应的、 可重复使用的组件，并内置了多个模板页面；同时自适应多种屏幕分辨率，兼容PC和移动端。通 过AdminLTE，我们可以快速的创建一个响应式的Html5网站。AdminLTE框架在网页架构与设计 上，有很大的辅助作用，尤其是前端架构设计师，用好AdminLTE 不但美观，而且可以免去写很大 CSS与JS的工作量。 ​ 结构介绍 bower_components：存放了这个框架依赖的其他框架，如bootstrap，jquery、字体样式、图标样式等。 build： 编译前的源文件目录 dist：编译后的静态资源目录 pages：目录下是一些示例页面 plugins：目录存放依赖的插件 starter.html ：是 AdminLTE 建议用来作为起点的参考示例 index.html：是AdminLTE中比较完善的展示品，用于参考、借鉴。","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"SSM框架整合","slug":"SSM框架整合","date":"2021-05-08T13:19:59.182Z","updated":"2020-04-29T02:44:38.034Z","comments":true,"path":"10555/","link":"","permalink":"http://tonymua.top/10555/","excerpt":"1.SSM 整合1.1 环境准备1.1.1 导入坐标并建立依赖","text":"1.SSM 整合1.1 环境准备1.1.1 导入坐标并建立依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.9&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.9&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.1.2编写实体类1234567891011121314151617181920212223242526272829303132333435363738public class Account implements Serializable &#123; private Integer id; private String name; private Double money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; 1.1.3 编写业务层接口12345678public interface AccountService &#123; //查询所有账户 public List&lt;Account&gt; findAll(); //保存账户信息 public void saveAccount(Account account);&#125; 1.2 整合步骤springmvc.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--开启注解扫描，只扫描Controller注解--&gt; &lt;context:component-scan base-package=\"controller\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--配置视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"internalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--过滤静态资源--&gt; &lt;mvc:resources location=\"/css/\" mapping=\"/css/**\" /&gt; &lt;mvc:resources location=\"/images/\" mapping=\"/images/**\" /&gt; &lt;mvc:resources location=\"/js/\" mapping=\"/js/**\" /&gt; &lt;!--开启SpringMVC注解的支持--&gt; &lt;mvc:annotation-driven/&gt;&lt;/beans&gt; web.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--配置前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--加载springmvc.xml文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--启动服务器,创建该servlet--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--解决中文乱码的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!--设定编码集--&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置Spring的监听器,默认只加载WEB-INF目录下的applicationContext.xml配置文件--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--设置配置文件的路径--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; applicationContext.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--开启注解的扫描，希望处理service和dao，controller不需要Spring框架去处理--&gt; &lt;context:component-scan base-package=\"dao,service\"&gt; &lt;!--配置哪些注解不扫描--&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--spring整合MyBatis框架--&gt; &lt;!--配置连接池--&gt; &lt;bean class=\"com.mchange.v2.c3p0.ComboPooledDataSource\" id=\"dataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///ssm\"/&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"547717253\"/&gt; &lt;/bean&gt; &lt;!--配置SqlSessionFactory工厂--&gt; &lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置AccountDao接口所在的包--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\" id=\"mapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"dao\"/&gt; &lt;/bean&gt; &lt;!--配置Spring框架声明式事务管理--&gt; &lt;!--配置事务管理器--&gt; &lt;bean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务通知--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" isolation=\"DEFAULT\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置AOP增强--&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(* service.impl.*ServiceImpl.*(..))\"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; AccountDao 123456789101112@Repositorypublic interface AccountDao &#123; //查询所有账户 @Select(\"select * from account\") public List&lt;Account&gt; findAll(); //保存账户信息 @Insert(\"insert into account(name,money) values(#&#123;name&#125;,#&#123;money&#125;)\") public void saveAccount(Account account);&#125; AccountServiceImpl 1234567891011121314151617@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public List&lt;Account&gt; findAll() &#123; System.out.println(\"业务层:查询所有账户...\"); return accountDao.findAll(); &#125; @Override public void saveAccount(Account account) &#123; System.out.println(\"业务层:保存账户...\"); accountDao.saveAccount(account); &#125;&#125; AccountController 12345678910111213141516171819202122@Controller@RequestMapping(\"/account\")public class AccountController &#123; @Autowired private AccountService accountService; @RequestMapping(\"/findAll\") public String findAll(Model model)&#123; System.out.println(\"表现层:查询所有账户...\"); //调用service的方法 List&lt;Account&gt; accounts = accountService.findAll(); model.addAttribute(\"accounts\",accounts); return \"list\"; &#125; @RequestMapping(\"/save\") public void save(Account account, HttpServletRequest request,HttpServletResponse response)throws Exception&#123; System.out.println(\"表现层:保存账户...\"); accountService.saveAccount(account); response.sendRedirect(request.getContextPath()+\"/account/findAll\"); return; &#125;&#125; index.jsp 12345678910111213141516&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;测试查询&lt;/h3&gt; &lt;a href=\"account/findAll\"&gt;findAll测试&lt;/a&gt; &lt;h3&gt;测试保存&lt;/h3&gt; &lt;form action=\"account/save\" method=\"post\"&gt; 姓名:&lt;input type=\"text\" name=\"name\"&gt;&lt;br&gt; 金额:&lt;input type=\"text\" name=\"money\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"保存\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; list.jsp 1234567891011121314&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;%@taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;查询所有账户信息!&lt;/h3&gt; &lt;c:forEach items=\"$&#123;accounts&#125;\" var=\"account\"&gt; $&#123;account.name&#125; &lt;/c:forEach&gt;&lt;/body&gt;&lt;/html&gt;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SQL执行慢分析及SQL语句优化","slug":"SQL执行慢分析及SQL语句优化","date":"2021-05-08T13:19:59.176Z","updated":"2020-04-29T02:44:37.936Z","comments":true,"path":"31546/","link":"","permalink":"http://tonymua.top/31546/","excerpt":"1.SQL语句执行速度慢一个SQL语句执行的速度很慢, 分两种情况讨论: 大多数情况下很正常, 偶尔很慢, 则有如下原因: 数据库在刷新脏页 执行的时候, 遇到锁, 如表锁, 行锁 一直执行很慢, 则有如下原因","text":"1.SQL语句执行速度慢一个SQL语句执行的速度很慢, 分两种情况讨论: 大多数情况下很正常, 偶尔很慢, 则有如下原因: 数据库在刷新脏页 执行的时候, 遇到锁, 如表锁, 行锁 一直执行很慢, 则有如下原因 没有用上索引: 例如该字段没有索引, 由于对字段进行运算, 函数操作导致无法使用索引 数据库选错了索引 2.SQL语句的优化 设置合适的字段属性 字段的长度越小, 占用的内存越小, 性能就越好; 例如,中国的手机号码为11位, vachar的长度设置为11位即可 使用join语法 join语法分为内连接, 左(外)连接, 右(外)连接 尽量少使用select * select *会进行全表查询, 消耗的性能较大 在查找唯一一条数据的时候, 使用limit 1, 在查找到数据的时候会终止查找 使用limit分页 尽量少使用排序order by, order by DESC, order by ASC 避免进行类型转换 使用索引 优点: 加快索引速度 缺点: 创建索引和维护索引需要耗费时间和精力 ​ 索引需要占用空间 ​ 进行数据的增删改查时需要动态维护索引","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Spring相关面试题","slug":"Spring相关面试题","date":"2021-05-08T13:19:59.175Z","updated":"2020-04-29T02:44:38.037Z","comments":true,"path":"11294/","link":"","permalink":"http://tonymua.top/11294/","excerpt":"1.Spring与Spring MVC的区别Spring是IOC和AOP的容器框架，SpringMVC是基于Spring功能之上添加的Web框架，想用SpringMVC必须先依赖Spring。 为了简化开发者的使用，从而推出了Spring Boot, Spring Boot实现了自动配置，降低了项目搭建的复杂度。 2.IOC AOPIOC(控制反转):由Spring来负责控制对象的生命周期和对象间的关系","text":"1.Spring与Spring MVC的区别Spring是IOC和AOP的容器框架，SpringMVC是基于Spring功能之上添加的Web框架，想用SpringMVC必须先依赖Spring。 为了简化开发者的使用，从而推出了Spring Boot, Spring Boot实现了自动配置，降低了项目搭建的复杂度。 2.IOC AOPIOC(控制反转):由Spring来负责控制对象的生命周期和对象间的关系 IOC 实现的基础 IOC 是工厂模式与反射机制, 只需要在spring配置文件中配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类。 AOP(面向切面编程):作为面向对象的一种补充, 用于处理系统中分布于各个模块的横切关注点, 比如事务管理, 日志, 缓存等等. ​ AOP的实现关键在于AOP框架自动创建的AOP代理, AOP代理主要分为静态代理和动态代理, 静态代理的代表为AspectJ; 而动态代理则以Spring AOP为代表. ​ 通常使用AspectJ的编译时增强实现AOP, AspectJ是静态代理的增强, 所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类, 因此也称为编译时增强. ​ Spring AOP中的动态代理主要有两种方式, JDK动态代理和CGLIB动态代理. JDK动态代理通过反射来接收被代理的类, 并要求被代理的类必须实现一个接口. JDK动态代理的核心是InvocationHandler接口和Proxy类. 如果目标类没有实现接口, 那么Spring AOP会选择使用CGLIB来动态代理目标类. CGLIB, 是一个代码生成的类库, 可以在运行时动态的生成某个类的子类, 注意, CGLIB是通过继承的方式做的动态代理, 因此如果某个类被标记为final, 那么它是无法使用CGLIB做动态代理的. 3.Spring支持的事务管理类型Spring支持如下两种方式的事务管理： 编程式事务管理:这意味着你可以通过编程的方式管理事务，这种方式带来了很大的灵活性, 允许你通过代码控制业务, 但很难维护。 声明式事务管理:这种方式意味着你可以将事务管理和业务代码分离。你只需要通过注解或者XML配置管理事务。 一般选择声明式事务管理，因为这种方式和应用程序的关联较少, 更加符合轻量级容器的概念。 4.DIDI叫做依赖注入, 是对IOC更简单的诠释. 控制反转是把传统上由程序代码直接操控的对象的调用权交给容器, 通过容器来实现对象组件的装配和管理, 由容器来创建对象命管理对象之间的依赖关系. DI是对IOC更准确的描述, 即组件之间的依赖关系，由容器在运行期决定. 形象的来说，既由容器动态的将某种依赖关系注入到组件之中. 依赖注入的三种方式: (1) 构造器注入：通过构造方法初始化 (2) setter方法注入：通过setter方法初始化 (3) 接口注入 5.Spring主要使用了哪些设计模式？ 工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 6.@RestController vs @Controller Controller 返回一个页面 单独使用 @Controller 不加 @ResponseBody的话一般使用在要返回一个视图的情况，这种情况属于比较传统的Spring MVC 的应用，对应于前后端不分离的情况。 @RestController 返回JSON 或 XML 形式数据 但@RestController只返回对象，对象数据直接以 JSON 或 XML 形式写入 HTTP 响应(Response)中，这种情况属于 RESTful Web服务，这也是目前日常开发所接触的最常用的情况（前后端分离）。 @Controller +@ResponseBody = @RestController 返回JSON 或 XML 形式数据 如果你需要在Spring4之前开发 RESTful Web服务的话，你需要使用@Controller 并结合@ResponseBody注解，也就是说@Controller +@ResponseBody= @RestController（Spring 4 之后新加的注解）。 @ResponseBody 注解的作用是将 Controller 的方法返回的对象通过适当的转换器转换为指定的格式之后，写入到HTTP 响应(Response)对象的 body 中，通常用来返回 JSON 或者 XML 数据，返回 JSON 数据的情况比较多。 7.Spring 中的 bean 的作用域有哪些? singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。 session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。 global-session： 全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话 8.Spring 中的单例 bean 的线程安全问题单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。 常见的有两种解决办法： 在Bean对象中尽量避免定义可变的成员变量（不太现实）。 在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 9.@Component 和 @Bean 的区别 作用对象不同: @Component 注解作用于类，而@Bean注解作用于方法。 @Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了Spring这是某个类的示例，当我需要用它的时候还给我。 @Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。 10.SpringMVC 工作原理 流程说明（重要）： 客户端（浏览器）发送请求，直接请求到 DispatcherServlet。 DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。 解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。 HandlerAdapter 会根据 Handler来调用真正的处理器开处理请求，并处理相应的业务逻辑。 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。 ViewResolver 会根据逻辑 View 查找实际的 View。 DispaterServlet 把返回的 Model 传给 View（视图渲染）。 把 View 返回给请求者（浏览器） 11.Spring的优点 方便解耦，简化开发 通过 Spring提供的 IOC 容器，可以将对象间的依赖关系交由 Spring进行控制，避免硬编码所造 成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可 以更专注于上层的应用。 AOP编程的支持 通过 Spring的 AOP 功能，方便进行面向切面的编程，许多不容易用传统OOP 实现的功能可以通过 AOP 轻松应付。 声明式事务的支持 可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式方式灵活的进行事务的管理， 提高开发效率和质量。 方便程序的测试 可以用非容器依赖的编程方式进行几乎所有的测试工作，测试不再是昂贵的操作，而是随手可做的事情。 方便集成各种优秀框架 Spring可以降低各种框架的使用难度，提供了对各种优秀框架（Struts、Hibernate、Hessian、Quartz 等）的直接支持。 降低 JavaEE API的使用难度 Spring对 JavaEE API（如 JDBC、JavaMail、远程调用等）进行了薄薄的封装层，使这些 API 的 使用难度大为降低。 12.Spring 中的 bean 生命周期 Bean 容器找到配置文件中 Spring Bean 的定义。 Bean 容器利用 Java Reflection API 创建一个Bean的实例。 如果涉及到一些属性值 利用 set()方法设置一些属性值。 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入Bean的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。 如果Bean实现了 BeanFactoryAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoade r对象的实例。 与上面的类似，如果实现了其他 *.Aware接口，就调用相应的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法 当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Spring框架(四)","slug":"Spring框架(四)","date":"2021-05-08T13:19:59.173Z","updated":"2020-04-29T02:44:38.107Z","comments":true,"path":"45219/","link":"","permalink":"http://tonymua.top/45219/","excerpt":"1.Spring中的 JdbcTemplate1.1 JdbcTemplate 概述​ 它是 spring 框架中提供的一个对象，是对原始 Jdbc API 对象的简单封装。spring 框架为我们提供了很多 的操作模板类。 操作关系型数据的： JdbcTemplate HibernateTemplate操作 nosql 数据库的： RedisTemplate操作消息队列的： JmsTemplate 我们今天的主角在 spring-jdbc-5.0.2.RELEASE.jar 中，我们在导包的时候，除了要导入这个 jar 包 外，还需要导入一个 spring-tx-5.0.2.RELEASE.jar（它是和事务相关的）。","text":"1.Spring中的 JdbcTemplate1.1 JdbcTemplate 概述​ 它是 spring 框架中提供的一个对象，是对原始 Jdbc API 对象的简单封装。spring 框架为我们提供了很多 的操作模板类。 操作关系型数据的： JdbcTemplate HibernateTemplate操作 nosql 数据库的： RedisTemplate操作消息队列的： JmsTemplate 我们今天的主角在 spring-jdbc-5.0.2.RELEASE.jar 中，我们在导包的时候，除了要导入这个 jar 包 外，还需要导入一个 spring-tx-5.0.2.RELEASE.jar（它是和事务相关的）。 1.2 JdbcTemplate 的增删改查操作 (dao)1.2.1 准备实体类Account 1234567891011121314151617181920212223242526272829303132333435363738public class Account implements Serializable &#123; private Integer id; private String name; private Float money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Float getMoney() &#123; return money; &#125; public void setMoney(Float money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; 1.2.2 第一种方式：在 dao 中定义 JdbcTemplateAccountDaoImpl 1234567891011121314151617181920212223242526272829@Repositorypublic class AccountDaoImpl implements AccountDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public Account findAccountById(Integer accountId) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where id =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountId); return accounts.isEmpty() ? null : accounts.get(0); &#125; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; jdbcTemplate.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; bean.xml 12345678910111213141516171819202122232425?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置jdbcTemplate--&gt; &lt;bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\"&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置账户持久层--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;!--注入jdbcTemplate--&gt; &lt;property name=\"jdbcTemplate\" ref=\"jdbcTemplate\"&gt;&lt;/property&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 存在的问题 ​ 有个小问题。就是我们的 dao 有很多时，每个 dao 都有一些重复性的代码。下面就是重复代码： 123private JdbcTemplate jdbcTemplate; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; 能不能把它抽取出来呢？ 1.2.3 第二种方式：让 dao 继承 JdbcDaoSupport​ JdbcDaoSupport 是spring 框架为我们提供的一个类，该类中定义了一个 JdbcTemplate 对象，我们可以 直接获取使用，但是要想创建该对象，需要为其提供一个数据源 AccountDaoImpl 123456789101112131415161718192021222324ublic class AccountDaoImpl extends JdbcDaoSupport implements AccountDao &#123; @Override public Account findAccountById(Integer accountId) &#123; List&lt;Account&gt; accounts = getJdbcTemplate().query(\"select * from account where id =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountId); return accounts.isEmpty() ? null : accounts.get(0); &#125; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = getJdbcTemplate().query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; getJdbcTemplate().update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; bean.xml 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置账户持久层--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 两版 Dao有什么区别呢？ 第一种在 Dao类中定义 JdbcTemplate 的方式，适用于所有配置方式（xml和注解都可以）。 第二种让 Dao继承 JdbcDaoSupport 的方式，只能用于基于 XML 的方式，注解用不了。 2.Spring中的事务控制2.1 Spring事务控制明确点第一：JavaEE 体系进行分层开发，事务处理位于业务层，Spring 提供了分层设计业务层的事务处理解决方 案。 第二：spring 框架为我们提供了一组事务控制的接口。这组接口是在 spring-tx-5.0.2.RELEASE.jar 中。 第三：spring 的事务控制都是基于 AOP 的，它既可以使用编程的方式实现，也可以使用配置的方式实现。我 们学习的重点是使用配置的方式实现 2.2 Spring中事务控制的 API介绍2.2.1 PlatformTransactionManager此接口是 spring 的事务管理器，它里面提供了我们常用的操作事务的方法，如下图： 我们在开发中都是使用它的实现类 真正管理事务的对象 org.springframework.jdbc.datasource.DataSourceTransactionManager 使用 Spring JDBC 或 iBatis 进行持久化数据时使用 org.springframework.orm.hibernate5.HibernateTransactionManager 使用 Hibernate 版本进行持久化数据时使用 2.2.2 TransactionDefinition它是事务的定义信息对象，里面有如下方法： 事务的隔离级别 *事务的传播行为 * REQUIRED:如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。一般的选 择（默认值） SUPPORTS:支持当前事务，如果当前没有事务，就以非事务方式执行（没有事务） MANDATORY：使用当前的事务，如果当前没有事务，就抛出异常 REQUERS_NEW:新建事务，如果当前在事务中，把当前事务挂起。 NOT_SUPPORTED:以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 NEVER:以非事务方式运行，如果当前存在事务，抛出异常 NESTED:如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行 REQUIRED 类似的操作。 超时时间 默认值是-1，没有超时限制。如果有，以秒为单位进行设置。 是否是只读事务 建议查询时设置为只读。 2.2.3 TransactionStatus此接口提供的是事务具体的运行状态，方法介绍如下图： 2.3 基于 XML 的声明式事务控制（配置方式）重点pom.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Account 1234567891011121314151617181920212223242526272829303132333435363738public class Account implements Serializable &#123; private Integer id; private String name; private Float money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Float getMoney() &#123; return money; &#125; public void setMoney(Float money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; AccountDao 1234567public interface AccountDao &#123; Account findAccountByName(String accountName); void updateAccount(Account account);&#125; AccountDaoImpl 123456789101112131415161718public class AccountDaoImpl extends JdbcDaoSupport implements AccountDao &#123; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = getJdbcTemplate().query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; getJdbcTemplate().update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; AccountService 1234public interface AccountService &#123; void transfer(String sourceName,String targetName,Float money);&#125; AccountServiceImpl 12345678910111213141516171819202122232425public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public void transfer(String sourceName, String targetName, Float money) &#123; //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125; AccountServiceTest 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:bean.xml\")public class AccountServiceTest &#123; @Autowired private AccountService accountService; @Test public void testTransfer()&#123; accountService.transfer(\"aaa\",\"bbb\",100f); &#125;&#125; bean.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!--配置账户持久层--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;!--注入jdbcTemplate--&gt; &lt;!--&lt;property name=\"jdbcTemplate\" ref=\"jdbcTemplate\"&gt;&lt;/property&gt;--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置业务层--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt; &lt;!--注入accountDao--&gt; &lt;property name=\"accountDao\" ref=\"accountDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- spring中基于XML的声明式事务控制配置步骤 1、配置事务管理器 2、配置事务的通知 此时我们需要导入事务的约束 tx名称空间和约束，同时也需要aop的 使用tx:advice标签配置事务通知 属性： id：给事务通知起一个唯一标识 transaction-manager：给事务通知提供一个事务管理器引用 3、配置AOP中的通用切入点表达式 4、建立事务通知和切入点表达式的对应关系 5、配置事务的属性 是在事务的通知tx:advice标签的内部 --&gt; &lt;!--1.配置事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!--注入dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--2.配置事务的通知--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!--5.配置事务的属性 isolation：用于指定事务的隔离级别。默认值是DEFAULT，表示使用数据库的默认隔离级别。 propagation：用于指定事务的传播行为。默认值是REQUIRED，表示一定会有事务，增删改的选择。查询方法可以选择SUPPORTS。 read-only：用于指定事务是否只读。只有查询方法才能设置为true。默认值是false，表示读写。 timeout：用于指定事务的超时时间，默认值是-1，表示永不超时。如果指定了数值，以秒为单位。 rollback-for：用于指定一个异常，当产生该异常时，事务回滚，产生其他异常时，事务不回滚。没有默认值。表示任何异常都回滚。 no-rollback-for：用于指定一个异常，当产生该异常时，事务不回滚，产生其他异常时事务回滚。没有默认值。表示任何异常都回滚。 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"*\" propagation=\"REQUIRED\" read-only=\"false\"/&gt; &lt;tx:method name=\"find*\" propagation=\"SUPPORTS\" read-only=\"true\"&gt;&lt;/tx:method&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置AOP--&gt; &lt;aop:config&gt; &lt;!--3.配置AOP中的通用切入点表达式--&gt; &lt;aop:pointcut id=\"pt1\" expression=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:pointcut&gt; &lt;!--4、建立事务通知和切入点表达式的对应关系--&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"pt1\"&gt;&lt;/aop:advisor&gt; &lt;/aop:config&gt;&lt;/beans&gt; 2.4 基于注解的配置方式AccountDaoImpl 123456789101112131415161718192021@Repository(\"accountDao\")public class AccountDaoImpl implements AccountDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; jdbcTemplate.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; AccountServiceImpl 12345678910111213141516171819202122232425@Service(\"accountService\")@Transactionalpublic class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public void transfer(String sourceName, String targetName, Float money) &#123; //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125;&#125; bean.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--配置spring创建容器时要扫描的包--&gt; &lt;context:component-scan base-package=\"service,dao\"&gt;&lt;/context:component-scan&gt; &lt;!--配置JdbcTemplate--&gt; &lt;bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\"&gt; &lt;!--注入dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- spring中基于注解 的声明式事务控制配置步骤 1、配置事务管理器 2、开启spring对注解事务的支持 3、在需要事务支持的地方使用@Transactional注解 --&gt; &lt;!--1.配置事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!--注入dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--2.开启spring对注解事务的支持--&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"&gt;&lt;/tx:annotation-driven&gt;&lt;/beans&gt; 2.5 纯注解的配置方式jdbcConfig.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/springjdbc.username=rootjdbc.password=547717253 JdbcConfig 12345678910111213141516171819202122232425262728public class JdbcConfig &#123; @Value(\"$&#123;jdbc.driver&#125;\") private String driver; @Value(\"$&#123;jdbc.url&#125;\") private String url; @Value(\"$&#123;jdbc.username&#125;\") private String username; @Value(\"$&#123;jdbc.password&#125;\") private String password; @Bean(name =\"jdbcTemplate\" ) public JdbcTemplate createJdbcTemplate(DataSource dataSource)&#123; return new JdbcTemplate(dataSource); &#125; @Bean(name = \"dataSource\") public DataSource createDataSource()&#123; DriverManagerDataSource dataSource=new DriverManagerDataSource(); dataSource.setDriverClassName(driver); dataSource.setUrl(url); dataSource.setUsername(username); dataSource.setPassword(password); return dataSource; &#125;&#125; TransactionConfig 123456789public class TransactionConfig &#123;// 用于创建事务管理器对象 @Bean(name =\"transactionManager\" ) public PlatformTransactionManager createTransactionManager(DataSource dataSource)&#123; return new DataSourceTransactionManager(dataSource); &#125;&#125; SpringConfiguration 123456789//spring的配置类，相当于bean.xml@Configuration@ComponentScan(&#123;\"dao\",\"service\",\"config\"&#125;)@Import(&#123;JdbcConfig.class,TransactionConfig.class&#125;)@PropertySource(\"jdbcConfig.properties\")@EnableTransactionManagementpublic class SpringConfiguration &#123;&#125; AccountDaoImpl 123456789101112131415161718192021@Repository(\"accountDao\")public class AccountDaoImpl implements AccountDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; jdbcTemplate.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; AccountService 12345678910111213141516171819202122232425@Service(\"accountService\")@Transactionalpublic class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public void transfer(String sourceName, String targetName, Float money) &#123; //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125;&#125; AccountServiceTest 12345678910111213141516/** * 使用Junit单元测试：测试我们的配置 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = SpringConfiguration.class)public class AccountServiceTest &#123; @Autowired private AccountService accountService; @Test public void testTransfer()&#123; accountService.transfer(\"aaa\",\"bbb\",100f); &#125;&#125; 3.Spring5的新特性3.1 与 JDK 相关的升级3.1.1 jdk 版本要求​ spring5.0 在 2017 年 9 月发布了它的 GA（通用）版本。该版本是基于 jdk8 编写的，所以 jdk8 以下版本 将无法使用。同时，可以兼容 jdk9 版本。 tomcat 版本要求 8.5 及以上。 注： 我们使用 jdk8 构建工程，可以降版编译。但是不能使用 jdk8 以下版本构建工程。 由于 jdk 和 tomcat 版本的更新，我们的 IDE 也需要同时更新。 3.1.2 利用 jdk8 版本更新的内容第一：基于 JDK8 的反射增强 第二：@NonNull 注解和@Nullable 注解的使用 用 @Nullable 和 @NotNull 注解来显示表明可为空的参数和以及返回值。这样就够在编译的时候处 理空值而不是在运行时抛出 NullPointerExceptions。 第三：日志记录方面 Spring Framework 5.0 带来了 Commons Logging 桥接模块的封装, 它被叫做 spring-jcl 而 不是标准的 Commons Logging。当然，无需任何额外的桥接，新版本也会对 Log4j 2.x, SLF4J, JUL ( java.util.logging) 进行自动检测。 3.2 核心容器的更新​ Spring Framework 5.0 现在支持候选组件索引作为类路径扫描的替代方案。该功能已经在类路径扫描器中 添加，以简化添加候选组件标识的步骤。 ​ 应用程序构建任务可以定义当前项目自己的 META-INF/spring.components 文件。在编译时，源模型是 自包含的，JPA 实体和 Spring 组件是已被标记的。 ​ 从索引读取实体而不是扫描类路径对于小于 200 个类的小型项目是没有明显差异。但对大型项目影响较大。 加载组件索引开销更低。因此，随着类数的增加，索引读取的启动时间将保持不变。 ​ 加载组件索引的耗费是廉价的。因此当类的数量不断增长，加上构建索引的启动时间仍然可以维持一个常数, 不过对于组件扫描而言，启动时间则会有明显的增长。 ​ 这个对于我们处于大型 Spring 项目的开发者所意味着的，是应用程序的启动时间将被大大缩减。虽然 20 或者 30 秒钟看似没什么，但如果每天要这样登上好几百次，加起来就够你受的了。使用了组件索引的话，就能帮助你每天过的更加高效。 你可以在 Spring 的 Jira 上了解更多关于组件索引的相关信息。 3.3 JetBrains Kotlin 语言支持​ Kolin概述：是一种支持函数式编程编程风格的面向对象语言。Kotlin 运行在 JVM 之上，但运行环境并不 限于 JVM。 3.4 响应式编程风格​ 此次 Spring 发行版本的一个激动人心的特性就是新的响应式堆栈 WEB 框架。这个堆栈完全的响应式且非 阻塞，适合于事件循环风格的处理，可以进行少量线程的扩展。 ​ Reactive Streams 是来自于 Netflix, Pivotal, Typesafe, Red Hat, Oracle, Twitter 以及 Spray.io 的工程师特地开发的一个 API。它为响应式编程实现的实现提供一个公共的 API，好实现 Hibernate 的 JPA。这里 JPA 就是这个 API, 而 Hibernate 就是实现。 ​ Reactive Streams API 是 Java 9 的官方版本的一部分。在 Java 8 中, 你会需要专门引入依赖来使 用 Reactive Streams API。 ​ Spring Framework 5.0 对于流式处理的支持依赖于 Project Reactor 来构建, 其专门实现了 Reactive Streams API。 ​ Spring Framework 5.0 拥有一个新的 spring-webflux 模块，支持响应式 HTTP 和 WebSocket 客 户端。 ​ Spring Framework 5.0 还提供了对于运行于服务器之上，包含了 REST, HTML, 以及 WebSocket 风 格交互的响应式网页应用程序的支持。 ​ 在 spring-webflux 中包含了两种独立的服务端编程模型： ​ 基于注解：使用到了@Controller 以及 Spring MVC 的其它一些注解； ​ 使用 Java 8 lambda 表达式的函数式风格的路由和处理。 ​ 有了 Spring Webflux, 你现在可以创建出 WebClient, 它是响应式且非阻塞的，可以作为 RestTemplate 的一个替代方案。 3.5 Junit5 支持​ 完全支持 JUnit 5 Jupiter，所以可以使用 JUnit 5 来编写测试以及扩展。此外还提供了一个编程以及 扩展模型，Jupiter 子项目提供了一个测试引擎来在 Spring 上运行基于 Jupiter 的测试。 ​ 另外，Spring Framework 5 还提供了在 Spring TestContext Framework 中进行并行测试的扩展。 ​ 针对响应式编程模型， spring-test 现在还引入了支持 Spring WebFlux 的 WebTestClient 集成测 试的支持，类似于 MockMvc，并不需要一个运行着的服务端。使用一个模拟的请求或者响应， WebTestClient 就可以直接绑定到 WebFlux 服务端设施。 ​ 你可以在这里找到这个激动人心的 TestContext 框架所带来的增强功能的完整列表。 ​ 当然， Spring Framework 5.0 仍然支持我们的老朋友 JUnit! 在我写这篇文章的时候， JUnit 5 还 只是发展到了 GA 版本。对于 JUnit4， Spring Framework 在未来还是要支持一段时间的。 3.6 依赖类库的更新终止支持的类库: Portlet. Velocity. JasperReports. XMLBeans. JDO. Guava. 支持的类库: Jackson 2.6+ EhCache 2.10+ / 3.0 GA Hibernate 5.0+ JDBC 4.0+ XmlUnit 2.x+ OkHttp 3.x+ Netty 4.1+","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring框架(二)","slug":"Spring框架(二)","date":"2021-05-08T13:19:59.172Z","updated":"2020-04-29T02:44:38.083Z","comments":true,"path":"46845/","link":"","permalink":"http://tonymua.top/46845/","excerpt":"1.使用 spring的 IoC的实现账户的 CRUD(xml)1.1 环境搭建1.1.1 环境配置1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbutils&lt;/groupId&gt; &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;","text":"1.使用 spring的 IoC的实现账户的 CRUD(xml)1.1 环境搭建1.1.1 环境配置1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbutils&lt;/groupId&gt; &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.1.2 编写实体类Account 123456789101112131415161718192021222324252627282930313233343536373839public class Account implements Serializable &#123; private Integer id; private String name; private Float money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Float getMoney() &#123; return money; &#125; public void setMoney(Float money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; 1.1.3 编写持久层代码AccountDao 1234567891011public interface AccountDao &#123; List&lt;Account&gt; findAllAccount(); Account findAccountById(Integer accountId); void saveAccount(Account account); void updateAccount(Account account); void deleteAccount(Integer accountId);&#125; AccountDaoImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class AccountDaoImpl implements AccountDao &#123; private QueryRunner queryRunner; public void setQueryRunner(QueryRunner queryRunner) &#123; this.queryRunner = queryRunner; &#125; @Override public List&lt;Account&gt; findAllAccount() &#123; try &#123; return queryRunner.query(\"select * from account\",new BeanListHandler&lt;Account&gt;(Account.class)); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public Account findAccountById(Integer accountId) &#123; try &#123; return queryRunner.query(\"select * from account where id=?\",new BeanHandler&lt;Account&gt;(Account.class),accountId); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public void saveAccount(Account account) &#123; try &#123; queryRunner.update(\"insert into account(name,money)values(?,?)\",account.getName(),account.getMoney()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void updateAccount(Account account) &#123; try &#123; queryRunner.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void deleteAccount(Integer accountId) &#123; try &#123; queryRunner.update(\"delete from account where id=?\",accountId); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 1.1.4 编写业务层代码AccountService 1234567891011public interface AccountService &#123; List&lt;Account&gt; findAllAccount(); Account findAccountById(Integer accountId); void saveAccount(Account account); void updateAccount(Account account); void deleteAccount(Integer accountId);&#125; AccountServiceImpl 1234567891011121314151617181920212223242526272829303132public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public List&lt;Account&gt; findAllAccount() &#123; return accountDao.findAllAccount(); &#125; @Override public Account findAccountById(Integer accountId) &#123; return accountDao.findAccountById(accountId); &#125; @Override public void saveAccount(Account account) &#123; accountDao.saveAccount(account); &#125; @Override public void updateAccount(Account account) &#123; accountDao.updateAccount(account); &#125; @Override public void deleteAccount(Integer accountId) &#123; accountDao.deleteAccount(accountId); &#125;&#125; 1.2 配置对象bean.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置service--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt; &lt;!--注入dao--&gt; &lt;property name=\"accountDao\" ref=\"accountDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置Dao对象--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;!-- 注入QueryRunner --&gt; &lt;property name=\"queryRunner\" ref=\"queryRunner\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置QueryRunner--&gt; &lt;bean id=\"queryRunner\" class=\"org.apache.commons.dbutils.QueryRunner\" scope=\"prototype\"&gt; &lt;!--注入数据源--&gt; &lt;constructor-arg name=\"ds\" ref=\"dataSource\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!--连接数据库的必备信息--&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 1.3 测试案例AccountServiceTest 12345678910111213141516171819202122232425262728293031323334353637383940@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:bean.xml\")public class AccountServiceTest &#123; @Autowired private AccountService accountService; @Test public void testFindAll()&#123; List&lt;Account&gt; accounts = accountService.findAllAccount(); for (Account account:accounts)&#123; System.out.println(account); &#125; &#125; @Test public void testFindOne() &#123; Account account = accountService.findAccountById(1); System.out.println(account); &#125; @Test public void testSave() &#123; Account account=new Account(); account.setName(\"test\"); account.setMoney(2000f); accountService.saveAccount(account); &#125; @Test public void testUpdate() &#123; Account account=accountService.findAccountById(4); account.setMoney(3000f); accountService.updateAccount(account); &#125; @Test public void testDelete() &#123; accountService.deleteAccount(4); &#125;&#125; 2.基于注解的 IOC 配置2.1 常用注解2.1.1 用于创建对象的相当于： 1&lt;bean id=\"\" class=\"\"&gt; @Component 作用： 把资源让 spring 来管理。相当于在 xml 中配置一个 bean。 属性： value：指定 bean 的 id。如果不指定 value 属性，默认 bean 的 id 是当前类的类名。首字母小写。 @Controller @Service @Repository ​ 他们三个注解都是针对一个的衍生注解，他们的作用及属性都是一模一样的。 他们只不过是提供了更加明确的语义化。 @Controller：一般用于表现层的注解。 @Service：一般用于业务层的注解。 @Repository：一般用于持久层的注解。 细节：如果注解中有且只有一个属性要赋值时，且名称是 value，value在赋值是可以不写。 2.1.2 用于注入数据的 相当于： 12&lt;property name=\"\" ref=\"\"&gt; &lt;property name=\"\" value=\"\"&gt; @Autowired 作用： 自动按照类型注入。当使用注解注入属性时，set方法可以省略。它只能注入其他 bean 类型。当有多个 类型匹配时，使用要注入的对象变量名称作为 bean 的 id，在 spring 容器查找，找到了也可以注入成功。找不到 就报错。 @Qualifier 作用： 在自动按照类型注入的基础之上，再按照 Bean 的 id 注入。它在给字段注入时不能独立使用，必须和 @Autowire 一起使用；但是给方法参数注入时，可以独立使用。 属性： value：指定 bean 的 id。 *@Resource * 作用： 直接按照 Bean 的 id 注入。它也只能注入其他 bean 类型。 属性： name：指定 bean 的 id @Value 作用： 注入基本数据类型和 String 类型数据的 属性： value：用于指定值 2.1.3 用于改变作用范围的相当于： 1&lt;bean id=\"\" class=\"\" scope=\"\"&gt; @Scope 作用： 指定 bean 的作用范围。 属性： value：指定范围的值。 取值：singleton prototype request session globalsession 2.1.4 和生命周期相关的相当于： 1&lt;bean id=\"\" class=\"\" init-method=\"\" destroy-method=\"\" /&gt; @PostConstruct 作用： 用于指定初始化方法。 @PreDestroy 作用： 用于指定销毁方法。 2.2 spring的纯注解配置2.2.1 待改造的问题我们发现，之所以我们现在离不开 xml 配置文件，是因为我们有一句很关键的配置： 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 告知spring在创建容器时要扫描的包 --&gt; &lt;context:component-scan base-package=\"dao,service\"&gt;&lt;/context:component-scan&gt; &lt;!--配置QueryRunner--&gt; &lt;bean id=\"queryRunner\" class=\"org.apache.commons.dbutils.QueryRunner\" scope=\"prototype\"&gt; &lt;!--注入数据源--&gt; &lt;constructor-arg name=\"ds\" ref=\"dataSource\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!--连接数据库的必备信息--&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 如果他要也能用注解配置，那么我们就离脱离 xml 文件又进了一步。 另外，数据源和 JdbcTemplate 的配置也需要靠注解来实现。 2.2.2 新注解说明@Configuration 作用： 用于指定当前类是一个 spring 配置类，当创建容器时会从该类上加载注解。获取容器时需要使用 AnnotationApplicationContext(有@Configuration 注解的类.class)。 属性： value:用于指定配置类的字节码 @ComponentScan 作用： 用于指定 spring 在初始化容器时要扫描的包。作用和在 spring 的 xml 配置文件中的： &lt;context:component-scan base-package=”com.itheima”/&gt;是一样的。 属性： basePackages：用于指定要扫描的包。和该注解中的 value 属性作用一样。 @Bean 作用： 该注解只能写在方法上，表明使用此方法创建一个对象，并且放入 spring 容器。 属性： name：给当前@Bean 注解方法创建的对象指定一个名称(即 bean 的 id）。 @PropertySource 作用： 用于加载.properties 文件中的配置。例如我们配置数据源时，可以把连接数据库的信息写到 properties 配置文件中，就可以使用此注解指定 properties 配置文件的位置。 属性： value[]：用于指定 properties 文件位置。如果是在类路径下，需要写上 classpath: @Import 作用： 用于导入其他配置类，在引入其他配置类时，可以不用再写@Configuration 注解。当然，写上也没问 题。 属性： value[]：用于指定其他配置类的字节码。 SpringConfiguration 1234567891011121314151617181920212223242526272829303132333435363738/** * 该类是一个配置类，它的作用和bean.xml是一样的 * spring中的新注解 * Configuration * 作用：指定当前类是一个配置类 * 细节：当配置类作为AnnotationConfigApplicationContext对象创建的参数时，该注解可以不写。 * ComponentScan * 作用：用于通过注解指定spring在创建容器时要扫描的包 * 属性： * value：它和basePackages的作用是一样的，都是用于指定创建容器时要扫描的包。 * 我们使用此注解就等同于在xml中配置了: * &lt;context:component-scan base-package=\"dao,service\"&gt;&lt;/context:component-scan&gt; * Bean * 作用：用于把当前方法的返回值作为bean对象存入spring的ioc容器中 * 属性: * name:用于指定bean的id。当不写时，默认值是当前方法的名称 * 细节： * 当我们使用注解配置方法时，如果方法有参数，spring框架会去容器中查找有没有可用的bean对象。 * 查找的方式和Autowired注解的作用是一样的 * Import * 作用：用于导入其他的配置类 * 属性： * value：用于指定其他配置类的字节码。 * 当我们使用Import的注解之后，有Import注解的类就父配置类，而导入的都是子配置类 * PropertySource * 作用：用于指定properties文件的位置 * 属性： * value：指定文件的名称和路径。 * 关键字：classpath，表示类路径下 */@Configuration//@ComponentScans(value = &#123;@ComponentScan(basePackages = \"dao\"),@ComponentScan(value = \"service\")&#125;)@ComponentScan(&#123;\"dao\",\"service\"&#125;)@Import(JdbcConfig.class)@PropertySource(\"classpath:jdbcConfig.properties\")public class SpringConfiguration &#123;&#125; JdbcConfig 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class JdbcConfig &#123; @Value(\"$&#123;jdbc.driver&#125;\") private String driver; @Value(\"$&#123;jdbc.url&#125;\") private String url; @Value(\"$&#123;jdbc.username&#125;\") private String username; @Value(\"$&#123;jdbc.password&#125;\") private String password; @Bean(name = \"queryRunner\") @Scope(\"prototype\") public QueryRunner createQueryRunner(@Qualifier(\"ds\") DataSource dataSource) &#123; return new QueryRunner(dataSource); &#125; @Bean(name = \"ds\") public DataSource createDataSource() &#123; try &#123; ComboPooledDataSource ds = new ComboPooledDataSource(); ds.setDriverClass(driver); ds.setJdbcUrl(url); ds.setUser(username); ds.setPassword(password); return ds; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; AccountDaoImpl 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Repository(\"accountDao\")public class AccountDaoImpl implements AccountDao &#123; @Autowired private QueryRunner queryRunner; @Override public List&lt;Account&gt; findAllAccount() &#123; try &#123; return queryRunner.query(\"select * from account\",new BeanListHandler&lt;Account&gt;(Account.class)); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public Account findAccountById(Integer accountId) &#123; try &#123; return queryRunner.query(\"select * from account where id=?\",new BeanHandler&lt;Account&gt;(Account.class),accountId); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public void saveAccount(Account account) &#123; try &#123; queryRunner.update(\"insert into account(name,money)values(?,?)\",account.getName(),account.getMoney()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void updateAccount(Account account) &#123; try &#123; queryRunner.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void deleteAccount(Integer accountId) &#123; try &#123; queryRunner.update(\"delete from account where id=?\",accountId); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; AccountServiceImpl 12345678910111213141516171819202122232425262728293031@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public List&lt;Account&gt; findAllAccount() &#123; return accountDao.findAllAccount(); &#125; @Override public Account findAccountById(Integer accountId) &#123; return accountDao.findAccountById(accountId); &#125; @Override public void saveAccount(Account account) &#123; accountDao.saveAccount(account); &#125; @Override public void updateAccount(Account account) &#123; accountDao.updateAccount(account); &#125; @Override public void deleteAccount(Integer accountId) &#123; accountDao.deleteAccount(accountId); &#125;&#125; jdbcConfig.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/springjdbc.username=rootjdbc.password=547717253 3. Spring 整合 JunitAccountServiceTest 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 使用Junit单元测试：测试我们的配置 * Spring整合junit的配置 * 1、导入spring整合junit的jar(坐标) * 2、使用Junit提供的一个注解把原有的main方法替换了，替换成spring提供的 * @Runwith * 3、告知spring的运行器，spring和ioc创建是基于xml还是注解的，并且说明位置 * @ContextConfiguration * locations：指定xml文件的位置，加上classpath关键字，表示在类路径下 * classes：指定注解类所在地位置 * * 当我们使用spring 5.x版本的时候，要求junit的jar必须是4.12及以上 *///1.使用@RunWith 注解替换原有运行器 @RunWith(SpringJUnit4ClassRunner.class)//2.使用@ContextConfiguration 指定 spring 配置文件的位置 @ContextConfiguration(classes = SpringConfiguration.class)public class AccountServiceTest &#123; //3.使用@Autowired 给测试类中的变量注入数据 @Autowired private AccountService accountService; @Test public void testFindAll()&#123; List&lt;Account&gt; accounts = accountService.findAllAccount(); for (Account account:accounts)&#123; System.out.println(account); &#125; &#125; @Test public void testFindOne() &#123; Account account = accountService.findAccountById(1); System.out.println(account); &#125; @Test public void testSave() &#123; Account account=new Account(); account.setName(\"test\"); account.setMoney(2000f); accountService.saveAccount(account); &#125; @Test public void testUpdate() &#123; Account account=accountService.findAccountById(4); account.setMoney(3000f); accountService.updateAccount(account); &#125; @Test public void testDelete() &#123; accountService.deleteAccount(4); &#125;&#125; 为什么不把测试类配到 xml 中 在解释这个问题之前，先解除大家的疑虑，配到 XML 中能不能用呢？ ​ 答案是肯定的，没问题，可以使用。 那么为什么不采用配置到 xml 中的方式呢？ ​ 原因： 第一：当我们在 xml 中配置了一个 bean，spring 加载配置文件创建容器时，就会创建对象。 第二：测试类只是我们在测试功能时使用，而在项目中它并不参与程序逻辑，也不会解决需求上的问 题，所以创建完了，并没有使用。那么存在容器中就会造成资源的浪费。 所以，基于以上两点，我们不应该把测试配置到 xml 文件中。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring框架(三)","slug":"Spring框架(三)","date":"2021-05-08T13:19:59.170Z","updated":"2020-04-29T02:44:38.103Z","comments":true,"path":"9823/","link":"","permalink":"http://tonymua.top/9823/","excerpt":"1. AOP的相关概念1.1 AOP 概述1.1.1 什么是 AOPAOP：全称是 Aspect Oriented Programming 即：面向切面编程。 ​ 简单的说它就是把我们程序重复的代码抽取出来，在需要执行的时候，使用动态代理的技术，在不修改源码的基础上，对我们的已有方法进行增强。 1.1.2 AOP 的作用及优势","text":"1. AOP的相关概念1.1 AOP 概述1.1.1 什么是 AOPAOP：全称是 Aspect Oriented Programming 即：面向切面编程。 ​ 简单的说它就是把我们程序重复的代码抽取出来，在需要执行的时候，使用动态代理的技术，在不修改源码的基础上，对我们的已有方法进行增强。 1.1.2 AOP 的作用及优势 作用： 在程序运行期间，不修改源码对已有方法进行增强。 优势： 减少重复代码 提高开发效率 维护方便 1.1.3 AOP 的实现方式使用动态代理技术 1.2 AOP 的具体应用1.2.1 案例中问题1234567891011public class AccountServiceImpl implements IAccountService &#123; private IAccountDao accountDao; public void setAccountDao(IAccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public void saveAccount(Account account) throws SQLException &#123; accountDao.save(account); &#125; &#125; ​ 事务被自动控制了。换言之，我们使用了 connection 对象的 setAutoCommit(true) 此方式控制事务，如果我们每次都执行一条 sql 语句，没有问题，但是如果业务方法一次要执行多条 sql 语句，这种方式就无法实现功能了。 12345678910111213141516/** * 转账 */ void transfer(String sourceName,String targetName,Float money); @Override public void transfer(String sourceName, String targetName, Float money)&#123; //根据名称查询两个账户信息 Account source = accountDao.findByName(sourceName); Account target = accountDao.findByName(targetName); //转出账户减钱，转入账户加钱 source.setMoney(source.getMoney()-money); target.setMoney(target.getMoney()+money); //更新两个账户 accountDao.update(source); int i=1/0; //模拟转账异常 accountDao.update(target); &#125; ​ 当我们执行时，由于执行有异常，转账失败。但是因为我们是每次执行持久层方法都是独立事务，导致无法实现事务控制（不符合事务的一致性） 1.2.2 问题的解决解决办法：让业务层来控制事务的提交和回滚。 1.2.3 动态代理回顾动态代理的特点 ​ 字节码随用随创建，随用随加载。 它与静态代理的区别也在于此。因为静态代理是字节码一上来就创建好，并完成加载。 装饰者模式就是静态代理的一种体现 动态代理常用的有两种方式 基于接口的动态代理: ​ 提供者：JDK 官方的 Proxy 类。 要求：被代理类最少实现一个接口。 基于子类的动态代理: ​ 提供者：第三方的 CGLib，如果报 asmxxxx 异常，需要导入 asm.jar。 要求：被代理类不能用 final 修饰的类（最终类）。 使用 JDK 官方的 Proxy 类创建代理对象 IProducer 123456public interface IProducer &#123; void saleProduct(float money); void afterService(float money);&#125; Producer 123456789public class Producer implements IProducer&#123; public void saleProduct(float money)&#123; System.out.println(\"销售产品,并获得:\"+money); &#125; public void afterService(float money)&#123; System.out.println(\"提供售后服务,并获得:\"+money); &#125;&#125; Client 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Client &#123; public static void main(String[] args) &#123; final Producer producer=new Producer(); /** * 动态代理： * 特点：字节码随用随创建，随用随加载 * 作用：不修改源码的基础上对方法增强 * 分类： * 基于接口的动态代理 * 基于子类的动态代理 * 基于接口的动态代理： * 涉及的类：Proxy * 提供者：JDK官方 * 如何创建代理对象： * 使用Proxy类中的newProxyInstance方法 * 创建代理对象的要求： * 被代理类最少实现一个接口，如果没有则不能使用 * newProxyInstance方法的参数： * ClassLoader：类加载器 * 它是用于加载代理对象字节码的。和被代理对象使用相同的类加载器。固定写法。 * Class[]：字节码数组 * 它是用于让代理对象和被代理对象有相同方法。固定写法。 * InvocationHandler：用于提供增强的代码 * 它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类，但不是必须的。 * 此接口的实现类都是谁用谁写。 */ IProducer proxyProducer = (IProducer) Proxy.newProxyInstance(producer.getClass().getClassLoader(), producer.getClass().getInterfaces(), new InvocationHandler() &#123; /** * 作用：执行被代理对象的任何接口方法都会经过该方法 * 方法参数的含义 * @param proxy 代理对象的引用 * @param method 当前执行的方法 * @param args 当前执行方法所需的参数 * @return 和被代理对象方法有相同的返回值 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //提供增强的代码 Object returnValue=null; //1.获取方法执行的参数 Float money = (Float) args[0]; //2.判断当前方法是不是销售 if (\"saleProduct\".equals(method.getName()))&#123; returnValue= method.invoke(producer,money*0.8f); &#125; return returnValue; &#125; &#125;); proxyProducer.saleProduct(5000f); &#125;&#125; 使用 CGLib 的 Enhancer 类创建代理对象 Producer 123456789public class Producer &#123; public void saleProduct(float money)&#123; System.out.println(\"销售产品,并获得:\"+money); &#125; public void afterService(float money)&#123; System.out.println(\"提供售后服务,并获得:\"+money); &#125;&#125; Client 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Client &#123; public static void main(String[] args) &#123; final Producer producer=new Producer(); /** * 动态代理： * 特点：字节码随用随创建，随用随加载 * 作用：不修改源码的基础上对方法增强 * 分类： * 基于接口的动态代理 * 基于子类的动态代理 * 基于子类的动态代理： * 涉及的类：Enhancer * 提供者：第三方cglib库 * 如何创建代理对象： * 使用Enhancer类中的create方法 * 创建代理对象的要求： * 被代理类不能是最终类 * create方法的参数： * Class：字节码 * 它是用于指定被代理对象的字节码。 * * Callback：用于提供增强的代码 * 它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类，但不是必须的。 * 此接口的实现类都是谁用谁写。 * 我们一般写的都是该接口的子接口实现类：MethodInterceptor */ Producer cglibProducer = (Producer) Enhancer.create(producer.getClass(), new MethodInterceptor() &#123; /** * 执行被代理对象的任何方法都会经过该方法 * @param proxy * @param method * @param args * 以上三个参数和基于接口的动态代理中invoke方法的参数是一样的 * @param methodProxy ：当前执行方法的代理对象 * @return * @throws Throwable */ @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float) args[0]; //2.判断当前方法是不是销售 if (\"saleProduct\".equals(method.getName())) &#123; returnValue = method.invoke(producer, money * 0.8f); &#125; return returnValue; &#125; &#125;); cglibProducer.saleProduct(5000f); &#125;&#125; 2. Spring中的 AOP2.1 Spring中 AOP 的细节AOP 相关术语 ​ Joinpoint(连接点): 所谓连接点是指那些被拦截到的点。在 spring 中,这些点指的是方法,因为 spring 只支持方法类型的 连接点。 ​ Pointcut(切入点): 所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义。 ​ Advice(通知/增强): 所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知。 通知的类型：前置通知,后置通知,异常通知,最终通知,环绕通知。 ​ Introduction(引介): 引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方 法或 Field。 ​ Target(目标对象): 代理的目标对象。 ​ Weaving(织入): 是指把增强应用到目标对象来创建新的代理对象的过程。 spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入。 ​ Proxy（代理）: 一个类被 AOP 织入增强后，就产生一个结果代理类。 ​ Aspect(切面): 是切入点和通知（引介）的结合。 2.2 基于 XML 的 AOP 配置123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; AccountService 123456789public interface AccountService &#123; //模拟保存账户 void saveAccount(); void updateAccount(int i); int deleteAccount();&#125; AccountServiceImpl 1234567891011121314151617public class AccountServiceImpl implements AccountService &#123; @Override public void saveAccount() &#123; System.out.println(\"保存......\"); &#125; @Override public void updateAccount(int i) &#123; System.out.println(\"更新......\"+i); &#125; @Override public int deleteAccount() &#123; System.out.println(\"删除......\"); return 0; &#125;&#125; Logger 1234567//用于记录日志的工具类，它里面提供了公共的代码public class Logger &#123;//用于打印日志：计划让其在切入点方法执行之前执行（切入点方法就是业务层方法） public void printLog()&#123; System.out.println(\"Logger类中的pringLog方法开始记录日志了。。。\"); &#125;&#125; bean.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- 配置srping的Ioc,把service对象配置进来--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;!--spring中基于XML的AOP配置步骤 1、把通知Bean也交给spring来管理 2、使用aop:config标签表明开始AOP的配置 3、使用aop:aspect标签表明配置切面 id属性：是给切面提供一个唯一标识 ref属性：是指定通知类bean的Id。 4、在aop:aspect标签的内部使用对应标签来配置通知的类型 我们现在示例是让printLog方法在切入点方法执行之前之前：所以是前置通知 aop:before：表示配置前置通知 method属性：用于指定Logger类中哪个方法是前置通知 pointcut属性：用于指定切入点表达式，该表达式的含义指的是对业务层中哪些方法增强 切入点表达式的写法： 关键字：execution(表达式) 表达式： 访问修饰符 返回值 包名.包名.包名...类名.方法名(参数列表) 标准的表达式写法： public void com.itheima.service.impl.AccountServiceImpl.saveAccount() 访问修饰符可以省略 void com.itheima.service.impl.AccountServiceImpl.saveAccount() 返回值可以使用通配符，表示任意返回值 * com.itheima.service.impl.AccountServiceImpl.saveAccount() 包名可以使用通配符，表示任意包。但是有几级包，就需要写几个*. * *.*.*.*.AccountServiceImpl.saveAccount()) 包名可以使用..表示当前包及其子包 * *..AccountServiceImpl.saveAccount() 类名和方法名都可以使用*来实现通配 * *..*.*() 参数列表： 可以直接写数据类型： 基本类型直接写名称 int 引用类型写包名.类名的方式 java.lang.String 可以使用通配符表示任意类型，但是必须有参数 可以使用..表示有无参数均可，有参数可以是任意类型 全通配写法： * *..*.*(..) 实际开发中切入点表达式的通常写法： 切到业务层实现类下的所有方法 * com.itheima.service.impl.*.*(..) --&gt; &lt;!--配置logger类--&gt; &lt;bean id=\"logger\" class=\"utils.Logger\"&gt;&lt;/bean&gt; &lt;!--配置AOP--&gt; &lt;aop:config&gt; &lt;!--配置切面--&gt; &lt;aop:aspect id=\"logAdvice\" ref=\"logger\"&gt; &lt;!-- 配置通知的类型，并且建立通知方法和切入点方法的关联--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(public void service.impl.AccountServiceImpl.saveAccount())\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(..))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(int))\"&gt;&lt;/aop:before&gt;--&gt; &lt;aop:before method=\"printLog\" pointcut=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:before&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; AOPTest 12345678910public class AOPTest &#123; public static void main(String[] args) &#123; //1.获取容器 ApplicationContext ac=new ClassPathXmlApplicationContext(\"bean.xml\"); //2.获取对象 AccountService accountService= (AccountService) ac.getBean(\"accountService\"); //3.执行方法 accountService.saveAccount(); &#125;&#125; 2.3 常用通知bean.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- 配置srping的Ioc,把service对象配置进来--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;!--配置logger类--&gt; &lt;bean id=\"logger\" class=\"utils.Logger\"&gt;&lt;/bean&gt; &lt;!--配置AOP--&gt; &lt;aop:config&gt; &lt;!-- 配置切入点表达式 id属性用于指定表达式的唯一标识。expression属性用于指定表达式内容 此标签写在aop:aspect标签内部只能当前切面使用。 它还可以写在aop:aspect外面，此时就变成了所有切面可用 --&gt; &lt;aop:pointcut id=\"pt1\" expression=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:pointcut&gt; &lt;!--配置切面--&gt; &lt;aop:aspect id=\"logAdvice\" ref=\"logger\"&gt; &lt;!-- 配置通知的类型，并且建立通知方法和切入点方法的关联--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(public void service.impl.AccountServiceImpl.saveAccount())\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(..))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(int))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--配置前置通知：在切入点方法执行之前执行--&gt; &lt;!--&lt;aop:before method=\"beforePrintLog\" pointcut=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--配置后置通知：在切入点方法正常执行之后值。它和异常通知永远只能执行一个--&gt; &lt;!--&lt;aop:after-returning method=\"afterReturningPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:after-returning&gt;--&gt; &lt;!--配置异常通知：在切入点方法执行产生异常之后执行。它和后置通知永远只能执行一个--&gt; &lt;!--&lt;aop:after-throwing method=\"afterThrowingPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:after-throwing&gt;--&gt; &lt;!--配置最终通知：无论切入点方法是否正常执行它都会在其后面执行--&gt; &lt;!--&lt;aop:after method=\"afterPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:after&gt;--&gt; &lt;!-- 配置环绕通知 详细的注释请看Logger类中--&gt; &lt;aop:around method=\"arroundPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:around&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; Logger 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Logger &#123; // 用于打印日志：计划让其在切入点方法执行之前执行（切入点方法就是业务层方法） //前置通知 public void beforePrintLog() &#123; System.out.println(\"Logger类中的beforPrintLog方法开始记录日志了。。。\"); &#125; //后置通知 public void afterReturningPrintLog() &#123; System.out.println(\"Logger类中的afterReturningPrintLog方法开始记录日志了。。。\"); &#125; //异常通知 public void afterThrowingPrintLog() &#123; System.out.println(\"Logger类中的afterThrowingPrintLog方法开始记录日志了。。。\"); &#125; //最终通知 public void afterPrintLog() &#123; System.out.println(\"Logger类中的afterPrintLog方法开始记录日志了。。。\"); &#125; /** * 环绕通知 * 问题： * 当我们配置了环绕通知之后，切入点方法没有执行，而通知方法执行了。 * 分析： * 通过对比动态代理中的环绕通知代码，发现动态代理的环绕通知有明确的切入点方法调用，而我们的代码中没有。 * 解决： * Spring框架为我们提供了一个接口：ProceedingJoinPoint。该接口有一个方法proceed()，此方法就相当于明确调用切入点方法。 * 该接口可以作为环绕通知的方法参数，在程序执行时，spring框架会为我们提供该接口的实现类供我们使用。 * &lt;p&gt; * spring中的环绕通知： * 它是spring框架为我们提供的一种可以在代码中手动控制增强方法何时执行的方式。 */ public Object arroundPrintLog(ProceedingJoinPoint pjp) &#123; Object returnValue = null; try &#123; Object[] args = pjp.getArgs();//得到方法执行所需的参数 System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。前置\"); returnValue = pjp.proceed(args);//明确调用业务层方法(切入点方法) System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。后置\"); return returnValue; &#125; catch (Throwable throwable) &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。异常\"); throw new RuntimeException(throwable); &#125; finally &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。最终\"); &#125; &#125;&#125; 2.4 基于注解的 AOP 配置AccountService 123456public interface AccountService &#123; //模拟保存账户 void saveAccount();&#125; AccountServiceImpl 12345678@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Override public void saveAccount() &#123; System.out.println(\"保存......\");// int i=1/0; &#125;&#125; bean.xml 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 配置spring创建容器时要扫描的包--&gt; &lt;context:component-scan base-package=\"service,utils\"&gt;&lt;/context:component-scan&gt; &lt;!-- 配置spring开启注解AOP的支持 --&gt; &lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;&lt;/beans&gt; Logger 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Component(\"logger\")@Aspect//表示当前类是一个切面类public class Logger &#123; @Pointcut(\"execution(* service.impl.*.*(..))\") private void pt1()&#123; &#125; //前置通知 @Before(\"pt1()\") public void beforePrintLog() &#123; System.out.println(\"Logger类中的beforPrintLog方法开始记录日志了。。。\"); &#125; //后置通知 @AfterReturning(\"pt1()\") public void afterReturningPrintLog() &#123; System.out.println(\"Logger类中的afterReturningPrintLog方法开始记录日志了。。。\"); &#125; //异常通知 @AfterThrowing(\"pt1()\") public void afterThrowingPrintLog() &#123; System.out.println(\"Logger类中的afterThrowingPrintLog方法开始记录日志了。。。\"); &#125; //最终通知 @After(\"pt1()\") public void afterPrintLog() &#123; System.out.println(\"Logger类中的afterPrintLog方法开始记录日志了。。。\"); &#125; @Around(\"pt1()\") public Object arroundPrintLog(ProceedingJoinPoint pjp) &#123; Object returnValue = null; try &#123; Object[] args = pjp.getArgs();//得到方法执行所需的参数 System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。前置\"); returnValue = pjp.proceed(args);//明确调用业务层方法(切入点方法) System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。后置\"); return returnValue; &#125; catch (Throwable throwable) &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。异常\"); throw new RuntimeException(throwable); &#125; finally &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。最终\"); &#125; &#125;&#125; 不使用 XML的配置方式 123456@Configuration//@ComponentScans(value = &#123;@ComponentScan(basePackages = \"dao\"),@ComponentScan(value = \"service\")&#125;)@ComponentScan(&#123;\"dao\",\"service\"&#125;)@EnableAspectJAutoProxypublic class SpringConfiguration &#123;&#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring框架(一)","slug":"Spring框架(一)","date":"2021-05-08T13:19:59.168Z","updated":"2020-04-29T02:44:38.081Z","comments":true,"path":"30297/","link":"","permalink":"http://tonymua.top/30297/","excerpt":"1. Spring概述1.1 spring 是什么​ Spring是分层的 Java SE/EE应用 full-stack 轻量级开源框架，以 IoC（Inverse Of Control： 反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多 著名的第三方框架和类库，逐渐成为使用最多的Java EE 企业应用开源框架。 1.2 spring 的优势方便解耦，简化开发","text":"1. Spring概述1.1 spring 是什么​ Spring是分层的 Java SE/EE应用 full-stack 轻量级开源框架，以 IoC（Inverse Of Control： 反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多 著名的第三方框架和类库，逐渐成为使用最多的Java EE 企业应用开源框架。 1.2 spring 的优势方便解耦，简化开发 ​ 通过 Spring提供的 IoC容器，可以将对象间的依赖关系交由 Spring进行控制，避免硬编码所造 成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可 以更专注于上层的应用。 AOP编程的支持 ​ 通过 Spring的 AOP 功能，方便进行面向切面的编程，许多不容易用传统OOP 实现的功能可以通过 AOP 轻松应付。 声明式事务的支持 ​ 可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式方式灵活的进行事务的管理， 提高开发效率和质量。 方便程序的测试 ​ 可以用非容器依赖的编程方式进行几乎所有的测试工作，测试不再是昂贵的操作，而是随手可 做的事情。 方便集成各种优秀框架 ​ Spring可以降低各种框架的使用难度，提供了对各种优秀框架（Struts、Hibernate、Hessian、Quartz 等）的直接支持。 降低 JavaEE API的使用难度 Spring对 JavaEE API（如 JDBC、JavaMail、远程调用等）进行了薄薄的封装层，使这些 API 的 使用难度大为降低。 Java源码是经典学习范例 ​ Spring的源代码设计精妙、结构清晰、匠心独用，处处体现着大师对Java 设计模式灵活运用以 及对 Java技术的高深造诣。它的源代码无意是 Java 技术的最佳实践的范例。 2. IoC 的概念和作用2.1 什么是程序的耦合​ 耦合性(Coupling)，也叫耦合度，是对模块间关联程度的度量。耦合的强弱取决于模块间接口的复杂性、调 用模块的方式以及通过界面传送数据的多少。模块间的耦合度是指模块之间的依赖关系，包括控制关系、调用关系、数据传递关系。模块间联系越多，其耦合性越强，同时表明其独立性越差( 降低耦合性，可以提高其独立 性)。耦合性存在于各个领域，而非软件设计中独有的，但是我们只讨论软件工程中的耦合。 ​ 在软件工程中，耦合指的就是就是对象之间的依赖性。对象之间的耦合越高，维护成本越高。因此对象的设计应使类和构件之间的耦合最小。软件设计中通常用耦合度和内聚度作为衡量模块独立程度的标准。划分模块的一个 准则就是高内聚低耦合。 它有如下分类： （1） 内容耦合。当一个模块直接修改或操作另一个模块的数据时，或一个模块不通过正常入口而转入另 一个模块时，这样的耦合被称为内容耦合。内容耦合是最高程度的耦合，应该避免使用之。 （2） 公共耦合。两个或两个以上的模块共同引用一个全局数据项，这种耦合被称为公共耦合。在具有大 量公共耦合的结构中，确定究竟是哪个模块给全局变量赋了一个特定的值是十分困难的。 （3） 外部耦合 。一组模块都访问同一全局简单变量而不是同一全局数据结构，而且不是通过参数表传 递该全局变量的信息，则称之为外部耦合。 （4） 控制耦合 。一个模块通过接口向另一个模块传递一个控制信号，接受信号的模块根据信号值而进 行适当的动作，这种耦合被称为控制耦合。 （5） 标记耦合 。若一个模块 A 通过接口向两个模块 B 和 C 传递一个公共参数，那么称模块 B 和 C 之间 存在一个标记耦合。 （6） 数据耦合。模块之间通过参数来传递数据，那么被称为数据耦合。数据耦合是最低的一种耦合形 式，系统中一般都存在这种类型的耦合，因为为了完成一些有意义的功能，往往需要将某些模块的输出数据作为另一些模块的输入数据。 （7） 非直接耦合 。两个模块之间没有直接关系，它们之间的联系完全是通过主模块的控制和调用来实 现的。 总结： 耦合是影响软件复杂程度和设计质量的一个重要因素，在设计上我们应采用以下原则：如果模块间必须 存在耦合，就尽量使用数据耦合，少用控制耦合，限制公共耦合的范围，尽量避免使用内容耦合。 内聚与耦合 内聚标志一个模块内各个元素彼此结合的紧密程度，它是信息隐蔽和局部化概念的自然扩展。内聚是从 功能角度来度量模块内的联系，一个好的内聚模块应当恰好做一件事。它描述的是模块内的功能联系。耦合是软件结构中各模块之间相互连接的一种度量，耦合强弱取决于模块间接口的复杂程度、进入或访问一个模块的点以及通过接口的数据。 程序讲究的是低耦合，高内聚。就是同一个模块内的各个元素之间要高度紧密，但是各个模块之 间的相互依存度却要不那么紧密。 ​ 内聚和耦合是密切相关的，同其他模块存在高耦合的模块意味着低内聚，而高内聚的模块意味着该模块同其他模块之间是低耦合。在进行软件设计时，应力争做到高内聚，低耦合。 ​ 我们在开发中，有些依赖关系是必须的，有些依赖关系可以通过优化代码来解除的。 请看下面的示例代码： 123public class AccountServiceImpl implements IAccountService &#123; private IAccountDao accountDao = new AccountDaoImpl(); &#125; ​ 上面的代码表示： 业务层调用持久层，并且此时业务层在依赖持久层的接口和实现类。如果此时没有持久层实现类，编译 将不能通过。这种编译期依赖关系，应该在我们开发中杜绝。我们需要优化代码解决。 ​ 再比如： 早期我们的 JDBC 操作，注册驱动时，我们为什么不使用 DriverManager 的 register 方法，而是采 用 Class.forName 的方式？ 12345678910public class JdbcDemo1 &#123; public static void main(String[] args) throws Exception &#123; //1.注册驱动 //DriverManager.registerDriver(new com.mysql.jdbc.Driver()); Class.forName(\"com.mysql.jdbc.Driver\"); //2.获取连接 //3.获取预处理 sql 语句对象 //4.获取结果集 //5.遍历结果集 &#125; &#125; ​ 原因就是： 我们的类依赖了数据库的具体驱动类（MySQL），如果这时候更换了数据库品牌（比如 Oracle），需要 修改源码来重新数据库驱动。这显然不是我们想要的. 2.2 解决程序耦合的思路​ 当是我们讲解 jdbc 时，是通过反射来注册驱动的，代码如下： 1Class.forName(\"com.mysql.jdbc.Driver\");//此处只是一个字符串 ​ 此时的好处是，我们的类中不再依赖具体的驱动类，此时就算删除 mysql 的驱动 jar 包，依然可以编译（运 行就不要想了，没有驱动不可能运行成功的）。 同时，也产生了一个新的问题，mysql 驱动的全限定类名字符串是在 java 类中写死的，一旦要改还是要修改 源码。 解决这个问题也很简单，使用配置文件配置。 2.3 工厂模式解耦​ 在实际开发中我们可以把三层的对象都使用配置文件配置起来，当启动服务器应用加载的时候，让一个类中的方法通过读取配置文件，把这些对象创建出来并存起来。在接下来的使用的时候，直接拿过来用就好了。 那么，这个读取配置文件，创建和获取三层对象的类就是工厂. 3.使用 spring的 IOC解决程序耦合3.1 案例的前期准​ 我们使用的案例是，账户的业务层和持久层的依赖关系解决。在开始 spring 的配置之前，我们要先准备 一下环境。由于我们是使用 spring 解决依赖关系，并不是真正的要做增删改查操作，所以此时我们没必要写实体 类。并且我们在此处使用的是 java 工程，不是 java web 工程。 3.1.1 准备 spring 的开发包pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.1.2 创建业务层接口和实现类123456789public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao = new AccountDaoImpl(); // private AccountDao accountDao= (AccountDao) BeanFactory.getBean(\"accountDao\"); @Override public void saveAccount() &#123; accountDao.saveAccount(); &#125;&#125; 1234public interface AccountService &#123; //模拟保存账户 void saveAccount();&#125; 3.1.3 创建持久层接口和实现类123456public class AccountDaoImpl implements AccountDao &#123; @Override public void saveAccount() &#123; System.out.println(\"保存了账户\"); &#125;&#125; 123public interface AccountDao &#123; void saveAccount();&#125; 3.2 基于 XML 的配置(入门案例)3.2.1 第一步：在类的根路径下创建一个任意名称的 xml 文件（不能是中文）1234&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;/beans&gt; 3.2.2 第二步：让 spring 管理资源，在配置文件中配置 service 和 dao12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--把对象的创建交给spring来管理--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt;&lt;/bean&gt;&lt;/beans&gt; 3.2.3 测试配置是否成功1234567891011121314151617181920212223/*applicationContext的三个常用实现类： * ClassPathXmlApplicationContext：它可以加载类路径下的配置文件，要求配置文件必须在类路径下。不在的话，加载不了。(更常用) * FileSystemXmlApplicationContext：它可以加载磁盘任意路径下的配置文件(必须有访问权限） * AnnotationConfigApplicationContext：它是用于读取注解创建容器的 * * 核心容器的两个接口引发出的问题： * ApplicationContext: 单例对象适用 采用此接口 * 它在构建核心容器时，创建对象采取的策略是采用立即加载的方式。也就是说，只要一读取完配置文件马上就创建配置文件中配置的对象。 * * BeanFactory: 多例对象使用 * 它在构建核心容器时，创建对象采取的策略是采用延迟加载的方式。也就是说，什么时候根据id获取对象了，什么时候才真正的创建对象。*/public class Client &#123; public static void main(String[] args) &#123; //1.获取核心容器对象 ApplicationContext ac = new ClassPathXmlApplicationContext(\"bean.xml\");// ApplicationContext ac=new FileSystemXmlApplicationContext() //2.根据id获取Bean对象 AccountService as = (AccountService) ac.getBean(\"accountService\"); AccountDao ad=ac.getBean(\"accountDao\",AccountDao.class); as.saveAccount(); &#125;&#125; 3.3 Spring基于 XML 的 IOC 细节3.3.1 BeanFactory和 ApplicationContext 的区别BeanFactory 才是 Spring 容器中的顶层接口。ApplicationContext 是它的子接口。 BeanFactory 和 ApplicationContext 的区别： 创建对象的时间点不一样。 ApplicationContext：只要一读取配置文件，默认情况下就会创建对象。 BeanFactory：什么使用什么时候创建对象 3.3.2 ApplicationContext 接口的实现类ClassPathXmlApplicationContext： 它是从类的根路径下加载配置文件 推荐使用这种 FileSystemXmlApplicationContext： 它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。 AnnotationConfigApplicationContext: 当我们使用注解配置容器对象时，需要使用此类来创建 spring 容器。它用来读取注解。 3.3.3 IOC 中 bean 标签和管理对象细节3.3.3.1 bean 标签作用： 用于配置对象让 spring 来创建的。 默认情况下它调用的是类中的无参构造函数。如果没有无参构造函数则不能创建成功。 属性： id：给对象在容器中提供一个唯一标识。用于获取对象。 class：指定类的全限定类名。用于反射创建对象。默认情况下调用无参构造函数。 scope：指定对象的作用范围。 ​ * singleton :默认值，单例的. * prototype :多例的. * request :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 request 域中. * session :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 session 域中. * global session :WEB 项目中,应用在 Portlet 环境.如果没有 Portlet 环境那么 globalSession 相当于 session. init-method：指定类中的初始化方法名称。 destroy-method：指定类中销毁方法名称。 3.3.3.2 bean 的作用范围和生命周期单例对象：scope=”singleton” 一个应用只有一个对象的实例。它的作用范围就是整个引用。 生命周期： 对象出生：当应用加载，创建容器时，对象就被创建了。 对象活着：只要容器在，对象一直活着。 对象死亡：当应用卸载，销毁容器时，对象就被销毁了。 多例对象：scope=”prototype” 每次访问对象时，都会重新创建对象实例。 ​ 生命周期： 对象出生：当使用对象时，创建新的对象实例。 对象活着：只要对象在使用中，就一直活着。 对象死亡：当对象长时间不用时，被 java 的垃圾回收器回收了。 3.3.3.3 实例化 Bean 的三种方式第一种方式：使用默认无参构造函数 12&lt;!--在默认情况下：它会根据默认无参构造函数来创建类对象。如果 bean 中没有默认无参构造函数，将会创建失败。 --&gt;&lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\" scope=\"singleton\"&gt;&lt;/bean&gt; 第二种方式：spring管理静态工厂-使用静态工厂的方法创建对象 1234567891011121314 /** 模拟一个静态工厂，创建业务层实现类 */ public class StaticFactory &#123; public static IAccountService createAccountService()&#123; return new AccountServiceImpl(); &#125; &#125; &lt;!-- 此种方式是: 使用 StaticFactory 类中的静态方法 createAccountService 创建对象，并存入 spring 容器 id 属性：指定 bean 的 id，用于从容器中获取 class 属性：指定静态工厂的全限定类名 factory-method 属性：指定生产对象的静态方法 --&gt; &lt;bean id=\"accountService\" class=\"factory.StaticFactory\" factory-method=\"createAccountService\"&gt;&lt;/bean&gt; 第三种方式：spring管理实例工厂-使用实例工厂的方法创建对象 1234567891011121314/** 模拟一个实例工厂，创建业务层实现类 * 此工厂创建对象，必须现有工厂实例对象，再调用方法 */ public class InstanceFactory &#123; public IAccountService createAccountService()&#123; return new AccountServiceImpl(); &#125; &#125; &lt;!-- 此种方式是： 先把工厂的创建交给 spring 来管理。然后在使用工厂的 bean 来调用里面的方法 factory-bean 属性：用于指定实例工厂 bean 的 id。 factory-method 属性：用于指定实例工厂中创建对象的方法。 --&gt; &lt;bean id=\"instancFactory\" class=\"com.itheima.factory.InstanceFactory\"&gt;&lt;/bean&gt; &lt;bean id=\"accountService\" factory-bean=\"instancFactory\" factory-method=\"createAccountService\"&gt;&lt;/bean&gt; 3.3.4 spring 的依赖注入3.3.4.1 依赖注入的概念依赖注入：Dependency Injection。 ​ 它是 spring 框架核心 ioc 的具体实现。 我们的程序在编写时，通过控制反转，把对象的创建交给了 spring，但是代码中不可能出现没有依赖的情况。 ioc 解耦只是降低他们的依赖关系，但不会消除。 例如：我们的业务层仍会调用持久层的方法。 那这种业务层和持久层的依赖关系，在使用 spring 之后，就让 spring 来维护了。 简单的说，就是坐等框架把持久层对象传入业务层，而不用我们自己去获取。 3.3.4.2 构造函数注入​ 顾名思义，就是使用类中的构造函数，给成员变量赋值。注意，赋值的操作不是我们自己做的，而是通过配置的方式，让 spring 框架来为我们注入。具体代码如下： 12345678910111213141516public class AccountServiceImpl implements AccountService &#123; //如果是经常变化的数据,并不适用注入的方式 private String name; private Integer age; private Date birthday; public AccountServiceImpl(String name,Integer age,Date birthday)&#123; this.name=name; this.age=age; this.birthday=birthday; &#125; @Override public void saveAccount() &#123; System.out.println(\"service中的saveAccount方法执行了\"+name+\"---\"+age+\"---\"+birthday); &#125;&#125; 123456789101112131415161718192021222324&lt;!--构造函数注入： 使用的标签:constructor-arg 标签出现的位置：bean标签的内部 标签中的属性 type：用于指定要注入的数据的数据类型，该数据类型也是构造函数中某个或某些参数的类型 index：用于指定要注入的数据给构造函数中指定索引位置的参数赋值。索引的位置是从0开始 name：用于指定给构造函数中指定名称的参数赋值 常用的 =============以上三个用于指定给构造函数中哪个参数赋值=============================== value：用于提供基本类型和String类型的数据 ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象 优势： 在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。 弊端： 改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据，也必须提供。--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\" scope=\"singleton\"&gt; &lt;constructor-arg name=\"name\" value=\"test\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"age\" value=\"18\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"birthday\" ref=\"now\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--配置一个日期对象--&gt; &lt;bean id=\"now\" class=\"java.util.Date\"&gt;&lt;/bean&gt; 3.3.4.3 set 方法注入​ 顾名思义，就是在类中提供需要注入成员的 set 方法。具体代码如下： 123456789101112public class AccountServiceImpl implements IAccountService &#123; private String name; private Integer age; private Date birthday; public void setName(String name) &#123; this.name = name; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; @Override public void saveAccount() &#123; System.out.println(name+\",\"+age+\",\"+birthday); &#125; &#125; 1234567891011121314151617&lt;!-- set方法注入 更常用的方式 涉及的标签：property 出现的位置：bean标签的内部 标签的属性 name：用于指定注入时所调用的set方法名称 value：用于提供基本类型和String类型的数据 ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象 优势： 创建对象时没有明确的限制，可以直接使用默认构造函数 弊端： 如果有某个成员必须有值，则获取对象是有可能set方法没有执行。 --&gt; &lt;bean id=\"accountService2\" class=\"service.impl.AccountServiceImpl2\" scope=\"singleton\"&gt; &lt;property name=\"name\" value=\"test2\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"18\"&gt;&lt;/property&gt; &lt;property name=\"birthday\" ref=\"now\"&gt;&lt;/property&gt; &lt;/bean&gt; 3.3.4.4 注入集合属性123456789101112131415161718192021222324252627282930313233343536public class AccountServiceImpl3 implements AccountService &#123; private String[] myStrs; private List&lt;String&gt; myList; private Set&lt;String&gt; mySet; private Map&lt;String,String&gt; myMap; private Properties myProps; public void setMyStrs(String[] myStrs) &#123; this.myStrs = myStrs; &#125; public void setMyList(List&lt;String&gt; myList) &#123; this.myList = myList; &#125; public void setMySet(Set&lt;String&gt; mySet) &#123; this.mySet = mySet; &#125; public void setMyMap(Map&lt;String, String&gt; myMap) &#123; this.myMap = myMap; &#125; public void setMyProps(Properties myProps) &#123; this.myProps = myProps; &#125; @Override public void saveAccount() &#123; System.out.println(Arrays.toString(myStrs)); System.out.println(myList); System.out.println(mySet); System.out.println(myMap); System.out.println(myProps); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!-- 复杂类型的注入/集合类型的注入 用于给List结构集合注入的标签： list array set 用于个Map结构集合注入的标签: map props 结构相同，标签可以互换 --&gt; &lt;bean id=\"accountService3\" class=\"service.impl.AccountServiceImpl3\"&gt; &lt;property name=\"myStrs\"&gt; &lt;array&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;ccc&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;property name=\"myList\"&gt; &lt;list&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;ccc&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=\"mySet\"&gt; &lt;set&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;ccc&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;property name=\"myProps\"&gt; &lt;props&gt; &lt;prop key=\"A\"&gt;aaa&lt;/prop&gt; &lt;prop key=\"b\"&gt;bbb&lt;/prop&gt; &lt;prop key=\"c\"&gt;ccc&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;property name=\"myMap\"&gt; &lt;map&gt; &lt;entry key=\"a\" value=\"aaa\"&gt;&lt;/entry&gt; &lt;entry key=\"b\"&gt; &lt;value&gt;bbb&lt;/value&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringMVC框架(二)","slug":"SpringMVC框架(二)","date":"2021-05-08T13:19:59.167Z","updated":"2020-04-29T02:44:38.101Z","comments":true,"path":"38896/","link":"","permalink":"http://tonymua.top/38896/","excerpt":"1. 响应数据和结果视图1.1 返回值分类1.1.1 字符串(String)​ controller 方法返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址。 1234567891011121314// 返回值类型为String @RequestMapping(\"/testString\") public String testString(Model model) &#123; System.out.println(\"testString方法执行了\"); //模拟从数据库中查询User对象 User user = new User(); user.setUsername(\"test\"); user.setPassword(\"123\"); user.setAge(12); model.addAttribute(\"user\", user); return \"success\"; &#125;","text":"1. 响应数据和结果视图1.1 返回值分类1.1.1 字符串(String)​ controller 方法返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址。 1234567891011121314// 返回值类型为String @RequestMapping(\"/testString\") public String testString(Model model) &#123; System.out.println(\"testString方法执行了\"); //模拟从数据库中查询User对象 User user = new User(); user.setUsername(\"test\"); user.setPassword(\"123\"); user.setAge(12); model.addAttribute(\"user\", user); return \"success\"; &#125; 1.1.2 void123456789101112131415 // 返回值类型为void @RequestMapping(\"/testVoid\") //如果没有返回值,默认请求testVoid.jsp public void testVoid(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; System.out.println(\"testVoid方法执行了\");// 编写请求转发的程序// 请求转发:一次请求,不用编写项目的名称// request.getRequestDispatcher(\"/WEB-INF/pages/success.jsp\").forward(request,response);// 重定向:两次请求// response.sendRedirect(request.getContextPath()+\"/index.jsp\");// 直接进行响应 response.setCharacterEncoding(\"UTF-8\"); response.setContentType(\"text/html;charset=UTF-8\"); response.getWriter().print(\"直接响应\"); return; &#125; 1.1.3 ModelAndView​ ModelAndView 是 SpringMVC 为我们提供的一个对象，该对象也可以用作控制器方法的返回值。 1234567891011121314151617 // 返回ModelAndView @RequestMapping(\"/testModelAndView\") public ModelAndView testModelAndView() &#123; System.out.println(\"testModelAndView方法执行了\"); //创建ModelAndView对象 ModelAndView modelAndView = new ModelAndView(); User user = new User(); user.setUsername(\"test\"); user.setPassword(\"123\"); user.setAge(12);// 把user对象存储到modelAndView对象中,也会把user对象存入到request对象 modelAndView.addObject(\"user\", user);// 跳转到哪个页面 modelAndView.setViewName(\"success\"); return modelAndView; &#125; 响应的 jsp代码： 123456789101112&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;成功!&lt;/h3&gt; $&#123;user.username&#125; $&#123;user.age&#125;&lt;/body&gt;&lt;/html&gt; ​ 我们在页面上上获取使用的是 requestScope.username 取的，所以返回 ModelAndView 类型时，浏览器跳转只能是请求转发。 1.2 转发和重定向​ controller 方法在提供了 String 类型的返回值之后，默认就是请求转发。需要注意的是，如果用了 formward：则路径必须写成实际视图 url，不能写逻辑视图。 它相当于“request.getRequestDispatcher(“url”).forward(request,response)”。使用请求 转发，既可以转发到 jsp，也可以转发到其他的控制器方法。 ​ contrller 方法提供了一个 String 类型返回值之后，它需要在返回值里使用:redirect:它相当于“response.sendRedirect(url)”。需要注意的是，如果是重定向到 jsp 页面，则 jsp 页面不 能写在 WEB-INF 目录中，否则无法找到。 123456789// 使用关键字的方式进行转发或者重定向 @RequestMapping(\"/testForwardOrRedirect\") public String testForwardOrRedirect() &#123; System.out.println(\"testForwardOrRedirect方法执行了\");// 请求转发// return \"forward:/WEB-INF/pages/success.jsp\";// 重定向 return \"redirect:/index.jsp\"; &#125; 1.3 ResponseBody 响应 json 数据1.3.1 使用说明作用：该注解用于将 Controller 的方法返回的对象，通过 HttpMessageConverter 接口转换为指定格式的 数据如：json,xml 等，通过 Response 响应给客户端 1.3.2 使用示例需求：使用@ResponseBody 注解实现将 controller 方法返回对象转换为 json 响应给客户端。 前置知识点：Springmvc 默认用 MappingJacksonHttpMessageConverter 对 json 数据进行转换，需要加入 jackson 的包。 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; 注意：2.7.0以下的版本用不了 jsp 中的代码： 123456789101112131415161718192021222324252627282930313233343536&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"js/jquery.min.js\"&gt;&lt;/script&gt; &lt;script&gt; // 页面加载，绑定单击事件 $(function()&#123; $(\"#btn\").click(function()&#123; // alert(\"hello btn\"); // 发送ajax请求 $.ajax(&#123; // 编写json格式，设置属性和值 url:\"user/testAjax\", contentType:\"application/json;charset=UTF-8\", data:'&#123;\"username\":\"hehe\",\"password\":\"123\",\"age\":30&#125;', dataType:\"json\", type:\"post\", success:function(data)&#123; // data:服务器端响应的json的数据，进行解析 alert(data); alert(data.username); alert(data.password); alert(data.age); &#125; &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;button id=\"btn\"&gt;发送ajax的请求&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 控制器中的代码： 12345678910111213// 模拟异步请求响应 @RequestMapping(\"/testAjax\") public @ResponseBody User testAjax(@RequestBody User user) &#123; System.out.println(\"testAjax方法执行了...\"); // 客户端发送ajax的请求，传的是json字符串，后端把json字符串封装到user对象中 System.out.println(user); // 做响应，模拟查询数据库 user.setUsername(\"haha\"); user.setAge(40); // 做响应 return user; &#125; 前端控制器: 1234&lt;!--前端控制器，哪些静态资源不拦截--&gt; &lt;mvc:resources location=\"/css/\" mapping=\"/css/**\"/&gt; &lt;mvc:resources location=\"/images/\" mapping=\"/images/**\"/&gt; &lt;mvc:resources location=\"/js/\" mapping=\"/js/**\"/&gt; 2.SpringMVC实现文件上传2.1 文件上传的回顾2.1.1 文件上传的必要前提A. form 表单的 enctype 取值必须是：multipart/form-data (默认值是:application/x-www-form-urlencoded) enctype:是表单请求正文的类型 B. method 属性取值必须是 Post C. 提供一个文件选择域 1&lt;input type=\"file\" /&gt; 2.1.2 文件上传的原理分析​ 当 form 表单的 enctype 取值不是默认值后，request.getParameter()将失效。 enctype=”application/x-www-form-urlencoded”时，form 表单的正文内容是： key=value&amp;key=value&amp;key=value​ 当 form 表单的 enctype 取值为 Mutilpart/form-data 时，请求正文内容就变成： 每一部分都是 MIME 类型描述的正文—————————–7de1a433602ac 分界符Content-Disposition: form-data; name=”userName” 协议头 aaa 协议的正文—————————–7de1a433602acContent-Disposition: form-data; name=”file”;filename=”C:\\Users\\zhy\\Desktop\\fileupload_demofile\\b.txt”Content-Type: text/plain 协议的类型（MIME 类型） bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb—————————–7de1a433602ac– 2.1.3 借助第三方组件实现文件上传​ 使用 Commons-fileupload 组件实现文件上传，需要导入该组件相应的支撑 jar 包：Commons-fileupload 和commons-io。commons-io 不属于文件上传组件的开发 jar 文件，但Commons-fileupload 组件从 1.1 版本开始，它工作时需要 commons-io 包的支持。 2.2 springmvc 传统方式的文件上传说明 ​ 传统方式的文件上传，指的是我们上传的文件和访问的应用存在于同一台服务器上。 并且上传完成之后，浏览器可能跳转。 配置文件上传的 jar 包到工程 1234567891011&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; jsp页面 1234567891011121314151617181920&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;传统方式文件上传&lt;/h3&gt; &lt;form action=\"user/fileUpload1\" method=\"post\" enctype=\"multipart/form-data\"&gt; 选择文件:&lt;input type=\"file\" name=\"upload\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"上传\"&gt;&lt;br&gt; &lt;/form&gt; &lt;h3&gt;SpringMVC方式文件上传&lt;/h3&gt; &lt;form action=\"user/fileUpload2\" method=\"post\" enctype=\"multipart/form-data\"&gt; 选择文件:&lt;input type=\"file\" name=\"upload\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"上传\"&gt;&lt;br&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 控制器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Controller@RequestMapping(\"/user\")public class UserController &#123; //传统方式文件上传 @RequestMapping(\"/fileUpload1\") public String fileUpload1(HttpServletRequest request) throws Exception&#123; System.out.println(\"传统方式文件上传...\");// 使用fileupload组件完成上传// 上传的位置 String Path = request.getSession().getServletContext().getRealPath(\"/uploads/\"); //判断该路径是否存在 File file = new File(Path); if (!file.exists())&#123; //创建该文件夹 file.mkdirs(); &#125; //解析request对象,获取上传文件项 DiskFileItemFactory fileItemFactory=new DiskFileItemFactory(); ServletFileUpload fileUpload=new ServletFileUpload(fileItemFactory); //解析request List&lt;FileItem&gt; fileItems = fileUpload.parseRequest(request); //遍历 for (FileItem fileItem:fileItems)&#123; //判断当前item对象是否是上传文件项 if (fileItem.isFormField())&#123; //普通表单项 &#125;else &#123; //上传文件项 //获取上传文件的名称 String fileItemName = fileItem.getName(); //把文件的名称设置唯一值,uuid String uuid = UUID.randomUUID().toString().replace(\"-\",\"\" ); fileItemName=uuid+\"_\"+fileItemName; //完成文件上传 fileItem.write(new File(Path,fileItemName)); //删除临时文件 fileItem.delete(); &#125; &#125; return \"success\"; &#125; //SpringMVC方式文件上传 @RequestMapping(\"/fileUpload2\") public String fileUpload2(HttpServletRequest request, MultipartFile upload) throws Exception&#123; System.out.println(\"SpringMVC方式文件上传...\"); String realPath = request.getSession().getServletContext().getRealPath(\"/uploads/\"); File file = new File(realPath); if (!file.exists())&#123; file.mkdirs(); &#125; String filename = upload.getOriginalFilename(); String uuid = UUID.randomUUID().toString().replace(\"-\", \"\"); filename=uuid+\"_\"+filename; upload.transferTo(new File(realPath,filename)); return \"success\"; &#125;&#125; 配置文件解析器 1234&lt;!--配置文件解析器--&gt; &lt;bean class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\" id=\"multipartResolver\"&gt; &lt;property name=\"maxUploadSize\" value=\"10485760\"/&gt; &lt;/bean&gt; 2.3 springmvc 跨服务器方式的文件上传2.3.1 分服务器的目的​ 在实际开发中，我们会有很多处理不同功能的服务器。例如： ​ 应用服务器：负责部署我们的应用 ​ 数据库服务器：运行我们的数据库 ​ 缓存和消息服务器：负责处理大并发访问的缓存和消息 ​ 文件服务器：负责存储用户上传文件的服务器。 (注意：此处说的不是服务器集群） ​ 分服务器处理的目的是让服务器各司其职，从而提高我们项目的运行效率。 2.3.2 准备两个 tomcat 服务器，并创建一个用于存放图片的 web 工程1.端口设置 HTTP port:9090 JMX port:1090 2.在webapp文件夹下创建文件夹images 3.web.xml中做如下配置: 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.catalina.servlets.DefaultServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;readonly&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;listings&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 2.3.3 配置 jar包12345678910&lt;dependency&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-core&lt;/artifactId&gt; &lt;version&gt;1.18.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;version&gt;1.18.1&lt;/version&gt; &lt;/dependency&gt; 2.3.4 编写控制器实现上传图片1234567891011121314151617181920//SpringMVC跨服务器文件上传 @RequestMapping(\"/fileUpload3\") public String fileUpload3(MultipartFile upload) throws Exception &#123; System.out.println(\"跨服务器文件上传...\"); //定义上传文件服务器路径 String path = \"http://localhost:9090/uploads/\"; String filename = upload.getOriginalFilename(); String uuid = UUID.randomUUID().toString().replace(\"-\", \"\"); filename = uuid + \"_\" + filename; //完成文件上传,跨服务器上传 //创建客户端对象 Client client = Client.create(); //和图片服务器进行连接 WebResource webResource = client.resource(path + filename); //上传文件 webResource.put(upload.getBytes()); return \"success\"; &#125; 2.3.5 编写 jsp 页面12345h3&gt;SpringMVC跨服务器文件上传&lt;/h3&gt; &lt;form action=\"user/fileUpload3\" method=\"post\" enctype=\"multipart/form-data\"&gt; 选择文件:&lt;input type=\"file\" name=\"upload\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"上传\"&gt;&lt;br&gt; &lt;/form&gt; 2.3.6 配置解析器1234&lt;!--配置文件解析器--&gt; &lt;bean class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\" id=\"multipartResolver\"&gt; &lt;property name=\"maxUploadSize\" value=\"10485760\"/&gt; &lt;/bean&gt; 3.SpringMVC中的异常处理3.1 异常处理的思路​ 系统中异常包括两类：预期异常和运行时异常 RuntimeException，前者通过捕获异常从而获取异常信息， 后者主要通过规范代码开发、测试通过手段减少运行时异常的发生。 系统的 dao、service、controller 出现都通过 throws Exception 向上抛出，最后由 springmvc 前端 控制器交由异常处理器进行异常处理，如下图： 3.2 实现步骤3.2.1 编写异常类和错误页面123456789101112131415161718public class SysException extends Exception &#123; //存储信息 private String message; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; public SysException(String message) &#123; this.message = message; &#125;&#125; error.jsp 123456789&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; $&#123;errorMsg&#125;&lt;/body&gt;&lt;/html&gt; 3.2.2 自定义异常处理器1234567891011121314151617public class SysExceptionResolver implements HandlerExceptionResolver &#123; @Override public ModelAndView resolveException(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) &#123; //获取异常对象 SysException exception = null; if (e instanceof SysException) &#123; exception = (SysException) e; &#125;else&#123; exception=new SysException(\"系统正在维护...\"); &#125; //创建ModelAndView对象 ModelAndView modelAndView=new ModelAndView(); modelAndView.addObject(\"errorMsg\",exception.getMessage()); modelAndView.setViewName(\"error\"); return modelAndView; &#125;&#125; 3.2.3 配置异常处理器123&lt;!--配置异常处理器--&gt; &lt;bean class=\"exception.SysExceptionResolver\" id=\"sysExceptionResolver\"/&gt; &lt;mvc:annotation-driven/&gt; 4. SpringMVC中的拦截器4.1 拦截器的作用​ Spring MVC 的处理器拦截器类似于 Servlet 开发中的过滤器 Filter，用于对处理器进行预处理和后处理。 用户可以自己定义一些拦截器来实现特定的功能。 ​ 谈到拦截器，还要向大家提一个词——拦截器链（Interceptor Chain）。拦截器链就是将拦截器按一定的顺 序联结成一条链。在访问被拦截的方法或字段时，拦截器链中的拦截器就会按其之前定义的顺序被调用。 ​ 说到这里，可能大家脑海中有了一个疑问，这不是我们之前学的过滤器吗？是的它和过滤器是有几分相似，但是也有区别，接下来我们就来说说他们的区别： ​ 过滤器是 servlet 规范中的一部分，任何 java web 工程都可以使用。 ​ 拦截器是 SpringMVC 框架自己的，只有使用了 SpringMVC 框架的工程才能用。 ​ 过滤器在 url-pattern 中配置了/*之后，可以对所有要访问的资源拦截。 ​ 拦截器它是只会拦截访问的控制器方法，如果访问的是 jsp，html,css,image 或者 js 是不会进行拦 截的。 它也是 AOP 思想的具体应用。 我们要想自定义拦截器， 要求必须实现：HandlerInterceptor 接口 4.2 自定义拦截器的步骤4.2.1 第一步：编写一个普通类实现 HandlerInterceptor 接口12345678910@Controller@RequestMapping(\"/user\")public class UserController &#123; @RequestMapping(\"/testInterceptor\") public String testInterceptor()&#123; System.out.println(\"testInterceptor方法执行了...\"); return \"success\"; &#125;&#125; 1234567891011121314151617181920212223242526public class MyInterceptor1 implements HandlerInterceptor &#123; /*预处理,controller方法执行前 return true:执行下一个拦截器,如果没有,执行controller中的方法 return false:不放行*/ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(\"MyInterceptor1方法执行了...前111\"); /*request.getRequestDispatcher(\"/WEB-INF/pages/error.jsp\").forward(request,response); return false;*/ return true; &#125;// 后处理方法，controller方法执行后，success.jsp执行之前 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; System.out.println(\"MyInterceptor1方法执行了...后111\"); &#125;// success.jsp页面执行后，该方法会执行 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; System.out.println(\"MyInterceptor1执行了...最后111\"); &#125;&#125; index.jsp 1234567891011&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;拦截器&lt;/h3&gt; &lt;a href=\"user/testInterceptor\"&gt;拦截器&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; success.jsp 12345678910&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;执行成功!&lt;/h3&gt; &lt;% System.out.println(\"success.jsp执行了..\");%&gt;&lt;/body&gt;&lt;/html&gt; error.jsp 123456789&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;错误页面!&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 4.2.2 第二步：配置拦截器123456789101112&lt;!--配置拦截器--&gt; &lt;mvc:interceptors&gt; &lt;!--配置拦截器--&gt; &lt;mvc:interceptor&gt; &lt;!--要拦截的具体方法--&gt; &lt;mvc:mapping path=\"/user/*\"/&gt; &lt;!--不要拦截的具体方法 &lt;mvc:exclude-mapping path=\"\"/&gt;--&gt; &lt;!--配置拦截器对象--&gt; &lt;bean class=\"interceptor.MyInterceptor1\"/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 4.3 拦截器的细节4.3.1 拦截器的放行​ 放行的含义是指，如果有下一个拦截器就执行下一个，如果该拦截器处于拦截器链的最后一个，则执行控制器中的方法。 4.3.2 拦截器中方法的说明1234567891011121314151617181920212223public interface HandlerInterceptor &#123; /** * 如何调用：按拦截器定义顺序调用 * 何时调用：只要配置了都会调用 * 有什么用：如果程序员决定该拦截器对请求进行拦截处理后还要调用其他的拦截器，或者是业务处理器去 进行处理，则返回 true。 如果程序员决定不需要再调用其他的组件去处理请求，则返回 false。 */ default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception &#123; return true; &#125; /** * 如何调用：按拦截器定义逆序调用 * 何时调用：在拦截器链内所有拦截器返成功调用 * 有什么用：在业务处理器处理完请求后，但是 DispatcherServlet 向客户端返回响应前被调用， 在该方法中对用户请求 request 进行处理。 */ default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,@Nullable ModelAndView modelAndView) throws Exception &#123; &#125; /** * 如何调用：按拦截器定义逆序调用 * 何时调用：只有 preHandle 返回 true 才调用 * 有什么用：在 DispatcherServlet 完全处理完请求后被调用， 可以在该方法中进行一些资源清理的操作。 */ default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123; &#125; &#125; 4.3.3 拦截器的作用路径1234567891011121314151617&lt;!--配置拦截器--&gt; &lt;mvc:interceptors&gt; &lt;!--配置拦截器--&gt; &lt;mvc:interceptor&gt; &lt;!--要拦截的具体方法--&gt; &lt;mvc:mapping path=\"/user/*\"/&gt; &lt;!--不要拦截的具体方法 &lt;mvc:exclude-mapping path=\"\"/&gt;--&gt; &lt;!--配置拦截器对象--&gt; &lt;bean class=\"interceptor.MyInterceptor1\"/&gt; &lt;/mvc:interceptor&gt; &lt;!--配置第二个拦截器--&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/**\"/&gt; &lt;bean class=\"interceptor.MyInterceptor2\"/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 4.3.4 多个拦截器的执行顺序 4.4 拦截器的简单案例（验证用户是否登录)4.4.1 实现思路1、有一个登录页面，需要写一个 controller 访问页面 2、登录页面有一提交表单的动作。需要在 controller 中处理。 ​ 2.1、判断用户名密码是否正确 ​ 2.2、如果正确 向 session 中写入用户信息 ​ 2.3、返回登录成功。 3、拦截用户请求，判断用户是否登录 ​ 3.1、如果用户已经登录。放行 ​ 3.2、如果用户未登录，跳转到登录页面 4.4.2 控制器代码1234567891011121314151617//登陆页面 @RequestMapping(\"/login\") public String login(Model model)throws Exception&#123; return \"login\"; &#125; //登陆提交 //userid：用户账号，pwd：密码 @RequestMapping(\"/loginsubmit\") public String loginsubmit(HttpSession session,String userid,String pwd)throws Exception&#123; //向 session 记录用户身份信息 session.setAttribute(\"activeUser\", userid); return \"redirect:/main.jsp\"; &#125; //退出@RequestMapping(\"/logout\") public String logout(HttpSession session)throws Exception&#123; //session 过期 session.invalidate(); return \"redirect:index.jsp\"; &#125; 4.4.3 拦截器代码123456789101112131415161718public class LoginInterceptor implements HandlerInterceptor&#123; @Override Public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //如果是登录页面则放行 if(request.getRequestURI().indexOf(\"login.action\")&gt;=0)&#123; return true; &#125; HttpSession session = request.getSession(); //如果用户已登录也放行 if(session.getAttribute(\"user\")!=null)&#123; return true; &#125; //用户没有登录挑战到登录页面 request.getRequestDispatcher(\"/WEB-INF/jsp/login.jsp\").forward(request, response); return false; &#125; &#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringMVC框架(一)","slug":"SpringMVC框架(一)","date":"2021-05-08T13:19:59.165Z","updated":"2020-04-29T02:44:38.126Z","comments":true,"path":"22356/","link":"","permalink":"http://tonymua.top/22356/","excerpt":"1.SpringMVC的基本概念1.1 关于三层架构和MVC1.1.1 三层架构​ 我们的开发架构一般都是基于两种形式，一种是 C/S 架构，也就是客户端/服务器，另一种是 B/S 架构，也就 是浏览器服务器。在 JavaEE 开发中，几乎全都是基于 B/S架构的开发。那么在 B/S架构中，系统标准的三层架构 包括：表现层、业务层、持久层。三层架构在我们的实际开发中使用的非常多，所以我们课程中的案例也都是基于三层架构设计的。 ​ 三层架构中，每一层各司其职，接下来我们就说说每层都负责哪些方面：","text":"1.SpringMVC的基本概念1.1 关于三层架构和MVC1.1.1 三层架构​ 我们的开发架构一般都是基于两种形式，一种是 C/S 架构，也就是客户端/服务器，另一种是 B/S 架构，也就 是浏览器服务器。在 JavaEE 开发中，几乎全都是基于 B/S架构的开发。那么在 B/S架构中，系统标准的三层架构 包括：表现层、业务层、持久层。三层架构在我们的实际开发中使用的非常多，所以我们课程中的案例也都是基于三层架构设计的。 ​ 三层架构中，每一层各司其职，接下来我们就说说每层都负责哪些方面： ​ 表现层：也就是我们常说的web层。它负责接收客户端请求，向客户端响应结果，通常客户端使用http协议请求 web 层，web 需要接收 http 请求，完成 http 响应。 表现层包括展示层和控制层：控制层负责接收请求，展示层负责结果的展示。 表现层依赖业务层，接收到客户端请求一般会调用业务层进行业务处理，并将处理结果响应给客户端。 表现层的设计一般都使用 MVC 模型。（MVC 是表现层的设计模型，和其他层没有关系 ​ 业务层：也就是我们常说的 service 层。它负责业务逻辑处理，和我们开发项目的需求息息相关。web 层依赖业 务层，但是业务层不依赖 web 层。 业务层在业务处理时可能会依赖持久层，如果要对数据持久化需要保证事务一致性。（也就是我们说的， 事务应该放到业务层来控制） ​ 持久层： 也就是我们是常说的 dao 层。负责数据持久化，包括数据层即数据库和数据访问层，数据库是对数据进 行持久化的载体，数据访问层是业务层和持久层交互的接口，业务层需要通过数据访问层将数据持久化到数据库中。通俗的讲，持久层就是和数据库交互，对数据库表进行曾删改查的。 1.1.2 MVC 模型MVC 全名是 Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写， 是一种用于设计创建 Web 应用程序表现层的模式。MVC 中每个部分各司其职： Model（模型）： 通常指的就是我们的数据模型。作用一般情况下用于封装数据。 ​ View（视图）：通常指的就是我们的 jsp 或者 html。作用一般就是展示数据的。 通常视图是依据模型数据创建的。 ​ Controller（控制器）：是应用程序中处理用户交互的部分。作用一般就是处理程序逻辑的。 它相对于前两个不是很好理解，这里举个例子： ​ 例如：我们要保存一个用户的信息，该用户信息中包含了姓名，性别，年龄等等。 这时候表单输入要求年龄必须是 1~100 之间的整数。姓名和性别不能为空。并且把数据填充 到模型之中。 此时除了 js 的校验之外，服务器端也应该有数据准确性的校验，那么校验就是控制器的该做 的。 ​ 当校验失败后，由控制器负责把错误页面展示给使用者。如果校验成功，也是控制器负责把数据填充到模型，并且调用业务层实现完整的业务需求 1.2 SpringMVC 概述1.2.1 SpringMVC 是什么​ SpringMVC 是一种基于 Java 的实现 MVC 设计模型的请求驱动类型的轻量级 Web 框架，属于 Spring FrameWork 的后续产品，已经融合在 Spring Web Flow 里面。Spring 框架提供了构建 Web 应用程序的全功 能 MVC 模块。使用 Spring 可插入的 MVC 架构，从而在使用 Spring 进行 WEB 开发时，可以选择使用 Spring 的 Spring MVC 框架或集成其他 MVC 开发框架，如 Struts1(现在一般不用)，Struts2 等。 ​ SpringMVC 已经成为目前最主流的 MVC 框架之一，并且随着 Spring3.0 的发布，全面超越 Struts2，成 为最优秀的 MVC 框架。 它通过一套注解，让一个简单的 Java 类成为处理请求的控制器，而无须实现任何接口。同时它还支持 RESTful 编程风格的请求。 1.2.2 SpringMVC 在三层架构的位置 1.2.3 SpringMVC 的优势​ 1、清晰的角色划分： 前端控制器（DispatcherServlet） ​ 请求到处理器映射（HandlerMapping） ​ 处理器适配器（HandlerAdapter） ​ 视图解析器（ViewResolver） ​ 处理器或页面控制器（Controller） ​ 验证器（ Validator） ​ 命令对象（Command 请求参数绑定到的对象就叫命令对象） ​ 表单对象（Form Object 提供给表单展示和提交到的对象就叫表单对象）。 ​ 2、分工明确，而且扩展点相当灵活，可以很容易扩展，虽然几乎不需要。 ​ 3、由于命令对象就是一个 POJO，无需继承框架特定 API，可以使用命令对象直接作为业务对象。 ​ 4、和 Spring 其他框架无缝集成，是其它 Web 框架所不具备的。 ​ 5、可适配，通过 HandlerAdapter 可以支持任意的类作为处理器。 ​ 6、可定制性，HandlerMapping、ViewResolver 等能够非常简单的定制。 ​ 7、功能强大的数据验证、格式化、绑定机制。 ​ 8、利用 Spring 提供的 Mock 对象能够非常简单的进行 Web 层单元测试。 ​ 9、本地化、主题的解析的支持，使我们更容易进行国际化和主题的切换。 ​ 10、强大的 JSP 标签库，使 JSP 编写更容易。 ​ ………………还有比如RESTful风格的支持、简单的文件上传、约定大于配置的契约式编程支持、基于注解的零配 置支持等等。 2.SpringMVC的入门2.1 SpringMVC入门案例配置pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;springmvc_start&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;springmvc_start Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.9&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.9&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;springmvc_start&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; web.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置Servlet的初始化参数，读取springmvc的配置文件，创建spring容器 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 配置servlet启动时加载对象 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--配置解决中文乱码的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; springmvc.xml 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--开启注解扫描--&gt; &lt;context:component-scan base-package=\"controller\"/&gt; &lt;!--视图解析器对象--&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--文件所在目录--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;!--文件后缀名--&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--配置自定义类型转换器--&gt; &lt;bean id=\"conversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\"&gt; &lt;property name=\"converters\"&gt; &lt;set&gt; &lt;bean class=\"utils.StringToDateConverter\"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 开启SpringMVC框架注解的支持 --&gt; &lt;mvc:annotation-driven conversion-service=\"conversionService\"/&gt;&lt;/beans&gt; 2.2 SpringMVC入门案例jsp页面 index.jsp 123456789101112&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;入门程序&lt;/h3&gt; &lt;%-- &lt;a href=\"hello\"&gt;入门程序&lt;/a&gt;--%&gt; &lt;a href=\"testRequestMapping?username=test\"&gt;RequestMapping注解&lt;/a&gt; &lt;%--&lt;a href=\"user/testRequestMapping\"&gt;RequestMapping注解&lt;/a&gt;--%&gt;&lt;/body&gt;&lt;/html&gt; param.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%--请求参数绑定--%&gt; &lt;a href=\"param/testParam?username=test&amp;password=123\"&gt;请求参数绑定&lt;/a&gt; &lt;%--把数据封装到Account类中--%&gt; &lt;form action=\"param/saveAccount\" method=\"post\"&gt; 用户名:&lt;input type=\"text\" name=\"username\" /&gt;&lt;br/&gt; &lt;%--name和javaBean中的属性对应--%&gt; 密码:&lt;input type=\"text\" name=\"password\" /&gt;&lt;br/&gt; 金额:&lt;input type=\"text\" name=\"money\" /&gt;&lt;br/&gt; 用户姓名:&lt;input type=\"text\" name=\"user.uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"user.age\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;%--把数据封装到Account类中,类中存在list和map的集合--%&gt; &lt;form action=\"param/saveAccount\" method=\"post\"&gt; 用户名:&lt;input type=\"text\" name=\"username\" /&gt;&lt;br/&gt; &lt;%--name和javaBean中的属性对应--%&gt; 密码:&lt;input type=\"text\" name=\"password\" /&gt;&lt;br/&gt; 金额:&lt;input type=\"text\" name=\"money\" /&gt;&lt;br/&gt; 用户姓名:&lt;input type=\"text\" name=\"list[0].uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"list[0].age\" /&gt;&lt;br/&gt; 用户姓名:&lt;input type=\"text\" name=\"map['one'].uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"map['one']user.age\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;%--自定义类型转换器--%&gt; &lt;form action=\"param/saveUser\" method=\"post\"&gt; 用户姓名:&lt;input type=\"text\" name=\"uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"age\" /&gt;&lt;br/&gt; 用户生日:&lt;input type=\"text\" name=\"date\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;%--Servlet原生API--%&gt; &lt;a href=\"param/testServlet\"&gt;Servlet原生API&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; anno.jsp 123456789101112131415161718192021222324252627282930313233343536&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%--常用的注解--%&gt; &lt;a href=\"anno/testRequestParam?name=哈哈\"&gt;RequestParam&lt;/a&gt;&lt;br&gt; &lt;form action=\"anno/testRequestBody\" method=\"post\"&gt; 用户姓名:&lt;input type=\"text\" name=\"uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"age\" /&gt;&lt;br/&gt; 用户生日:&lt;input type=\"text\" name=\"date\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;a href=\"anno/testPathVariable/10\"&gt;PathVariable&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/testRequestHeader\"&gt;RequestHeader&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/testCookieValue\"&gt;CookieValue&lt;/a&gt;&lt;br&gt; &lt;form action=\"anno/testModelAttribute\" method=\"post\"&gt; 用户姓名:&lt;input type=\"text\" name=\"uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"age\" /&gt;&lt;br/&gt; &lt;%--用户生日:&lt;input type=\"text\" name=\"date\" /&gt;&lt;br/&gt;--%&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;a href=\"anno/testSessionAttributes\"&gt;SessionAttributes&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/getSessionAttributes\"&gt;getSessionAttributes&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/delSessionAttributes\"&gt;delSessionAttributes&lt;/a&gt;&lt;br&gt;&lt;/body&gt;&lt;/html&gt; success.jsp 1234567891011&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;成功!&lt;/h3&gt; $&#123;msg&#125; $&#123;sessionScope&#125;&lt;/body&gt;&lt;/html&gt; 2.3 SpringMVC入门案例代码Account 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Account implements Serializable &#123; private String username; private String password; private Double money;// private User user; private List&lt;User&gt; list; private Map&lt;String,User&gt; map; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; /* public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125;*/ public List&lt;User&gt; getList() &#123; return list; &#125; public void setList(List&lt;User&gt; list) &#123; this.list = list; &#125; public Map&lt;String, User&gt; getMap() &#123; return map; &#125; public void setMap(Map&lt;String, User&gt; map) &#123; this.map = map; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"username='\" + username + '\\'' + \", password='\" + password + '\\'' + \", money=\" + money + \", list=\" + list + \", map=\" + map + '&#125;'; &#125;&#125; User 1234567891011121314151617181920212223242526272829303132333435363738public class User implements Serializable &#123; private String uname; private Integer age; private Date date; public String getUname() &#123; return uname; &#125; public void setUname(String uname) &#123; this.uname = uname; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public Date getDate() &#123; return date; &#125; public void setDate(Date date) &#123; this.date = date; &#125; @Override public String toString() &#123; return \"User&#123;\" + \"uname='\" + uname + '\\'' + \", age=\" + age + \", date=\" + date + '&#125;'; &#125;&#125; HelloController 123456789101112131415161718//控制器类@Controller//@RequestMapping(path = \"user\") 此时对应&lt;a href=\"user/testRequestMapping\"&gt;RequestMapping注解&lt;/a&gt;public class HelloController &#123; @RequestMapping(path = \"/hello\") public String sayHello()&#123; System.out.println(\"Hello SpringMVC\"); return \"success\"; &#125; @RequestMapping(path =\"/testRequestMapping\",method =&#123;RequestMethod.GET&#125;,params =&#123;\"username=test\"&#125;,headers =&#123;\"Accept\"&#125; )// @RequestMapping(value =\"/testRequestMapping\" ) public String testRequestMapping()&#123; System.out.println(\"测试RequestMapping注解...\"); return \"success\"; &#125;&#125; ParamController 1234567891011121314151617181920212223242526272829303132333435363738//请求参数绑定@Controller@RequestMapping(\"/param\")public class ParamController &#123; @RequestMapping(\"/testParam\") public String testParam(String username,String password)&#123; System.out.println(\"testParam执行了...\"); System.out.println(\"username:\"+username+\"---\"+\"password:\"+password); return \"success\"; &#125;// 请求参数绑定把数据封装到JavaBean的类中 @RequestMapping(\"/saveAccount\") public String saveAccount(Account account)&#123; System.out.println(\"saveAccount执行了...\"); System.out.println(account); return \"success\"; &#125;//自定义类型转换器 @RequestMapping(\"/saveUser\") public String saveUser(User user)&#123; System.out.println(\"saveUser执行了...\"); System.out.println(user); return \"success\"; &#125;// Servlet原生API @RequestMapping(\"/testServlet\") public String testServlet(HttpServletRequest request, HttpServletResponse response)&#123; System.out.println(\"testServlet执行了...\"); System.out.println(request); HttpSession session = request.getSession(); System.out.println(session); ServletContext servletContext = session.getServletContext(); System.out.println(servletContext); System.out.println(response); return \"success\"; &#125;&#125; AnnoController 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101//常用的注解@Controller@RequestMapping(\"/anno\")@SessionAttributes(value = &#123;\"msg\"&#125;) //把msg=test存入到session域对象中public class AnnoController &#123; @RequestMapping(\"/testRequestParam\") public String testRequestParam(@RequestParam(name = \"name\") String username) &#123; System.out.println(\"testRequestParam执行了...\"); System.out.println(username); return \"success\"; &#125; // 获取到请求体的内容 @RequestMapping(\"/testRequestBody\") public String testRequestBody(@RequestBody String body) &#123; System.out.println(\"testRequestParam执行了...\"); System.out.println(body); return \"success\"; &#125; // PathVariable注解 @RequestMapping(value = \"/testPathVariable/&#123;sid&#125;\", method = RequestMethod.PUT) public String testPathVariable(@PathVariable(name = \"sid\") String id) &#123; System.out.println(\"testPathVariable执行了...\"); System.out.println(\"id\" + id); return \"success\"; &#125; // RequestHeader注解,获取请求头的值 @RequestMapping(value = \"/testRequestHeader\") public String testRequestHeader(@RequestHeader(value = \"Accept\") String header) &#123; System.out.println(\"testPathVariable执行了...\"); System.out.println(\"header:\" + header); return \"success\"; &#125; // CookieValue注解,获取Cookie的值 @RequestMapping(value = \"/testCookieValue\") public String testCookieValue(@CookieValue(value = \"JSESSIONID\") String cookieValue) &#123; System.out.println(\"testCookieValue执行了...\"); System.out.println(\"cookieValue:\" + cookieValue); return \"success\"; &#125; // ModelAttribute注解 @RequestMapping(value = \"/testModelAttribute\") public String testModelAttribute(@ModelAttribute(\"test\") User user) &#123; System.out.println(\"testModelAttribute执行了...\"); System.out.println(user); return \"success\"; &#125;// 该方法会先执行 /*@ModelAttribute public User showUser(String uname)&#123; System.out.println(\"showUser执行了...\"); //通过用户查询数据库(模拟) User user=new User(); user.setUname(uname); user.setAge(20); user.setDate(new Date()); return user; &#125;*/ @ModelAttribute public void showUser(String uname, Map&lt;String, User&gt; map) &#123; System.out.println(\"showUser执行了...\"); //通过用户查询数据库(模拟) User user = new User(); user.setUname(uname); user.setAge(20); user.setDate(new Date()); map.put(\"test\", user); &#125; // SessionAttributes注解 @RequestMapping(value = \"/testSessionAttributes\") public String testSessionAttributes(Model model) &#123; System.out.println(\"testSessionAttributes执行了...\"); //底层会存储到request域对象中 model.addAttribute(\"msg\",\"test\"); return \"success\"; &#125; // 获取值 @RequestMapping(value = \"/getSessionAttributes\") public String getSessionAttributes(ModelMap modelMap) &#123; System.out.println(\"getSessionAttributes执行了...\"); String msg = (String) modelMap.get(\"msg\"); System.out.println(msg); return \"success\"; &#125; // 删除值 @RequestMapping(value = \"/delSessionAttributes\") public String delSessionAttributes(SessionStatus sessionStatus) &#123; System.out.println(\"delSessionAttributes执行了...\"); sessionStatus.setComplete(); return \"success\"; &#125;&#125; StringToDateConverter 123456789101112131415161718//把字符串转换日期public class StringToDateConverter implements Converter&lt;String, Date&gt; &#123; @Override public Date convert(String source) &#123; //判断 if (source==null)&#123; throw new RuntimeException(\"请您传入数据...\"); &#125; DateFormat dateFormat=new SimpleDateFormat(\"yyyy-MM-dd\"); try &#123; //把字符串转换成日期 return dateFormat.parse(source); &#125; catch (Exception e) &#123; throw new RuntimeException(\"数据类型转换出现错误\"); &#125; &#125;&#125; 2.4 入门案例中涉及的组件2.4.1 DispatcherServlet：前端控制器​ 用户请求到达前端控制器，它就相当于 mvc 模式中的 c，dispatcherServlet 是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet 的存在降低了组件之间的耦合性。 2.4.2 HandlerMapping：处理器映射器​ HandlerMapping 负责根据用户请求找到 Handler 即处理器，SpringMVC 提供了不同的映射器实现不同的 映射方式，例如：配置文件方式，实现接口方式，注解方式等。 2.4.3 Handler：处理器​ 它就是我们开发中要编写的具体业务控制器。由 DispatcherServlet 把用户请求转发到 Handler。由 Handler 对具体的用户请求进行处理。 2.4.4 HandlAdapter：处理器适配器​ 通过 HandlerAdapter 对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理 器进行执行。 2.4.5 View Resolver：视图解析器​ View Resolver 负责将处理结果生成 View 视图，View Resolver 首先根据逻辑视图名解析成物理视图名 即具体的页面地址，再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户。 2.4.6 View：视图​ SpringMVC 框架提供了很多的 View 视图类型的支持，包括：jstlView、freemarkerView、pdfView 等。我们最常用的视图就是 jsp。 ​ 一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 2.3.7 mvc:annotation-driven说明​ 在 SpringMVC 的各个组件中，处理器映射器、处理器适配器、视图解析器称为 SpringMVC 的三大组件。 使用mvc:annotation-driven 自动加载 RequestMappingHandlerMapping （处理映射器）和 RequestMappingHandlerAdapter （ 处 理 适 配 器 ） ， 可 用 在 SpringMVC.xml 配 置 文 件 中 使 用 mvc:annotation-driven替代注解处理器和适配器的配置。 明确：我们只需要编写处理具体业务的控制器以及视图。 2.5 RequestMapping 注解作用： 用于建立请求 URL 和处理请求方法之间的对应关系。 出现位置： ​ 类上： 请求 URL 的第一级访问目录。此处不写的话，就相当于应用的根目录。写的话需要以/开头。 它出现的目的是为了使我们的 URL 可以按照模块化管理: 例如： 账户模块： /account/add /account/update /account/delete … 订单模块： /order/add /order/update /order/delete 红色的部分就是把 RequsetMappding 写在类上，使我们的 URL 更加精细。 ​ 方法上： 请求 URL 的第二级访问目录。 属性： value：用于指定请求的 URL。它和 path 属性的作用是一样的。 ​ method：用于指定请求的方式。 ​ params：用于指定限制请求参数的条件。它支持简单的表达式。要求请求参数的 key 和 value 必须和 配置的一模一样。 例如： params = {“accountName”}，表示请求参数必须有 accountName params = {“moeny!100”}，表示请求参数中 money 不能是 100。 ​ headers：用于指定限制请求消息头的条件。 注意： 以上四个属性只要出现 2 个或以上时，他们的关系是与的关系。 3.请求参数的绑定3.1 绑定说明3.1.1 绑定的机制​ 我们都知道，表单中请求参数都是基于 key=value 的。 SpringMVC 绑定请求参数的过程是通过把表单提交请求参数，作为控制器中方法参数进行绑定的。 3.1.2 支持的数据类型基本类型参数： ​ 包括基本类型和 String 类型 POJO 类型参数： ​ 包括实体类，以及关联的实体类 数组和集合类型参数： ​ 包括 List 结构和 Map 结构的集合（包括数组） ​ SpringMVC 绑定请求参数是自动实现的，但是要想使用，必须遵循使用要求。 3.1.3 使用要求如果是基本类型或者 String类型： ​ 要求我们的参数名称必须和控制器中方法的形参名称保持一致。(严格区分大小写) 如果是 POJO类型，或者它的关联对象： ​ 要求表单中参数名称和 POJO 类的属性名称保持一致。并且控制器方法的参数类型是 POJO 类型。 如果是集合类型,有两种方式： ​ 第一种： 要求集合类型的请求参数必须在 POJO 中。在表单中请求参数名称要和 POJO 中集合属性名称相同。给 List 集合中的元素赋值，使用下标。 给 Map 集合中的元素赋值，使用键值对。 ​ 第二种： 接收的请求参数是 json 格式数据。需要借助一个注解实现。 3.1.4 请求参数乱码问题post 请求方式：在 web.xml 中配置一个过滤器 12345678910111213&lt;!--配置解决中文乱码的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; get 请求方式： tomacat 对 GET和 POST 请求处理方式是不同的，GET请求的编码问题，要改 tomcat 的 server.xml 配置文件，如下： 12345&lt;Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\"/&gt; 改为： &lt;Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" useBodyEncodingForURI=\"true\"/&gt; 如果遇到 ajax 请求仍然乱码，请把： useBodyEncodingForURI=\"true\"改为 URIEncoding=\"UTF-8\" 即可。 3.2 特殊情况3.2.1 自定义类型转换器12345678&lt;!--配置自定义类型转换器--&gt; &lt;bean id=\"conversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\"&gt; &lt;property name=\"converters\"&gt; &lt;set&gt; &lt;bean class=\"utils.StringToDateConverter\"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 3.2.2 使用原生ServletAPI 对象作为方法参数​ SpringMVC 还支持使用原始 ServletAPI 对象作为控制器方法的参数。支持原始 ServletAPI 对象有： HttpServletRequest HttpServletResponse HttpSession java.security.Principal Locale InputStream OutputStream Reader Writer 我们可以把上述对象，直接写在控制的方法参数中使用。 123456789101112// Servlet原生API @RequestMapping(\"/testServlet\") public String testServlet(HttpServletRequest request, HttpServletResponse response)&#123; System.out.println(\"testServlet执行了...\"); System.out.println(request); HttpSession session = request.getSession(); System.out.println(session); ServletContext servletContext = session.getServletContext(); System.out.println(servletContext); System.out.println(response); return \"success\"; &#125; 4.常用注解4.1 RequestParam作用：把请求中指定名称的参数给控制器中的形参赋值。 属性：value：请求参数中的名称。 required：请求参数中是否必须提供此参数。默认值：true。表示必须提供，如果不提供将报错。 4.2 RequestBody作用：用于获取请求体内容。直接使用得到是 key=value&amp;key=value…结构的数据。 get 请求方式不适用。 属性：required：是否必须有请求体。默认值是:true。当取值为 true 时,get 请求方式会报错。如果取值 为 false，get 请求得到是 null。 4.3 PathVaribale作用：用于绑定 url 中的占位符。例如：请求 url 中 /delete/{id}，这个{id}就是 url 占位符。 url 支持占位符是 spring3.0 之后加入的。是 springmvc 支持 rest 风格 URL 的一个重要标志。 属性：value：用于指定 url 中占位符名称。 required：是否必须提供占位符。 REST 风格 URL 什么是 rest： ​ REST（英文：Representational State Transfer，简称 REST）描述了一个架构样式的网络系统， 比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，他是 HTTP 规范的主要编写者之 一。在目前主流的三种 Web 服务交互方案中，REST 相比于 SOAP（Simple Object Access protocol，简单 对象访问协议）以及 XML-RPC 更加简单明了，无论是对 URL 的处理还是对 Payload 的编码，REST 都倾向于用更 加简单轻量的方法设计和实现。值得注意的是 REST 并没有一个明确的标准，而更像是一种设计的风格。 ​ 它本身并没有什么实用性，其核心价值在于如何设计出符合 REST 风格的网络接口。 restful 的优点 ​ 它结构清晰、符合标准、易于理解、扩展方便，所以正得到越来越多网站的采用。 restful 的特性： ​ 资源（Resources）：网络上的一个实体，或者说是网络上的一个具体信息。 它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的存在。可以用一个 URI（统一 资源定位符）指向它，每种资源对应一个特定的 URI 。要 获取这个资源，访问它的 URI 就可以，因此 URI 即为每一个资源的独一无二的识别符。 表现层（Representation）：把资源具体呈现出来的形式，叫做它的表现层 （Representation）。 比如，文本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现，甚至可以采用二进制格式。 状态转化（State Transfer）：每 发出一个请求，就代表了客户端和服务器的一次交互过程。 HTTP 协议，是一个无状态协议，即所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生“状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是 “表现层状态转化”。具体说，就是 HTTP 协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。 ​ restful 的示例： /account/1 HTTP GET ： 得到 id = 1 的 account ​ /account/1 HTTP DELETE： 删除 id = 1 的 account ​ /account/1 HTTP PUT： 更新 id = 1 的 account ​ /account HTTP POST： 新增 account 4.4 RequestHeader作用： 用于获取请求消息头。 属性： value：提供消息头名称 required：是否必须有此消息头 注： 在实际开发中一般不怎么用。 4.5 CookieValue作用： 用于把指定 cookie 名称的值传入控制器方法参数。 属性： value：指定 cookie 的名称。 required：是否必须有此 cookie。 4.6 ModelAttribute作用： 该注解是 SpringMVC4.3 版本以后新加入的。它可以用于修饰方法和参数。 出现在方法上，表示当前方法会在控制器的方法执行之前，先执行。它可以修饰没有返回值的方法，也可 以修饰有具体返回值的方法。 出现在参数上，获取指定的数据给参数赋值。 属性： value：用于获取数据的 key。key 可以是 POJO 的属性名称，也可以是 map 结构的 key。 应用场景： 当表单提交数据不是完整的实体类数据时，保证没有提交数据的字段使用数据库对象原来的数据。 例如： 我们在编辑一个用户时，用户有一个创建信息字段，该字段的值是不允许被修改的。在提交表单数 据是肯定没有此字段的内容，一旦更新会把该字段内容置为 null，此时就可以使用此注解解决问题。 4.7 SessionAttribute作用： 用于多次执行控制器方法间的参数共享。 属性： value：用于指定存入的属性名称 type：用于指定存入的数据类型。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringCloud框架(二)(微服务)","slug":"SpringCloud框架(二)(微服务)","date":"2021-05-08T13:19:59.164Z","updated":"2020-04-29T02:44:38.079Z","comments":true,"path":"50010/","link":"","permalink":"http://tonymua.top/50010/","excerpt":"1.Hystrix1.1 简介Hystrix是Netflix公司的一款组件。 主页：https://github.com/Netflix/Hystrix/ Hystix是Netflix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。 1.2 雪崩问题​ 微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路. 一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务。 ​ 如果此时，某个服务出现异常, 请求阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成雪崩效应。 Hystix解决雪崩问题的手段有两个：","text":"1.Hystrix1.1 简介Hystrix是Netflix公司的一款组件。 主页：https://github.com/Netflix/Hystrix/ Hystix是Netflix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。 1.2 雪崩问题​ 微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路. 一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务。 ​ 如果此时，某个服务出现异常, 请求阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成雪崩效应。 Hystix解决雪崩问题的手段有两个： 线程隔离 服务熔断 1.3 线程隔离，服务降级1.3.1 原理Hystrix为每个依赖服务调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队.加速失败判定时间。 用户的请求将不再直接访问服务，而是通过线程池中的空闲线程来访问服务，如果线程池已满，或者请求超时，则会进行降级处理，什么是服务降级？ 服务降级：优先保证核心服务，而非核心服务不可用或弱可用。 用户的请求故障时，不会被阻塞，更不会无休止的等待或者看到系统崩溃，至少可以看到一个执行结果（例如返回友好的提示信息） 。 服务降级虽然会导致请求失败，但是不会导致阻塞，而且最多会影响这个依赖服务对应的线程池中的资源，对其它服务没有响应。 触发Hystix服务降级的情况： 线程池已满 请求超时 1.3.2 动手实践首先在consumer_demo的pom.xml中引入Hystrix依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 开启熔断 在启动类中加注解@EnableCircuitBreaker 1234567891011121314@EnableCircuitBreaker@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; 可以看到，我们类上的注解越来越多，在微服务中，经常会引入上面的三个注解，于是Spring就提供了一个组合注解：@SpringCloudApplication 123456789101112@SpringCloudApplicationpublic class ConsumerApplication &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; 编写降级逻辑 我们改造consumer_demo，当目标服务的调用出现故障，我们希望快速失败，给用户一个友好提示。因此需要提前编写好失败时的降级处理逻辑，要使用HystixCommond来完成： 123456789101112131415161718192021222324252627@RestController@RequestMapping(\"consumer\")@DefaultProperties(defaultFallback =\"fallbackMethod\" )public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"&#123;id&#125;\") @HystrixCommand/* @HystrixCommand(commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\",value = \"2000\"), @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\",value = \"10\"), @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\",value = \"10000\"), @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\",value = \"60\") &#125;)*/ public String queryById(@PathVariable(\"id\")Integer id)&#123; String url = \"http://account-service/account/\"+id; return restTemplate.getForObject(url,String.class); &#125; /*熔断方法 * 返回值要和被熔断的方法的返回值一致 * 熔断方法不需要参数 * @return*/ public String fallbackMethod()&#123; return \"请求繁忙，请稍后再试！\"; &#125;&#125; 要注意，因为熔断的降级逻辑方法必须跟正常逻辑方法保证：相同的参数列表和返回值声明。失败逻辑中返回User对象没有太大意义，一般会返回友好提示。所以我们把queryById的方法改造为返回String，反正也是Json数据。这样失败逻辑中返回一个错误说明，会比较方便。 @DefaultProperties(defaultFallback = “defaultFallBack”)：在类上指明统一的失败降级方法 @HystrixCommand：在方法上直接使用该注解，使用默认的剪辑方法。 defaultFallback：默认降级方法，不用任何参数，以匹配更多方法，但是返回值一定一致 设置超时 在之前的案例中，请求在超过1秒后都会返回错误信息，这是因为Hystix的默认超时时长为1，我们可以通过配置修改这个值： 我们可以通过hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds来设置Hystrix超时时间。该配置没有提示。 1234567hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 # 设置hystrix的超时时间为2000ms 1.4 服务熔断1.4.1 熔断原理 熔断状态机3个状态： Closed：关闭状态，所有请求都正常访问。 Open：打开状态，所有请求都会被降级。Hystix会对请求情况计数，当一定时间内失败请求百分比达到阈值，则触发熔断，断路器会完全打开。默认失败比例的阈值是50%，请求次数最少不低于20次。 Half Open：半开状态，open状态不是永久的，打开后会进入休眠时间（默认是5S）。随后断路器会自动进入半开状态。此时会释放部分请求通过，若这些请求都是健康的，则会完全关闭断路器，否则继续保持打开，再次进行休眠计时 1.4.2 动手实践认的熔断触发要求较高，休眠时间窗较短，为了测试方便，我们可以通过配置修改熔断策略： 123circuitBreaker.requestVolumeThreshold=10circuitBreaker.sleepWindowInMilliseconds=10000circuitBreaker.errorThresholdPercentage=50 解读： requestVolumeThreshold：触发熔断的最小请求次数，默认20 errorThresholdPercentage：触发熔断的失败请求最小占比，默认50% sleepWindowInMilliseconds：休眠时长，默认是5000毫秒 2.Feign2.1 简介​ Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。 项目主页：https://github.com/OpenFeign/feign 2.2 快速入门导入依赖: 我们在启动类上，添加注解，开启Feign功能 1234567@SpringCloudApplication@EnableFeignClients //开启feign客户端public class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; 删除RestTemplate：feign已经自动集成了Ribbon负载均衡的RestTemplate。所以，此处不需要再注册RestTemplate。 Feign的客户端 在consumer_demo工程中，添加AccountClient接口： 12345@FeignClient(\"account-service\")public interface AccountClient &#123; @GetMapping(\"account/&#123;id&#125;\") Account queryById(@PathVariable(\"id\")Integer id);&#125; 首先这是一个接口，Feign会通过动态代理，帮我们生成实现类。这点跟mybatis的mapper很像 @FeignClient，声明这是一个Feign客户端，类似@Mapper注解。同时通过value属性指定服务名称 接口中的定义方法，完全采用SpringMVC的注解，Feign会根据注解帮我们生成URL，并访问获取结果 改造原来的调用逻辑，调用UserClient接口: 1234567891011@RestController@RequestMapping(\"consumer\")public class ConsumerController &#123; @Autowired private AccountClient accountClient; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; return accountClient.queryById(id); &#125;&#125; 2.3 负载均衡Feign中本身已经集成了Ribbon依赖和自动配置： 因此我们不需要额外引入依赖，也不需要再注册RestTemplate对象。 2.4 Hystrix支持Feign默认也有对Hystrix的集成： 只不过，默认情况下是关闭的。我们需要通过下面的参数来开启：(consumer_demo工程添加配置内容) 123feign: hystrix: enabled: true # 开启Feign的熔断功能 但是，Feign中的Fallback配置不像hystrix中那样简单了。 1）首先，我们要定义一个类AccountClientFallback，实现刚才编写的UserClient，作为fallback的处理类 123456789@Componentpublic class AccountClientFallback implements AccountClient&#123; @Override public Account queryById(Integer id) &#123; Account account=new Account(); account.setName(\"服务器繁忙，请稍后再试！\"); return account; &#125;&#125; 2）然后在AccountClient中，指定刚才编写的实现类 12345@FeignClient(value = \"account-service\",fallback = AccountClientFallback.class)public interface AccountClient &#123; @GetMapping(\"account/&#123;id&#125;\") Account queryById(@PathVariable(\"id\")Integer id);&#125; 2.5.请求压缩(了解)Spring Cloud Feign 支持对请求和响应进行GZIP压缩，以减少通信过程中的性能损耗。通过下面的参数即可开启请求与响应的压缩功能： 123456feign: compression: request: enabled: true # 开启请求压缩 response: enabled: true # 开启响应压缩 同时，我们也可以对请求的数据类型，以及触发压缩的大小下限进行设置： 123456feign: compression: request: enabled: true # 开启请求压缩 mime-types: text/html,application/xml,application/json # 设置压缩的数据类型 min-request-size: 2048 # 设置触发压缩的大小下限 注：上面的数据类型、压缩大小下限均为默认值。 2.6 日志级别(了解)3.Zuul网关​ 服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。 3.1 简介官网：https://github.com/Netflix/zuul 3.2 Zuul加入后的架构 ​ 不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都会经过Zuul这个网关，然后再由网关来实现 鉴权、动态路由等等操作。Zuul就是我们服务的统一入口。 3.3 快速入门新建一个module:gateway 引入依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 启动类GatewayApplication 1234567@SpringBootApplication@EnableZuulProxypublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class); &#125;&#125; application.yaml 1234567891011121314151617server: port: 8084spring: application: name: gatewayeureka: client: service-url: defaultZone: http://localhost:8082/eurekazuul: routes: account-service: path: /account/** serviceId: account-service strip-prefix: false ignored-services: - consumer-service //忽略某些服务的配置 3.4 简化的路由配置在刚才的配置中，我们的规则是这样的： zuul.routes.&lt;route&gt;.path=/xxx/**： 来指定映射路径。&lt;route&gt;是自定义的路由名 zuul.routes.&lt;route&gt;.serviceId=service-provider：来指定服务名。 而大多数情况下，我们的&lt;route&gt;路由名称往往和服务名会写成一样的。因此Zuul就提供了一种简化的配置语法：zuul.routes.&lt;serviceId&gt;=&lt;path&gt; 比方说上面我们关于service-provider的配置可以简化为一条： 123zuul: routes: account-service: /account-service/** # 这里是映射路径 省去了对服务名称的配置。 3.5 默认的路由规则在使用Zuul的过程中，上面讲述的规则已经大大的简化了配置项。但是当服务较多时，配置也是比较繁琐的。因此Zuul就指定了默认的路由规则： 默认情况下，一切服务的映射路径就是服务名本身。例如服务名为：account-service，则默认的映射路径就 是：/account-service/** 也就是说，刚才的映射规则我们完全不配置也是OK的，不信就试试看。 3.6 路由前缀配置示例： 1234zuul: routes: account-service: /account-service/** prefix: /api # 添加路由前缀 我们通过zuul.prefix=/api来指定了路由的前缀，这样在发起请求时，路径就要以/api开头。 3.7 过滤器Zuul作为网关的其中一个重要功能，就是实现请求的鉴权。而这个动作我们往往是通过Zuul提供的过滤器来实现的。 3.7.1 ZuulFilterZuulFilter是过滤器的顶级父类。在这里我们看一下其中定义的4个最重要的方法： 12345678910public abstract ZuulFilter implements IZuulFilter&#123; abstract public String filterType(); abstract public int filterOrder(); boolean shouldFilter();// 来自IZuulFilter Object run() throws ZuulException;// IZuulFilter&#125; shouldFilter：返回一个Boolean值，判断该过滤器是否需要执行。返回true执行，返回false不执行。 run：过滤器的具体业务逻辑。 filterType：返回字符串，代表过滤器的类型。包含以下4种： pre：请求在被路由之前执行 route：在路由请求时调用 post：在route和errror过滤器之后调用 error：处理请求时发生错误调用 filterOrder：通过返回的int值来定义过滤器的执行顺序，数字越小优先级越高。 3.7.2 过滤器执行生命周期这张是Zuul官网提供的请求生命周期图，清晰的表现了一个请求在各个过滤器的执行顺序。 正常流程： 请求到达首先会经过pre类型过滤器，而后到达route类型，进行路由，请求就到达真正的服务提供者，执行请求，返回结果后，会到达post过滤器。而后返回响应。 异常流程： 整个过程中，pre或者route过滤器出现异常，都会直接进入error过滤器，在error处理完毕后，会将请求交给POST过滤器，最后返回给用户。 如果是error过滤器自己出现异常，最终也会进入POST过滤器，将最终结果返回给请求客户端。 如果是POST过滤器出现异常，会跳转到error过滤器，但是与pre和route不同的是，请求不会再到达POST过滤器了。 3.7.3 使用场景场景非常多： 请求鉴权：一般放在pre类型，如果发现没有访问权限，直接就拦截了 异常处理：一般会在error类型和post类型过滤器中结合来处理。 服务调用时长统计：pre和post结合使用。 3.8 自定义过滤器接下来我们来自定义一个过滤器，模拟一个登录的校验。基本逻辑：如果请求中有access-token参数，则认为请求有效，放行。 LoginFilter 1234567891011121314151617181920212223242526272829303132333435@Componentpublic class LoginFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FilterConstants.PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; //获取请求上下文 RequestContext ctx = RequestContext.getCurrentContext(); //获取Request HttpServletRequest request = ctx.getRequest(); //获取请求参数access-token String token = request.getParameter(\"access-token\"); //判断是否存在 if (StringUtils.isBlank(token))&#123; //不存在,则拦截 ctx.setSendZuulResponse(false); //设置响应状态码，403 ctx.setResponseStatusCode(HttpStatus.FORBIDDEN.value()); &#125; return null; &#125;&#125; 若使用StringUtils, 需要导入依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;&lt;/dependency&gt; 测试 3.9 负载均衡和熔断Zuul中默认就已经集成了Ribbon负载均衡和Hystix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议我们手动进行配置： 12345678910hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 4000 # 设置hystrix的超时时间为4000msribbon: ConnectionTimeOut: 500 ReadTimeOut: 1000 ribbon的超时时长, 真实值是(connect+read)*2, 需小于hystrix时长.","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringCloud框架(一)(微服务)","slug":"SpringCloud框架(一)(微服务)","date":"2021-05-08T13:19:59.162Z","updated":"2020-04-29T02:44:38.100Z","comments":true,"path":"52552/","link":"","permalink":"http://tonymua.top/52552/","excerpt":"1.系统架构演变​ 随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安一隅得过且过？ 其实生活不止眼前的苟且，还有诗和远方。所以我们今天就回顾历史，看一看系统架构演变的历程；把握现在，学习现在最火的技术架构；展望未来，争取成为一名优秀的Java工程师。 今天主要介绍的是微服务架构 微服务 ​ SOA，英文翻译过来是面向服务。微服务，似乎也是服务，都是对系统进行拆分。因此两者非常容易混淆，但其实却有一些差别：","text":"1.系统架构演变​ 随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安一隅得过且过？ 其实生活不止眼前的苟且，还有诗和远方。所以我们今天就回顾历史，看一看系统架构演变的历程；把握现在，学习现在最火的技术架构；展望未来，争取成为一名优秀的Java工程师。 今天主要介绍的是微服务架构 微服务 ​ SOA，英文翻译过来是面向服务。微服务，似乎也是服务，都是对系统进行拆分。因此两者非常容易混淆，但其实却有一些差别： 微服务的特点： 单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责 微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。 面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。 自治：自治是说服务间互相独立，互不干扰 团队独立：每个服务都是一个独立的开发团队，人数不能过多。 技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉 前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动段开发不同接口 数据库分离：每个服务都使用自己的数据源 部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护 微服务结构图： 2.远程调用方式无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？ 常见的远程调用方式有以下几种： RPC：Remote Produce Call远程过程调用，类似的还有RMI。自定义数据格式，基于原生TCP通信，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型 Http：http其实是一种网络传输协议，基于TCP，规定了数据传输的格式。现在客户端浏览器与服务端通信基本都是采用Http协议。也可以用来进行远程服务调用。缺点是消息封装臃肿。 现在热门的Rest风格，就可以通过http协议来实现。 2.1 认识RPCRPC，即 Remote Procedure Call（远程过程调用），是一个计算机通信协议。 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。说得通俗一点就是：A计算机提供一个服务，B计算机可以像调用本地服务那样调用A计算机的服务。 通过上面的概念，我们可以知道，实现RPC主要是做到两点： 实现远程调用其他计算机的服务 要实现远程调用，肯定是通过网络传输数据。A程序提供服务，B程序通过网络将请求参数传递给A，A本地执行后得到结果，再将结果返回给B程序。这里需要关注的有两点： 1）采用何种网络通讯协议？ 现在比较流行的RPC框架，都会采用TCP作为底层传输协议 2）数据传输的格式怎样？ 两个程序进行通讯，必须约定好数据传输格式。就好比两个人聊天，要用同一种语言，否则无法沟通。所以，我们必须定义好请求和响应的格式。另外，数据在网路中传输需要进行序列化，所以还需要约定统一的序列化的方式。 像调用本地服务一样调用远程服务 如果仅仅是远程调用，还不算是RPC，因为RPC强调的是过程调用，调用的过程对用户而言是应该是透明的，用户不应该关心调用的细节，可以像调用本地服务一样调用远程服务。所以RPC一定要对调用的过程进行封装 RPC调用流程图： 2.2 认识HttpHttp协议：超文本传输协议，是一种应用层协议。规定了网络传输的请求格式、响应格式、资源定位和操作的方式等。但是底层采用什么网络传输协议，并没有规定，不过现在都是采用TCP协议作为底层传输协议。说到这里，大家可能觉得，Http与RPC的远程调用非常像，都是按照某种规定好的数据格式进行网络通信，有请求，有响应。没错，在这点来看，两者非常相似，但是还是有一些细微差别。 RPC并没有规定数据传输格式，这个格式可以任意指定，不同的RPC协议，数据格式不一定相同。 Http中还定义了资源定位的路径，RPC中并不需要 最重要的一点：RPC需要满足像调用本地服务一样调用远程服务，也就是对调用过程在API层面进行封装。Http协议没有这样的要求，因此请求、响应等细节需要我们自己去实现。 优点：RPC方式更加透明，对用户更方便。Http方式更灵活，没有规定API和语言，跨语言、跨平台 缺点：RPC方式需要在API层面进行封装，限制了开发的语言环境。 例如我们通过浏览器访问网站，就是通过Http协议。只不过浏览器把请求封装，发起请求以及接收响应，解析响应的事情都帮我们做了。如果是不通过浏览器，那么这些事情都需要自己去完成。 2.3 如何选择？既然两种方式都可以实现远程调用，我们该如何选择呢？ 速度来看，RPC要比http更快，虽然底层都是TCP，但是http协议的信息往往比较臃肿，不过可以采用gzip压缩。 难度来看，RPC实现较为复杂，http相对比较简单 灵活性来看，http更胜一筹，因为它不关心实现细节，跨平台、跨语言。 因此，两者都有不同的使用场景： 如果对效率要求更高，并且开发过程使用统一的技术栈，那么用RPC还是不错的。 如果需要更加灵活，跨语言、跨平台，显然http更合适 那么我们该怎么选择呢？ 微服务，更加强调的是独立、自治、灵活。而RPC方式的限制较多，因此微服务框架中，一般都会采用基于Http的Rest风格服务。 3.初始SpringCloud微服务是一种架构方式，最终肯定需要技术架构去实施。 微服务的实现方式很多，但是最火的莫过于Spring Cloud了。为什么？ 后台硬：作为Spring家族的一员，有整个Spring全家桶靠山，背景十分强大。 技术强：Spring作为Java领域的前辈，可以说是功力深厚。有强力的技术团队支撑，一般人还真比不了 群众基础好：可以说大多数程序员的成长都伴随着Spring框架，试问：现在有几家公司开发不用Spring？SpringCloud与Spring的各个框架无缝整合，对大家来说一切都是熟悉的配方，熟悉的味道。 使用方便：相信大家都体会到了SpringBoot给我们开发带来的便利，而SpringCloud完全支持SpringBoot的开发，用很少的配置就能完成微服务框架的搭建 SpringCloud是Spring旗下的项目之一，官网地址：http://projects.spring.io/spring-cloud/ Spring最擅长的就是集成，把世界上最好的框架拿过来，集成到自己的项目中。 SpringCloud也是一样，它将现在非常流行的一些技术整合到一起，实现了诸如：配置管理，服务发现，智能路由，负载均衡，熔断器，控制总线，集群状态等等功能。其主要涉及的组件包括： netflix Eureka：注册中心 Zuul：服务网关 Ribbon：负载均衡 Feign：服务调用 Hystix：熔断器 以上只是其中一部分，架构图： 4.微服务场景模拟首先，我们需要模拟一个服务调用的场景。方便后面学习微服务架构 4.1 父工程 配置依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;account_service&lt;/module&gt; &lt;module&gt;consumer_demo&lt;/module&gt; &lt;module&gt;eureka_server&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt; &lt;demo.mapper.starter.version&gt;2.0.3&lt;/demo.mapper.starter.version&gt; &lt;mysql.version&gt;5.1.32&lt;/mysql.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.mapper.starter.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 4.2 服务提供者首先, 我们需要模拟一个服务调用的场景。方便后面学习微服务架构 pom.xml 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;account_service&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类AccountApplication 12345678@EnableDiscoveryClient@SpringBootApplication@MapperScan(\"lwy.mapper\")public class AccountApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AccountApplication.class); &#125;&#125; Account 1234567891011@Data@Table(name = \"account\")public class Account &#123; @Id @KeySql(useGeneratedKeys = true) private Integer id; private String name; private Double money;&#125; AccountMapper 12public interface AccountMapper extends Mapper&lt;Account&gt; &#123;&#125; AccountService 1234567891011121314@Servicepublic class AccountService &#123; @Autowired private AccountMapper accountMapper; public Account queryById(Integer id)&#123; return accountMapper.selectByPrimaryKey(id); &#125; @Transactional public void insert(Account account)&#123; accountMapper.insert(account); &#125;&#125; AccountController 1234567891011@RestController@RequestMapping(\"account\")public class AccountController &#123; @Autowired private AccountService accountService; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; return accountService.queryById(id); &#125;&#125; application.yaml 12345678910111213141516spring: application: name: account-service datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm?&amp;serverTimezone=UTC username: root password: 547717253server: port: 8081eureka: client: service-url: defaultZone: http://localhost:8082/eureka 4.3 服务调用者pom.xml 1234567891011121314151617181920212223&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;consumer_demo&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类ConsumerApplication 123456789101112@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; Account 12345678@Datapublic class Account &#123; private Integer id; private String name; private Double money;&#125; ConsumerController 123456789101112131415161718@RestController@RequestMapping(\"consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; //根据服务id获取实例 List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"account-service\"); //从实例中取出ip和端口 ServiceInstance instance = instances.get(0); String url = instance.getHost() + \":\" + instance.getPort()+\"/account/\"+id; return restTemplate.getForObject(url,Account.class); &#125;&#125; application.yaml 12345678eureka: client: service-url: defaultZone: http://localhost:8082/eurekaspring: application: name: consumer-server 4.4 Eureka注册中心 认识Eureka Eureka：就是服务注册中心（可以是一个集群），对外暴露自己的地址 提供者：启动后向Eureka注册自己信息（地址，提供什么服务） 消费者：向Eureka订阅服务，Eureka会将对应服务的所有提供者地址列表发送给消费者，并且定期更新 心跳(续约)：提供者定期通过http方式向Eureka刷新自己的状态 pom.xml 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;eureka_server&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; EureakServer 1234567@EnableEurekaServer@SpringBootApplicationpublic class EureakServer &#123; public static void main(String[] args) &#123; SpringApplication.run(EureakServer.class,args); &#125;&#125; application.yaml 1234567891011server: port: 8082eureka: client: service-url: defaultZone: http://localhost:8082/eurekaspring: application: name: eureka-server 5.Eureka详解接下来我们详细讲解Eureka的原理及配置。 5.1 基础架构Eureka架构中的三个核心角色： 服务注册中心 Eureka的服务端应用，提供服务注册和发现功能，就是刚刚我们建立的itcast-eureka。 服务提供者 提供服务的应用，可以是SpringBoot应用，也可以是其它任意技术实现，只要对外提供的是Rest风格服务即可。本例中就是我们实现的itcast-service-provider。 服务消费者 消费应用从注册中心获取服务列表，从而得知每个服务方的信息，知道去哪里调用服务方。本例中就是我们实现的itcast-service-consumer。 5.2 高可用的Eureka ServerEureka Server即服务的注册中心，在刚才的案例中，我们只有一个EurekaServer，事实上EurekaServer也可以是一个集群，形成高可用的Eureka中心。 服务同步 多个Eureka Server之间也会互相注册为服务，当服务提供者注册到Eureka Server集群中的某个节点时，该节点会把服务的信息同步给集群中的每个节点，从而实现数据同步。因此，无论客户端访问到Eureka Server集群中的任意一个节点，都可以获取到完整的服务列表信息。 5.3 服务提供者服务提供者要向EurekaServer注册服务，并且完成服务续约等工作。 服务注册 服务提供者在启动时，会检测配置属性中的：eureka.client.register-with-eureka=true参数是否正确，事实上默认就是true。如果值确实为true，则会向EurekaServer发起一个Rest请求，并携带自己的元数据信息，Eureka Server会把这些信息保存到一个双层Map结构中。 第一层Map的Key就是服务id，一般是配置中的spring.application.name属性 第二层Map的key是服务的实例id。一般host+ serviceId + port，例如：locahost:service-provider:8081 值则是服务的实例对象，也就是说一个服务，可以同时启动多个不同实例，形成集群。 服务续约 在注册服务完成以后，服务提供者会维持一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”。这个我们称为服务的续约（renew）； 有两个重要参数可以修改服务续约的行为： 1234eureka: instance: lease-expiration-duration-in-seconds: 90 lease-renewal-interval-in-seconds: 30 lease-renewal-interval-in-seconds：服务续约(renew)的间隔，默认为30秒 lease-expiration-duration-in-seconds：服务失效时间，默认值90秒 也就是说，默认情况下每个30秒服务会向注册中心发送一次心跳，证明自己还活着。如果超过90秒没有发送心跳，EurekaServer就会认为该服务宕机，会从服务列表中移除，这两个值在生产环境不要修改，默认即可。 但是在开发时，这个值有点太长了，经常我们关掉一个服务，会发现Eureka依然认为服务在活着。所以我们在开发阶段可以适当调小。 1234eureka: instance: lease-expiration-duration-in-seconds: 10 # 10秒即过期 lease-renewal-interval-in-seconds: 5 # 5秒一次心跳 5.4 服务消费者 获取服务列表 ​ 当服务消费者启动时，会检测eureka.client.fetch-registry=true参数的值，如果为true，则会拉取Eureka Server服务的列表只读备份，然后缓存在本地。并且每隔30秒会重新获取并更新数据。我们可以通过下面的参数来修改： 123eureka: client: registry-fetch-interval-seconds: 5 生产环境中，我们不需要修改这个值。 但是为了开发环境下，能够快速得到服务的最新状态，我们可以将其设置小一点。 5.5 失效剔除和自我保护 服务下线 ​ 当服务进行正常关闭操作时，它会触发一个服务下线的REST请求给Eureka Server，告诉服务注册中心：“我要下线了”。服务中心接受到请求之后，将该服务置为下线状态。 失效剔除 ​ 有些时候，我们的服务提供方并不一定会正常下线，可能因为内存溢出、网络故障等原因导致服务无法正常工作。Eureka Server需要将这样的服务剔除出服务列表。因此它会开启一个定时任务，每隔60秒对所有失效的服务（超过90秒未响应）进行剔除。 可以通过eureka.server.eviction-interval-timer-in-ms参数对其进行修改，单位是毫秒，生产环境不要修改。 自我保护 ​ 我们关停一个服务,触发了Eureka的自我保护机制。当一个服务未按时进行心跳续约时，Eureka会统计最近15分钟心跳失败的服务实例的比例是否超过了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务剔除列表并不妥当，因为服务可能没有宕机。Eureka就会把当前实例的注册信息保护起来，不予剔除。生产环境下这很有效，保证了大多数服务依然可用。 但是这给我们的开发带来了麻烦， 因此开发阶段我们都会关闭自我保护模式：（eureka） 1234eureka: server: enable-self-preservation: false # 关闭自我保护模式（缺省为打开） eviction-interval-timer-in-ms: 1000 # 扫描失效服务的间隔时间（缺省为60*1000ms） 6.负载均衡Ribbon什么是Ribbon： 6.1 开启负载均衡因为Eureka中已经集成了Ribbon，所以我们无需引入新的依赖，直接修改代码。 修改consumer_demo的引导类，在RestTemplate的配置方法上添加@LoadBalanced注解： 12345@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; 修改调用方式，不再手动获取ip和端口，而是直接通过服务名称调用： ConsumerController 1234567891011@RestController@RequestMapping(\"consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; String url = \"http://account-service/account/\"+id; return restTemplate.getForObject(url,Account.class); &#125;&#125; 6.2 负载均衡策略SpringBoot帮我们提供了修改负载均衡规则的配置入口，在consumer_demo的application.yml中添加如下配置： 123account-service: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 格式是：服务名称.ribbon.NFLoadBalancerRuleClassName，值就是IRule的实现类。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringBoot框架","slug":"SpringBoot框架","date":"2021-05-08T13:19:59.161Z","updated":"2020-04-29T02:44:38.036Z","comments":true,"path":"58845/","link":"","permalink":"http://tonymua.top/58845/","excerpt":"1. 了解SpringBoot1.1 什么是SpringBoot​ 用一些固定的方式来构建生产级别的spring应用。Spring Boot 推崇约定大于配置的方式以便于你能够尽可能快速的启动并运行程序。 ​ 其实人们把Spring Boot 称为搭建程序的脚手架。其最主要作用就是帮我们快速的构建庞大的spring项目，并且尽可能的减少一切xml配置，做到开箱即用，迅速上手，让我们关注与业务而非配置。 1.2 为什么要学习SpringBoot​ Spring Boot 简化了基于Spring的应用开发，只需要“run”就能创建一个独立的、生产级别的Spring应用。Spring Boot为Spring平台及第三方库提供开箱即用的设置（提供默认设置，存放默认配置的包就是启动器），这样我们就可以简单的开始。多数Spring Boot应用只需要很少的Spring配置。 1.3 SpringBoot的特点Spring Boot 主要目标是：","text":"1. 了解SpringBoot1.1 什么是SpringBoot​ 用一些固定的方式来构建生产级别的spring应用。Spring Boot 推崇约定大于配置的方式以便于你能够尽可能快速的启动并运行程序。 ​ 其实人们把Spring Boot 称为搭建程序的脚手架。其最主要作用就是帮我们快速的构建庞大的spring项目，并且尽可能的减少一切xml配置，做到开箱即用，迅速上手，让我们关注与业务而非配置。 1.2 为什么要学习SpringBoot​ Spring Boot 简化了基于Spring的应用开发，只需要“run”就能创建一个独立的、生产级别的Spring应用。Spring Boot为Spring平台及第三方库提供开箱即用的设置（提供默认设置，存放默认配置的包就是启动器），这样我们就可以简单的开始。多数Spring Boot应用只需要很少的Spring配置。 1.3 SpringBoot的特点Spring Boot 主要目标是： 为所有 Spring 的开发者提供一个非常快速的、广泛接受的入门体验 开箱即用（启动器starter-其实就是SpringBoot提供的一个jar包），但通过自己设置参数（.properties），即可快速摆脱这种方式。 提供了一些大型项目中常见的非功能性特性，如内嵌服务器、安全、指标，健康检测、外部化配置等 绝对没有代码生成，也无需 XML 配置。 2.快速入门2.1 添加依赖​ 现在我们的项目与SpringBoot还没有什么关联。SpringBoot提供了一个名为spring-boot-starter-parent的工程，里面已经对各种常用依赖（并非全部）的版本进行了管理，我们的项目需要以这个项目为父工程，这样我们就不用操心依赖的版本问题了，需要什么依赖，直接引入坐标即可！ 添加父工程坐标 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;&lt;/parent&gt; 添加web启动器 ​ 为了让SpringBoot帮我们完成各种自动配置，我们必须引入SpringBoot提供的自动配置依赖，我们称为启动器。因为我们是web项目，这里我们引入web启动器： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 需要注意的是，我们并没有在这里指定版本信息。因为SpringBoot的父工程已经对版本进行了管理了。 2.2 启动类123456@SpringBootApplicationpublic class BootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(BootDemoApplication.class,args); &#125;&#125; 2.3 编写controller接下来，我们就可以像以前那样开发SpringMVC的项目了！ 我们编写一个controller： 12345678@RestControllerpublic class HelloController &#123; @GetMapping(\"hello\") public String hello()&#123; return \"hello, spring boot!\"; &#125;&#125; 2.4 启动测试接下来，我们运行main函数 1）监听的端口是8080 2）SpringMVC的映射路径是：/ 3）/hello路径已经映射到了HelloController中的hello()方法 打开页面访问：http://localhost:8080/hello 3.Java配置在入门案例中，我们没有任何的配置，就可以实现一个SpringMVC的项目了，快速、高效！ 但是有同学会有疑问，如果没有任何的xml，那么我们如果要配置一个Bean该怎么办？比如我们要配置一个数据库连接池, 现在该怎么做呢？ 3.1 SpringBoot的属性注入首先引入Druid连接池依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.19&lt;/version&gt; &lt;/dependency&gt; 创建一个jdbc.properties文件，编写jdbc属性： 1234jdbc.driverClassName=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/ssmjdbc.username=rootjdbc.password=547717253 在SpringBoot中，提供了一种新的属性注入方式，支持各种java基本数据类型及复杂类型的注入。 1）我们新建一个类，用来进行属性注入： JdbcProperties 123456789@ConfigurationProperties(prefix = \"jdbc\")@Datapublic class JdbcProperties &#123; String driverClassName; String url; String username; String password;&#125; 此时使用@Data需要安装lombok插件并导入相关依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 2）在JdbcConfig中使用这个属性： 1234567891011121314@Configuration@EnableConfigurationProperties(JdbcProperties.class)public class JdbcConfig &#123; @Bean public DataSource dataSource(JdbcProperties jdbc) &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(jdbc.getUrl()); dataSource.setDriverClassName(jdbc.getDriverClassName()); dataSource.setUsername(jdbc.getUsername()); dataSource.setPassword(jdbc.getPassword()); return dataSource; &#125;&#125; 通过@EnableConfigurationProperties(JdbcProperties.class)来声明要使用JdbcProperties这个类的对象 然后你可以通过以下方式注入JdbcProperties： @Autowired注入 12@Autowiredprivate JdbcProperties prop; 构造函数注入 1234private JdbcProperties prop;public JdbcConfig(Jdbcproperties prop)&#123; this.prop = prop;&#125; 声明有@Bean的方法参数注入 1234@Beanpublic Datasource dataSource(JdbcProperties prop)&#123; // ...&#125; 本例中，我们采用第三种方式。 优势： Relaxed binding：松散绑定 不严格要求属性文件中的属性名与成员变量名一致。支持驼峰，中划线，下划线等等转换，甚至支持对象引导。比如：user.friend.name：代表的是user对象中的friend属性中的name属性，显然friend也是对象。@value注解就难以完成这样的注入方式。 meta-data support：元数据支持，帮助IDE生成属性提示（写开源框架会用到）。 3.2 更优雅的注入​ 事实上，如果一段属性只有一个Bean需要使用，我们无需将其注入到一个类（JdbcProperties）中。而是直接在需要的地方声明即可： JdbcConfig 123456789@Configuration@EnableConfigurationProperties(JdbcProperties.class)*/ @Bean // 声明要注入的属性前缀，SpringBoot会自动把相关属性通过set方法注入到DataSource中 @ConfigurationProperties(prefix = \"jdbc\") public DataSource dataSource() &#123; return new DruidDataSource(); &#125;&#125; ​ 我们直接把@ConfigurationProperties(prefix = &quot;jdbc&quot;)声明在需要使用的@Bean的方法上，然后SpringBoot就会自动调用这个Bean（此处是DataSource）的set方法，然后完成注入。使用的前提是：该类必须有对应属性的set方法！ 使用yaml代替properties application.yaml 12345jdbc: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm username: root password: 547717253 4.自动配置原理SpringBoot为我们提供了默认配置，而默认配置生效的条件一般有两个： 你引入了相关依赖 你自己没有配置 1）启动器 所以，我们如果不想配置，只需要引入依赖即可，而依赖版本我们也不用操心，因为只要引入了SpringBoot提供的stater（启动器），就会自动管理依赖及版本了。 因此，玩SpringBoot的第一件事情，就是找启动器，SpringBoot提供了大量的默认启动器. 2）全局配置 另外，SpringBoot的默认配置，都会读取默认属性，而这些属性可以通过自定义application.properties文件来进行覆盖。这样虽然使用的还是默认配置，但是配置中的值改成了我们自定义的。 因此，玩SpringBoot的第二件事情，就是通过application.properties来覆盖默认属性值，形成自定义配置。我们需要知道SpringBoot的默认属性key，非常多. 5.SpringBoot实践5.1.整合SpringMVC虽然默认配置已经可以使用SpringMVC了，不过我们有时候需要进行自定义配置。 5.1.1 修改端口查看SpringBoot的全局属性可知，端口通过以下方式在application.yaml中配置： 12server: port: 80 5.1.2 访问静态资源现在，我们的项目是一个jar工程，那么就没有webapp，我们的静态资源该放哪里呢？ 默认的静态资源路径为： classpath:/META-INF/resources/ classpath:/resources/ classpath:/static/ classpath:/public 只要静态资源放在这些目录中任何一个，SpringMVC都会帮我们处理。 我们习惯会把静态资源放在classpath:/static/目录下。即在resources目录下创建static目录，并且添加一些静态资源. 5.1.3 添加拦截器拦截器也是我们经常需要使用的，在SpringBoot中该如何配置呢？ 过实现WebMvcConfigurer并添加@Configuration注解来实现自定义部分SpringMvc配置。 首先我们定义一个拦截器： MyInterceptor 123456789101112131415161718@Slf4jpublic class MyInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; log.debug(\"preHandle method is running\"); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; log.debug(\"postHandle method is running\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; log.debug(\"afterCompletion method is running\"); &#125;&#125; 然后，我们定义配置类，添加拦截器： MvcConfig 12345678@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new MyInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; 接下来运行并查看日志： 你会发现日志中什么都没有，因为我们记录的log级别是debug，默认是显示info以上，我们需要进行配置。 SpringBoot通过logging.level.*=debug来配置日志级别，*填写包名 在application.yaml中配置： 123logging: level: demo: debug 5.2 整合连接池其实，在刚才引入jdbc启动器的时候，SpringBoot已经自动帮我们引入了一个连接池： ​ HikariCP应该是目前速度最快的连接池 因此，我们只需要指定连接池参数即可： ​ 在application.yaml中配置： 123456spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm?&amp;serverTimezone=UTC username: root password: 547717253 5.3 通用mapper通用Mapper的作者为自己的插件编写了启动器，我们直接引入即可： 123456&lt;!--通用mapper--&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt; 此时也不再需要mybatis启动器及jdbc的依赖 Account 1234567891011@Data@Table(name = \"account\")public class Account &#123; @Id @KeySql(useGeneratedKeys = true) private Integer id; private String name; private Double money;&#125; AccountMapper 123public interface AccountMapper extends Mapper&lt;Account&gt; &#123;&#125; AccountServiceImpl 1234567891011121314@Servicepublic class AccountServiceImpl &#123; @Autowired private AccountMapper accountMapper; public Account queryById(Integer id)&#123; return accountMapper.selectByPrimaryKey(id); &#125; @Transactional public void insert(Account account)&#123; accountMapper.insert(account); &#125;&#125; HelloController 12345678910111213@RestController@Slf4j@RequestMapping(\"account\")public class HelloController &#123; @Autowired private AccountServiceImpl accountService; @GetMapping(\"&#123;id&#125;\") public Account hello(@PathVariable(\"id\")Integer id)&#123; log.debug(\"hello method is running\"); return accountService.queryById(id); &#125;&#125; 启动测试 访问http://localhost:8080/account/5","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring AOP","slug":"Spring-AOP","date":"2021-05-08T13:19:59.159Z","updated":"2020-08-19T06:47:53.564Z","comments":true,"path":"spring_aop/","link":"","permalink":"http://tonymua.top/spring_aop/","excerpt":"1.AOP概述1.1 什么是AOP？AOP(Aspect Oriented Programming 面向切面编程)，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。常用于日志记录，性能统计，安全控制，事务处理，异常处理等等。","text":"1.AOP概述1.1 什么是AOP？AOP(Aspect Oriented Programming 面向切面编程)，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。常用于日志记录，性能统计，安全控制，事务处理，异常处理等等。 1.2 AOP术语切面(Aspect)：由横切关注点构成的特殊对象。连接点(Join Point)：连接点是指在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候；通知(Advice)：指在切面的某个特定的连接点上执行的动作。Spring切面可以应用5种通知： 前置通知(Before):在目标方法或者说连接点被调用前执行的通知； 后置通知(After)：指在某个连接点完成后执行的通知； 返回通知(After-returning)：指在某个连接点成功执行之后执行的通知； 异常通知(After-throwing)：指在方法抛出异常后执行的通知； 环绕通知(Around)：指包围一个连接点通知，在被通知的方法调用之前和之后执行自定义的方法。 切点(Pointcut)：指匹配连接点的断言。通知与一个切入点表达式关联，并在满足这个切入的连接点上运行，例如：当执行某个特定的名称的方法。引入(Introduction)：引入也被称为内部类型声明，声明额外的方法或者某个类型的字段。目标对象(Target Object)：目标对象是被一个或者多个切面所通知的对象。AOP代理(AOP Proxy)：向目标对象应用通知之后创建的对象。织入(Wearving)：增强添加到目标类具体连接点上的过程。AOP有三种织入的方式：编译期织入、类装载期织入、动态代理织入(spring采用动态代理织入)。 1.3 通知执行顺序 正常情况@Around -&gt;@Before-&gt;主方法体-&gt;@Around中pjp.proceed()-&gt;@After-&gt;@AfterReturning 存在异常 异常在Around中pjp.proceed()之前@Around -&gt; @After -&gt; @AfterThrowing 异常在Around中pjp.proceed()之后@Around -&gt;@Before-&gt;主方法体-&gt;@Around中pjp.proceed()-&gt;@After-&gt;@AfterThrowing1.4 实现原理 JDK动态代理(JDK提供，只能代理接口) 使用动态代理可以为一个或多个接口在运行期动态生成实现对象，生成的对象中实现接口的方法时可以添加增强代码，从而实现AOP。缺点是只能针对接口进行代理，另外由于动态代理是通过反射实现的，有时可能要考虑反射调用的开销。 CGLib动态代理: (适用CGLib工具)采用动态的字节码生成技术，运行时动态生成指定类的一个子类对象，并覆盖其中特定方法，覆盖方法时可以添加增强代码，从而实现AOP 。1.5 Pointcut切入点的语法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 1、使用within表达式匹配 * 下面示例表示匹配com.example.controller包下所有的类的方法 */@Pointcut(\"within(com.example.controller..*)\")public void pointcutWithin()&#123;&#125;/** * 2、this匹配目标指定的方法，此处就是HelloController的方法 */@Pointcut(\"this(com.example.controller.HelloController)\")public void pointcutThis()&#123;&#125;/** * 3、target匹配实现UserInfoService接口的目标对象 */@Pointcut(\"target(com.leo.service.UserInfoService)\")public void pointcutTarge()&#123;&#125;/** * 4、bean匹配所有以Service结尾的bean里面的方法， * 注意：使用自动注入的时候默认实现类首字母小写为bean的id */@Pointcut(\"bean(*ServiceImpl)\")public void pointcutBean()&#123;&#125;/** * 5、args匹配第一个入参是String类型的方法 */@Pointcut(\"args(String, ..)\")public void pointcutArgs()&#123;&#125;/** * 6、@annotation匹配是@Controller类型的方法 */@Pointcut(\"@annotation(org.springframework.stereotype.Controller)\")public void pointcutAnnocation()&#123;&#125;/** * 7、@within匹配@Controller注解下的方法，要求注解的@Controller级别为@Retention(RetentionPolicy.CLASS) */@Pointcut(\"@within(org.springframework.stereotype.Controller)\")public void pointcutWithinAnno()&#123;&#125;/** * 8、@target匹配的是@Controller的类下面的方法，要求注解的@Controller级别为@Retention(RetentionPolicy.RUNTIME) */@Pointcut(\"@target(org.springframework.stereotype.Controller)\")public void pointcutTargetAnno()&#123;&#125;/** * 9、@args匹配参数中标注为@Sevice的注解的方法 */@Pointcut(\"@args(org.springframework.stereotype.Service)\")public void pointcutArgsAnno()&#123;&#125;/** * 10、使用excution表达式 * execution( * modifier-pattern? //用于匹配public、private等访问修饰符 * ret-type-pattern //用于匹配返回值类型，不可省略 * declaring-type-pattern? //用于匹配包类型 * name-pattern(param-pattern) //用于匹配类中的方法，不可省略 * throws-pattern? //用于匹配抛出异常的方法 * ) * * 下面的表达式解释为：匹配com.example.controller.HelloController类中以hello开头的修饰符为public返回类型任意的方法 */@Pointcut(value = \"execution(public * com.example.controller.HelloController.hello*(..))\")public void pointCut() &#123;&#125; 2.AOP实践2.1 HTTP接口鉴权需求： 可以定制地为某些指定的 HTTP RESTful api 提供权限验证功能。 当调用方的权限不符时, 返回错误。相关依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 2.1.1 自定义注解1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface AuthChecker &#123;&#125; AuthChecker 注解是一个方法注解，它用于注解 RequestMapping 方法。 2.1.2 aspect的实现12345678910111213141516171819202122232425262728293031323334353637@Component@Aspectpublic class HttpAopAdviseDefine &#123; //定义一个 Pointcut, 使用切点表达式函数来描述对哪些Join point使用advice. @Pointcut(\"@annotation(com.example.annotation.AuthChecker)\") public void pointcut()&#123; &#125; //定义advice @Around(\"pointcut()\") public Object checkAuth(ProceedingJoinPoint proceedingJoinPoint)&#123; HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); //检查用户所传递的 token 是否合法 String token = getToken(request); if (!token.equalsIgnoreCase(\"111\"))&#123; return \"token不合法！\"; &#125; try &#123; return proceedingJoinPoint.proceed(); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); return null; &#125; &#125; private String getToken(HttpServletRequest request) &#123; Cookie[] cookies = request.getCookies(); if (cookies == null) &#123; return \"\"; &#125; for (Cookie cookie : cookies) &#123; if (cookie.getName().equalsIgnoreCase(\"token\")) &#123; return cookie.getValue(); &#125; &#125; return \"\"; &#125;&#125; 2.1.3 Controller12345678910111213@RestController@RequestMapping(\"/aop/http\")public class AopController &#123; @GetMapping(\"alive\") public String alive()&#123; return \"服务一切正常\"; &#125; @AuthChecker @GetMapping(\"login\") public String login()&#123; return \"登录成功！\"; &#125;&#125; 2.1.4 测试token缺失/不正确：token正确： 2.2 方法调用日志需求: 某个服务下的方法的调用需要有log记录调用的参数以及返回结果。 当方法调用出异常时，有特殊处理，例如打印异常 log，报警等。2.2.1 aspect 的实现123456789101112131415161718192021222324252627282930313233@Component@Aspectpublic class LogAopAdviseDefine &#123; private Logger logger = LoggerFactory.getLogger(getClass()); // 定义一个Pointcut, 使用切点表达式函数来描述对哪些 Join point 使用 advise. @Pointcut(\"within(com.example.service..*)\") public void poincut() &#123; &#125; // 定义advise @Before(\"poincut()\") public void logMethodInvokeParam(JoinPoint joinPoint) &#123; logger.info(\"---Before method &#123;&#125; invoke, param: &#123;&#125;---\", joinPoint.getSignature().toShortString(), joinPoint.getArgs()); &#125; @AfterReturning(pointcut = \"poincut()\",returning = \"message\") public void logMethodInvokeResult(JoinPoint joinPoint,Object message)&#123; logger.info(\"---After method &#123;&#125; invoke, result: &#123;&#125;---\", joinPoint.getSignature().toShortString(), joinPoint.getArgs()); &#125; @AfterThrowing(pointcut = \"poincut()\",throwing = \"exception\") public void logMethodInvokeException(JoinPoint joinPoint,Exception exception)&#123; logger.info(\"---method &#123;&#125; invoke exception: &#123;&#125;---\", joinPoint.getSignature().toShortString(), exception.getMessage()); &#125;&#125; 2.2.2 Service1234567891011121314151617@Servicepublic class LogServiceImpl implements LogService &#123; private Logger logger = LoggerFactory.getLogger(getClass()); private Random random = new Random(System.currentTimeMillis()); @Override public int LogMethod(String param) &#123; logger.info(\"---LogService: logMethod invoked, param: &#123;&#125;---\", param); return random.nextInt(); &#125; @Override public void exceptionMethod() throws Exception &#123; logger.info(\"---LogService: exceptionMethod invoked---\"); throw new Exception(\"Something bad happened!\"); &#125;&#125; 123456789@Servicepublic class NormalServiceImpl implements NormalService &#123; private Logger logger = LoggerFactory.getLogger(getClass()); @Override public void normalMethod() &#123; logger.info(\"---NormalService: someMethod invoked---\"); &#125;&#125; 2.2.3 测试123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTestpublic class LogAdviseTest &#123; @Autowired private LogService logService; @Autowired private NormalService normalService; @Test @PostConstruct public void testLogAdvise()&#123; logService.LogMethod(\"LogMethod Test!\"); try &#123; logService.exceptionMethod(); &#125;catch (Exception e)&#123; &#125; normalService.normalMethod(); &#125;&#125; 2.3 方法耗时统计需求: 为服务中的每个方法调用进行调用耗时记录. 将方法调用的时间戳, 方法名, 调用耗时上报到监控平台2.3.1 aspect 实现12345678910111213141516171819202122232425262728293031323334353637383940@Component@Aspectpublic class ExpiredAopAdviseDefine &#123; private Logger logger = LoggerFactory.getLogger(getClass()); @Pointcut(\"within(com.example.service.impl.ExpiredServiceImpl)\") public void pointcut() &#123; &#125; @Around(\"pointcut()\") public Object methodInvokeExpiredTime( ProceedingJoinPoint proceedingJoinPoint) &#123; try &#123; // StopWatch 任务执行时间监视器 StopWatch stopWatch = new StopWatch(); // 开始 stopWatch.start(); Object proceed = proceedingJoinPoint.proceed(); // 结束 stopWatch.stop(); // 上报到监控平台 reportToMonitorSystem( proceedingJoinPoint.getSignature().toShortString(), stopWatch.getTotalTimeMillis()); return proceed; &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); return null; &#125; &#125; public void reportToMonitorSystem(String methodName, long expiredTime) &#123; logger.info(\"---method &#123;&#125; invoked, expired time: &#123;&#125; ms---\", methodName, expiredTime); &#125;&#125; 2.3.2 Service123456789101112131415161718@Servicepublic class ExpiredServiceImpl implements ExpiredService &#123; private Logger logger = LoggerFactory.getLogger(getClass()); private Random random = new Random(System.currentTimeMillis()); @Override public void expiredTimeMethod() &#123; logger.info(\"---SomeService: someMethod invoked---\"); try &#123; //模拟耗时任务 Thread.sleep(random.nextInt(500)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.3 测试123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class ExpiredAdviseTest &#123; @Autowired private ExpiredService expiredService; @Test @PostConstruct public void testExpiredTime() &#123; expiredService.expiredTimeMethod(); &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"http://tonymua.top/tags/AOP/"},{"name":"面向切面编程","slug":"面向切面编程","permalink":"http://tonymua.top/tags/面向切面编程/"}]},{"title":"Sping Cloud Alibaba","slug":"Sping-Cloud-Alibaba","date":"2021-05-08T13:19:59.157Z","updated":"2021-03-17T14:58:25.266Z","comments":true,"path":"SpringCloudAlibaba/","link":"","permalink":"http://tonymua.top/SpringCloudAlibaba/","excerpt":"1.主要功能 服务限流降级 服务注册与发现 分布式配置管理 消息驱动能力 分布式事务","text":"1.主要功能 服务限流降级 服务注册与发现 分布式配置管理 消息驱动能力 分布式事务 Spring Cloud Alibaba使用@GlobalTransactional注解，高效并且零入侵地解决分布式事务问题。 2.主要组件 SentinelSentinel把流量作为切入点，从流量控制、熔断降级、系统负载等多个维度保障服务的稳定性。Sentinel主要分为两部分，客户端在我们的程序中集成，控制台基于Spring Boot开发，打包后直接运行。利用Sertinel流量控制功能可以对网关、服务进行过载保护，另一个核心功能是熔断降级，与Hystrix一致。 NacosNacos是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。主要功能有注册中心和配置中心。Nacos可以代替Eureka和Apollo。 RocketMQ分布式消息系统，基于高可用分布式集群技术，提供低延时、高可靠的消息发布与订阅服务。使用消息队列可以让服务之间更加解耦，还可以进行流量削峰，还可以用事务消息来实现分布式事务。 DubboJava RPC框架，Spring Cloud Alibaba体系中，服务之间的通信可以使用Dubbo进行远程调用。Rest的优势：通用性强、无语言限制、调试方便，但一般都是JSON格式，报文较大，Dubbo是二进制传输，性能更好。Spring Cloud Alibaba中可以将Dubbo和Feign结合使用，即服务可以暴露Dubbo协议，也可以暴露Rest协议，调用方选择对应的协议进行调用，对于性能要求高的使用Dubbo，其它的使用Rest。 Seata分布式事务解决方案，提供了AT、TCC等事务模式。 3.技术选型推荐 服务注册与发现：Nacos 服务熔断限流：Sentinel 服务通信调用：Feign 配置中心：Nacos 服务网关：Spring Cloud Gateway 分布式事务：Seata 消息队列：RocketMQ 调用链监控：Sleuth+Zipkin 分布式任务调度：XXL-JOB","categories":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"}]},{"title":"Sping Cloud组件扩展","slug":"Sping Cloud组件扩展","date":"2021-05-08T13:19:59.156Z","updated":"2021-03-17T14:13:35.253Z","comments":true,"path":"SpringCloud_02/","link":"","permalink":"http://tonymua.top/SpringCloud_02/","excerpt":"1.Apollo统一管理配置信息，增强配置管理的服务能力。使用配置中心管理配置后，可以将配置信息从项目转移到配置中心，一般一个项目会有一个唯一的标识ID，通过这个ID从配置中心获取对应的配置内容。","text":"1.Apollo统一管理配置信息，增强配置管理的服务能力。使用配置中心管理配置后，可以将配置信息从项目转移到配置中心，一般一个项目会有一个唯一的标识ID，通过这个ID从配置中心获取对应的配置内容。 拉取项目在启动的时候通过配置中心拉取配置信息。 推送在配置中心修改配置后，可以实时地推送给客户端进行更新。 解决的问题：每个节点都要重启、格式不规范、容易被错改、没有历史记录、安全性不高 1.1 主要功能 统一管理不同环境、不同集群的配置 配置修改实时生效，即热发布功能 版本发布管理 灰度发布 权限管理、发布审核、操作审计 提供Java和.Net原生客户端，轻松集成、操作简单 提供开放平台API 部署简单 Apollo 和 Spring Cloud Config 对比 1.2 概念介绍 应用应用指项目，标识用appId来指定，Spring Boot项目中建议直接配置在application.yml中。 环境Apollo客户端在运行时除了需要知道项目当前的身份标识，还需要知道当前项目对应的环境，从而根据环境去配置中心获取对应的配置。可以通过Java System Property或配置文件指定，目前支持的环境有Local、DEV、FAT(测试环境)、UAT(集成环境)、PRO(生产环境)。 集群不同的集群可以有不同的配置文件，可以通过Java System Property或配置文件来指定。 命名空间可以用来对配置做分类，不同类型的配置存放在不同的命名空间中，如数据库配置文件、消息队列配置、业务相关配置等。命名空间还可以让多个项目共用一份配置，如Redis集群。 权限控制 1.3 架构设计 Config Service服务于Client对配置的操作，提供配置的查询、更新接口(基于Http long polling) Admin Service服务于后台Portal(Web管理端)，提供配置管理接口 Meta ServerMeta Server是对Eureka的一个封装，提供了HTTP接口获取Admin Service和Config Service的服务信息。部署时和Config Service是在一个JVM进程中的，所以IP、端口和Config Service一致。 Eureka用于提供服务注册和发现，Config Service和Admin Service都会向Eureka注册服务。Eureka在部署时和Config Service在一个JVM进程中，即Config Service包含了Meta Server和Eureka。 Portal后台Web界面管理配置，通过Meta Server获取Admin Service服务列表(IP+Port)进行配置的管理，客户端做负载均衡。 CilentApollo提供的客户端，用于项目中对配置的获取、更新。通过Meta Server获取Config Service服务列表(IP+Port)进行配置的管理，客户端内做负载均衡。 工作流程： 注册、续约、取消，也就是服务注册的操作，Config Service和Admin Service都会注册到Eureka中。 服务发现的逻辑，Client需要指定所有的Config Service，Portal需要知道所有的Admin Service，然后才能发起对应的操作。查找服务列表是通过负载进行转发到Meta Server. Meta Server去Eureka中获取对应的服务列表。 当获取到对应的服务信息后，就可以直接发起远程调用了。 推送设计：在Portal中进行配置的编辑和发布操作后，Portal会调用Admin Service提供的接口进行发布操作。Admin Service收到请求后，发送ReleaseMessage给各个Config Service，通知Config Service配置发生了变化。Config Service收到ReleaseMessage后，通知对应的客户端，基于HTTP长连接实现。 消息设计：ReleaseMessage消息是通过MySQL实现了一个简单的消息队列。Admin Service在配置发布后会往ReleaseMessage表插入一条消息记录，Config Service会启动一个线程定时扫描ReleaseMessage表，去查看是否有新的消息记录。Config Service发现有新的消息记录，那么就会通知所有的消息监听器，消息监听器得到配置发布的信息后，则会通知对应的客户端。 客户端设计：客户端和服务端保持了一个长连接，编译配置的实时更新推送。定时拉取配置是客户端本地的一个定时任务，默认5分钟1次，也可以通过在运行时指定System Property:apollo.refreshInterval来进行覆盖，单位是分钟，采用推送+定时拉取的方式就等于双保险。客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中。客户端会把从服务取到的配置在本地文件系统中缓存一份，当服务或网络不可用时可以使用本地配置，也就是本地开发模式env=Local。 2.分布式链路跟踪分布式链路跟踪的关键在于如何将请求经过的服务节点都关联起来。 2.1 核心概念 Span基本工作单元，如发送RPC请求是一个新的Span、发送HTTP请求是一个新的Span、内部方法调用也是一个新的Span。 Trace一次分布式调用的链路信息，每次调用链路信息都会在请求入口处生成一个TraceId。 Annotation用于记录事件的信息。在Annotation中会有CS、SR、SS、CR这些信息。 CSClient Sent，客户端发送一个请求，这个Annotation表示Span的开始。 SRServer Received，服务端获得请求并开始处理，用SR的时间减去CS的时间即网络延迟时间。 SSServer Sent，在请求处理完成时将响应发送回客户端，SR-SS，即服务端处理请求所需的时间。 CRClient Recevied，表示Span结束，客户端从服务端收到响应，CR-CS，即全部时间。 2.2 请求追踪过程分解 当一个请求访问SERVICE1时，此时没有Trace和Span，会生成Trace和Span，如图所示生成Trace ID是X，Span ID是A。 接着SERVICE1请求SERVICE2，这是一次远程请求，会生成一个新的Span，Span ID为B，Trace ID不变还是X。Span B处于CS状态，当请求到达SERVICE2后，SERVICE2有内部操作，生成了一个新的Span，Span ID为C，Trace ID不变。 SERVICE2处理完后向SERVICE3发起请求，生成新的Span，Span ID为D，Span D处于CS状态，SERVICE3接收请求后，Span D处于RS状态，同时SERVICE内部操作也会生成新的Span，Span ID为E。 SERVICE3处理完后，需要将结果响应给调用方，此时Span D处于SS状态，当SERVICE2收到响应后，Span D处于CR状态。 一次请求会经过多个服务，会产生多个Span，但Trace ID只有一个。 2.3 Spring Cloud Sleuth 可以添加链路信息到日志中 链路数据可直接上报给Zipkin 内置了很多框架的埋点，如Zuul、Feign、Hystrix 2.4 Zipkin收集数据、查询数据。 CollectorZipkin的数据收集器，进行数据验证、存储。 Storage存储组件，Zipkin默认在内存中存储数据，数据落地的话支持ElasticSearch和MySQL。 SearchZipkin的查询API，用于查找和检索数据，主要使用者为Web UI。 Web UI提供可视化的操作界面，直观的查询链路跟踪数据。 链路跟踪的信息会通过Transport传递给Zipkin的Collector，Transport支持的方式有HTTP和MQ进行传输。 2.5 Sleuth关联整个请求链路日志集成Spring Cloud Sleuth后，会在原始的日志加上一些链路的信息。 application name应用名称，即application.yml里的spring.application.name参数配置的属性。 traceId为请求分配的唯一请求号，用来标识一条请求链路。 spanId基本的工作单元，一个请求可以包含多个步骤，每个步骤有自己的Span ID，一次请求只有一个Trace ID和多个Span Id。 export布尔类型，表示是否将该信息输出到Zipkin进行收集和展示。 2.6 使用技巧 抽样采集数据spring.sleuth.sampler.probability=10请求次数：Zipkin数据条数=10：1 RabbitMQ代替HTTP发送调用链路数据删除配置spring.zipkin.base-url，在启动Zipkin服务时指定RabbitMQ信息： 1java -DRABBIT_ADDRESSES=192.168.10.124:5672 -DRABBIT_USER=admin -DRABBIT_PASSWORD=123456 -jar zipkin.jar ElasticSearch存储调用链数据启动Zipkin的时候指定存储类型为ES，指定ES的URL信息： 1java -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=http://localhost:9200 -jar zipkin.jar 手动埋点检测性能 Hystrix埋点分析 3.微服务安全认证3.1 常用的认证方式 session用户登陆后将信息存储在服务端，客户端通过cookie中的sessionId来标识对应的用户。 缺点： 服务端需要保存每个用户的登录信息，如果用户量非常的，服务端的存储压力也会增大。 多节点时，通过负载均衡器进行转发，session可能会丢失。 解决办法：session复制，Nginx可以设置黏性Cookie来保证一个用户的请求只访问同一个节点；session集中存储，如存储在Redis中。 HTTP Basic AuthenticationHTTP基本认证，客户端会在请求头中增加Authorization，Authorization是用户名和密码Base64加密后的内容，服务端获取Authorization Header中的用户名与密码进行验证。 Token与HTTP Basic Authentication类似，与session不同，session只是一个key，会话信息存储在服务端。而Token中会存储用户的信息，然后通过加密算法进行加密，只有服务端才能解密，服务端拿到Token后进行解密获取用户信息。 3.2 JWT认证简介：JWT(JSON Web Token)如用户登录时，基本思路就是用户提供用户名和密码给认证服务器，服务器验证用户提交信息的合法性；如果验证成功，会产生并返回一个Token，用户可以使用这个Token访问服务器上受保护的资源。 JWT由三部分构成：头部(Header)、消息体(Payload)、签名(Signature) 1token = encodeBase64(header) + '.' + encodeBase64(payload) + '.' + encodeBase64(signature) 头部信息：令牌类型、签名算法 1&#123; \"alg\": \"HS256\", \"typ\": \"JWT\" &#125; 消息体：应用需要的信息，如用户的id 1&#123;\"id\": \"1234567890\", \"name\": \"John Doe\"&#125; 签名：用来判断消息在传递的路径上是否被篡改 1HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) JWT认证流程：客户端需要调用服务端提供的认证接口来获取 Token。获取 Token 的流程如图所示，客户端会首先发起一个认证的请求到网关，网关会将请求转发到后端的用户服务中，在用户服务中验证身份后，就会根据用户的信息生成一个 Token 返回给客户端，这样客户端就获取了后面请求的通行证。然后，客户端会将获取的 Token 存储起来，在下次请求时带上这个 Token，一般会将 Token 放入请求头中进行传递。当请求到达网关后，会在网关中对 Token 进行校验，如果校验成功，则将该请求转发到后端的服务中，在转发时会将 Token 解析出的用户信息也一并带过去，这样在后端的服务中就不用再解析一遍 Token 获取的用户信息，这个操作统一在网关进行的。如果校验失败，那么就直接返回对应的结果给客户端，不会将请求进行转发。 在网关中，验证过滤器会对 /oauth/token 这个认证 API 进行放行，不进行验证。用户信息的全局传递扩展：不需要加参数，直接通过请求头进行传递，在服务内部通过ThreadLocal进行上下文传递。主要流程：从网关传递到后端服务，后端服务接受数据后存储到ThreadLocal中，服务会调用其它服务，如果用Feign调用可以利用Feign的拦截器传递数据，如果用RestTemplate的拦截器传递数据也一样。 3.3 Token的使用Token注销Token的有效期存储在Token本身中，只有解析出Token的信息，才能获取到Token的有效时间，不能修改。Token的有效期越短，安全性越高。还可以在用户退出登录时，进行Token的注销操作，如将注销的Token放入Redis中进行一层过滤，即在网关中验证Token有效性时先从Redis中判断Token是否存在，如果存在，直接拦截。Token放入Redis的过期时间一般会设置为Token剩余的有效时间。 使用建议 设置较短(合理)的过期时间 注销的Token及时清除(放入Redis中做一层过滤) 监控Token的使用频率 核心功能敏感操作可以使用动态验证(验证码) 网络环境、浏览器信息等识别 加密密钥支持动态修改 加密密钥支持动态修改 3.4 内部服务之间的认证 IP白名单如用户服务只能某些IP或IP段访问，IP白名单可以采用配置中心来存储，具备实时刷新的能力。 内部同样使用Token进行验证服务在启动时就可以在统一的认证服务中申请Token，申请需要的认证信息可以放在配置中心。这样服务启动时就有了能够访问其他服务的Token，在调用时带上Token，被调用的服务中进行Token的校验。对于Token的失效更新： 在请求时如果返回的Token已经失效，那么可以重新获取Token后再发起调用，这种在并发量大时需要加锁，不然会发生同时申请多个Token的情况。 定时更新，如Token有效期1个小时，那么定时任务可以50分钟更新一次。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"}]},{"title":"Sping Cloud相关组件了解","slug":"Sping Cloud相关组件了解","date":"2021-05-08T13:19:59.154Z","updated":"2021-03-15T02:09:38.855Z","comments":true,"path":"SpringCloud_01/","link":"","permalink":"http://tonymua.top/SpringCloud_01/","excerpt":"1.Eureka如果需要实现完整的服务注册与服务发现的功能，我们需要有注册中心来统一存储和管理服务信息，应用程序需要将自身的信息注册到注册中心，也就是服务提供者和服务消费者的信息。整个过程中包含的操作有注册、拉取、心跳、剔除等动作。","text":"1.Eureka如果需要实现完整的服务注册与服务发现的功能，我们需要有注册中心来统一存储和管理服务信息，应用程序需要将自身的信息注册到注册中心，也就是服务提供者和服务消费者的信息。整个过程中包含的操作有注册、拉取、心跳、剔除等动作。 注册中心：用来集中存储管理服务信息。 服务提供者：通过API供其他方调用服务。 服务消费者：需要调用其他方的API获取服务。 项目启动后Eureka Client会向Eureka Server发送请求，进行注册，并将自身信息发送给Eureka Server。注册成功后，每隔一定的时间，Eureka Client会向Eureka Server发送心跳来续约服务，汇报健康状态。如果客户端长时间没有续约，那么Eureka Server大约在90秒内从服务器注册表中清除客户端的信息。应用程序停止时Eureka Client会通知Eureka Server移除相关信息，信息移除成功后，对应的客户端会更新服务的信息，这样就不会调用已经下线的服务，但操作具有延迟，有可能会调到已经失效的服务，所以在客户端会开启失败重试功能来避免这个问题。Eureka Serve集群保证高可用，Eureka Server没有集成其它第三方存储，而是存储在内存中。所以Eureka Server之间会将注册信息复制到集群中的Eureka Serve的所有节点。这样数据才是共享状态，任何的Eureka Client都可以在任何一个Eureka Server节点查找到注册信息。 1.1 Eureka注册表Eureka的注册信息是存储在ConcurrentHashMap中的，Map的key是服务名称，value是一个Map。value的Map的key是服务实例的ID，value是Lease类，Lease中存储了实例的注册时间、上线时间等信息，还有具体的实例信息，如IP、端口、健康检查的地址等信息。 Eureka将注册的服务信息存储在内存中的原因：性能高；部署简单，不需要依赖于第三方存储。劣势：扩容难度高，每个Eureka Server都全量的存储一份注册表，假如存储空间不够了，需要扩容，那么所有的Eureka Server节点都必须扩容，必须采用的内存配置。 Eureka核心操作主要有注册、续约、下线、移除，接口为com.netflix.eureka.lease.LeaseManager，这些操作都是针对注册表的操作，也就是Map的操作。 1.2 自我保护机制自我保护机制是为了避免因网络分区故障而导致服务不可用的问题。自我保护机制带来的问题：若服务提供者B真的下线了，由于Eureka Serve自我保护机制打开，不会移除任务信息，当服务消费者对服务提供者B进行调用时，就会出错。出现某些有问题的实例没能及时移除掉的情况，服务消费者可以通过Ribbon来进行重试，保证调用能够成功。 自我保护开启的条件：AbstractInstanceRegistry中有两个字段，numberOfRenewsPerMinThreshold(期望最小每分钟能够续租的次数)、expectedNumberOfClientsSendingRenews(期望的服务实例数)。假如有10个实例，每个实例每分钟续约2次，那么10x2x0.85=17，即每分钟至少有17次续约才是正常的。 1.3 健康检查Eureka Client会定时发送心跳给Eureka Server来证明自己是否处于健康的状态。但某些场景下，服务处于存活状态，却已经不能对外提供服务，如数据库出问题了，但心跳正常，客户端在请求时还会请求到这个出问题的实例。可以在项目中集成Actuator，统一管理应用的健康状态，将这个状态反馈给Eureka Server。 2.Ribbon2.1 负载均衡负载均衡是一种基础的网络服务，它的核心原理是按照指定的负载均衡算法，将请求分配到后端服务集群上，从而为系统提供并行处理和高可用的能力。 集中式负载均衡：在消费者和提供者中间使用独立的代理方式进行负载，有硬件的负载均衡器，如F5，也有软件，如Nginx。客户端不需要关心对应服务实例的信息，只需要与负载均衡器进行交互，服务实例扩容或者缩容，客户端不需要修改任何代码。 客户端负载均衡：需要自己维护服务实例信息，然后通过某些负载均衡算法，从实例中选取一个实例，直接进行访问。区别：对服务实例信息的维护。集中式负载均衡的信息是集中进行维护的，如Nginx，都会在配置文件中进行指定。客户端负载均衡的信息是在客户端本地进行维护的，可以手动配置，最常见的是从注册中心拉取。 2.2 Ribbon使用方式： 原生API Ribbon+RestTemplate Ribbon+Feign通过给加了@LoadBalanced的RestTemplate添加拦截器，拦截器中通过Ribbon选取服务实例，然后将请求地址中的服务名称替换成Ribbon选取服务实例的IP和端口。 2.3 负载均衡策略 内置负载均衡策略 RoundRobinRule：轮询算法 RandomRule：随机算法 BestAvailableRule：选择一个最小的并发请求server，如果有A、B两个实例，当A有4个请求正在处理中，B有2个，下次请求会选择B，适用于服务所在机器配置相同的情况。 WeightedResponseTimeRule：根据请求的响应时间计算权重，如果响应时间越长，那么对应的权重越低，权重越低的服务器，被选择的可能性就越低。 自定义负载均衡算法 实现IRule接口或继承AbstractLoadBanlancerRule 实现choose方法 指定Ribbon的算法类使用场景： 定制与业务更匹配的策略。 灰度发布 多版本隔离 故障隔离 2.4 饥饿加载模式Ribbon在进行客户端负载均衡时并不是启动时就加载上下文，而是第一次请求时才去创建的，因此第一次调用会比较慢，有可能会引起调用超时。可以指定Ribbon客户端的名称，在启动时加载这些子应用程序上下文。 初始化后进行了缓存操作，getContext()方法中，如果在contexts中不存在才会创建，创建时会用synchronized加锁，并进行二次判断，防止并发下出现创建多次的问题，最后进行增加操作。如果有的话就直接从contexts获取返回。contexts就是一个ConcurrentHashMap。 3.Hystrix3.1 服务雪崩微服务架构下，会存在服务之间相互依赖调用的情况，当某个服务不可用时，很容易因为服务之间的依赖关系使故障扩大，甚至造成整个系统不可用，这种现象称为服务雪崩效应。 产生原因： 服务提供者代码的Bug问题，由于某些代码导致CPU飙升，将资源耗尽等；服务器出现问题，磁盘出问题，导致数据读写特别慢，拉高了响应时间；慢SQL语句问题；请求量太大，超出系统本身的承受能力。 服务消费者同步调用等待结果导致资源耗尽；自己既是服务消费者也是服务提供者。 解决方案： 服务提供者代码Bug问题：测试、Code Review等方式；慢SQL问题：数据库性能优化；服务器硬件故障问题：加大运维粒度，通过监控等手段提前预防；请求量超出承受能力：扩容或限流 服务消费者资源隔离、快速失败。 3.2 容错实现设计原则： 封装请求：将用户的操作进行统一封装，目的在于进行统一控制。 资源隔离：将对应的资源按照指定的类型进行隔离，如线程池和信号量。 失败回退：备用方案，当请求失败后，Hystrix会让用户自定义备用方案。 断路器：决定了请求是否需要真正的执行，如果断路器打开，那么所有的请求都将失败，执行回退逻辑。如果断路器关闭，那么请求将正常执行。 指标监控：对请求的生命周期进行监控。 工作原理： 构建一个HystrixCommand或者HystrixObservableCommand对象，将请求包装到Command对象中。 执行构建好的命令。 判断当前请求是否有缓存，如果有就直接返回缓存的内容。 判断断路器是否打开，如果打开，跳到第8步，获取fallback方法，执行fallback逻辑。如果没有打开，执行第5步。 如果是线程池隔离模式，判断线程池队列的容量；如果是信号量隔离模式，会判断信号量的值是否已经被使用完。如果线程池和信号量都已经满了，同样请求不被执行，直接跳到第8步。 执行HystrixObservableCommand.construct()或HystrixCommand.run()方法，正在执行的请求逻辑就封装在construct()或run()方法中。 请求过程中，若出现异常或者超时，会直接到第8步，执行成功就返回结果。执行结果会将数据上报给断路器，断路器会根据上报的数据来判断断路器是否打开 fallback 3.3 Hystrix使用 HystrixCommand注解方式 在Feign中使用 在Zuul中使用 Hystrix配置： 3.4 Hystrix隔离机制 线程池隔离：当用户请求A服务后，A服务需要调用其它服务，这个时候可以为不同的服务创建独立的线程池，假如A需要调用B和C，那么可以创建两个独立的线程池，将调用B服务的线程池丢入到一个线程池，将调用C服务的线程丢入另一个线程池，这样起隔离效果，就算其中某个线程池请求满了，无法处理请求了，对另一个线程池页没有影响。使用线程隔离。需要调整好线程池参数，否则和信号量一样，并发量大的时候性能上不去。设置最大线程数，默认为10，队列大小决定了能够堆积多少请求，但请求不能一直堆积，所有还需要设置一个阈值来进行拒绝。 信号量隔离：信号量就算一个计数器，如初始化是100，那么每次请求过来时信号量就会减1，当信号量计数为0时，请求就会被拒绝，等之前的请求处理完成后，信号量就会加1。起到了限流的作用，信号量隔离是在请求主线程中执行的。 线程池隔离的特点是Command运行在独立的线程池中，可以支持超时，是单独的线程，支持异步。信号量隔离运行在调用的主线程中，不支持超时，只能同步调用。 3.5 使用技巧 配置可以对接配置中心进行动态调整 回退逻辑中可以手动埋点或者通过输出日志进行告警 使用线程池隔离模式再用ThreadLocal会有坑被隔离的方法会包装成一个Command丢入到独立的线程中执行，这个时候就是从A线程切换到了B线程，ThreadLocal的数据就会丢失。 网关中尽量用信号隔离 插件机制可以实现很多扩展 Hystrix各种超时配置方式 commandKey、groupKey、threadPoolKey的使用在使用HystrixCommand注解时，会配置commandKey、groupKey、threadPoolKey。commandKey表示封装的command的名称，可以给指定的commandKey进行参数的设置。groupKey是将一组command进行分组，如果没有设置threadPoolKey的话，那么线程池的名称会用groupKey。threadPollKey是线程池的名称，多个command的threadPoolKey相同，那么会使用同一个线程池。 4.FeignFeign是一个声明式的REST客户端，Feign提供了HTTP请求的模板，通过编写简单的接口和插入注解，就可以定义好Http请求的参数、格式、地址等信息。Feign会完全代理HTTP请求，Spring Cloud对Feign进行了封装，使其支持SpringMVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡，与Hystrix组合使用，支持熔断回退。 4.1 重要组件 Contract 契约组件Contract允许用户自定义契约去解析注解信息，如在Spring Cloud中使用Feign，可以使用SpringMVC的注解来定义Feign的客户端。 Encoder 编码组件通过该组件可以将请求信息采用指定的编码方式来进行编码后传输。 Decoder 编码组件 Decoder将相应数据解码成对象。 ErrorDecoder 异常解码器当被调用方发生异常后，可以在ErrorDecoder中将响应的数据转换成具体的异常返回给调用方，适合内部服务之间调用，但不想通过指定的字段来判断是否成功的场景，直接用自定义异常代替。 Logger 日志记录Logger组件负责Feign中记录日志的，可以指定Logger的级别及自定义日志的输出。 Client 请求执行组件Client是负责HTTP请求执行的组件，Feign将请求信息封装好后会交由Client来执行，Feign中默认的Client是通过JDK的HttpURLConnection发起请求的，每次发起请求的适合，都会建立新的HttpURLConnection链接，性能很差。可以扩展该接口，使用Apache HttpClient等基于连接池的高性能HTTP客户端。 Retryer 重试组件Retryer是负责重试的组件，Feign内置了重试器，当HTTP请求出现IO异常时，Feign会限定最大重试次数来进行重试操作。 InvocationHandlerFactory 代理IncocationHandlerFactory采用JDK的动态代理方式生成代理对象，定义的Feign接口，当调用这个接口中定义的方法时，实际上是去调用远程的HTTP API，这里用了动态代理的方式，当调用某个方法时，会进入代理中正在的去调用远程HTTP API。 RequestInterceptor 请求拦截器可以为Feign添加多个拦截器，在请求执行前设置一些扩展的参数信息。 QueryMapEncoder 参数查询QueryMapEncoder是针对实体类参数查询的编码器，可以基于QueryMapEncoder将实体类生成对应的查询参数。 4.2 Feign执行过程定义对应的接口类，在接口类上使用Feign自带的注解来标识HTTP的参数信息，当调用接口对应的方法时，Feign内部会基于面向接口的动态代理方式生成实现类，将请求调用委托到动态代理实现类，负责动态代理的组件是InvocationHandlerFactory。根据Contract规则，解析接口类的注解信息，翻译成Feign内部能识别的信息。Spring Cloud OpenFeign中就扩展了SpringMVCContract。MethodHandler在执行的时候会生成Request对象，在构建Request对象的时候会为其设置拦截器，交由Client执行前记录一些日志，Client执行完成后也记录一些日志，然后使Decoder进行相应结果的解码操作，并返回结果。 4.3 使用技巧 继承特性将API的定义提取出来封装成一个单独的接口，给API的实现方和调用方共用。 拦截器添加自己的拦截器来实现某些场景下的需求，实现RequestInterceptor接口，在apply方法中编写自己的逻辑。 GET请求多参数传递一般超过3个以上的参数会封装在一个实体类中，在Spring Cloud Open Feign中要支持对象接收多个参数，需要增加@SpringQueryMap注解。 日志配置Feign日志级别： NONE：不输出日志 BASIC：只输出请求方法的URL和响应的状态码及执行的时间 HEADERS：将BASIC和请求头信息输出 FULL：会输出全部完整的请求信息 异常解码器 5.ZuulAPI网关是对外提供服务的一个入口，并且隐藏了内部架构的实现。可以为我们管理大量的API接口，负责对接用户、协议适配、安全认证、路由转发、流量限制、日志监控、防止爬虫、灰度发布等功能。 动态路由将客户端的请求路由到后端不同的服务上，如果没有网关去做统一的路由，那么客户端就要关注后端N个服务。 请求监控对整个系统的请求进行监控，详细的记录请求响应日志，可以实时的统计当前系统的访问量及监控状态。 认证鉴权统一对访问请求做认证，拒绝非法请求，保护后端的服务。 压力测试动态的将测试请求转发到后端服务的集群中，还可以识别测试流量和真实流量，用来做一些特殊的处理。 灰度发布当需要发布新版本时，通过测试请求对1.1版本的服务进行测试，若没发现问题，可以将正常的请求转发过来，若有问题，不影响用户使用的1.0版本。 5.1 过滤器过滤器可以对请求或响应结果进行处理，Zuul支持动态加载、编译、运行这些过滤器。 pre过滤器：可以在请求被路由器之前调用。适用于身份认证的场景，认证通过后再继续执行下个流程。 route过滤器：在路由请求时被调用。适用于灰度发布的场景，在将要路由的时候可以做一些自定义的逻辑。 post过滤器：在route和error过滤器之后被调用。将请求路由到达具体的服务之后执行，适用于添加响应头，记录响应日志等应用场景。 error过滤器：处理请求发生错误时被调用。在执行过程中发送错误时会进入error过滤器，可以用来统一记录错误信息。 自定义过滤器：继承ZuulFilter，然后重写ZuulFilter的四个方法shouldFilter方法决定了是否执行该过滤器，true为执行，false不执行，可以利用配置中心实现动态的开启或关闭过滤器。filterType方法是要返回过滤器的类型，可选择为pre、route、post、error四种类型。过滤器可以有多个，先后顺序可以通过filterOrder来指定过滤器的执行顺序，数字越小，优先级越高。业务逻辑写在run方法中。 5.2 请求生命周期请求先进入pre过滤器，在pre过滤器执行完后，进入routing过滤器，开始路由到具体的服务中，路由完成后，接着到了post过滤器，然后将请求结果返回给客户端。如果过程中出现异常，则会进入error过滤器。源码对应ZuulServlet。 5.3 Zuul容错与回退5.4 使用技巧 内置端点当@EnableZuulProxy与Spring Boot Actuator配合使用时，Zuul会暴露一个路由管理端点/routes。借助这个端点，可以直观的查看及管理Zuul的路由。还有一个/filters端点可以查看Zuul中所有过滤器的信息。 文件上传通过Zuul上传文件，超过1M的文件会上传失败，配置max-file-size和max-request-size，Zuul中需要配置，最终接受文件的服务也要配置。或在网关请求地址前面上加上/zuul，可以绕过Spring DispatcherServlet上传大文件。Zuul服务不用再配置，但接收文件的服务还是要配置文件上传大小。在上传大文件时，时间较长，可以设置Ribbon的ConnectTimeOut和ReadTimeOut。如果Zuul的Hystrix隔离模式为线程的话需要设置Hystrix的超时时间。 请求响应输出 Zuul Debug 跨域配置 关闭Zuul全局路由转发配置zuul.ignored-service=*关闭路由转发，配置zuui.ignoredPatterns忽略不想暴露的API。 动态过滤器定期扫描存放Groovy Filter文件的目录，如果发现有新Groovy Filter文件或者Groovy Filter源码有改动，那么就会对Groovy文件进行编译加载。首先在项目中增加Groovy的依赖，然后在项目启动后设置Groovy的动态加载任务，定时动态加载指定目录的Groovy文件。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"}]},{"title":"Redis五种数据类型的底层结构","slug":"Redis五种数据类型的底层结构","date":"2021-05-08T13:19:59.153Z","updated":"2021-04-24T15:10:14.121Z","comments":true,"path":"redisfive/","link":"","permalink":"http://tonymua.top/redisfive/","excerpt":"RedisObject: Redis 中只有一个 K，一个 V。其中 K 绝对是字符串对象，而 V 可以是 String、List、Hash、Set、ZSet 任意一种。","text":"RedisObject: Redis 中只有一个 K，一个 V。其中 K 绝对是字符串对象，而 V 可以是 String、List、Hash、Set、ZSet 任意一种。 123456789101112typedef struct redisObject &#123; // 类型 string list set hash zset等 4bit unsigned type:4; // 编码方式 4bit unsigned encoding:4; // LRU 时间 24bit unsigned lru:LRU_BITS; // 引用计数 4byte int refcount; // 指向对象的指针 8byte 指针指向具体的数据，如set test hello，ptr指向的就是存储hello的字符串。 void *ptr;&#125; robj; encoding： 1234567891011/** 对象编码*/#define REDIS_ENCODING_RAW 0 // 编码为字符串#define REDIS_ENCODING_INT 1 // 编码为整数#define REDIS_ENCODING_HT 2 // 编码为哈希表#define REDIS_ENCODING_ZIPMAP 3 // 编码为 zipmap(2.6 后不再使用)#define REDIS_ENCODING_LINKEDLIST 4 // 编码为双端链表#define REDIS_ENCODING_ZIPLIST 5 // 编码为压缩列表#define REDIS_ENCODING_INTSET 6 // 编码为整数集合#define REDIS_ENCODING_SKIPLIST 7 // 编码为跳跃表 lru 记录对象最后一次被命令程序访问的时间，通过lru时间和当前时间可以计算某个对象的空转时间；利用object idletiem命令可以显示空转时间(单位为秒)，且不会改变该对象的lru。 refcount 该对象被引用的次数，目前共享对象只支持整数值的字符串对象。 1.String三种编码方式： int：存储的字符串全是数字 embstr：存储的字符串长度小于44个字符 raw：存储的字符串长度大于44个字符 embstr类型，它的数据指针和SDS对象在内存地址是连在一起的；但对于raw类型，二者在内存地址不是连续的。 SDS封装char[]，一个SDS最大512M 12345struct sdshdr&#123; unsigned int len; // 标记char[]的长度 unsigned int free; //标记char[]中未使用的元素个数 char buf[]; // 存放元素的坑&#125; Redis底层对SDS做的优化 预空间分配 SDS长度(len的值)小于1MB，那么程序将分配和len属性同样大小的未使用空间，此时 free和len属性值相同。假如SDS的len将变成15字节，则程序也会分配15字节的未使用空间，SDS的buf数组的实际长度变为15+15+1=31字节(额外一个字节用户保存空字符串) SDS长度(len的值)大于等于1MB，程序会分配1MB的未使用空间。如进行修改之后，SDS的len变成30MB，那么它的实际长度为30MB+1MB+1byte 惰性释放空间 当执行sdstrim(截取字符串)之后，SDS不会立即释放多出来的空间，如果下次在进行字符串拼接操作，且拼接的没有刚才释放的大，就会使用刚才的空间，不需要再重新申请空间。 二进制安全 C语言通过是否存在空字符\\0来判断是否已经是字符串的结尾。某些情况下(如使用空格进行分割一段字符串、或图片、视频等二进制文件)时，就会出现问题。SDS通过len字段判断，因此具备二进制安全性。 2.ListquickList(快速列表，是zipList压缩列表和linkedList双端链表的组合)，最大长度2^32-1，自测两端插入和弹出，并可以获得指定位置(或范围)的元素，可以充当数组、队列和栈。 lpush+lpop 先进后出的栈 lpush+rpop 先进先出的队列 lpush+ltrim 有限集合 lpush+Brpop 消息队列 linkedList 1234567891011121314151617181920212223//定义链表节点的结构体 typedef struct listNode &#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value; &#125;typedef struct list&#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表包含节点的数量 unsigned long len; //节点复制函数，用于链表转移复制时对节点value拷贝的实现，一般情况下使用等号，某些特殊情况下给这个函数赋值NULL即表示使用等号进行节点转移 vode *(*dup) (void *ptr); //节点释放函数，用于释放一个节点所占用的内存空间，默认赋值NULL，即使用Redis自带的zfree函数进行内存空间释放 vode *(*free) (void *ptr); //节点对比函数，用于对比两个链表节点的value是否相等，相等返回1，不相等返回0 vode *(*match) (void *ptr,void *key);&#125; 获取前置节点、后置节点、表头节点和表尾节点的复杂度都是O(1)，获取节点数量也是O(1)。与双端链表相比，压缩列表可以节省空间，但进行修改或增删操作时，复杂度较高；因此节点数量较少时，可以使用压缩列表，但节点数量较多时，还是使用双端链表。 zipList 123456789101112131415161718192021typedf struct ziplist&lt;T&gt;&#123; //压缩列表占用字符数 int32 zlbytes; //最后一个元素距离起始位置的偏移量，用于快速定位最后一个节点 int32 zltail_offset; //元素个数 int16 zllength; //元素内容 T[] entries; //结束位 0xFF int8 zlend;&#125;ziplist typede struct entry&#123; //前一个entry的长度，倒序遍历可以通过这个参数定位到上一个entry的位置 int&lt;var&gt; prelen; //元素类型编码 int&lt;var&gt; encoding; //元素内容 optional byte[] content;&#125;entry zltail_offset这个参数可以快速定位到最后一个entry节点的位置，然后开始倒序遍历，即ziplist支持双向遍历。zipList遍历的时候，先根据zlbytes和zltail_offset定位到最后一个entry的位置，然后根据根据entry的prelen时确定前一个entry的位置。 zipList相比linkedList少了pre和next两个指针16个字节(64位系统1个指针就是8个字节)，linkedList每个节点内存都是单独分配，家具内存碎片化，zipList是由连续的内存组成的。 连锁更新 entry的prelen字段：前一个节点的长度小于254个字节时，prelen长度为1字节；前一个节点的长度大于254个字节时，prelen长度为5字节 假设现在有一组压缩列表，长度都在250~253字节之间，突然新增一个entry节点，这个entry节点长度大于等于254字节。由于新的entry节点大于等于254字节，这个entry节点的prelen为5个字节，随后会导致其余的所有entry节点的prelen增大为5字节；同样地，删除操作也会导致出现连锁更新这种情况。 zipList与linkedList的区别 当列表中元素的长度较小或数量较少时，通常采用zipList，当列表中元素长度较大或者数量较多时，使用linkedList 双向链表linkedList便于在列表的两端进行push和pop，插入节点复杂度很低，但内存开销比较大。(额外保存prev和next指针；内存碎片) zipList存储在一块连续的内存上，所以存储效率高，但插入和删除操作需要频繁的申请和释放内存。 3.2版本之后List使用quickList代替了zipList和linkedList，是zipList和linkedList的混合体。它将linkedList按段切分，每一段使用zipList来紧凑存储，多个zipList之间使用双向指针串接起来。 quickList内部默认单个zipList长度为8k字节，即redis.conf中list-max-ziplist-size的值为-2，超过这个阈值就会重新生成一个zipList来存储数据。当list-max-ziplist-size为正数n时，表示每个quicklist节点上的ziplist最多包含n个数据项。 压缩深度 quickList可以使用LZF算法对zipList进一步压缩，压缩后的zipList结构为 123456typedf struct ziplist_compressed&#123; //元素个数 int32 size; //元素内容 byte[] compressed_data&#125; 此时quicList为： redis.conf中list-compress-depth表示一个quickList两端不被压缩的节点的个数(指quickList双向链表节点个数，而不是zipList里数据项个数)，quickList默认压缩深度为0，即不开启压缩；当list-compress-depth为1，表示quickList的两端各有1个节点不进行压缩，中间节点进行压缩；当list-compress-dept为2，表示quickList的首尾各有2个节点不进行压缩，中间节点进行压缩；由此类推，对于quickList来说，首尾两个节点永远不会被压缩。 3.Hash dict 底层可以是zipList或hashtable(字典也叫哈希表)，hash中元素数量小于512个且所有键值对的键和值字符串长度都小于64字节时，才会使用zipList。 1234567typedf struct dict&#123; dictType *type;//类型特定函数，包括一些自定义函数，这些函数使得key和value能够存储 void *private;//私有数据 dictht ht[2];//两张hash表 int rehashidx;//rehash索引，字典没有进行rehash时，此值为-1 unsigned long iterators; //正在迭代的迭代器数量&#125;dict; type和private这两个属性是为了实现字典多态而设置的，当字典中存放着不同类型的值，对于的一些复制、比较函数也不一样。 rehashidx，这是一个辅助变量，用于记录rehash过程的进度，以及是否正在进行rehash等信息，等于-1时，表示dict此时没有rehash过程。 iterators，记录此时dict有几个迭代器正在进行遍历过程。 dictht dict本质上是对dicht的一个简单封装 123456typedf struct dictht&#123; dictEntry **table;//存储数据的dicEntry类型的数组 二维 unsigned long size;//数组的大小 unsigned long sizemask;//哈希表的大小的掩码，用于计算索引值，总是等于size-1 unsigned long used;//// 哈希表中中元素个数&#125;dictht; dicthtEntry 12345678910typedf struct dictEntry&#123; void *key;//键 union&#123; void val; unit64_t u64; int64_t s64; double d; &#125;v;//值 struct dictEntry *next；//指向下一个节点的指针&#125;dictEntry; 扩容与缩容 渐进式hash 假设当前数据在dictht[0]中，那么首先未dictht[1]分配足够的空间，如果是扩容，则dictht[1]的大小按照扩容规则进行扩容，如果是缩减，则dictht[1]的大小按照缩减规则进行缩减。 在字典dict中维护一个变量，rehashidx=0，表示rehash正式开始。 rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，还会顺带将dictht[0]哈希表在rehashidx索引上的所有键值对rehash到dichth[1]，当一次rehash工作完成之后，程序将rehashidx属性的值+1。同时在serverCron中调用rehash相关函数，在1ms的时间内，进行rehash处理，每次仅处理少量的转移任务(100个元素)。 当dichth[0]的所有键值对都会被rehash至dichth[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。 每次对字典执行增删改查才会触发rehash，万一某段时间没有任何命令请求命令呢？ Redis有一个定时器，会定时判断rehash是否完成，如果没有完成，则继续hash。 如果是添加操作，会将新的数据直接添加到dichth[1]上，而对于删除、更改、查询操作，会直接在dictht[0]上进行，当dictht[0]上查询不到时，会接着去dictht[1]上查找，如果再找不到，则表明不存在该K-V值。 优点：采用分而治之的思想，将rehash操作分散到每一次到hash表的操作上及定时函数上，避免了集中式hash带来的性能压力。 缺点：在rehash过程中，需要保存两个hash表，对内存的占用比较大，如果在Redis服务器本来内存满了的时候，突然进行rehash会造成大量的key被抛弃。 4.Set无序且存储元素不重复。当value是整数时，且数据量不大时使用inset存储，其他情况用字典dict来存储。 inset 12345678typedf struct inset&#123; uint32_t encoding;//编码方式 有三种 默认 INSET_ENC_INT16 会根据插入数据的大小选择不一样的类型来存储 uint32_t length;//集合元素个数 int8_t contents[];//实际存储元素的数组，元素类型并不一定是ini8_t类型，柔性数组不占intset结构体大小，并且数组中的元素从小到大排列&#125;inset;#define INTSET_ENC_INT16 (sizeof(int16_t)) //16位，2个字节，表示范围-32,768~32,767#define INTSET_ENC_INT32 (sizeof(int32_t)) //32位，4个字节，表示范围-2,147,483,648~2,147,483,647#define INTSET_ENC_INT64 (sizeof(int64_t)) //64位，8个字节，表示范围-9,223,372,036,854,775,808~9,223,372,036,854,775,807 inset升级过程 了解旧的存储格式，计算出目前已有元素占用大小，计算规则是length*encoding，如4 * 16=64 确定新的编码格式，当原有的编码格式不能存储下新增的数据时，此时就要选择新的合适的编码格式 根据新的编码格式计算出需要新增的内存大小，然后从尾部将数据插入 根据新的编码格式重置之前的值，此时contents存在两种编码格式的值，需要统一，从插入新数据的位置开始，从后向前将之前的数据按照新的编码格式进行移动和设置。从后往前是为了防止数据被覆盖。 优点：根据存入的数据选择合适的编码方式，且只在必要的时候进行升级操作，节省内存。 缺点：耗费系统资源，不支持降级。 5.SortedSet常用作排行榜等功能，以用户id为value，关注事件或者分数作为score进行排序。zipList和skipList两种不同的实现： zipList [score,value]键值对数量少于128个 每个元素的长度小于64字节 skipList 不满足以上两个条件时使用跳表、组合了hash和skipList，hash用来存储value到score的映射，这样就可以在O(1)时间内找到value对应的分数；skipList按照从小到大的顺序存储分数；skipList每个元素的值都是[score,value]对。 skipList 空间换时间 跳表一个节点最高可以达到64层，一个跳表中最多可以存储2^64个元素。跳表中，每个节点都是一个skipListNode，每个跳表的节点也都会维护一个score值，这个值在跳表中是按照从小到大的顺序排列好的。 12345678910typedf struct zskiplist&#123; //头节点 struct zskiplistNode *header; //尾节点 struct zskiplistNode *tail; //跳表中元素个数 unsigned long length; //目前表内节点的最大层数 int level;&#125;zskiplist; 123456789typedf struct zskiplistNode&#123; sds ele;// 具体的数据 每个节点所保存的数据是唯一的，但节点的分数可以是一样的。两个相同分数的节点是按照元素的字典序进行排列的； double score;// 分数 从小到大排序 struct zskiplistNode *backward;//后退指针，用于从表尾向表头遍历，每个节点只有一个，即每次只能后退一步 struct zskiplistLevel&#123; struct zskiplistNode *forward;//前进指针forward，指向下一个节点 unsigned int span;//跨度span用来计算当前节点在跳表中的一个排名 &#125;level[];//层级数组 最大32&#125;zskiplistNode;","categories":[{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/tags/Redis/"}]},{"title":"Redis","slug":"Redis","date":"2021-05-08T13:19:59.151Z","updated":"2020-04-29T02:44:38.032Z","comments":true,"path":"27273/","link":"","permalink":"http://tonymua.top/27273/","excerpt":"1.Redis概述redis是一款高性能的NOSQL系列的非关系型数据库 1.1 什么是NoSQL​ NoSQL(NoSQL = Not Only SQL)，意即“不仅仅是SQL”，是一项全新的数据库理念，泛指非关系型的数据库。​ 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集和多重数据种类带来的挑战，尤其是大数据应用难题。 1.1.1 NOSQL和关系型数据库比较","text":"1.Redis概述redis是一款高性能的NOSQL系列的非关系型数据库 1.1 什么是NoSQL​ NoSQL(NoSQL = Not Only SQL)，意即“不仅仅是SQL”，是一项全新的数据库理念，泛指非关系型的数据库。​ 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集和多重数据种类带来的挑战，尤其是大数据应用难题。 1.1.1 NOSQL和关系型数据库比较 优点： (1) 成本：nosql数据库简单易部署，基本都是开源软件，不需要像使用oracle那样花费大量成本购买使用，相比关系型数据库价格便宜。 (2) 查询速度：nosql数据库将数据存储于缓存之中，关系型数据库将数据存储在硬盘中，自然查询速度远不及nosql数据库。 (3) 存储数据的格式：nosql的存储格式是key,value形式、文档形式、图片形式等等，所以可以存储基础类型以及对象或者是集合等各种格式，而数据库则只支持基础类型。 (4) 扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。 缺点： (1) 维护的工具和资料有限，因为nosql是属于新的技术，不能和关系型数据库10几年的技术同日而语。 (2) 不提供对sql的支持，如果不支持sql这样的工业标准，将产生一定用户的学习和使用成本。 (3) 不提供关系型数据库对事务的处理。 1.1.2 非关系型数据库的优势​ (1) 性能NoSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。​ (2) 可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。 1.1.3 关系型数据库的优势​ (1) 复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。​ (2) 事务支持使得对于安全性能很高的数据访问要求得以实现。对于这两类数据库，对方的优势就是自己的弱势，反之亦然。 1.1.4 总结​ 关系型数据库与NoSQL数据库并非对立而是互补的关系，即通常情况下使用关系型数据库，在适合使用NoSQL的时候使用NoSQL数据库，让NoSQL数据库对关系型数据库的不足进行弥补。​ 一般会将数据存储在关系型数据库中，在nosql数据库中备份存储关系型数据库的数据 1.2 主流的产品常见的关系型数据库: Oracle、DB2、MySQL、[SQL Server](https://baike.baidu.com/item/Microsoft SQL Server/2947866) 常见的非关系型数据库: Redis、MongodDB、HBase、Neo4J (1) 键值(Key-Value)存储数据库 相关产品： Tokyo Cabinet/Tyrant、Redis、Voldemort、Berkeley DB 典型应用： 内容缓存，主要用于处理大量数据的高访问负载。 数据模型： 一系列键值对 优势： 快速查询 劣势： 存储的数据缺少结构化 (2) 列存储数据库 相关产品：Cassandra, HBase, Riak 典型应用：分布式的文件系统 数据模型：以列簇式存储，将同一列数据存在一起 优势：查找速度快，可扩展性强，更容易进行分布式扩展 劣势：功能相对局限 (3) 文档型数据库 相关产品：CouchDB、MongoDB 典型应用：Web应用（与Key-Value类似，Value是结构化的） 数据模型： 一系列键值对 优势：数据结构要求不严格 劣势： 查询性能不高，而且缺乏统一的查询语法 (4) 图形(Graph)数据库 相关数据库：Neo4J、InfoGrid、Infinite Graph 典型应用：社交网络 数据模型：图结构 优势：利用图结构相关算法。 劣势：需要对整个图做计算才能得出结果，不容易做分布式的集群方案。 1.3 什么是Redis​ Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库，官方提供测试数据，50个并发执行100000个请求,读的速度是110000次/s,写的速度是81000次/s ，且Redis通过提供多种键值数据类型来适应不同场景下的存储需求，目前为止Redis支持的键值数据类型如下：​ (1) 字符串类型 string​ (2) 哈希类型 hash​ (3) 列表类型 list​ (4) 集合类型 set​ (5) 有序集合类型 sortedset redis的应用场景 缓存（数据查询、短连接、新闻内容、商品内容等等） 聊天室的在线好友列表 任务队列（秒杀、抢购、12306等等） 应用排行榜 网站访问统计 数据过期处理（可以精确到毫秒 分布式集群架构中的session分离 2.常用命令操作2.1 redis的数据结构redis存储的是：key, value格式的数据，其中key都是字符串，value有5种不同的数据结构 value的数据结构： (1) 字符串类型 string (2) 哈希类型 hash ： map格式 (3) 列表类型 list ： linkedlist格式。支持重复元素 (4) 集合类型 set ： 不允许重复元素 (5) 有序集合类型 sortedset：不允许重复元素，且元素有顺序 字符串类型 string 123456789存储： set key value 127.0.0.1:6379&gt; set username zhangsan OK获取： get key 127.0.0.1:6379&gt; get username \"zhangsan\"删除： del key 127.0.0.1:6379&gt; del age (integer) 1 哈希类型 hash 1234567891011121314151617181920存储： hset key field value 127.0.0.1:6379&gt; hset myhash username lisi (integer) 1 127.0.0.1:6379&gt; hset myhash password 123 (integer) 1获取： hget key field: 获取指定的field对应的值 127.0.0.1:6379&gt; hget myhash username \"lisi\" hgetall key：获取所有的field和value 127.0.0.1:6379&gt; hgetall myhash 1) \"username\" 2) \"lisi\" 3) \"password\" 4) \"123\"删除： hdel key field 127.0.0.1:6379&gt; hdel myhash username (integer) 1 列表类型 list: 可以添加一个元素到列表的头部（左边）或者尾部（右边） 12345678910111213141516171819202122添加： lpush key value: 将元素加入列表左表 rpush key value：将元素加入列表右边 127.0.0.1:6379&gt; lpush myList a (integer) 1 127.0.0.1:6379&gt; lpush myList b (integer) 2 127.0.0.1:6379&gt; rpush myList c (integer) 3获取： lrange key start end ：范围获取 127.0.0.1:6379&gt; lrange myList 0 -1 (1) \"b\" (2) \"a\" (3) \"c\"删除： lpop key： 删除列表最左边的元素，并将元素返回 rpop key： 删除列表最右边的元素，并将元素返回 集合类型 set : 不允许重复元素 12345678910111213存储：sadd key value 127.0.0.1:6379&gt; sadd myset a (integer) 1 127.0.0.1:6379&gt; sadd myset a (integer) 0获取：smembers key:获取set集合中所有元素 127.0.0.1:6379&gt; smembers myset (1) \"a\"删除：srem key value:删除set集合中的某个元素 127.0.0.1:6379&gt; srem myset a (integer) 1 有序集合类型 sortedset：不允许重复元素，且元素有顺序.每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 123456789101112131415161718192021222324存储：zadd key score value 127.0.0.1:6379&gt; zadd mysort 60 zhangsan (integer) 1 127.0.0.1:6379&gt; zadd mysort 50 lisi (integer) 1 127.0.0.1:6379&gt; zadd mysort 80 wangwu (integer) 1获取：zrange key start end [withscores] 127.0.0.1:6379&gt; zrange mysort 0 -1 (1) \"lisi\" (2) \"zhangsan\" (3) \"wangwu\" 127.0.0.1:6379&gt; zrange mysort 0 -1 withscores (1) \"zhangsan\" (2) \"60\" (3) \"wangwu\" (4) \"80\" (5) \"lisi\" (6) \"500\"删除：zrem key value 127.0.0.1:6379&gt; zrem mysort lisi (integer) 1 2.2 通用命令1231. keys * : 查询所有的键2. type key ： 获取键对应的value的类型3. del key：删除指定的key value 3.Java客户端 Jedis3.1 Jedis操作各种redis中的数据结构123456//1. 获取连接 Jedis jedis = new Jedis(\"localhost\",6379); //2. 操作 jedis.set(\"username\",\"zhangsan\"); //3. 关闭连接 jedis.close(); 字符串类型 string 123456789101112//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 //存储 jedis.set(\"username\",\"zhangsan\"); //获取 String username = jedis.get(\"username\"); System.out.println(username); //可以使用setex()方法存储可以指定过期时间的 key value jedis.setex(\"activecode\",20,\"hehe\");//将activecode：hehe键值对存入redis，并且20秒后自动删除该键值对 //3. 关闭连接 jedis.close(); 哈希类型 hash: map格式 12345678910111213141516171819202122//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // 存储hash jedis.hset(\"user\",\"name\",\"lisi\"); jedis.hset(\"user\",\"age\",\"23\"); jedis.hset(\"user\",\"gender\",\"female\"); // 获取hash String name = jedis.hget(\"user\", \"name\"); System.out.println(name); // 获取hash的所有map中的数据 Map&lt;String, String&gt; user = jedis.hgetAll(\"user\"); // keyset Set&lt;String&gt; keySet = user.keySet(); for (String key : keySet) &#123; //获取value String value = user.get(key); System.out.println(key + \":\" + value); &#125; //3. 关闭连接 jedis.close(); 列表类型 list: linkedlist格式 支持重复元素 ​ lpush / rpush​ lpop / rpop​ lrange start end : 范围获取 123456789101112131415161718192021222324//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // list 存储 jedis.lpush(\"mylist\",\"a\",\"b\",\"c\");//从左边存 jedis.rpush(\"mylist\",\"a\",\"b\",\"c\");//从右边存 // list 范围获取 List&lt;String&gt; mylist = jedis.lrange(\"mylist\", 0, -1); System.out.println(mylist); // list 弹出 String element1 = jedis.lpop(\"mylist\");//c System.out.println(element1); String element2 = jedis.rpop(\"mylist\");//c System.out.println(element2); // list 范围获取 List&lt;String&gt; mylist2 = jedis.lrange(\"mylist\", 0, -1); System.out.println(mylist2); //3. 关闭连接 jedis.close(); 集合类型 set: 不允许重复元素 12345678910//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // set 存储 jedis.sadd(\"myset\",\"java\",\"php\",\"c++\"); // set 获取 Set&lt;String&gt; myset = jedis.smembers(\"myset\"); System.out.println(myset); //3. 关闭连接 jedis.close(); 有序集合类型 sortedset: 不允许重复元素，且元素有顺序 123456789101112//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // sortedset 存储 jedis.zadd(\"mysortedset\",3,\"亚瑟\"); jedis.zadd(\"mysortedset\",30,\"后裔\"); jedis.zadd(\"mysortedset\",55,\"孙悟空\"); // sortedset 获取 Set&lt;String&gt; mysortedset = jedis.zrange(\"mysortedset\", 0, -1); System.out.println(mysortedset); //3. 关闭连接 jedis.close(); 3.2 jedis连接池: JedisPool* 使用： 1. 创建JedisPool连接池对象 2. 调用方法 getResource()方法获取Jedis连接1234567891011121314//0.创建一个配置对象 JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(50); config.setMaxIdle(10); //1.创建Jedis连接池对象 JedisPool jedisPool = new JedisPool(config,\"localhost\",6379); //2.获取连接 Jedis jedis = jedisPool.getResource(); //3. 使用 jedis.set(\"hehe\",\"heihei\"); //4. 关闭 归还到连接池中 jedis.close(); 连接池工具类 12345678910111213141516171819202122232425262728public class JedisPoolUtils &#123; private static JedisPool jedisPool; static&#123; //读取配置文件 InputStream is = JedisPoolUtils.class.getClassLoader().getResourceAsStream(\"jedis.properties\"); //创建Properties对象 Properties pro = new Properties(); //关联文件 try &#123; pro.load(is); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //获取数据，设置到JedisPoolConfig中 JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(Integer.parseInt(pro.getProperty(\"maxTotal\"))); config.setMaxIdle(Integer.parseInt(pro.getProperty(\"maxIdle\"))); //初始化JedisPool jedisPool = new JedisPool(config,pro.getProperty(\"host\"),Integer.parseInt(pro.getProperty(\"port\"))); &#125; /** * 获取连接方法 */ public static Jedis getJedis()&#123; return jedisPool.getResource(); &#125;&#125;","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Redis, Nginx常见面试题","slug":"Redis, Nginx常见面试题","date":"2021-05-08T13:19:59.150Z","updated":"2020-04-29T06:05:05.796Z","comments":true,"path":"35847/","link":"","permalink":"http://tonymua.top/35847/","excerpt":"1.Redis常见面试题1.1 为什么使用redis 性能: 我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 并发: 在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。 1.2 使用redis有什么缺点 缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存的并发竞争问题","text":"1.Redis常见面试题1.1 为什么使用redis 性能: 我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 并发: 在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。 1.2 使用redis有什么缺点 缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存的并发竞争问题 1.3 单线程的redis为什么这么快 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用机制 ​ redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 1.4 redis的数据类型，以及每种数据类型的使用场景 String hash ​ 这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。单点登录的时候，用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。 list ​ 使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。 set 因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。 sorted set sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。 1.5 redis的过期策略以及内存淘汰机制redis采用的是定期删除+惰性删除策略。 1.6 redis和数据库双写一致性问题​ 一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。 首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 1.7 如何应对缓存穿透和缓存雪崩问题 缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。 缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。 给缓存的失效时间，加上一个随机值，避免集体失效。 使用互斥锁，但是该方案吞吐量明显下降了。 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点: I 从缓存A读数据库，有则直接返回II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。III 更新线程同时更新缓存A和缓存B。 1.8 Redis如何做持久化的？​ bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。 1.9 Redis的同步机制了解么？​ Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 1.10 是否使用过Redis集群，集群的原理是什么？Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。 Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。 2.nginx常见面试题2.1 什么是Nginx？ Nginx是一个高性能的HTTP和反向代理服务器，及电子邮件（IMAP/POP3）代理服务器，同时也是一个非常高效的反向代理、负载平衡。 2.2 为什么要用Nginx？ 跨平台、配置简单 非阻塞、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发 内存消耗小：开启10个nginx才占150M内存，Nginx采取了分阶段资源分配技术 nginx处理静态文件好,耗费内存少 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。 节省宽带：支持GZIP压缩，可以添加浏览器本地缓存 稳定性高：宕机的概率非常小 master/worker结构：一个master进程，生成一个或者多个worker进程 接收用户请求是异步的：浏览器将请求发送到nginx服务器，它先将用户请求全部接收下来，再一次性发送给后端web服务器，极大减轻了web服务器的压力 一边接收web服务器的返回数据，一边发送给浏览器客户端 网络依赖性比较低，只要ping通就可以负载均衡 可以有多台nginx服务器 2.3 为什么Nginx性能这么高？ 得益于它的事件处理机制： 异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决 2.4 为什么不使用多线程？Apache: 创建多个进程或线程，而每个进程或线程都会为其分配cpu和内存（线程要比进程小的多，所以worker支持比perfork高的并发），并发过大会榨干服务器资源。 Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。所以才使得Nginx支持更高的并发。 2.5 正向代理与反向代理 正向代理一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器), 然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理 正向代理总结就一句话：代理端代理的是客户端 反向代理反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求，发给内部网络上的服务器, 并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器 反向代理总结就一句话：代理端代理的是服务端 2.6 动态资源、静态资源分离​ 动态资源、静态资源分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后, 我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路 动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离 2.7 为什么要做动、静分离？​ 在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js等等文件, 这些不需要经过后台处理的文件称为静态文件，否则动态文件。因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗? 当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决, 动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问 这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中 2.8 负载均衡负载均衡即是代理服务器将接收的请求均衡的分发到各服务器中 负载均衡主要解决网络拥塞问题，提高服务器响应速度，服务就近提供，达到更好的访问质量，减少后台服务器大并发压力。","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Oracle(二)","slug":"Oracle(二)","date":"2021-05-08T13:19:59.148Z","updated":"2020-04-29T02:44:38.075Z","comments":true,"path":"25938/","link":"","permalink":"http://tonymua.top/25938/","excerpt":"1.视图视图就是封装了一条复杂查询的语句。语法 1.：CREATE VIEW 视图名称 AS 子查询 如果视图已经存在我们可以使用语法 2 来创建视图，这样已有的视图会被覆盖。 语法 2：CREATE OR REPLACE VIEW 视图名称 AS 子查询 我们可以设置视图为只读。语法 3：CREATE OR REPLACE VIEW 视图名称 AS 子查询 WITH READ ONLY","text":"1.视图视图就是封装了一条复杂查询的语句。语法 1.：CREATE VIEW 视图名称 AS 子查询 如果视图已经存在我们可以使用语法 2 来创建视图，这样已有的视图会被覆盖。 语法 2：CREATE OR REPLACE VIEW 视图名称 AS 子查询 我们可以设置视图为只读。语法 3：CREATE OR REPLACE VIEW 视图名称 AS 子查询 WITH READ ONLY 12345678910111213141516--视图:视图就是提供一个查询的窗口,所有数据来自于原表--查询语句创建表create table emp as select * from scott.emp;select * from emp;--创建视图(必须有dba权限)create view v_emp as select ename,job from emp;--查询视图select * from v_emp;--修改视图(不推荐)update v_emp set job=&apos;CLERK&apos; where ename=&apos;ALLEN&apos;;commit;--创建只读视图create view v_emp_readonly as select ename,job from emp with read only;--视图的作用--1.视图可以屏蔽掉一些敏感字段--2.保证总部和分布数据及时统一 2.索引​ 索引是用于加速数据存取的数据对象。合理的使用索引可以大大降低 i/o 次数,从而 提高数据访问性能。索引有很多种我们主要介绍常用的几种: ​ 为什么添加了索引之后，会加快查询速度呢？ ​ 图书馆：如果杂乱地放书的话检索起来就非常困难,所以将书分类，然后再建一个箱子，箱 子里面放卡片，卡片里面可以按类查询,按书名查或者类别查,这样的话速度会快很多很多， 这个就有点像索引。索引的好处就是提高你找到书的速度，但是正是因为你建了索引，就应该有人 专门来维护索引，维护索引是要有时间精力的开销的，也就是说索引是不能乱建的，所以建索引有 个原则：如果有一个字段如果不经常查询，就不要去建索引。现在把书变成我们的表，把卡片变成 我们的索引，就知道为什么索引会快，为什么会有开销。 创建索引的语法： 创建索引： 1．单列索引 单列索引是基于单个列所建立的索引，比如: ​ CREATE index 索引名 on 表名(列名) 2．复合索引 复合索引是基于两个列或多个列的索引。在同一张表上可以有多个索引，但是 要求列的组合必须不同,比如： ​ Create index emp_idx1 on emp(ename,job); ​ Create index emp_idx1 on emp(job,ename); 索引的使用原则：  在大表上建立索引才有意义  在 where子句后面或者是连接条件上的字段建立索引  表中数据修改频率高时不建议建立索引 12345678910111213141516--索引:索引就是在表的列上构建一个二叉树--达到大幅度提高查询效率的目的,但是索引会影响增删改的效率--单列索引--创建单列索引create index idx_ename on emp(ename);--单列索引触发规则,条件必须是索引列中的原始值--单行函数,模糊查询都会影响索引的触发select * from emp where ename=&apos;SCOTT&apos;;--复合索引--创建复合索引create index idx_enamejob on emp(ename,job);--复合索引中第一列为优先检索列--如果要触发复合索引,必须包含优先检索列中的原始值select * from emp where ename=&apos;SCOTT&apos; and job=&apos;xx&apos;;--触发复合索引select * from emp where ename=&apos;SCOTT&apos; or job=&apos;xx&apos;;--不触发索引select * from emp where ename=&apos;SCOTT&apos;;--触发单列索引 3.pl/sql基本语法什么是 PL/SQL? ​ PL/SQL（Procedure Language/SQL） PLSQL 是 Oracle 对sql 语言的过程化扩展，指在 SQL 命令语言中增加了过程处理语句（如分支、循 环等），使 SQL语言具有过程处理能力。把SQL 语言的数据操纵能力与过程语言的数据处理能力结合 起来，使得 PLSQL面向过程但比过程语言简单、高效、灵活和实用。 3.1 pl/sql程序语法程序语法： ​ declare 说明部分 （变量说明，游标申明，例外说明 ) ​ begin 语句序列 （DML 语句〕… ​ exception 例外处理语句 ​ End; 3.2 常量和变量定义​ 在程序的声明阶段可以来定义常量和变量。  变量的基本类型就是 oracle 中的建表时字段的变量如 char, varchar2, date, number, boolean, long ​ 定义语法： ​ varl char(15); ​ Psal number(9,2); ​ 说明变量名、数据类型和长度后用分号结束说明语句。 ​ 常量定义：married constant boolean:=true  引用变量 Myname emp.ename%type; ​ 引用型变量，即my_name 的类型与emp 表中 ename 列的类型一样 在 sql中使用 into 来赋值  记录型变量 Emprec emp%rowtype ​ 记录变量分量的引用 emp_rec.ename:=’ADAMS’; 1234567891011121314151617181920--pl/sql编程语言--pl/sql编程语言是对sql语言的扩展，使得sql语言具有过程化编程的特性--pl/sql编程语言比一般的过程化编程语言，更加灵活高效--pl/sql编程语言主要用来编写存储过程和存储函数等--声明方法--赋值操作可以使用:=也可以使用into查询语句赋值declare i number(2):=10; s varchar2(10):=&apos;小明&apos;; ename emp.ename%type;--引用型变量 emprow emp%rowtype;--记录型变量begin dbms_output.put_line(i); dbms_output.put_line(s); select ename into ename from emp where empno=7788; dbms_output.put_line(ename); select * into emprow from emp where empno=7788; dbms_output.put_line(emprow.ename||&apos;的工作为:&apos;||emprow.job);end; 3.3 if 分支语法 1： ​ IF 条件 THEN 语句 1; ​ 语句 2; ​ END IF; 语法 2： ​ IF 条件 THEN 语句序列 1； ​ ELSE 语句序列 2； ​ END IF； 语法 3： ​ IF 条件 THEN 语句; ​ ELSIF 语句 THEN 语句; ​ ELSE 语句; ​ END IF; 123456789101112131415--pl/sql中的if判断--输入小于18的数字，输出未成年--输入大于18小于40的数字，输出中年人--输入大于40的数字，输出老年人declare i number(3):=&amp;ii;begin if i&lt;18 then dbms_output.put_line(&apos;未成年&apos;); elsif i&lt;40 then dbms_output.put_line(&apos;中年人&apos;); else dbms_output.put_line(&apos;老年人&apos;); end if;end; 3.4 LOOP 循环语句语法 1： ​ WHILE total &lt;= 25000 LOOP ​ .. . ​ total : = total + salary; ​ END LOOP; 语法 2： ​ Loop ​ EXIT [when 条件]; ​ …… ​ End loop 语法 3： ​ FOR I IN 1 . . 3 LOOP ​ 语句序列 ; ​ END LOOP ; 1234567891011121314151617181920212223242526272829--pl/sql中的loop循环--用三种方式输出1到10是个数字--while循环declare i number(2):=1;begin while i&lt;11 loop dbms_output.put_line(i); i:=i+1; end loop;end;--exit循环declare i number(2):=1;begin loop exit when i&gt;10; dbms_output.put_line(i); i:=i+1; end loop;end;--for循环declarebegin for i in 1..10 loop dbms_output.put_line(i); end loop;end; 3.5 游标 Cursor​ 在写 java 程序中有集合的概念，那么在 pl/sql 中也会用到多条记录，这时候我们就要用到游标， 游标可以存储查询返回的多条数据。 语法： CURSOR 游标名 [ (参数名 数据类型,参数名 数据类型,…)] IS SELECT 语句; 游标的使用步骤： ​  打开游标： open c1; (打开游标执行查询) ​  取一行游标的值：fetch c1 into pjob; (取一行到变量中) ​  关闭游标： close c1;(关闭游标释放资源) ​  游标的结束方式 exit when c1%notfound ​  注意： 上面的 pjob 必须与 emp表中的 job 列类型一致： ​ 定义：pjob emp.empjob%type; 12345678910111213141516171819202122232425262728293031--游标：可以存放多个对象，多行记录--输出emp表中所有员工的姓名declare cursor c1 is select * from emp; emprow emp%rowtype;begin open c1; loop fetch c1 into emprow; exit when c1%notfound; dbms_output.put_line(emprow.ename); end loop; close c1;end;--给指定部门员工涨工资declare cursor c2(eno emp.deptno%type) is select empno from emp where deptno=eno; en emp.empno%type;begin open c2(10); loop fetch c2 into en; exit when c2%notfound; update emp set sal=sal+100 where empno=en; commit; end loop; close c2;end;--查询10号部门员工信息select * from emp where deptno = 10; 4. 存储过程​ 存储过程（Stored Procedure）是在大型数据库系统中，一组为了完成特定功能的 SQL 语句集，经 编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来 执行它。存储过程是数据库中的一个重要对象，任何一个设计良好的数据库应用程序都应该用到存储过程。 创建存储过程语法： ​ create [or replace] PROCEDURE 过程名[(参数名 in/out 数据类型)] ​ AS ​ begin ​ PLSQL子程序体； ​ End; 或者 ​ create [or replace] PROCEDURE 过程名[(参数名 in/out 数据类型)] ​ is ​ begin ​ PLSQL子程序体； ​ End 过程名; 1234567891011121314151617--存储过程：存储过程就是提前已经编译好的一段pl/sql语言，放置在数据库端--可以直接被调用。这一段pl/sql一般都是固定步骤的业务。--给指定员工涨100块钱create or replace procedure p1(eno emp.empno%type)isbegin update emp set sal=sal+100 where empno=eno; commit;end;select * from emp where empno=7788;--测试p1declarebegin p1(7788);end; 5.存储函数create or replace function 函数名(Name in type, Name in type, …) return 数据类型 is ​ 结果变量 数据类型; begin ​ return(结果变量); end函数名; 存储过程和存储函数的区别 ​ 一般来讲，过程和函数的区别在于函数可以有一个返回值；而过程没有返回值。 但过程和函数都可以通过 out 指定一个或多个输出参数。我们可以利用out 参数，在过程和函数中实 现返回多个值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768--通过存储函数实现计算指定员工的年薪--存储过程和存储函数的参数都不能带长度--存储函数的返回值类型不能带长度create or replace function f_yearsal(eno emp.empno%type)return numberis s number(10);begin select sal*12+nvl(comm,0)into s from emp where empno=eno; return s;end;--测试f_yearsal--存储函数在调用的时候，返回值需要接收declare s number(10);begin s:=f_yearsal(7788); dbms_output.put_line(s);end;--out类型参数如何使用--使用存储过程来算年薪create or replace procedure p_yearsal(eno emp.empno%type,yearsal out number)is s number(10); c emp.comm%type;begin select sal*12,nvl(comm,0)into s,c from emp where empno=eno; yearsal:=s+c;end;--测试p_yearsaldeclare yearsal number(10);begin p_yearsal(7788,yearsal); dbms_output.put_line(yearsal);end;--in和out类型参数的区别是什么？--凡是涉及到into查询语句赋值或者:=赋值操作的参数，都必须使用out来修饰--存储过程和存储函数的区别--语法区别：关键字不一样，--存储函数比存储过程多了两个return--本质区别：存储函数有返回值，而存储过程没有返回值。--如果存储过程想实现有返回值的业务，我们就必须使用out类型的参数--即便是存储过程使用了out类型的参数，起本质也不是真的有了返回值--而是在存储过程内部给out类型参数赋值，在执行完毕后，我们直接拿到输出类型参数的值--我们可以使用存储函数有返回值的特性，来自定义函数--而存储过程不能用来自定义函数--案例需求：查询出员工姓名，员工所在部门名称--案例准备工作：把scott用户下的dept表复制到当前用户下create table dept as select * from scott.dept;--使用传统方式来实现案例需求select e.ename,d.dnamefrom emp e,dept dwhere e.deptno=d.deptno;--使用存储函数来实现提供一个部门编号，输出一个部门名称create or replace function fdna(dno dept.deptno%type)return dept.dname%typeis dna dept.dname%type;begin select dname into dna from dept where deptno=dno; return dna;end;--使用fdna存储函数来实现案例需求：查询出员工姓名，员工所在部门名称select e.ename,fdna(e.deptno) from emp e; 6.触发器​ 数据库触发器是一个与表相关联的、存储的 PL/SQL 程序。每当一个特定的数据操作语句(Insert,update,delete)在指定的表上发出时，Oracle 自动地执行触发器中定义的语句序列。 触发器可用于 ​  数据确认 ​  实施复杂的安全性检查 ​  做审计，跟踪表上所做的数据操作等 ​  数据的备份和同步 *触发器的类型 * ​ 语句级触发器 ：在指定的操作语句操作之前或之后执行一次，不管这条语句影响了多少行 。 ​ 行级触发器（FOR EACH ROW） ：触发语句作用的每一条记录都被触发。在行级触 发器中使用 old 和 new伪记录变量, 识别值的状态。 语法： ​ CREATE [or REPLACE] TRIGGER 触发器名 ​ {BEFORE | AFTER} ​ {DELETE | INSERT | UPDATE [OF 列名]} ​ ON 表名 ​ [FOR EACH ROW [WHEN(条件) ] ] ​ begin ​ PLSQL 块 ​ End 触发器名 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--触发器:就是制定一个规则，在我们做增删改操作的时候，只要满足该规则，自动触发，无需调用--语句级触发器：不包含有for each row的触发器--行级触发器：包含有for each row的就是行级触发器--加for each row是为了使用:old或者:new对象或者一行记录--语句级触发器--插入一条记录，输出一个新员工入职create or replace trigger t1afterinsert on persondeclarebegin dbms_output.put_line(&apos;一个新员工入职&apos;);end;--触发t1insert into person values (1, &apos;小红&apos;);commit;select * from person;--行级别触发器--不能给员工降薪create or replace trigger t2beforeupdate on empfor each row declare begin if:old.sal&gt;:new.sal then raise_application_error(-20001,&apos;不能给员工降薪&apos;); end if; end;--触发t2select * from emp where empno = 7788;update emp set sal=sal-1 where empno = 7788;commit;--触发器实现主键自增。(行级触发器)--分析：在用户做插入操作的之前，拿到即将插入的数据，给该数据中的主键列赋值create or replace trigger autoidbeforeinsert on personfor each row declare begin select s_person.nextval into :new.pid from dual; end;--使用auid实现主键自增insert into person(pname) values(&apos;a&apos;);commit;--查询person表数据select * from person; 7.Java程序调用导入jar包 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc14&lt;/artifactId&gt; &lt;version&gt;10.2.0.4.0&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; OracleDemo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class OracleDemo &#123; @Test public void javaCallOracle()throws Exception&#123; //加载数据库驱动 Class.forName(\"oracle.jdbc.driver.OracleDriver\"); //得到Connection连接 Connection connection = DriverManager.getConnection(\"jdbc:oracle:thin:@192.168.17.130:1521:orcl\", \"test1\", \"test1\"); //得到预编译的ps对象 PreparedStatement ps = connection.prepareStatement(\"select * from emp where empno = ?\"); //给参数赋值 ps.setObject(1,7788); //执行数据库查询操作 ResultSet rs = ps.executeQuery(); //输出结果 while (rs.next())&#123; System.out.println(rs.getString(\"ename\")); &#125; //释放资源 rs.close(); ps.close(); connection.close(); &#125; /** * java调用存储过程 * &#123;?= call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储函数使用 * &#123;call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储过程使用 * @throws Exception */ @Test public void javaCallProcedure()throws Exception&#123; //加载数据库驱动 Class.forName(\"oracle.jdbc.driver.OracleDriver\"); //得到Connection连接 Connection connection = DriverManager.getConnection(\"jdbc:oracle:thin:@192.168.17.130:1521:orcl\", \"test1\", \"test1\"); //得到预编译对象 CallableStatement cs = connection.prepareCall(\"&#123;call p_yearsal(?,?)&#125;\"); //给参数赋值 cs.setObject(1,7788); cs.registerOutParameter(2, OracleTypes.NUMBER); //执行数据库查询操作 cs.execute(); //输出结果[第二个参数] System.out.println(cs.getObject(2)); //释放资源 cs.close(); connection.close(); &#125; /** * java调用存储函数 * &#123;?= call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储函数使用 * &#123;call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储过程使用 * @throws Exception */ @Test public void javaCallFunction() throws Exception &#123; //加载数据库驱动 Class.forName(\"oracle.jdbc.driver.OracleDriver\"); //得到Connection连接 Connection connection = DriverManager.getConnection(\"jdbc:oracle:thin:@192.168.17.130:1521:orcl\", \"test1\", \"test1\"); //得到预编译的Statement对象 CallableStatement cs = connection.prepareCall(\"&#123;?= call f_yearsal(?)&#125;\"); //给参数赋值 cs.setObject(2, 7788); cs.registerOutParameter(1, OracleTypes.NUMBER); //执行数据库查询操作 cs.execute(); //输出结果[第一个参数] System.out.println(cs.getObject(1)); //释放资源 cs.close(); connection.close(); &#125;&#125;","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"}]},{"title":"Oracle(一)","slug":"Oracle(一)","date":"2021-05-08T13:19:59.147Z","updated":"2020-04-29T02:44:38.074Z","comments":true,"path":"42486/","link":"","permalink":"http://tonymua.top/42486/","excerpt":"1.oracle介绍​ ORACLE 数据库系统是美国ORACLE 公司（甲骨文）提供的以分布式数据库为核心的一组软件产品，是目前最流行的客户/服务器(CLIENT/SERVER)或 B/S体系结构的数据库之一。比如SilverStream 就是基于数据库的一种中间件。ORACLE数据库是目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系数据库，它是一个完备关系的产品；作为分布式数据库它实现了分布式处理功能。但它的所有知识，只要在一种机型上学习了 ORACLE知识，便能在各种类型的机器上使用它。 2.Oracle体系结构","text":"1.oracle介绍​ ORACLE 数据库系统是美国ORACLE 公司（甲骨文）提供的以分布式数据库为核心的一组软件产品，是目前最流行的客户/服务器(CLIENT/SERVER)或 B/S体系结构的数据库之一。比如SilverStream 就是基于数据库的一种中间件。ORACLE数据库是目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系数据库，它是一个完备关系的产品；作为分布式数据库它实现了分布式处理功能。但它的所有知识，只要在一种机型上学习了 ORACLE知识，便能在各种类型的机器上使用它。 2.Oracle体系结构 2.1 数据库​ Oracle 数据库是数据的物理存储。这就包括（数据文件ORA或者 DBF、控制文件、联机日志、参数文件）。其实Oracle 数据库的概念和其它数据库不一样，这里的数据库是一个操作系统只有一个库。可以看作是Oracle 就只有一个大数据库。 2.2 实例​ 一个 Oracle 实例（Oracle Instance）有一系列的后台进程（Backguound Processes)和内存结构（Memory Structures)组成。一个数据库可以有 n 个实例。 2.3 用户​ 用户是在实例下建立的。不同实例可以建相同名字的用户。 2.4 表空间​ 表空间是 Oracle 对物理数据库上相关数据文件（ORA或者 DBF 文件）的逻辑映射。一个数据库在逻辑上被划分成一到若干个表空间，每个表空间包含了在逻辑上相关联的一组结构。每个数据库至少有一个表空间(称之为system表空间)。 ​ 每个表空间由同一磁盘上的一个或多个文件组成，这些文件叫数据文件(datafile)。一个数据文件只能属于一个表空间。 2.5 数据文件（dbf、ora）​ 数据文件是数据库的物理存储单位。数据库的数据是存储在表空间中的，真正是在某一个或者多个数据文件中。而一个表空间可以由一个或多个数据文件组成，一个数据文件只能属于一个表空间。一旦数据文件被加入到某个表空间后，就不能删除这个文件，如果要删除某个数据文件，只能删除其所属于的表空间才行。 ​ 注：表的数据，是有用户放入某一个表空间的，而这个表空间会随机把这些表数据放到一个或者多个数据文件中。 ​ 由于 oracle 的数据库不是普通的概念，oracle 是有用户和表空间对数据进行管理和存放的。但是表不是有表空间去查询的，而是由用户去查的。因为不同用户可以在同一个表空间建立同一个名字的表！这里区分就是用户了！ 3.创建表空间​ 表空间:ORACLE数据库的逻辑单元。 一个表空间可以与多个数据文件（物理结构）关联 一个数据库下可以建立多个表空间，一个表空间可以建立多个用户、一个用户下可以建立多个表。 123456-创建表空间create tablespace test1datafile &apos;c:\\test1.dbf&apos;size 100mautoextend onnext 10m; ​ test1 为表空间名称 datafile 指定表空间对应的数据文件 size 后定义的是表空间的初始大小 autoextend on 自动增长 ，当表空间存储都占满时，自动增长 next 后指定的是一次自动增长的大小。 12--删除表空间drop tablespace test1; 4. 用户4.1 创建用户1234--创建用户create user test1identified by test1default tablespace test1; identified by 后边是用户的密码 default tablespace 后边是表空间名称 oracle 数据库与其它数据库产品的区别在于，表和其它的数据库对象都是存储在用户下的。 4.2 用户赋权限新创建的用户没有任何权限，Oracle 中已存在三个重要的角色：connect 角色，resource角色，dba角色。 CONNECT 角色： –是授予最终用户的典型权利，最基本的 ALTER SESSION –修改会话 CREATE CLUSTER –建立聚簇 CREATE DATABASE LINK –建立数据库链接 CREATE SEQUENCE –建立序列 CREATE SESSION –建立会话 CREATE SYNONYM –建立同义词 CREATE VIEW –建立视图 RESOURCE 角色： –是授予开发人员的 CREATE CLUSTER –建立聚簇 CREATE PROCEDURE –建立过程 CREATE SEQUENCE –建立序列 CREATE TABLE –建表 CREATE TRIGGER –建立触发器 CREATE TYPE –建立类型 DBA角色：拥有全部特权，是系统最高权限，只有 DBA才可以创建数据库结构，并且系统权限也需要DBA授出，且 DBA用户可以操作全体用户的任意基表，包括删除 ​ 进入 system 用户下给用户赋予 dba 权限，否则无法正常登陆 1234567--给用户授权,否则无法登录--Oracle数据库中常用角色:connect--连接角色,基本角色resource--开发者角色dba--超级管理员角色--给test1用户授予dba角色grant dba to test1; 5.Oracle数据类型 6.表的管理6.1 建表语法： Create table 表名（ 字段 1 数据类型 [default 默认值], 字段 2 数据类型 [default 默认值], … 字段 n 数据类型 [default 默认值] ）; 12345--创建一个person表create table person( pid number(20), pname varchar(10)); 6.2 表的修改在 sql中使用 alter 可以修改表 添加语法：ALTER TABLE 表名称 ADD(列名 1 类型 [DEFAULT 默认值]，列名 1 类型 [DEFAULT 默认值]…) 修改语法：ALTER TABLE 表名称 MODIFY(列名 1 类型 [DEFAULT 默认值]，列名 1 类型 [DEFAULT 默认值]…) 修改列名: ALTER TABLE 表名称 RENAME 列名 1 TO 列名 2 123456789--修改表结构--添加一列alter table person add (gender number(1));--修改列类型alter table person modify gender char(1);--修改列名称alter table person rename column gender to sex;--删除一列alter table person drop column sex; 6.3 表删除123456789--三个删除--删除表中全部记录delete from person;--删除表结构drop table person;--先删除表,再次创建表结构.效果等同于删除表中全部记录--在数据量大的情况下,尤其在表中带有索引的情况下--索引可以提高查询效率,但是会影响增删改效率truncate table person; 6.4 表中数据的增删改INSERT（增加） 标准写法： INSERT INTO 表名[(列名 1，列名 2，…)]VALUES(值 1，值 2，…) 简单写法（不建议）: INSERT INTO 表名 VALUES(值 1，值 2，…) 注意：使用简单的写法必须按照表中的字段的顺序来插入值，而且如果有为空的字段使用 null *UPDATE（修改） * 全部修改：UPDATE 表名 SET 列名 1=值 1，列名 2=值 2，…. 局部修改：UPDATE 表名 SET 列名 1=值 1，列名 2=值 2，….WHERE 修改条件； *DELETE（删除） * 语法 : DELETE FROM 表名 WHERE 删除条件; ​ 在删除语句中如果不指定删除条件的话就会删除所有的数据 因为 oracle 的事务对数据库的变更的处理，我们必须做提交事务才能让数据真正的插入到数据库中，在同样在执行完数据库变更的操作后还可以把事务进行回滚，这样就不会插入到数据库。如果事务提交后则不可以再回滚。提交：commit回滚：rollback 12345678--查询表中记录select * from person;--添加一条记录insert into person (pid,pname) values(1,&apos;小明&apos;);commit;--修改一条记录update person set pname=&apos;小马&apos; where pid=1;commit; 6.5 序列​ 在很多数据库中都存在一个自动增长的列,如果现在要想在 oracle 中完成自动增长的功能, 则只能依靠序列完成,所有的自动增长操作,需要用户手工完成处理。 语法： CREATE SEQUENCE 序列名 [INCREMENT BY n] [START WITH n] [{MAXVALUE/ MINVALUE n|NOMAXVALUE}] [{CYCLE|NOCYCLE}] [{CACHE n|NOCACHE}]; 123456--序列不真的属于任何一张表,但是可以逻辑和表做绑定--序列:默认从1开始,依次递增,主要用来给主键赋值使用--dual:虚表,只是为了补全语法,没有任何意义create sequence s_person;select s_person.nextval from dual;select s_person.currval from dual; ​ 序列创建完成之后,所有的自动增长应该由用户自己处理,所以在序列中提供了以下的两种操作： nextval :取得序列的下一个内容 currval :取得序列的当前内容 ​ 在实际项目中每一张表会配一个序列，但是表和序列是没有必然的联系的，一个序列被哪一张表使用都可以，但是我们一般都是一张表用一个序列。 7.Scott用户123456--scott用户,密码tiger--解锁scott用户alter user scott account unlock;--解锁scott用户的密码(此句也可以用来重置密码)alter user scott identified by tiger;--切换到scott用户下 8.单行函数8.1 字符函数接收字符输入返回字符或者数值，dual是伪表 把小写的字符转换成大小的字符 把大写字符变成小写字符 1234--单行函数:作用于一行,返回一个值--字符函数select upper(&apos;yes&apos;) from dual;--YESselect lower(&apos;YES&apos;) from dual;--yes 8.2 数值函数四舍五入函数：ROUND() 默认情况下 ROUND 四舍五入取整，可以自己指定保留的位数。 1234--数值函数select round(26.18,1) from dual;--四舍五入,后面的参数保留的小数位数select trunc(26.18,1) from dual;--直接截取,不再看后面的数字是否大于5select mod(10,3) from dual;--求余数 8.3 日期函数​ Oracle 中提供了很多和日期相关的函数，包括日期的加减，在日期加减时有一些规律日期 – 数字 = 日期日期 + 数字 = 日期日期 – 日期 = 数字 1234567891011--日期函数--查询出emp表中所有员工入职距离现在几天select sysdate-e.hiredate from emp e;--算出明天此刻select sysdate+1 from dual;--查询出emp表中所有员工入职距离现在几月select months_between(sysdate,e.hiredate) from emp e;--查询出emp表中所有员工入职距离现在几年select months_between(sysdate,e.hiredate)/12 from emp e;--查询出emp表中所有员工入职距离现在几周select round(sysdate-e.hiredate)/7 from emp e; 8.4 转换函数 TO_CHAR:字符串转换函数 拆分时需要使用通配符 年：y, 年是四位使用 yyyy 月：m, 月是两位使用 mm 日：d, 日是两位使用 dd 时: h,时是两位使用 hh 24小时制:hh24 分：分是两位使用 mi 秒：秒是两位使用 ss 如果前面被补了前导零，可以使用 fm 去掉前导零 TO_DATE:日期转换函数 12345--转换函数--日期转字符串select to_char(sysdate,&apos;fm yyyy-mm-dd hh24:mi:ss&apos;) from dual;--字符串转日期select to_date(&apos; 2019-8-1 15:41:34&apos;,&apos;fm yyyy-mm-dd hh24:mi:ss&apos;) from dual; 8.5 通用函数1．空值处理nvl ​ 我们发现很多员工的年薪是空的，原因是很多员工的奖金是 null，null和任何数值计算都是null，这时我们可以使用 nvl来处理。 1234--通用函数--算出emp表中所有员工的年薪--奖金里面有null值，如果null值和任意数字做算术运算，结果都是nullselect e.sal*12+nvl(e.comm,0) from emp e; *2.Decode函数 * 该函数类似 if….else if…esle语法：DECODE(col/expression, [search1,result1],[search2, result2]….[default])Col/expression:列名或表达式Search1，search2…:用于比较的条件Result1, result2…:返回值如果 col/expression 和 Searchi匹配就返回 resulti,否则返回 default 的默认值 123456789--oracle中除了起别名，都用单引号。--oracle专用条件表达式select e.ename, decode(e.ename, &apos;SMITH&apos;,&apos;张三&apos;, &apos;ALLEN&apos;,&apos;李四&apos;, &apos;WARD&apos;,&apos;王二&apos;, &apos;无名&apos;)&quot;中文名&quot;from emp e; *3.case when * 12345678910111213141516171819--条件表达式--条件表达式的通用写法，mysql和oracle通用--给emp表中员工起中文名select e.ename, case e.ename when &apos;SMITH&apos; then &apos;张三&apos; when &apos;ALLEN&apos; then &apos;李四&apos; when &apos;WARD&apos; then &apos;王二&apos; --else &apos;无名&apos; endfrom emp e;--判断emp表中员工工资，如果高于3000显示高收入，如果高于1500低于3000显示中等收入，其余显示低收入select e.sal, case when e.sal&gt;3000 then &apos;高收入&apos; when e.sal&gt;1500 then &apos;中等收入&apos; else &apos;低收入&apos; endfrom emp e; 9.多行函数（聚合函数)123456--多行函数(聚合函数):作用于多行,返回一个值select count(1) from emp;--查询总数量select sum(sal) from emp;--工资总和select max(sal) from emp;--最大工资select min(sal) from emp;--最低工资select avg(sal) from emp;--平均工资 10. 分组统计分组统计需要使用 GROUP BY来分组 语法：SELECT * |列名 FROM 表名 {WEHRE 查询条件} {GROUP BY 分组字段} ORDER BY 列 名 1 ASC|DESC，列名 2…ASC|DESC 123456789101112131415161718192021222324252627282930--分组查询--查询出每个部门的平均工资--分组查询中，出现在group by后面的原始列，才能出现在select后面--没有出现在group by后面的列，想在select后面，必须加上聚合函数。--聚合函数有一个特性，可以把多行记录变成一个值。select e.deptno,avg(e.sal)from emp egroup by e.deptno;--查询出平均工资高于2000的部门信息select e.deptno,avg(e.sal) asalfrom emp egroup by e.deptnohaving avg(e.sal)&gt;2000;--所有条件都不能使用别名来判断--比如下面的条件语句也不能使用别名当条件select ename,sal s from where s&gt;1500;--查询出每个部门工资高于800的员工的平均工资----where是过滤分组前的数据，having是过滤分组后的数据---表现形式：where必须在group by之前，having是在group by之后select e.deptno,avg(e.sal) asalfrom emp ewhere e.sal&gt;800group by e.deptno;---查询出每个部门工资高于800的员工的平均工资---然后再查询出平均工资高于2000的部门select e.deptno,avg(e.sal) asalfrom emp ewhere e.sal&gt;800group by e.deptnohaving avg(e.sal)&gt;2000; 11.多表查询使用一张以上的表做查询就是多表查询 语法： SELECT {DISTINCT} *|列名.. FROM 表名 别名，表名 1 别名 ​ {WHERE 限制条件 ORDER BY 排序字段 ASC|DESC…} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--多表查询中的一些概念--笛卡尔积select * from emp e,dept d;--等值连接(推荐使用)select * from emp e,dept d where e.deptno=d.deptno;--内连接select * from emp e inner join dept d on e.deptno=d.deptno;--查询所有部门,以及部门下的员工信息(外连接)select * from emp e right join dept d on e.deptno=d.deptno;--查询所有员工信息，以及员工所属部门select * from emp e left join dept d on e.deptno=d.deptno;--oracle中专用外连接:查询所有部门,以及部门下的员工信息select * from emp e,dept d where e.deptno(+)=d.deptno;--查询出员工姓名,员工领导姓名--自连接：自连接其实就是站在不同的角度把一张表看成多张表select e1.ename,e2.enamefrom emp e1,emp e2where e1.mgr=e2.empno;--查询出员工姓名，员工部门名称，员工领导姓名，员工领导部门名称select e1.ename,d1.dname,e2.ename,d2.dnamefrom emp e1,emp e2,dept d1,dept d2where e1.mgr=e2.empnoand e1.deptno=d1.deptnoand e2.deptno=d2.deptno;--查询出每个员工编号，姓名，部门名称，工资等级和他的上级领导的姓名，工资等级select e1.empno,e1.ename, (case s1.grade when 1 then &apos;一级&apos; when 2 then &apos;二级&apos; when 3 then &apos;三级&apos; when 4 then &apos;四级&apos; when 5 then &apos;五级&apos; end)&quot;grade&quot;,d1.dname,e2.empno,e2.ename, (case s2.grade when 1 then &apos;一级&apos; when 2 then &apos;二级&apos; when 3 then &apos;三级&apos; when 4 then &apos;四级&apos; when 5 then &apos;五级&apos; end)&quot;grade&quot; from emp e1,emp e2,dept d1,salgrade s1,salgrade s2where e1.mgr=e2.empnoand e1.deptno=d1.deptnoand e1.sal between s1.losal and s1.hisaland e2.sal between s2.losal and s2.hisal; 12.子查询子查询：在一个查询的内部还包括另一个查询，则此查询称为子查询。Sql的任何位置都可以加入子查询。 子查询在操作中有三类：单列子查询：返回的结果是一列的一个内容 单行子查询：返回多个列，有可能是一个完整的记录 多行子查询：返回多条记录 在返回多条记录的子查询可以把它的结果集当做一张表，给起个别名 1234567891011121314151617181920212223--子查询--子查询返回一个值--查询出工资和SCOTT一样的员工信息select * from emp where sal in(select sal from emp where ename=&apos;SCOTT&apos;);--子查询返回一个集合--查询出工资和10号部门任意员工一样的员工信息select * from emp where sal in(select sal from emp where deptno=10);--子查询返回一张表--查询出每个部门最低工资，和最低工资员工姓名，和该员工所在部门名称--1.先查询出每个部门最低工资select deptno,min(sal) msalfrom empgroup by deptno--2.三表联查，得到最终结果。select t.deptno,t.msal,e.ename,d.dnamefrom(select deptno,min(sal) msal from emp group by deptno) t,emp e,dept dwhere t.deptno=e.deptnoand t.msal=e.saland e.deptno=d.deptno; 13.Rownum与分页查询ROWNUM:表示行号，实际上此是一个列,但是这个列是一个伪列,此列可以在每张表中出现。 ​ 我们可以根据 rownum 来取结果集的前几行，比如前 5 行 ,但是我们不能取到中间几行，因为rownum不支持大于号，只支持小于号，如果想 实现我们的 需求怎么办呢？答案是使用子查询，也正是oracle分页的做法。 12345678910111213141516171819--oracle中的分页--rownum行号：当我们做select操作的时候，每查询出一行记录，就会在该行上加上一个行号，行号从1开始，依次递增，不能跳着走--排序操作会影响rownum的顺序select rownum,e.* from emp e order by e.sal desc;--如果涉及到排序，但是还要使用rownum的话，我们可以再次嵌套查询select rownum,t.* from(select rownum,e.* from emp e order by e.sal desc)t;--emp表工资倒叙排列后，每页五条记录，查询第二页--rownum行号不能写上大于一个正数select * from( select rownum rn,t.* from( select * from emp order by sal desc )t where rownum&lt;11)where rn&gt;5;--第二种写法： select * from ( select rownum rn ,emp.* from emp) t where t.rn &gt;5 and t.rn &lt;11","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"}]},{"title":"Mybatis框架(二)","slug":"Mybatis框架(二)","date":"2021-05-08T13:19:59.145Z","updated":"2020-04-29T02:44:38.072Z","comments":true,"path":"28604/","link":"","permalink":"http://tonymua.top/28604/","excerpt":"1.Mybatis 的输出结果封装1.1 resultType 配置结果类型​ resultType 属性可以指定结果集的类型，它支持基本类型和实体类类型。 我们在前面的 CRUD 案例中已经对此属性进行过应用了。 需要注意的是，它和 parameterType 一样，如果注册过类型别名的，可以直接使用别名。没有注册过的必须 使用全限定类名。例如：我们的实体类此时必须是全限定类名（今天最后一个章节会讲解如何配置实体类的别名） 同时，当是实体类名称是，还有一个要求，实体类中的属性名称必须和查询语句中的列名保持一致，否则无法 实现封装。 1.2 resultMap 结果类型​ resultMap 标签可以建立查询的列名和实体类的属性名称不一致时建立对应关系。从而实现封装。 在 select 标签中使用 resultMap 属性指定引用即可。同时 resultMap 可以实现将查询结果映射为复杂类 型的 pojo，比如在查询结果映射对象中包括 pojo 和 list 实现一对一查询和一对多查询。","text":"1.Mybatis 的输出结果封装1.1 resultType 配置结果类型​ resultType 属性可以指定结果集的类型，它支持基本类型和实体类类型。 我们在前面的 CRUD 案例中已经对此属性进行过应用了。 需要注意的是，它和 parameterType 一样，如果注册过类型别名的，可以直接使用别名。没有注册过的必须 使用全限定类名。例如：我们的实体类此时必须是全限定类名（今天最后一个章节会讲解如何配置实体类的别名） 同时，当是实体类名称是，还有一个要求，实体类中的属性名称必须和查询语句中的列名保持一致，否则无法 实现封装。 1.2 resultMap 结果类型​ resultMap 标签可以建立查询的列名和实体类的属性名称不一致时建立对应关系。从而实现封装。 在 select 标签中使用 resultMap 属性指定引用即可。同时 resultMap 可以实现将查询结果映射为复杂类 型的 pojo，比如在查询结果映射对象中包括 pojo 和 list 实现一对一查询和一对多查询。 定义 resultMap : 1234567891011121314&lt;!-- 建立 User 实体和数据库表的对应关系 type 属性：指定实体类的全限定类名 id 属性：给定一个唯一标识，是给查询 select 标签引用用的。 --&gt; &lt;resultMap type=\"com.itheima.domain.User\" id=\"userMap\"&gt; &lt;id column=\"id\" property=\"userId\"/&gt; &lt;result column=\"username\" property=\"userName\"/&gt; &lt;result column=\"sex\" property=\"userSex\"/&gt; &lt;result column=\"address\" property=\"userAddress\"/&gt; &lt;result column=\"birthday\" property=\"userBirthday\"/&gt; &lt;/resultMap&gt; id 标签：用于指定主键字段 result 标签：用于指定非主键字段 column 属性：用于指定数据库列名 property 属性：用于指定实体类属性名称 映射配置 : 1&lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultMap=\"userMap\"&gt; select * from user &lt;/select&gt; 2.SqlMapConfig.xml配置文件2.1 SqlMapConfig.xml 中配置的内容和顺序1234567891011121314151617-properties（属性） --property -settings（全局配置参数） --setting -typeAliases（类型别名） --typeAliase --package -typeHandlers（类型处理器） -objectFactory（对象工厂） -plugins（插件） -environments（环境集合属性对象） --environment（环境子属性对象） ---transactionManager（事务管理） ---dataSource（数据源） -mappers（映射器） --mapper --package 2.2 properties（属性） 在classpath 下定义 jdbcConfig.properties 文件 1234567jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/eesy_mybatis jdbc.username=root jdbc.password=547717253 properties 标签配置 : 123456&lt;!-- 配置连接数据库的信息 resource 属性：用于指定 properties 配置文件的位置，要求配置文件必须在类路径下 resource=\"jdbcConfig.properties\" url 属性： URL： Uniform Resource Locator 统一资源定位符 http://localhost:8080/mystroe/CategoryServlet URL 协议 主机 端口 URI URI：Uniform Resource Identifier 统一资源标识符 /mystroe/CategoryServlet 它是可以在 web 应用中唯一定位一个资源的路径 --&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; 此时我们的 dataSource 标签就变成了引用上面的配置: 123456&lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; 2.3 typeAliases（类型别名）自定义别名： 1234567在 SqlMapConfig.xml 中配置： &lt;typeAliases&gt; &lt;!-- 单个别名定义 --&gt; &lt;typeAlias alias=\"user\" type=\"com.itheima.domain.User\"/&gt; &lt;!-- 批量别名定义，扫描整个包下的类，别名为类名（首字母大写或小写都可以） --&gt; &lt;package name=\"com.itheima.domain\"/&gt; &lt;package name=\" 其它包 \"/&gt; &lt;/typeAliases&gt; 2.4 mappers（映射器） 使用相对于类路径的资源 如： 1&lt;mapper resource=\"com/itheima/dao/IUserDao.xml\" /&gt; 1使用 mapper 接口类路径 如：&lt;mapper class=\"com.itheima.dao.UserDao\"/&gt; 注意：此种方法要求 mapper 接口名称和 mapper 映射文件名称相同，且放在同一个目录中。 1注册指定包下的所有 mapper 接口 如：&lt;package name=\"cn.itcast.mybatis.mapper\"/&gt; 注意：此种方法要求 mapper 接口名称和 mapper 映射文件名称相同，且放在同一个目录中。 3.Mybatis 的连接池技术1234567891011数据源配置就是在 SqlMapConfig.xml 文件中，具体配置如下： &lt;!-- 配置数据源（连接池）信息 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; MyBatis 在初始化时，根据&lt;dataSource&gt;的 type 属性来创建相应类型的的数据源 DataSource，即： type=”POOLED”：MyBatis 会创建 PooledDataSource 实例 type=”UNPOOLED” ： MyBatis 会创建 UnpooledDataSource 实例 type=”JNDI”：MyBatis 会从 JNDI 服务上查找 DataSource 实例，然后返回使用 4.Mybatis 自动提交事务的设置123456789101112131415161718为什么 CUD 过程中必须使用 sqlSession.commit()提交事 务？主要原因就是在连接池中取出的连接，都会将调用 connection.setAutoCommit(false)方法，这样我们 就必须使用 sqlSession.commit()方法，相当于使用了 JDBC 中的 connection.commit()方法实现事务提 交。 明白这一点后，我们现在一起尝试不进行手动提交，一样实现 CUD 操作。 @Before//在测试方法执行之前执行 public void init()throws Exception &#123; //1.读取配置文件 in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); //2.创建构建者对象 SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); //3.创建 SqlSession 工厂对象 factory = builder.build(in); //4.创建 SqlSession 对象 session = factory.openSession(true); //5.创建 Dao 的代理对象 userDao = session.getMapper(IUserDao.class); &#125; @After//在测试方法执行完成之后执行 public void destroy() throws Exception&#123; //7.释放资源 session.close(); in.close(); &#125; 5.Mybatis 的动态 SQL 语句5.1 动态 SQL 之if标签12345/** * 根据用户信息，查询用户列表 * @param user * @return */ List&lt;User&gt; findByUser(User user); 12345678910&lt;select id=\"findByUser\" resultType=\"user\" parameterType=\"user\"&gt; select * from user where 1=1 &lt;if test=\"username!=null and username != '' \"&gt; and username like #&#123;username&#125; &lt;/if&gt; &lt;if test=\"address != null\"&gt; and address like #&#123;address&#125; &lt;/if&gt; &lt;/select&gt; 注意：&lt;if&gt;标签的 test 属性中写的是对象的属性名，如果是包装类的对象要使用 OGNL 表达式的写法。 另外要注意 where 1=1 的作用~！ 1234567891011@Test public void testFindByUser() &#123; User u = new User(); u.setUsername(\"%王%\"); u.setAddress(\"%顺义%\"); //6.执行操作 List&lt;User&gt; users = userDao.findByUser(u); for(User user : users) &#123; System.out.println(user); &#125; &#125; 5.2动态 SQL 之where标签为了简化上面 where 1=1 的条件拼装，我们可以采用标签来简化开发。 1234567891011&lt;!-- 根据用户信息查询 --&gt; &lt;select id=\"findByUser\" resultType=\"user\" parameterType=\"user\"&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; &lt;where&gt; &lt;if test=\"username!=null and username != '' \"&gt; and username like #&#123;username&#125; &lt;/if&gt; &lt;if test=\"address != null\"&gt; and address like #&#123;address&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 5.3动态标签之foreach标签​ 传入多个 id 查询用户信息，用下边两个 sql 实现： SELECT * FROM USERS WHERE 1username LIKE '%张%' AND (id =10 OR id =89 OR id=16) SELECT * FROM USERS WHERE username LIKE '%张%' AND id IN (10,89,16) 这样我们在进行范围查询时，就要将一个集合中的值，作为参数动态添加进来。 在 QueryVo 中加入一个 List 集合用于封装参数: 123456789101112/** * * &lt;p&gt;Title: QueryVo&lt;/p&gt; * &lt;p&gt;Description: 查询的条件&lt;/p&gt; * &lt;p&gt;Company: http://www.itheima.com/ &lt;/p&gt; */ public class QueryVo implements Serializable &#123; private List&lt;Integer&gt; ids; public List&lt;Integer&gt; getIds() &#123; return ids; &#125; public void setIds(List&lt;Integer&gt; ids) &#123; this.ids = ids; &#125; &#125; 12345/** * 根据 id 集合查询用户 * @param vo * @return */ List&lt;User&gt; findInIds(QueryVo vo); 1234567891011121314151617181920&lt;!-- 查询所有用户在 id 的集合之中 --&gt; &lt;select id=\"findInIds\" resultType=\"user\" parameterType=\"queryvo\"&gt; &lt;!-- select * from user where id in (1,2,3,4,5); --&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; &lt;where&gt; &lt;if test=\"ids != null and ids.size() &gt; 0\"&gt; &lt;foreach collection=\"ids\" open=\"id in ( \" close=\")\" item=\"uid\" separator=\",\"&gt; #&#123;uid&#125; &lt;/foreach&gt; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; SQL 语句： select 字段 from user where id in (?) &lt;foreach&gt;标签用于遍历集合，它的属性： collection:代表要遍历的集合元素，注意编写时不要写#&#123;&#125; open:代表语句的开始部分 close:代表结束部分 item:代表遍历集合的每个元素，生成的变量名 sperator:代表分隔符 12345678910111213141516@Test public void testFindInIds() &#123; QueryVo vo = new QueryVo(); List&lt;Integer&gt; ids = new ArrayList&lt;Integer&gt;(); ids.add(41); ids.add(42); ids.add(43); ids.add(46); ids.add(57); vo.setIds(ids); //6.执行操作 List&lt;User&gt; users = userDao.findInIds(vo); for(User user : users) &#123; System.out.println(user); &#125; &#125; 5.4 Mybatis 中简化编写的 SQL 片段Sql 中可将重复的 sql 提取出来，使用时用 include 引用即可，最终达到 sql 重用的目的。 定义代码片段 : 1234&lt;!-- 抽取重复的语句代码片段 --&gt; &lt;sql id=\"defaultSql\"&gt; select * from user &lt;/sql&gt; 引用代码片段 : 123456789&lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultType=\"user\"&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; &lt;/select&gt; &lt;!-- 根据 id 查询 --&gt; &lt;select id=\"findById\" resultType=\"UsEr\" parameterType=\"int\"&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; where id = #&#123;uid&#125; &lt;/select&gt; 6.Mybatis 延迟加载策略6.1 何为延迟加载?延迟加载： 就是在需要用到数据时才进行加载，不需要用到数据时就不加载数据。延迟加载也称懒加载. 好处：先从单表查询，需要时再从关联表去关联查询，大大提高数据库性能，因为查询单表要比关联查询多张表速 度要快。 坏处： 因为只有当需要用到数据时，才会进行数据库查询，这样在大批量数据查询时，因为查询工作也要消耗 时间，所以可能造成用户等待时间变长，造成用户体验下降。 6.2 实现需求需求：查询账户(Account)信息并且关联查询用户(User)信息。如果先查询账户(Account)信息即可满足要 求，当我们需要查询用户(User)信息时再查询用户(User)信息。把对用户(User)信息的按需去查询就是延迟加 载。 实现多表操作时，使用resultMap来实现一对一，一对多，多对多关系的操作。主要 是通过 association、collection 实现一对一及一对多映射。association、collection 具备延迟加载功 能。 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"dao.IAccountDao\"&gt; &lt;!-- 建立对应关系 --&gt; &lt;resultMap type=\"account\" id=\"accountMap\"&gt; &lt;id column=\"aid\" property=\"id\"/&gt; &lt;result column=\"uid\" property=\"uid\"/&gt; &lt;result column=\"money\" property=\"money\"/&gt; &lt;!-- 它是用于指定从表方的引用实体属性的 --&gt; &lt;association property=\"user\" javaType=\"user\" select=\"com.itheima.dao.IUserDao.findById\" column=\"uid\"&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id=\"findAll\" resultMap=\"accountMap\"&gt; select * from account &lt;/select&gt; &lt;/mapper&gt; select： 填写我们要调用的 select 映射的 id column ： 填写我们要传递给 select 映射的参数 6.3 使用 assocation 实现延迟加载123456我们需要在 Mybatis 的配置文件 SqlMapConfig.xml 文件中添加延迟加载的配置。 &lt;!-- 开启延迟加载的支持 --&gt; &lt;settings&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;setting name=\"aggressiveLazyLoading\" value=\"false\"/&gt; &lt;/settings&gt; 6.4 使用 Collection 实现延迟加载​ 同样我们也可以在一对多关系配置的结点中配置延迟加载策略。 结点中也有 select 属性，column 属性。 需求： 完成加载用户对象时，查询该用户所拥有的账户信息。 在 User 实体类中加入 List属性: 123private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; 编写用户持久层映射配置: 12345678910111213141516171819&lt;resultMap type=\"user\" id=\"userMap\"&gt; &lt;id column=\"id\" property=\"id\"&gt;&lt;/id&gt; &lt;result column=\"username\" property=\"username\"/&gt; &lt;result column=\"address\" property=\"address\"/&gt; &lt;result column=\"sex\" property=\"sex\"/&gt; &lt;result column=\"birthday\" property=\"birthday\"/&gt; &lt;!-- collection 是用于建立一对多中集合属性的对应关系 ofType 用于指定集合元素的数据类型 select 是用于指定查询账户的唯一标识（账户的 dao 全限定类名加上方法名称） column 是用于指定使用哪个字段的值作为条件查询 --&gt; &lt;collection property=\"accounts\" ofType=\"account\" select=\"com.itheima.dao.IAccountDao.findByUid\" column=\"id\"&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultMap=\"userMap\"&gt; select * from user &lt;/select&gt; &lt;collection&gt;标签： 主要用于加载关联的集合对象 select 属性： 用于指定查询 account 列表的 sql 语句，所以填写的是该 sql 映射的 id column 属性： 用于指定 select 属性的 sql 语句的参数来源，上面的参数来自于 user 的 id 列，所以就写成 id 这一 个字段名了 7.Mybatis 缓存7.1 Mybatis 一级缓存一级缓存是 SqlSession 级别的缓存，只要 SqlSession 没有 flush 或 close，它就存在。 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"dao.IUserDao\"&gt; &lt;!-- 根据 id 查询 --&gt; &lt;select id=\"findById\" resultType=\"UsEr\" parameterType=\"int\" useCache=\"true\"&gt; select * from user where id = #&#123;uid&#125; &lt;/select&gt; &lt;/mapper&gt; 一级缓存的分析 : ​ 一级缓存是 SqlSession 范围的缓存，当调用 SqlSession 的修改，添加，删除，commit()，close()等方法时，就会清空一级缓存。 ​ 第一次发起查询用户 id 为 1 的用户信息，先去找缓存中是否有 id 为 1 的用户信息，如果没有，从数据库查 询用户信息。 得到用户信息，将用户信息存储到一级缓存中。 如果 sqlSession 去执行 commit 操作（执行插入、更新、删除），清空 SqlSession 中的一级缓存，这样 做的目的为了让缓存中存储的是最新的信息，避免脏读。 第二次发起查询用户 id 为 1 的用户信息，先去找缓存中是否有 id 为 1 的用户信息，缓存中有，直接从缓存 中获取用户信息。 7.2 Mybatis 二级缓存​ 二级缓存是 mapper 映射级别的缓存，多个 SqlSession 去操作同一个 Mapper 映射的 sql 语句，多个 SqlSession 可以共用二级缓存，二级缓存是跨 SqlSession 的。 二级缓存的分析 : 首先开启 mybatis 的二级缓存。sqlSession1 去查询用户信息，查询到用户信息会将查询数据存储到二级缓存中。 如果 SqlSession3 去执行相同 mapper 映射下 sql，执行 commit 提交，将会清空该 mapper 映射下的二 级缓存区域的数据。sqlSession2 去查询与 sqlSession1 相同的用户信息，首先会去缓存中找是否存在数据，如果存在直接从 缓存中取出数据。 二级缓存的开启与关闭: 第一步：在 SqlMapConfig.xml 文件开启二级缓存 12345&lt;settings&gt; &lt;!-- 开启二级缓存的支持 --&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; 因为 cacheEnabled 的取值默认就为 true，所以这一步可以省略不配置。为 true 代表开启二级缓存；为 false 代表不开启二级缓存。 第二步：配置相关的 Mapper 映射文件 1234567&lt;cache&gt;标签表示当前这个 mapper 映射将使用二级缓存，区分的标准就看 mapper 的 namespace 值。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"dao.IUserDao\"&gt; &lt;!-- 开启二级缓存的支持 --&gt; &lt;cache&gt;&lt;/cache&gt; &lt;/mapper&gt; 第三步：配置 statement 上面的 useCache 属性 123456&lt;!-- 根据 id 查询 --&gt; &lt;select id=\"findById\" resultType=\"user\" parameterType=\"int\" useCache=\"true\"&gt; select * from user where id = #&#123;uid&#125; &lt;/select&gt; 将 UserDao.xml 映射文件中的&lt;select&gt;标签中设置 useCache=”true”代表当前这个 statement 要使用 二级缓存，如果不使用二级缓存可以设置为 false。 注意：针对每次查询都需要最新的数据 sql，要设置成 useCache=false，禁用二级缓存。 二级缓存注意事项 : 123456789101112当我们在使用二级缓存时，所缓存的类一定要实现 java.io.Serializable 接口，这种就可以使用序列化 方式来保存对象。 /** * * &lt;p&gt;Title: User&lt;/p&gt; * &lt;p&gt;Description: 用户的实体类&lt;/p&gt; */ public class User implements Serializable &#123; private Integer id; private String username; private Date birthday; private String sex; private String address; &#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Mybatis框架(三)","slug":"Mybatis框架(三)","date":"2021-05-08T13:19:59.144Z","updated":"2020-04-29T02:44:38.069Z","comments":true,"path":"65310/","link":"","permalink":"http://tonymua.top/65310/","excerpt":"1. Mybatis 注解开发1.1 mybatis 的常用注解说明@Insert:实现新增 @Update:实现更新 @Delete:实现删除 @Select:实现查询 @Result:实现结果集封装 @Results:可以与@Result 一起使用，封装多个结果集","text":"1. Mybatis 注解开发1.1 mybatis 的常用注解说明@Insert:实现新增 @Update:实现更新 @Delete:实现删除 @Select:实现查询 @Result:实现结果集封装 @Results:可以与@Result 一起使用，封装多个结果集 @ResultMap:实现引用@Results 定义的封装 @One:实现一对一结果集封装 @Many:实现一对多结果集封装 @SelectProvider: 实现动态 SQL 映射 @CacheNamespace:实现注解二级缓存的使用 1.2 使用 Mybatis 注解实现基本 CRUD1.2.1 编写实体类 1234567891011121314151617181920public class User implements Serializable &#123; private Integer userId; private String userName; private Date userBirthday; private String userSex; private String userAddress; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public Date getUserBirthday() &#123; return userBirthday; &#125; public void setUserBirthday(Date userBirthday) &#123; this.userBirthday = userBirthday; &#125; public String getUserSex() &#123; return userSex; &#125; public void setUserSex(String userSex) &#123; this.userSex = userSex; &#125; public String getUserAddress() &#123; return userAddress; &#125; public void setUserAddress(String userAddress) &#123; this.userAddress = userAddress; &#125; @Override public String toString() &#123; return \"User [userId=\" + userId + \", userName=\" + userName + \", userBirthday=\" + userBirthday + \", userSex=\" + userSex + \", userAddress=\" + userAddress + \"]\"; &#125; &#125; 注意： 此处我们故意和数据库表的列名不一致。 1.2.2 使用注解方式开发持久层接口 1234567891011121314151617181920212223242526272829303132333435363738394041public interface IUserDao &#123; /** * 查询所有用户 * @return */ @Select(\"select * from user\") @Results(id=\"userMap\", value= &#123; @Result(id=true,column=\"id\",property=\"userId\"), @Result(column=\"username\",property=\"userName\"), @Result(column=\"sex\",property=\"userSex\"), @Result(column=\"address\",property=\"userAddress\"), @Result(column=\"birthday\",property=\"userBirthday\") &#125;) List&lt;User&gt; findAll(); /** * 根据 id 查询一个用户 * @param userId * @return */ @Select(\"select * from user where id = #&#123;uid&#125; \") @ResultMap(\"userMap\") User findById(Integer userId); /** * 保存操作 * @param user * @return */ @Insert(\"insert into user(username,sex,birthday,address)values(#&#123;username&#125;,#&#123;sex&#125;,#&#123;birthday&#125;,#&#123;address&#125; )\") @SelectKey(keyColumn=\"id\",keyProperty=\"id\",resultType=Integer.class,before = false, statement = &#123; \"select last_insert_id()\" &#125;) int saveUser(User user); /** * 更新操作 * @param user * @return */ @Update(\"update user set username=#&#123;username&#125;,address=#&#123;address&#125;,sex=#&#123;sex&#125;,birthday=#&#123;birthday&#125; where id =#&#123;id&#125; \") int updateUser(User user); /** * 删除用户 * @param userId * @return */ @Delete(\"delete from user where id = #&#123;uid&#125; \") int deleteUser(Integer userId); /** * 查询使用聚合函数 * @return */ @Select(\"select count(*) from user \") int findTotal(); /** * 模糊查询 * @param name * @return */ @Select(\"select * from user where username like #&#123;username&#125; \") List&lt;User&gt; findByName(String name); &#125; 通过注解方式，我们就不需要再去编写 UserDao.xml 映射文件了。 1.2.3 编写 SqlMapConfig 配置文件 123456789101112131415161718192021222324252627 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!-- 配置 properties 文件的位置 --&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; &lt;!-- 配置别名的注册 --&gt; &lt;typeAliases&gt; &lt;package name=\"domain\"/&gt; &lt;/typeAliases&gt; &lt;!-- 配置环境 --&gt; &lt;environments default=\"mysql\"&gt; &lt;!-- 配置 mysql 的环境 --&gt; &lt;environment id=\"mysql\"&gt; &lt;!-- 配置事务的类型是 JDBC --&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;!-- 配置数据源 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 配置映射信息 --&gt; &lt;mappers&gt; &lt;!-- 配置 dao 接口的位置，它有两种方式 第一种：使用 mapper 标签配置 class 属性 第二种：使用 package 标签，直接指定 dao 接口所在的包 --&gt; &lt;package name=\"com.itheima.dao\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 1.2.4 编写测试方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class AnnotationCRUDTest &#123; private InputStream in; private SqlSessionFactory factory; private SqlSession sqlSession; private UserDao userDao; @Before public void init() throws Exception &#123; in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); factory = new SqlSessionFactoryBuilder().build(in); sqlSession=factory.openSession(true); userDao=sqlSession.getMapper(UserDao.class); &#125; @After public void destroy() throws Exception &#123; sqlSession.close(); in.close(); &#125; @Test public void testSave()&#123; User user=new User(); user.setUsername(\"test\"); user.setSex(\"男\"); user.setBirthday(new Date()); user.setAddress(\"兰州\"); userDao.saveUser(user); &#125; @Test public void testUpdate()&#123; User user=new User(); user.setId(54); user.setUsername(\"testUpdate\"); user.setSex(\"女\"); user.setBirthday(new Date()); user.setAddress(\"西安\"); userDao.updateUser(user); &#125; @Test public void testDelete()&#123; userDao.deletUser(54); &#125; @Test public void testFindOne()&#123; User user =userDao.findById(48); System.out.println(user); &#125; @Test public void testFindByName()&#123;// List&lt;User&gt; users = userDao.findUserByName(\"%王%\"); List&lt;User&gt; users = userDao.findUserByName(\"王\"); for (User user:users)&#123; System.out.println(user); &#125; &#125; @Test public void testFindTotal()&#123; int totalUser = userDao.findTotalUser(); System.out.println(totalUser); &#125;&#125; 1.3 使用注解实现复杂关系映射开发​ 实现复杂关系映射之前我们可以在映射文件中通过配置来实现，在使用注解开发时我们需要借 助@Results 注解，@Result 注解，@One 注解，@Many 注解。 1.3.1 复杂关系映射的注解说明 @Results 注解 代替的是标签 该注解中可以使用单个@Result 注解，也可以使用@Result 集合 @Results（{@Result（），@Result（）}）或@Results（@Result（）） @Resutl 注解 代替了 标签和标签 @Result 中 属性介绍： id 是否是主键字段 column 数据库的列名 property 需要装配的属性名 one 需要使用的@One 注解（@Result（one=@One）（））） many 需要使用的@Many 注解（@Result（many=@many）（））） @One 注解（一对一） 代替了标签，是多表查询的关键，在注解中用来指定子查询返回单一对象。 @One 注解属性介绍： select 指定用来多表查询的 sqlmapper fetchType 会覆盖全局的配置参数 lazyLoadingEnabled。 使用格式： @Result(column=” “,property=””,one=@One(select=””)) @Many 注解（多对一） 代替了标签,是是多表查询的关键，在注解中用来指定子查询返回对象集合。 注意：聚集元素用来处理“一对多”的关系。需要指定映射的 Java 实体类的属性，属性的 javaType （一般为 ArrayList）但是注解中可以不定义； 使用格式： @Result(property=””,column=””,many=@Many(select=””)) 1.3.2 使用注解实现一对一复杂关系映射及延迟加载 需求： 加载账户信息时并且加载该账户的用户信息，根据情况可实现延迟加载。（注解方式实现） 添加 User 实体类及 Account 实体类: 1234//多对一关系映射：从表方应该包含一个主表方的对象引用 private User user; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; 添加账户的持久层接口并使用注解配置 : 12345678910111213public interface IAccountDao &#123; /** * 查询所有账户，采用延迟加载的方式查询账户的所属用户 * @return */ @Select(\"select * from account\") @Results(id=\"accountMap\", value= &#123; @Result(id=true,column=\"id\",property=\"id\"), @Result(column=\"uid\",property=\"uid\"), @Result(column=\"money\",property=\"money\"), @Result(column=\"uid\", property=\"user\", one=@One(select=\"com.itheima.dao.IUserDao.findById\", fetchType=FetchType.LAZY) ) &#125;) List&lt;Account&gt; findAll(); &#125; 添加用户的持久层接口并使用注解配置 : 123456789101112131415161718public interface IUserDao &#123; /** * 查询所有用户 * @return */ @Select(\"select * from user\") @Results(id=\"userMap\", value= &#123; @Result(id=true,column=\"id\",property=\"userId\"), @Result(column=\"username\",property=\"userName\"), @Result(column=\"sex\",property=\"userSex\"), @Result(column=\"address\",property=\"userAddress\"), @Result(column=\"birthday\",property=\"userBirthday\") &#125;) List&lt;User&gt; findAll(); /** * 根据 id 查询一个用户 * @param userId * @return */ @Select(\"select * from user where id = #&#123;uid&#125; \") @ResultMap(\"userMap\") User findById(Integer userId);&#125; 1.3.3 使用注解实现一对多复杂关系映射需求： 查询用户信息时，也要查询他的账户列表。使用注解方式实现。 分析： 一个用户具有多个账户信息，所以形成了用户(User)与账户(Account)之间的一对多关系。 User 实体类加入 List: 12345//一对多关系映射：主表方法应该包含一个从表方的集合引用 private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; 编写用户的持久层接口并使用注解配置 : 12345678910111213141516171819public interface IUserDao &#123; /** * 查询所有用户 * @return */ @Select(\"select * from user\") @Results(id=\"userMap\", value= &#123; @Result(id=true,column=\"id\",property=\"userId\"), @Result(column=\"username\",property=\"userName\"), @Result(column=\"sex\",property=\"userSex\"), @Result(column=\"address\",property=\"userAddress\"), @Result(column=\"birthday\",property=\"userBirthday\"), @Result(column=\"id\",property=\"accounts\", many=@Many( select=\"com.itheima.dao.IAccountDao.findByUid\", fetchType=FetchType.LAZY ) ) &#125;) List&lt;User&gt; findAll(); &#125; @Many: 相当于&lt;collection&gt;的配置 select 属性：代表将要执行的 sql 语句 fetchType 属性：代表加载方式，一般如果要延迟加载都设置为 LAZY 的值 编写账户的持久层接口并使用注解配置: 12345678public interface IAccountDao &#123; /** * 根据用户 id 查询用户下的所有账户 * @param userId * @return */ @Select(\"select * from account where uid = #&#123;uid&#125; \") List&lt;Account&gt; findByUid(Integer userId); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class AnnotationCRUDTest &#123; private InputStream in; private SqlSessionFactory factory; private SqlSession sqlSession; private UserDao userDao; @Before public void init() throws Exception &#123; in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); factory = new SqlSessionFactoryBuilder().build(in); sqlSession=factory.openSession(true); userDao=sqlSession.getMapper(UserDao.class); &#125; @After public void destroy() throws Exception &#123; sqlSession.close(); in.close(); &#125; @Test public void FindAll()&#123; List&lt;User&gt; users = userDao.findAll(); for (User user:users)&#123; System.out.println(\"------每个用户的信息------\"); System.out.println(user); System.out.println(user.getAccounts()); &#125; &#125; @Test public void testFindOne()&#123; User user =userDao.findById(48); System.out.println(user); &#125; @Test public void testFindByName()&#123;// List&lt;User&gt; users = userDao.findUserByName(\"%王%\"); List&lt;User&gt; users = userDao.findUserByName(\"王\"); for (User user:users)&#123; System.out.println(user); &#125; &#125;&#125; 2.mybatis 基于注解的二级缓存2.1 在 SqlMapConfig 中开启二级缓存支持1234&lt;!--配置开启二级缓存--&gt; &lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; 2.2 在持久层接口中使用注解配置二级缓存1@CacheNamespace(blocking = true)//开启二级缓存 3.Mybatis使用总结SqlMapConfig.xml 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--配置外部文件--&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; &lt;!--配置开启二级缓存--&gt; &lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; &lt;!--使用typeAliases配置别名，它只能配置domain中类的别名 --&gt; &lt;typeAliases&gt; &lt;package name=\"domain\"&gt;&lt;/package&gt; &lt;/typeAliases&gt; &lt;!--配置环境--&gt; &lt;environments default=\"mysql\"&gt; &lt;environment id=\"mysql\"&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"&gt;&lt;/property&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--指定带有注解的dao接口所在位置--&gt; &lt;mappers&gt; &lt;package name=\"dao\"&gt;&lt;/package&gt; &lt;/mappers&gt;&lt;/configuration&gt; jdbcConfig.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/eesy_mybatisjdbc.username=rootjdbc.password=547717253 User 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class User implements Serializable &#123; private Integer userId; private String userName; private String userSex; private Date userBirthday; private String userAddress; //一对多关系映射,一个用户对应多个账户 private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getUserSex() &#123; return userSex; &#125; public void setUserSex(String userSex) &#123; this.userSex = userSex; &#125; public Date getUserBirthday() &#123; return userBirthday; &#125; public void setUserBirthday(Date userBirthday) &#123; this.userBirthday = userBirthday; &#125; public String getUserAddress() &#123; return userAddress; &#125; public void setUserAddress(String userAddress) &#123; this.userAddress = userAddress; &#125; @Override public String toString() &#123; return \"User&#123;\" + \"userId=\" + userId + \", userName='\" + userName + '\\'' + \", userSex='\" + userSex + '\\'' + \", userBirthday=\" + userBirthday + \", userAddress='\" + userAddress + '\\'' + '&#125;'; &#125;&#125; Account 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Account implements Serializable &#123; private Integer id; private Integer uid; private Double money; //多对一(mybatis中称之一对一)的映射:一个账户只能对应一个用户 private User user; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getUid() &#123; return uid; &#125; public void setUid(Integer uid) &#123; this.uid = uid; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", uid=\" + uid + \", money=\" + money + '&#125;'; &#125;&#125; UserDao 12345678910111213141516171819202122232425@CacheNamespace(blocking = true)//开启二级缓存public interface UserDao &#123; @Select(\"select * from user\") @Results(id = \"userMap\",value = &#123; @Result(id = true ,property = \"userId\",column = \"id\"), @Result(id = false,property = \"userName\",column =\"username\" ), @Result(id = false,property = \"userSex\",column = \"sex\"), @Result(id = false,property = \"userBirthday\",column = \"birthday\"), @Result(id = false,property = \"userAddress\",column = \"address\"), @Result(property = \"accounts\",column =\"id\",many = @Many(select = \"dao.AccountDao.findAccountByUid\",fetchType = FetchType.LAZY)) &#125;) List&lt;User&gt; findAll(); @Select(\"select * from user where id=#&#123;id&#125;\")// @ResultMap(value = &#123;\"userMap\"&#125;) @ResultMap(\"userMap\") User findById(Integer id);// @Select(\"select * from user where username like #&#123;username&#125;\") @Select(\"select * from user where username like '%$&#123;value&#125;%'\") @ResultMap(\"userMap\") List&lt;User&gt; findUserByName(String username);&#125; AccountDao 1234567891011121314public interface AccountDao &#123; @Select(\"select * from account\") @Results(id = \"accountMap\",value = &#123; @Result(id = true,property = \"id\",column = \"id\"), @Result(id = false,property = \"uid\",column = \"uid\"), @Result(id = false,property = \"money\",column = \"money\"), @Result(property =\"user\",column = \"uid\",one = @One(select = \"dao.UserDao.findById\",fetchType = FetchType.EAGER)) &#125;) List&lt;Account&gt; findAll(); @Select(\"select * from account where uid=#&#123;userId&#125;\") List&lt;Account&gt; findAccountByUid(Integer userId);&#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Mybatis框架(一)","slug":"Mybatis框架(一)","date":"2021-05-08T13:19:59.142Z","updated":"2020-04-29T02:44:38.022Z","comments":true,"path":"44824/","link":"","permalink":"http://tonymua.top/44824/","excerpt":"1.框架概述1.1 什么是框架​ 框架（Framework）是整个或部分系统的可重用设计，表现为一组抽象构件及构件实例间交互的方法;另一种 定义认为，框架是可被应用开发者定制的应用骨架。前者是从应用方面而后者是从目的方面给出的定义。 简而言之，框架其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别 人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。 1.2 框架要解决的问题​ 框架要解决的最重要的一个问题是技术整合的问题，在 J2EE 的 框架中，有着各种各样的技术，不同的 软件企业需要从 J2EE 中选择不同的技术，这就使得软件企业最终的应用依赖于这些技术，技术自身的复杂性和技 术的风险性将会直接对应用造成冲击。而应用是软件企业的核心，是竞争力的关键所在，因此应该将应用自身的设计和具体的实现技术解耦。这样，软件企业的研发将集中在应用的设计上，而不是具体的技术实现，技术实现是应 用的底层支撑，它不应该直接对应用产生影响。","text":"1.框架概述1.1 什么是框架​ 框架（Framework）是整个或部分系统的可重用设计，表现为一组抽象构件及构件实例间交互的方法;另一种 定义认为，框架是可被应用开发者定制的应用骨架。前者是从应用方面而后者是从目的方面给出的定义。 简而言之，框架其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别 人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。 1.2 框架要解决的问题​ 框架要解决的最重要的一个问题是技术整合的问题，在 J2EE 的 框架中，有着各种各样的技术，不同的 软件企业需要从 J2EE 中选择不同的技术，这就使得软件企业最终的应用依赖于这些技术，技术自身的复杂性和技 术的风险性将会直接对应用造成冲击。而应用是软件企业的核心，是竞争力的关键所在，因此应该将应用自身的设计和具体的实现技术解耦。这样，软件企业的研发将集中在应用的设计上，而不是具体的技术实现，技术实现是应 用的底层支撑，它不应该直接对应用产生影响。 ​ 框架一般处在低层应用平台（如 J2EE）和高层业务逻辑之间的中间层。 1.3 软件开发的分层重要性​ 框架的重要性在于它实现了部分功能，并且能够很好的将低层应用平台和高层业务逻辑进行了缓和。为了实现软件工程中的“高内聚、低耦合”。把问题划分开来各个解决，易于控制，易于延展，易于分配资源。我们常见的 MVC 软件设计思想就是很好的分层思想。 2.Mybatis 框架快速入门2.1 mybatis 环境搭建步骤​ 第一步：创建 maven 工程 ​ 第二步：导入坐标 ​ 第三步：编写必要代码（实体类和持久层接口） ​ 第四步：编写 SqlMapConfig.xml ​ 第五步：编写映射配置文件 ​ 第六步：编写测试类 2.2 创建 maven 工程1&lt;packaging&gt;jar&lt;/packaging&gt; 2.3 添加 Mybatis3.4.5 及相关的坐标12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.基于代理 Dao 实现 CRUD 操作3.1 SqlMapConfig.xml12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--配置环境--&gt; &lt;environments default=\"mysql\"&gt; &lt;!--配置mysql的环境--&gt; &lt;environment id=\"mysql\"&gt; &lt;!--配置事务--&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;!--配置连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/eesy_mybatis\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"547717253\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--配置映射文件的位置--&gt; &lt;mappers&gt; &lt;mapper resource=\"dao/UserDao.xml\"&gt;&lt;/mapper&gt; &lt;/mappers&gt;&lt;/configuration&gt; 3.2 在持久层Dao接口中添加方法12345678910111213141516171819202122232425public interface UserDao &#123; List&lt;User&gt; findAll(); void saveUser(User user); void updateUser(User user); void deleteUser(User user); User findById(Integer id); //模糊查询 List&lt;User&gt; findByName(String username); //查询总用户数 int findTotal();&#125;public interface UserDao &#123; List&lt;User&gt; findAll(); void saveUser(User user); void updateUser(User user); void deleteUser(User user);&#125; 3.3 在用户的映射配置文件中配置1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"dao.UserDao\"&gt; &lt;select id=\"findAll\" resultType=\"domain.User\"&gt; select * from user ; &lt;/select&gt; &lt;insert id=\"saveUser\" parameterType=\"domain.User\"&gt; insert into user (username,birthday,sex,address)values (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;); &lt;/insert&gt; &lt;update id=\"updateUser\" parameterType=\"domain.User\"&gt; update user set username=#&#123;username&#125;,birthday=#&#123;birthday&#125;,sex=#&#123;sex&#125;,address=#&#123;address&#125; where id=#&#123;id&#125;; &lt;/update&gt; &lt;delete id=\"deleteUser\" parameterType=\"domain.User\"&gt; delete from user where id=#&#123;id&#125;; &lt;/delete&gt; &lt;select id=\"findById\" parameterType=\"int\" resultType=\"domain.User\"&gt; select * from user where id =#&#123;id&#125;; &lt;/select&gt; &lt;select id=\"findByName\" parameterType=\"String\" resultType=\"domain.User\"&gt; &lt;!--select * from user where username like #&#123;username&#125;--&gt; &lt;!--以下方式比较常用--&gt; select * from user where username like '%$&#123;value&#125;%'; &lt;/select&gt; &lt;select id=\"findTotal\" resultType=\"int\"&gt; select count(id) from user ; &lt;/select&gt;&lt;/mapper&gt; 细节： ​ parameterType 属性： 代表参数的类型，因为我们要传入的是一个类的对象，所以类型就写类的全名称。 ​ sql 语句中使用#{}字符： 它代表占位符，相当于原来 jdbc 部分所学的?，都是用于执行语句时替换实际的数据。 具体的数据是由#{}里面的内容决定的。 ​ #{}中内容的写法： 由于我们保存方法的参数是 一个 User 对象，此处要写 User 对象中的属性名称。 它用的是 ognl 表达式。 ​ ognl 表达式： 它是 apache 提供的一种表达式语言，全称是： Object Graphic Navigation Language 对象图导航语言 它是按照一定的语法格式来获取数据的。 语法格式就是使用 #{对象.对象}的方式 ​ #{user.username}它会先去找 user 对象，然后在 user 对象中找到 username 属性，并调用 getUsername()方法把值取出来。但是我们在 parameterType 属性上指定了实体类名称，所以可以省略 user. 而直接写 username。 3.4添加测试类中的测试方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class MybatisTest &#123; private InputStream in; private SqlSessionFactory factory; private SqlSession sqlSession; private UserDao userDao; @Before//在测试方法执行之前执行 public void init() throws Exception &#123; //1.读取配置文件,生成字节输入流 in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); //2.获取SqlSessionFactory对象 factory = new SqlSessionFactoryBuilder().build(in); //3.获取SqlSession对象 sqlSession = factory.openSession(); //4.获取dao的代理对象 userDao = sqlSession.getMapper(UserDao.class); &#125; @After//在测试方法执行之后执行 public void destrory() throws Exception &#123; //提交事务 sqlSession.commit(); //6.释放资源 sqlSession.close(); in.close(); &#125; // 测试查询所有 @Test public void testfindAll() throws Exception &#123; //1.读取配置文件,生成字节输入流 InputStream in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); //2.获取SqlSessionFactory对象 SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(in); //3.获取SqlSession对象 SqlSession sqlSession = factory.openSession(); //4.获取dao的代理对象 UserDao userDao = sqlSession.getMapper(UserDao.class); //5.执行查询所有方法 List&lt;User&gt; users = userDao.findAll(); for (User user : users) &#123; System.out.println(user); &#125; //6.释放资源 sqlSession.close(); in.close(); &#125; // 测试保存 @Test public void testSave() &#123; User user = new User(); user.setUsername(\"张三\"); user.setBirthday(new Date()); user.setSex(\"男\"); user.setAddress(\"上海\"); //执行保存方法 userDao.saveUser(user); &#125; @Test public void testUpdate() &#123; User user=new User(); user.setId(51); user.setUsername(\"李四\"); user.setBirthday(new Date()); user.setSex(\"女\"); user.setAddress(\"北京\"); userDao.updateUser(user); &#125; @Test public void testDelete()&#123; User user=new User(); user.setId(52); userDao.deleteUser(user); &#125; @Test public void testFindById()&#123; User user = userDao.findById(51); System.out.println(user); &#125; @Test public void testFindByName()&#123; // List&lt;User&gt; users = userDao.findByName(\"%王%\"); List&lt;User&gt; users = userDao.findByName(\"王\"); for (User user:users)&#123; System.out.println(user); &#125; &#125; @Test public void testFindTotal()&#123; int total = userDao.findTotal(); System.out.println(total); &#125;&#125; 模糊查询注意事项:第一步：修改 SQL 语句的配置，配置如下： 1&lt;!-- 根据名称模糊查询 --&gt; &lt;select id=\"findByName\" parameterType=\"string\" resultType=\"com.itheima.domain.User\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; 我们在上面将原来的#{}占位符，改成了${value}。注意如果用模糊查询的这种写法，那么${value}的写 法就是固定的，不能写成其它名字。 第二步：测试，如下： /** 12测试模糊查询操作 */ @Test public void testFindByName()&#123; //5.执行查询一个方法 List&lt;User&gt; users = userDao.findByName(\"王\"); for(User user : users)&#123; System.out.println(user); &#125; &#125; **#{}与${}的区别:** #{}表示一个占位符号 通过#{}可以实现 preparedStatement 向占位符中设置值，自动进行 java 类型和 jdbc 类型转换， #{}可以有效防止 sql 注入。 #{}可以接收简单类型值或 pojo 属性值。 如果 parameterType 传输单个简单类 型值，#{}括号中可以是 value 或其它名称。 ${}表示拼接 sql 串 通过${}可以将 parameterType 传入的内容拼接在 sql中且不进行 jdbc 类型转换， ${}可以接收简 单类型值或 pojo 属性值，如果 parameterType 传输单个简单类型值，${}括号中只能是 value。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"MyBatis是如何防止SQL注入的","slug":"MyBatis是如何防止SQL注入的","date":"2021-05-08T13:19:59.141Z","updated":"2020-04-29T02:44:37.934Z","comments":true,"path":"16852/","link":"","permalink":"http://tonymua.top/16852/","excerpt":"1.MyBatis概述​ MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Ordinary Java Object,普通的 Java对象)映射成数据库中的记录。 2.SQL 注入攻击概述","text":"1.MyBatis概述​ MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Ordinary Java Object,普通的 Java对象)映射成数据库中的记录。 2.SQL 注入攻击概述 ​ SQL注入攻击，简称SQL攻击或注入攻击，是发生于应用程序之数据库层的安全漏洞。简而言之，是在输入的字符串之中注入SQL指令，在设计不良的程序当中忽略了检查，那么这些注入进去的指令就会被数据库服务器误认为是正常的SQL指令而运行，因此遭到破坏或是入侵。 ​ 最常见的就是我们在应用程序中使用字符串联结方式组合 SQL 指令，有心之人就会写一些特殊的符号，恶意篡改原本的 SQL 语法的作用，达到注入攻击的目的。 举个例子: 比如验证用户登录需要 username 和 password，编写的 SQL 语句如下： 1select * from user where (name = '\"+ username +\"') and (pw = '\"+ password +\"'); username 和 password 字段被恶意填入 1username = \"1' OR '1'='1\"; 与 1password = \"1' OR '1'='1\"; 将导致原本的 SQL 字符串被填为： 1select * from user where (name = '1' or '1'='1') and (pw = '1' or '1'='1'); 实际上运行的 SQL 语句将变成： 1select * from user; 也就是不再需要 username 和 password 账密即达到登录的目的，结果不言而喻。 3.MyBatis 解决 SQL 注入问题#{}和${}的区别是什么？ (1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。 （2）mybatis在处理${}时，就是把${}替换成变量的值。 （3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。 （4）预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。 MyBatis框架作为一款半自动化的持久层框架，其SQL语句都要我们自己手动编写，这个时候当然需要防止SQL注入。其实，MyBatis的SQL是一个具有“输入+输出”的功能，类似于函数的结构，参考上面的两个例子。其中，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中使用#的即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的： 1select id, username, password, role from user where username=? and password=? 不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。 底层实现原理 ​ MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。 在使用MyBatis框架时，有以下场景极易产生SQL注入 SQL语句中的一些部分，例如order by字段、表名等，是无法使用预编译语句的。这种场景极易产生SQL注入。推荐开发在Java层面做映射，设置一个字段/表名数组，仅允许用户传入索引值。这样保证传入的字段或者表名都在白名单里面(手动过滤，添加白名单)。 like参数注入。使用如下SQL语句可防止SQL注入 1like concat('%',#&#123;title&#125;, '%')， in之后参数的SQL注入。使用如下SQL语句可防止SQL注入 1234id in&lt;foreach collection=\"ids\" item=\"item\" open=\"(\"separator=\",\" close=\")\"&gt;#&#123;item&#125; &lt;/foreach&gt;","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Maven","slug":"Maven","date":"2021-05-08T13:19:59.139Z","updated":"2020-04-29T02:44:38.123Z","comments":true,"path":"38008/","link":"","permalink":"http://tonymua.top/38008/","excerpt":"1.maven 构建 SSM 工程1.1 需求实现 SSM 工程构建，规范依赖管理。场景：根据 id 展示商品信息 1.2 知识点准备什么是依赖传递 ? ​ 除了 spring-webmvc 以外的其他 jar。因为我们的项目依赖 spring-webmv.jar，而spring-webmv.jar 会依赖spring-beans.jar 等等，所以 spring-beans.jar 这些 jar 包也出现在了我们的 maven 工程中，这种现象我们称为依赖传递 *依赖冲突的解决 * 1.2.1依赖调解原则maven 自动按照下边的原则调解：","text":"1.maven 构建 SSM 工程1.1 需求实现 SSM 工程构建，规范依赖管理。场景：根据 id 展示商品信息 1.2 知识点准备什么是依赖传递 ? ​ 除了 spring-webmvc 以外的其他 jar。因为我们的项目依赖 spring-webmv.jar，而spring-webmv.jar 会依赖spring-beans.jar 等等，所以 spring-beans.jar 这些 jar 包也出现在了我们的 maven 工程中，这种现象我们称为依赖传递 *依赖冲突的解决 * 1.2.1依赖调解原则maven 自动按照下边的原则调解： 1、第一声明者优先原则 在 pom 文件定义依赖，先声明的依赖为准。测试： 如果将上边 spring-webmvc 和 spring-context 顺序颠倒，系统将导入 spring-beans-5.0.2。分析： 由于 spring-webmvc 在前边以 spring-webmvc 依赖的 spring-beans-5.0.2 为准，所以最终spring-beans-5.0.2 添加到了工程中。 2、路径近者优先原则 例如：还是上述情况，spring-contex 和 spring-webmvc 都会传递过来 spirng-beans，那如果直接把 spring-beans 的依赖直接写到 pom 文件中，那么项目就不会再使用其他依赖传递来的 spring-beans，因为自己直接在 pom 中定义 spring-beans要比其他依赖传递过来的路径要近。 ​ 在本工程中的 pom 中加入 spirng-beans-5.0.2 的依赖，根据路径近者优先原则，系统将导入spirng-beans-5.0.2 1.2.2 排除依赖​ 上边的问题也可以通过排除依赖方法辅助依赖调解，如下： 比如在依赖 spring-webmvc 的设置中添加排除依赖，排除 spring-beans,下边的配置表示：依赖 spring-webmvc，但排除 spring-webmvc 所依赖的 spring-beans。 1.2.3 锁定版本 (推荐)​ 面对众多的依赖，有一种方法不用考虑依赖路径、声明优化等因素可以采用直接锁定版本的方法确定依赖构件的版本，版本锁定后则不考虑依赖的声明顺序或依赖的路径，以锁定的版本的为准添加到工程中，此方法在企业开发中常用。 还可以把版本号提取出来，使用标签设置成变量。 注意：在工程中锁定依赖的版本并不代表在工程中添加了依赖，如果工程需要添加锁定版本的依赖则需要单独添加标签 1.3 定义 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;maven_1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!--maven工程要导入jar包的坐标，就必须要考虑解决jar包冲突。 解决jar包冲突的方式一： 第一声明优先原则：哪个jar包的坐标在靠上的位置，这个jar包就是先声明的。 先声明的jar包坐标下的依赖包，可以优先进入项目中。 maven导入jar包中的一些概念： 直接依赖：项目中直接导入的jar包，就是该项目的直接依赖包。 传递依赖：项目中没有直接导入的jar包，可以通过项目直接依赖jar包传递到项目中去。 解决jar包冲突的方式二： 路径近者优先原则。直接依赖路径比传递依赖路径近，那么最终项目进入的jar包会是路径近的直接依赖包。 解决jar包冲突的方式三【推荐使用】： 直接排除法。 当我们要排除某个jar包下依赖包，在配置exclusions标签的时候，内部可以不写版本号。 因为此时依赖包使用的版本和默认和本jar包一样。--&gt; &lt;!-- 统一管理jar包版本 --&gt; &lt;properties&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;shiro.version&gt;1.2.3&lt;/shiro.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;spring.security.version&gt;5.0.1.RELEASE&lt;/spring.security.version&gt; &lt;/properties&gt; &lt;!--maven工程是可以分父子依赖关系的。 凡是依赖别的项目后，拿到的别的项目的依赖包，都属于传递依赖。 比如：当前A项目，被B项目依赖。那么我们A项目中所有jar包都会传递到B项目中。 B项目开发者，如果再在B项目中导入一套ssm框架的jar包，对于B项目是直接依赖。 那么直接依赖的jar包就会把我们A项目传递过去的jar包覆盖掉。 为了防止以上情况的出现。我们可以把A项目中主要jar包的坐标锁住，那么其他依赖该项目的项目中， 即便是有同名jar包直接依赖，也无法覆盖。 --&gt; &lt;!-- 锁定jar包版本 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 项目依赖jar包 --&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-taglibs&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 添加tomcat7插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 1.4 案例实现Items 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Items implements Serializable &#123; private Integer id; private String name; private Double price; private String pic; private Date createtime; private String detail; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getPrice() &#123; return price; &#125; public void setPrice(Double price) &#123; this.price = price; &#125; public String getPic() &#123; return pic; &#125; public void setPic(String pic) &#123; this.pic = pic; &#125; public Date getCreatetime() &#123; return createtime; &#125; public void setCreatetime(Date createtime) &#123; this.createtime = createtime; &#125; public String getDetail() &#123; return detail; &#125; public void setDetail(String detail) &#123; this.detail = detail; &#125;&#125; ItemsDao 12345@Repositorypublic interface ItemsDao &#123; @Select(\"select * from items where id=#&#123;id&#125;\") public Items findById(Integer id);&#125; ItemsService 123public interface ItemsService &#123; public Items findById(Integer id);&#125; ItemsServiceImpl 12345678910@Servicepublic class ItemsServiceImpl implements ItemsService &#123; @Autowired private ItemsDao itemsDao; @Override public Items findById(Integer id) &#123; return itemsDao.findById(id); &#125;&#125; ItemsController 12345678910111213@Controller@RequestMapping(\"/items\")public class ItemsController &#123; @Autowired private ItemsService itemsService; @RequestMapping(\"/findDetail\") public String findDetail(Model model)&#123; Items items = itemsService.findById(1); model.addAttribute(\"item\",items); return \"itemDetail\"; &#125;&#125; applicationContext.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--开启注解的扫描，希望处理service和dao，controller不需要Spring框架去处理--&gt; &lt;context:component-scan base-package=\"dao,service\" &gt; &lt;!--配置哪些注解不扫描--&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\" /&gt; &lt;/context:component-scan&gt; &lt;!--配置AccountDao接口所在包--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\" id=\"mapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"dao\"/&gt; &lt;/bean&gt; &lt;!--配置连接池--&gt; &lt;bean class=\"com.alibaba.druid.pool.DruidDataSource\" id=\"dataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///maven\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"547717253\"/&gt; &lt;/bean&gt; &lt;!--配置SqlSessionFactory工厂--&gt; &lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--aop面向切面编程，切面就是切入点和通知的组合--&gt; &lt;!--配置事务管理器--&gt; &lt;bean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务的通知--&gt; &lt;tx:advice id=\"advice\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置切面--&gt; &lt;aop:config&gt; &lt;aop:pointcut id=\"pointcut\" expression=\"execution(* service.impl.*.*(..))\"/&gt; &lt;aop:advisor advice-ref=\"advice\" pointcut-ref=\"pointcut\"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; springmvc.xml 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!--组件扫描--&gt; &lt;context:component-scan base-package=\"contrler\"/&gt; &lt;!--处理器映射器，处理器适配器--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"viewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--释放静态资源--&gt; &lt;mvc:default-servlet-handler/&gt;&lt;/beans&gt; web.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" version=\"3.0\"&gt; &lt;!--编码过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置spring核心监听器--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--重新指定spring配置文件的路径--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--springmvc的核心servlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; itemDetail.jsp 12345678910111213141516171819202122232425262728293031323334&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/fmt\" prefix=\"fmt\"%&gt; &lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form&gt; &lt;table width=\"100%\" border=1&gt; &lt;tr&gt; &lt;td&gt;商品名称&lt;/td&gt; &lt;td&gt; $&#123;item.name &#125; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;商品价格&lt;/td&gt; &lt;td&gt; $&#123;item.price &#125; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;生成日期&lt;/td&gt; &lt;td&gt; &lt;fmt:formatDate value=\"$&#123;item.createtime&#125;\" pattern=\"yyyy-MM-dd HH:mm:ss\"/&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;商品简介&lt;/td&gt; &lt;td&gt;$&#123;item.detail&#125; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 1.5 运行与调试12345678910&lt;!-- 添加tomcat7插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; *注意: *解决配置本地tomcat中文乱码问题:在VM options处添加-Dfile.enconding=UTF-8 2.分模块构建工程基于上边的三个工程分析继承：创建一个 parent 工程将所需的依赖都配置在 pom 中聚合：聚合多个模块运行 2.1 需求将 SSM 工程拆分为多个模块开发： maven_dao maven_service maven_web 理解继承和聚合 通常继承和聚合同时使用 何为继承？ ​ 继承是为了消除重复，如果将 dao、service、web 分开创建独立的工程则每个工程的 pom.xml文件中的内容存在重复，比如：设置编译版本、锁定 spring的版本的等，可以将这些重复的配置提取出来在父工程的 pom.xml 中定义。 何为聚合？ ​ 项目开发通常是分组分模块开发，每个模块开发完成要运行整个工程需要将每个模块聚合在一起运行，比如：dao、service、web 三个工程最终会打一个独立的war 运行。 2.2 案例实现2.2.1 创建父工程定义与原案例相同的pom.xml 2.2.2 创建 dao 子模块选中父工程右键-new-Module并命名为maven_dao 将原工程中的 domain实体类 dao接口拷贝到 src/main/java 中 maven_dao 模块的 pom.xml 文件中需要继承父模块 将applicationContext.xml拆分出一个applicationContext-dao.xml，此文件中只配置 dao 相关放到resources-spring文件夹中 2.2.3 创建service 子模块选中父工程右键-new-Module并命名为maven_service maven_service 模块的 pom.xml 文件中需要继承父模块，maven_service 依赖 maven_dao 模块 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;maven_parent&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;maven_service&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;maven_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 将原工程中的service接口拷贝到 src/main/java中 创建 applicationContext-service.xml，此文件中定义的service放到resources-spring文件夹中 依赖范围对传递依赖的影响 ​ 是因为依赖会有依赖范围，依赖范围对传递依赖也有影响，例如有 A、B、C，A 依赖 B、B依赖 C，C可能是 A的传递依赖 ​ 遇到依赖没有传递过来的问题我们通常的解决方案是在本工程中直接添加依赖： 把依赖添加到 maven_service的工程中 2.2.4 创建 web 子模块​ 选择骨架创建web 子模块 maven_web 模块的 pom.xml 文件中需要继承父模块，maven_web 依赖 maven_service 模块 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;maven_parent&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;maven_web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;maven_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 将原工程中的controller 代码拷贝到src/main/java 中 将原工程中的springmvc代码拷贝到sresources中,applicationContext.xml引入以上两个工程中的applicationContext.xml 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;import resource=\"classpath:spring/applicationContext-dao.xml\"/&gt; &lt;import resource=\"classpath:spring/applicationContext-service.xml\"/&gt;&lt;/beans&gt; 将原工程中的pages及web.xml拷贝到WEB-INF中 2.3 运行调试方法 1：在maven_web 工程的 pom.xml 中配置 tomcat 插件运行 ​ 运行 maven_web 工程它会从本地仓库下载依赖的 jar 包，所以当 maven_web 依赖的 jar 包内容修改了必须及时发布到本地仓库，比如：maven_web 依赖的 maven_service 修改了，需要及时将maven_service 发布到本地仓库。 方法 2：在父工程的 pom.xml 中配置 tomcat插件运行，自动聚合并执行 ​ 推荐方法2，如果子工程都在本地，采用方法2则不需要子工程修改就立即发布到本地仓库，父工程会自动聚合并使用最新代码执行。注意：如果子工程和父工程中都配置了tomcat 插件，运行的端口和路径以子工程为准。 3.maven 私服3.1 需求正式开发，不同的项目组开发不同的工程。maven_dao工程开发完毕，发布到私服。 maven_service 从私服下载 dao 3.2 分析​ 公司在自己的局域网内搭建自己的远程仓库服务器，称为私服，私服服务器即是公司内部的 maven 远程仓库，每个员工的电脑上安装 maven 软件并且连接私服服务器，员工将自己开发的项目打成 jar 并发布到私服服务器，其它项目组从私服服务器下载所依赖的构件（jar） 。​ 私服还充当一个代理服务器，当私服上没有 jar 包会从互联网中央仓库自动下载，如下图： 3.4 将项目发布到私服​ 企业中多个团队协作开发通常会将一些公用的组件、开发模块等发布到私服供其它团队或模块开发人员使用。​ 本例子假设多团队分别开发 maven_dao、maven_service、maven_web，某个团队开发完在maven_dao会将 maven_dao 发布到私服供 maven_service团队使用，本例子会将 maven_dao 工程打成jar 包发布到私服 *配置 * 第一步： ​ 需要在客户端即部署 maven_dao工程的电脑上配置 maven环境，并 修改 settings.xml 文件，配置连接私服的用户和密码 。​ 此用户名和密码用于私服校验，因为私服需要知道上传的账号和密码是否和私服中的账号和密码一致。 12345678910&lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; releases 连接发布版本项目仓库snapshots 连接测试版本项目仓库 第二步： 配置项目 pom.xml ​ 配置私服仓库的地址，本公司的自己的 jar 包会上传到私服的宿主仓库，根据工程的版本号决定上传到哪个宿主仓库，如果版本为 release 则上传到私服的 release 仓库，如果版本为snapshot 则上传到私服的 snapshot仓库 1234567&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; *测试 * 将项目 dao 工程打成 jar 包发布到私服： 1、首先启动 nexus 2、对 maven_dao工程执行 deploy 命令 ​ 根据本项目pom.xml中version定义决定发布到哪个仓库，如果version定义为snapshot，执行deploy后查看nexus的snapshot仓库，如果 version定义为release则项目将发布到nexus的 release仓库，本项目将发布到 snapshot仓库 3.5 从私服下载 jar包​ 没有配置 nexus 之前，如果本地仓库没有，去中央仓库下载，通常在企业中会在局域网内部署一台私服服务器，有了私服本地项目首先去本地仓库找 jar，如果没有找到则连接私服从私服下载 jar 包，如果私服没有 jar 包私服同时作为代理服务器从中央仓库下载 jar 包，这样做的好处是一方面由私服对公司项目的依赖 jar 包统一管理，一方面提高下载速度，项目连接私服下载 jar 包的速度要比项目连接中央仓库的速度快的多。 ​ 本例子测试从私服下载 maven_dao 工程 jar 包 *管理仓库组 * ​ nexus中包括很多仓库，hosted中存放的是企业自己发布的jar包及第三方公司的jar包，proxy 中存放的是中央仓库的 jar，为了方便从私服下载 jar 包可以将多个仓库组成一个仓库组，每个工程需要连接私服的仓库组下载 jar 包。 在 setting.xml 中配置仓库 ​ 在客户端的 setting.xml 中配置私服的仓库，由于 setting.xml 中没有 repositories 的配置标签需要使用 profile 定义仓库。 1234567891011121314151617181920212223242526272829&lt;profile&gt; &lt;!--profile 的 id--&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!--仓库 id，repositories 可以配置多个仓库，保证 id 不重复--&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!--仓库地址，即 nexus 仓库组的地址--&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;!--是否下载 releases 构件--&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;!--是否下载 snapshots 构件--&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!-- 插件仓库，maven 的运行依赖插件，也需要从私服下载插件 --&gt; &lt;pluginRepository&gt; &lt;!-- 插件仓库的 id 不允许重复，如果重复后边配置会覆盖前边 --&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; 使用 profile 定义仓库需要激活才可生效 123&lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 测试从私服下载 jar 包 测试 1：局域网环境或本地网络即可 在maven_service 工程中添加以上配置后，添加 maven_dao 工程的依赖，删除本地仓库中 maven_dao工程，同时在 IDEA 中关闭 maven_dao工程。 观察控制台： 项目先从本地仓库找 maven_dao，找不到从私服找，由于之前执行 deploy 将 maven_dao 部署到私服中，所以成功从私服下载 maven_dao 并在本地仓库保存一份。 测试 2：需要互联网环境 在项目的 pom.xml 添加一个依赖，此依赖在本地仓库和私服都不存在，maven 会先从本地仓库找，本地仓库没有再从私服找，私服没有再去中央仓库下载，jar 包下载成功在私服、本地仓库分别存储一份。 4.把第三方 jar 包放入本地仓库或私服4.1 导入本地库​ 随便找一个jar包测试，可以先CMD进入到jar包所在位置，运行 ​ mvn install:install-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37 -Dfile= fastjson-1.1.37.jar -Dpackaging=jar 4.2 导入私服​ 需要在 maven 软件的核心配置文件 settings.xml 中配置第三方仓库的 server 信息 12345&lt;server&gt; &lt;id&gt;thirdparty&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; ​ 才能执行一下命令 mvn deploy:deploy-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37-Dpackaging=jar -Dfile=fastjson-1.1.37.jar-Durl=http://localhost:8081/nexus/content/repositories/thirdparty/-DrepositoryId=thirdparty 4.3 参数说明DgroupId 和 DartifactId 构成了该 jar 包在 pom.xml 的坐标，项目就是依靠这两个属性定位。自己起名字也行。Dfile 表示需要上传的 jar 包的绝对路径。Durl 私服上仓库的位置，打开 nexus——&gt;repositories菜单，可以看到该路径。DrepositoryId 服务器的表示 id，在 nexus 的configuration 可以看到。Dversion 表示版本信息，关于 jar 包准确的版本： 包的名字上一般会带版本号，如果没有那可以解压该包，会发现一个叫 MANIFEST.MF 的文件，这个文件就有描述该包的版本信息。 比如 Specification-Version: 2.2 可以知道该包的版本了。 上传成功后，在 nexus 界面点击3rd party 仓库可以看到这包。","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"JVM&垃圾回收","slug":"JVM&垃圾回收","date":"2021-05-08T13:19:59.138Z","updated":"2021-04-07T14:48:19.865Z","comments":true,"path":"jvmAndgc/","link":"","permalink":"http://tonymua.top/jvmAndgc/","excerpt":"1.JRE、JDK JRE：Java的运行时环境，JVM的标准加上实现的一大堆基础类库。 JDK：包含JRE，还提供了一些小工具，如Javac、Java、Jar。 2.JVM","text":"1.JRE、JDK JRE：Java的运行时环境，JVM的标准加上实现的一大堆基础类库。 JDK：包含JRE，还提供了一些小工具，如Javac、Java、Jar。 2.JVM 3.类的加载过程 加载将外部的.class文件加载到方法区。 验证不能将任何的.class文件都加载，不符合规范的将抛出java.lang.VerifyError错误。(如低版本的JVM无法加载一些高版本的类库) 准备为一些类变量分配内存，并将其初始化为默认值。此时，实例对象还没有分配内存，所以这些动作是在方法区上进行的。 123456789101112131415161718code-snippet 1： public class A &#123; //类变量 static int a ; public static void main(String[] args) &#123; System.out.println(a); &#125; &#125;a:0code-snippet 2： public class A &#123; public static void main(String[] args) &#123; //局部变量 int a ; System.out.println(a); &#125; &#125;编译错误 类变量有两次赋初始值的过程：1.准备阶段，赋予初始值(也可以是指定值) 2.初始化阶段，赋予程序员指定的值 局部变量不存在准备阶段，如果没有赋予初始值就不能使用 解析将符号引用替换成直接引用符号引用：一种定义，可以是任何字面上的含义直接引用：直接指向目标的指针、相对变量，直接引用的对象都存在于内存中 类或接口的解析 类方法的解析 接口方法的解析 字段解析 初始化初始化成员变量 123456789101112public class A &#123; static int a = 0 ; static &#123; a = 1; b = 1; &#125; static int b = 0; public static void main(String[] args) &#123; System.out.println(a); //a:1 System.out.println(b); //b:0 &#125; &#125; static语句块只能访问到定义在static语句块之前的变量 JVM会保证在子类的初始化方法执行之前，父类的初始化方法已经执行完毕 类初始化顺序 父类静态变量、静态代码块(只有第一次加载类时执行) 子类静态变量、静态代码块(只有第一次加载类时执行) 父类非静态代码块 父类构造器 子类非静态代码块 子类构造器 4.clinit和init123456789101112131415161718192021222324252627public class A &#123; static &#123; System.out.println(\"1\"); &#125; public A()&#123; System.out.println(\"2\"); &#125; &#125; public class B extends A &#123; static&#123; System.out.println(\"a\"); &#125; public B()&#123; System.out.println(\"b\"); &#125; public static void main(String[] args)&#123; A ab = new B(); ab = new B(); &#125; &#125;// 1// a// 2// b// 2// b static字段和static代码块属于类，在类的初始化阶段就被执行，类的信息存放在方法区，同一个类加载器只有一份，所以上面的static只会执行一次，对应clinit方法。 对象初始化，在new一个新对象时，会调用构造方法来初始化对象的属性，对应init，每次新建对象都会执行。 5.双亲委派机制除了顶层的启动类加载器以外，其余的类加载器，在加载之前，都会委派给其父加载器进行加载。这样一层层向上传递，直到祖先们都无法胜任，它才会真正的加载。 6.引用级别 强引用当内存空间不足时，JVM抛出OutOfMemoryError。即使程序异常终止，这种对象也不会被回收，是最普通最强硬的一种存在，只有在和GC Roots断绝关系时才会被消灭掉。 软引用用于维护一些可有可无的对象。在内存足够时，软引用对象不会被回收，内存不足时，系统会回收软引用对象。如果回收了软引用对象仍然没有足够的内存，才会抛出内存溢出异常。软引用可以和引用队列联合使用，如果软引用的对象被垃圾回收，JVM就会把这个软引用加入到与之关联的引用队列中。 弱引用垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象，它拥有更短的生命周期。 虚引用如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。虚引用必须和引用队列联合使用，当垃圾回收准备回收一个对象时，如果发现它还有虚引用，就会在回收对象之前，把这个虚引用加入到与之关联的引用队列中。 7.典型OOM场景除了程序计数器，其它区域都有可能会发生OOM，但最常见的还是发生在堆上。 内存容量太小了，需要扩容，或者需要调整堆的空间 错误的引用的方式，发生了内存泄漏。如线程池里的线程，在复用的情况下忘记清理ThreadLocal的内容。 接口没有进行范围校验，外部传参超出范围。比如数据库查询时的每页条数等。 对堆外内存无限制的使用。这种情况更加严重，会造成操作系统内存耗尽。 8.垃圾回收算法 标记清除 标记：从根集合扫描，对存活的对象进行标记 清除：从堆内粗从头到尾进行线性遍历，回收不可达对象内存 标记整理 标记：从根集合扫描，对存活的对象进行标记 整理：移动所有存活的对象，按照内存地址排序，内存地址以后的内存全部回收。 复制算法分对象面和空闲面，对象在对象面创建，回收时，存活的对象被从对象面复制到空闲面，后将对象面所有对象清除。 分代收集把死的快的对象所占区域，叫作年轻代。其他活的长的对象所占的区域，叫作老年代。 年轻代：使用复制算法年轻代分为：一个伊甸园空间(Eden)，两个幸存者空间(Survivor)当年轻代中的Eden区分配满的时候，就会触发年轻代的GC(Minoe GC)。 在Eden区执行了第一次GC之后，存活的对象会移动到其中一个Survivor区(from) Eden再次GC，这时会采用复制算法，将Eden和from区一起清理。存活的对象会被复制到to区，接下来清空from区就可以了。 Eden：from：to = 8：1：1 -XX:SurvivorRatio 默认为8 TLAB：JVM默认给每个线程开辟一个buffer区域来加速对象分配，这个buffer就放在Eden区。对象的分配优先在TLAB上分配，但通常TLAB很小，所以对象比较大时，会在Eden的共享区域进行分配。 老年代：使用标记清除、标记整理算法 9.对象如何进入老年代 提升每当发生一次Minor GC，存活下的对象年龄会加1，达到阈值(-XX:+MaxTenuringThreshold，最大值为15)，就会提升到老年代。 分配担保每次存活的对象，都会放入其中一个幸存区，默认比例为10%。但无法保证每次存活的对象小于10%，当Survivor空间不够，就需要依赖其他内存(老年代)进行分配担保。 大对象直接在老年代分配超过某个大小的对象将直接在老年代分配，-XX:PretenureSizeThreshold进行配置，默认为0。 动态对象年龄判定有的垃圾回收算法，并不需要年龄达到15，会使用一些动态的计算方法，如幸存区中相同年龄对象大小的和大于幸存区的一半，大于或等于age的对象将直接进入老年代 10.垃圾回收器 年轻代垃圾收集器 Serial垃圾收集器处理GC的只有一条线程，并且在垃圾回收过程中暂停一切用户线程。 ParNew垃圾收集器Serial的多线程版本，多条GC线程并行的进行垃圾清理，清理过程中依然要停止用户线程。 Parallel Scavenge垃圾收集器另一个多线程版本的垃圾回收器。与ParNew的主要区别： Parallel Scacenge：追求CPU吞吐量，适合没有交互的后台计算。弱交互强计算。 ParNew：追求降低用户停顿时间，适合交互式应用。强交互弱计算。 老年代垃圾收集器 Serial Old垃圾收集器与年轻代的Serial垃圾收集器对应，都是单线程版本，同样适用客户端使用。年轻代的Serial，使用复制算法，老年代的Serial Old，使用标记-整理算法。 Parallel OldParallel Scavenge的老年代版本，追求CPU吞吐量。 CMS垃圾收集器垃圾收集时用户线程和GC线程可以并发执行。 11.CMS回收过程Minor GC：发生在年轻代的GC Major GC：发生在老年代的GC Full GC：全堆垃圾回收，如Metaspace区引起年轻代和老年代的回收 CMS(主要并发标记清除收集器)，年轻代使用复制算法，老年代使用标记-清除算法 初始标记初始标记阶段，只标记直接关联GC root的对象，不用向下追溯。最耗时的就是tracing阶段，极大地缩短了初始标记阶段，所以该过程时间较短，这个过程是STW的。 并发标记在初始标记的基础上，进行并发标记。tracing，标记所有可达的对象。这个阶段会比较久，但却可以和用户线程并行。 有些对象，从新生代晋升到了老年代 有些对象，直接分配到了老年代 老年代或者新生代的对象引用发生了变化 并发预清理不需要STW，目的是缩短重新标记的时间。这个时候，老年代中被标记为dirty的卡页中的对象，就会被重新标记，然后清除掉dirty的状态。由于这个阶段也是可以并发的，有可能还会有处于dirty状态的卡页。 并发可取消的预清理重新标记阶段是STW的，所以会有很多次预清理动作。可以在满足某些条件时，可以终止，如迭代次数、有用工作量、消耗的系统时间等。 意图：避免回扫年轻代的大量对象；当满足重新标记时，自动退出。 重新标记CMS尝试在年轻代尽可能空的情况下运行重新标记，以免接连多次发生STW。这是CMS垃圾回收阶段的第二次STW阶段，目标是完成老年代中所有存活对象的标记。 并发清理用户线程被重新激活，目标时删掉不可达对象。 由于CMS并发清理阶段用户线程还在运行中，CMS无法在当次GC中处理它们，只好留在下一处GC时再清理掉，这一部分垃圾称为”浮动垃圾”。 并发重置与用户线程并发执行，重置CMS算法相关的内部数据，为下一次GC循环做准备。 12.内存碎片 CMS执行过程中，用户线程还在运行，如果老年代空间快满了，才开始回收，用户线程可能会产生”Concurrent Mode Failure”的错误，这时会临时启用Serial Old收集器来重新进行老年代垃圾收集，这样STW会很久。 CMS对老年代回收的时候，并没有内存的整理阶段。程序长时间运行后，碎片太多，如果你申请一个稍大的对象，就会引起分配失败。(1) UseCMSCompactAtFullCollection(默认开启)，在进行Full GC时，进行碎片整理。内存碎片整理是无法并发的，STW时间较长。(2)CMSFullGCsBeforeCompation(默认为0)，每隔多少次不压缩的Full GC后，执行一次带压缩的Full GC。 13.CMS优势： 低延迟，尤其对大堆来说。大部分垃圾回收过程并发执行。 劣势： 内存碎片问题。Full GC的整理阶段，会造成较长时间的停顿。 需要预留空间，用来收集”浮动垃圾”。 使用更多的CPU资源。 14.G1 G1也是有Eden区和Survivor区的概念的，但内存上不是连续的。小区域(Region)的大小是固定的，名字叫做小队区，小队区可以是Eden，也可以是Survivor，还可以是Old。Region大小（-XX:G1HeapRegionSize=M)一致，为1M-32M字节间的一个2的幂指数。如果对象太大，大小超过Region 50%的对象，将会分配在Humongous Region。垃圾最多的小堆区，会被优先收集。-XX:MaxGCPauseMills=10 15.卡表与RSet 卡表老年代被分成众多的卡页(一般是2的次幂)，卡表就是用于标记卡页状态的一个集合，每个卡表对应一个卡页。如果年轻代有对象分配，而且老年代有对象指向这个新对象，那么这个老年代对象所对应内存的卡页，就会标识为dirty，卡表只需要很小的存储空间就可以保留这些状态。垃圾回收时，就可以先读卡表，进行快速判断。 RSetRSet是一个空间换时间的数据结构。卡表是一种points-out(我引用了谁对象)的结构，而RSet是一种points-into(谁引用了我的对象)的结构。RSet类似一个Hash，key是引用的Region地址，value是引用它的对象的卡页集合 16.G1回收过程 年轻代回收JVM启动时，G1会先准备好Eden区，程序在运行时不断创建到Eden区，当所有的Eden区满了，启动一次年轻代垃圾回收过程。年轻代是一个STW过程，它的跨代引用使用RSet来追溯，会一次回收掉年轻代的所有Region。 并发标记当整个堆内存使用达到一定比例(-XX:InitatingHeapOccupancyPercent 默认45%)，启动并发标记阶段。为混合回收提供标记服务，类似CMS的垃圾回收过程。 混合回收通过并发标记阶段，已经统计了老年代的垃圾占比，在Minor GC之后，如果占比达到阈值(-XX:G1HeapWastePercent 默认是堆大小的5%，该参数可以调整Mixed GC的频率)，下次就会触发混合回收。参数G1MixedGCCountTarget：一次并发标记之后，最多执行Mixed GC的次数。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://tonymua.top/tags/垃圾回收/"},{"name":"GC","slug":"GC","permalink":"http://tonymua.top/tags/GC/"}]},{"title":"Java面试总结","slug":"Java面试总结","date":"2021-05-08T13:19:59.137Z","updated":"2020-04-29T02:44:38.133Z","comments":true,"path":"20365/","link":"","permalink":"http://tonymua.top/20365/","excerpt":"1.网络基础1.1 OSI七层模型: 物理层, 数据链路层, 网络层, 传输层, 会话层, 表示层, 应用层 ​ 【1】物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特。 【2】数据链路层：定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问，这一层通常还提供错误检测和纠正，以确保数据的可靠传输。","text":"1.网络基础1.1 OSI七层模型: 物理层, 数据链路层, 网络层, 传输层, 会话层, 表示层, 应用层 ​ 【1】物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特。 【2】数据链路层：定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问，这一层通常还提供错误检测和纠正，以确保数据的可靠传输。 【3】网络层：在位于不同地理位置的网络中的两个主机系统之间提供连接和路径选择，Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层。 【4】传输层：定义了一些传输数据的协议和端口号（WWW端口80等），如：TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的）， 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组，常常把这一层数据叫做段。 【5】会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路，主要在你的系统之间发起会话或者接受会话请求（设备之间需要互相认识可以是IP也可以是MAC或者是主机名）。 【6】表示层：可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。例如，PC程序与另一台计算机进行通信，其中一台计算机使用扩展二一十进制交换码（EBCDIC），而另一台则使用美国信息交换标准码（ASCII）来表示相同的字符。如有必要，表示层会通过使用一种通格式来实现多种数据格式之间的转换。 ​ 【7】应用层： 是最靠近用户的OSI层，这一层为用户的应用程序（例如电子邮件、文件传输和终端仿真）提供网络服务。 1.2 TCP三次握手 第一次握手：客户端发送SYN包（seq=x），进入SYN_SENT（同步发送）状态第二次握手：服务器收到SYN包，确认SYN并发送ACK包（ack=x+1），同时发送一个SYN包（seq=y），即SYN+ACK包，进入SYN_RECV（同步接收）状态第三次握手：客户端收到SYN+ACK包，发送确认包ACK(ack=y+1），发送完毕后，客户端和服务器进入ESTABLISHED（连接成功）状态 需要三次握手的原因:为了防止失效的连接请求报文突然又传送到服务器产生错误。 1.3 TCP四次挥手 第一次挥手：客户端发送一个FIN包（seq=x），进入FIN_WAIT（结束等待）状态第二次挥手：服务器收到FIN包，发回一个ACK包(ack=x+1)，进入CLOSE_WAIT（关闭等待）状态第三次挥手：服务器关闭客户端的连接，并发送一个FIN包(seq=y)，进入LAST_ACK（最后确认）状态第四次挥手：客户端发回ACK(ack=y+1)包确认，发送完毕后，连接断开 需要四次挥手的原因:确保数据能够完全传输。 1.4 TCP 和 UDP的区别 (1) TCP是一种面向连接的可靠传输协议，UDP是面向无连接的不可靠传输协议(2) TCP支持报文传输，还支持字节流的传输。而UDP协议只支持传输报文 TCP:20个字节 UDP:8个字节(3) TCP数据报格式比较复杂，传输过程数据不容易丢失和出错，而UDP数据报格式较为简单，容易丢失(4) TCP传输在接收端会进行重排，所以是有序的，UDP则不保证有序(5) TCP速度慢，UDP速度快(6) TCP有流量控制和拥塞控制，而UDP没有 1.5 Get与Post的区别 (1) GET请求一般用于获取服务器上的资源，是幂等的。POST请求一般用于对服务器上资源进行更新，非幂等的（幂等即每次请求返回结果一样）(2) GET请求没有请求体，请求参数跟是在URL后面的，所以使用GET请求时请求参数用户是可以直接看到的。POST请求有请求体，请求参数放在请求体，对用户是不可见的。相对来说POST请求比GET请求更安全(3) GET请求的参数长度有限制，最多只能有1024个字节, 这是因为URL长度有限导致的。POST请求的参数长度可以认为是无限制的 1.6 forward 和 redirect的区别 (1) forward为转发，进行forward操作后，请求URL不发生变化，并且会把请求的数据携带到下一个请求中。redirect是重定向，进行redirect操作后，请求URL是发生变化的(2) forward是服务器内部请求转发，不可以请求到其它站点，redirect是服务器通知客户端重新请求，可以请求到其它站点(3) forward速度快，redirect速度慢 1.7 cookie 和 session的区别 (1) cookie由于把信息保存在客户端中。session把信息保存在服务器中(2) cookie性能更高一点，速度较快，用户的信息存在各自的浏览器中，可以分担服务器的一部分存储工作。session速度较慢，所有用户的信息都存在服务器中，在高并发时必然影响服务器性能(3) cookie有限制大小，在4K以内。session没有限制(4) cookie对用户是透明的，安全性低，不重要的或者可以公开的信息保存在cookie。session对用户是不可见的，安全性高，重要信息应该保存在session 1.8 Http与Https的区别 (1) https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 (2) http是超文本传输协议，信息是明文传输，https则是具有安全性的SSL加密传输协议。 (3) http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 (4) http的连接很简单，是无状态的。Https协议是由SSL+Http协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。(无状态的意思是其数据包的发送、传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。) 1.9 在浏览器地址键入URL, 按下回车之后经历的流程 (1) DNS解析(查询缓存) (2) TCP连接(三次握手) (3) 发送Http请求 (4) 服务器处理请求并返回Http报文 (5) 浏览器解析渲染页面 (6) 连接结束(四次挥手) 1.10 Http请求常见状态码 (1) 200 OK，请求成功(2) 404 Not Found，对应的URL上不存在资源(3) 405 Method Not Allowed，请求不被允许，即请求方式错误(4) 500 Internal Server Error，服务器内部错误，发现严重BUG，要及时修复 2.数据库2.1 索引的作用？和它的优点缺点是什么？ ​ 索引就一种特殊的查询表，数据库的搜索可以利用它加速对数据的检索。它很类似与现实生活中书的目录，不需要查询整本书内容就可以找到想要的数据。索引可以是唯一的，创建索引允许指定单个列或者是多个列。缺点是它减慢了数据录入的速度，同时也增加了数据库的尺寸大小。 2.2 什么样的字段适合建索引? (1) 经常被查询的字段 (2) 不为空且字段值不重复 (3) 字段的值不经常被修改 2.3 Hash索引与B+树索引 时间复杂度分别为O(1)和O(logN) (1) 这和业务场景有关。只选一个数据，hash更快（o(1)）。数据库中经常会选择N条如果使用hash索引那就是o(n)，这时候由于B+树索引有序(o(logn))，且叶子节点上有链表相连，它的查询效率比hash就快很多了 (2) 索引存储在硬盘上，一般来说索引本身很大，不能一次性全部存在内存中，B+树的设计可以允许数据分批加载，同时树的高度较低，查找效率高 (3) 大家都知道硬盘的I/O速度相比内存来说非常慢，而索引是用于加快查询速度的，需要减少I/O操作 2.4 密集索引与稀疏索引的区别 (1) 密集索引文件中的每个搜索码值都对应一个索引值 (2) 稀疏索引文件只为索引码的某些值建立索引项 MyISAM:不管是主键索引，唯一键索引还是普通索引都是稀疏索引 InnoDB:若一个主键被定义, 该主键则作为密集索引; 若没有主键被定义, 该表的第一个唯一非空索引则作为密集索引; 若不满足以上条件, InnoDB内部会生成一个隐藏主键(密集索引); 若主键索引存储相关键位和其对应的主键值, 包含两次查找 2.5 数据库优化方法 (1) 选取最适用的字段属性 (2) 使用连接(JOIN)的方式来代替子查询 (3) 使用联合(UNION)来代替手动创建的临时表 (4) 事务 2.6 数据库ACID的特性 原子性:指事务是一个不可分割的工作单位, 事务的操作要么都发生, 要么都不发生 一致性:指事务前后数据的完整性必须保持一致 隔离性:指多个用户并发访问数据库时, 一个用户的事务不能被其他用户的事务所干扰, 多个并发事务之间数据要相互隔离 持久性:指一个事务一旦提交, 它对数据库中数据的改变就是永久性的, 即便数据库发生故障也不应该对其有任何影响 2.7 悲观锁与乐观锁 悲观锁:当我们要对一个数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制，在修改数据之前先锁定，再修改的方式被称之为悲观并发控制。 乐观锁:乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息，让用户决定如何去做。 2.8 数据库的三范式 第一范式:强调的是列的原子性, 即列不能够再分成其他几列 第二范式:首先是1NF, 另外包含两部分内容, 一是表必须有一个主键; 二是没有包含在主键中的列必须完全依赖于主键, 而不能只依赖于主键的一部分 在1NF基础上, 任何非主属性不依赖与其它非主属性(在2NF基础上消除传递依赖) 第三范式:第三范式是第二范式的一个子集, 即满足第三范式必须满足第二范式 首先是2NF, 另外非主键必须直接依赖于主键, 直接依赖于主键, 不能存在传递依赖. 即不能存在: 非主键列A依赖于非主键列B, 非主键列B依赖于主键的情况 2.9 什么是内联接、左外联接、右外联接？ (1) 内联接（Inner Join）：匹配2张表中相关联的记录。(2) 左外联接（Left Outer Join）：除了匹配2张表中相关联的记录外，还会匹配左表中剩余的记录，右表中未匹配到的字段用NULL表示。(3) 右外联接（Right Outer Join）：除了匹配2张表中相关联的记录外，还会匹配右表中剩余的记录，左表中未匹配到的字段用NULL表示。 2.10 数据库隔离级别 脏读（Read out of invalid data)：指事务A读到了事务B还没有提交的数据，但事务B又进行了回滚，产生了脏数据，事务A读取到的数据就是脏数据，依据脏数据所做的操作可能是不正确的。 不可重复读（Unrepeatable Read)：指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据，即原始读取不可重复。这是由于在查询间隔，被另一个事务修改并提交了。与脏读的区别在于，脏读读取到另一个事务未提交的数据，而不可重复读是读取了前一事务提交的数据。 幻读（Phantom Read)：指在一个事务的两次查询中数据笔数不一致，例如有一个事务A查询了几列(Row)数据，而另一个事务B却在此时插入了新的几列数据，先前的事务A在接下来的查询中，就会发现有几列数据是它先前所没有的，就好像发生幻觉一样。 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（读未提交） 可能 可能 可能 Read committed（读提交） 不可能 可能 可能 Repeatable read（可重复读） 不可能 不可能 可能 Serializable（序列化 ） 不可能 不可能 不可能 2.11 MyISAM 和 InnoDB的区别是什么? (1) MyIASM是非事务安全的，而InnoDB是事务安全的 (2) MyIASM锁的粒度是表级的，而InnoDB支持行级锁也支持表级锁 (3) MyIASM支持全文类型索引，而InnoDB不支持全文索引 (4) MyIASM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyIASM (5) MyIASM表保存成文件形式，跨平台使用更加方便 MyISAM适用场景:频繁执行全表count语句; 对数据进行增删改的频率不高, 查询非常频繁; 没有事务 InnoDB适用场景:数据库增删改查都相当频繁; 可靠性要求比较高，要求支持事务 2.12 InnoDB可重复读隔离级别下如何避免幻读 表象：快照读（非阻塞读）—伪MVCC 内在：next-key锁（行锁+gap锁） 对主键索引或者唯一索引会用Gap锁吗 如果where条件全部命中，则不会用Gap锁，只会加记录锁 如果where条件部分命中或者全不命中，则会加Gap锁 2.13 关键语法 (1) group by:满足”select子句中的列名必须为分组列或列函数”; 列函数对于group by 子句定义的每个组各返回一个结果 12345678910select student_id,count(course_id),sum(score),course_id from score group by student_idselect s.student_id,stu.name,count(s.course_id),sum(s.score)from score s, student stuwhere s.student_id=stu.student_idgroup by s.student_id (2) having:通常与group by子句一起使用; where过滤行, having过滤组; 出现在同一sql的顺序: where&gt;group by&gt;having 123456789101112select student_id,avg(score) from scoregroup by student_idhaving avg(score)&gt;60select stu.student_id,stu.namefrom student stu, score s where stu.student_id=s.student_idgroup by s.student_idhaving count(*)&lt;(select count(*) from course) 3.Redis3.1 Memcache与Redis的区别 Memcache:代码层次类似hash, 支持简单数据类型, 不支持数据持久化存储, 不支持主从, 不支持分片 Redis:数据类型丰富, 支持数据磁盘持久化存储, 支持主从, 支持分片 3.2 为什么Redis能这么快 (1) 完全基于内存, 绝大部分请求是纯粹的内存操作, 执行效率高 (2) 数据结构简单, 对数据操作也简单 (3) 采用单线程, 避免了频繁的上下文切换. 单线程也能处理高并发请求, 想多核也可以启动多实例 (4) 采用了非阻塞I/O多路复用机制 3.3 Redis的数据类型 String:最基本的数据类型, 二进制安全 Hash:String元素组成的字典, 适用于存储对象 List:列表, 按照String元素插入顺序排序 Set:String元素组成的无序集合, 通过哈希表实现, 不允许重复 ZSet(Sorted Set):通过分数来为集合中的成员进行从小到大的排序 3.4 从海量数据里查询某一固定前缀的key 注意:摸清数据规模, 即问清楚数据边界 KEYS pattern：查找所有符合给定模式pattern的key 缺点： KEYS指令一次性返回所有匹配的key； 键的数量过大会使得服务卡顿； SCAN cursor [MATCH pattern] [COUNT count] 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程； 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历； 不保证每次执行都返回某个给定数量的元素，支持模糊查询； 对于增量式迭代命令，一次返回的数量不可控，只能是大概率符合count参数； 3.5 何通过Redis实现分布式锁 set key value[EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置键的过期时间为second（秒） PX milliseconds：设置键的过期时间为millisecond（毫秒） NX：只在键不存在的时候，才对键进行设置操作，效果等同于setnx XX：只在键已存在的时候，才对键进行设置操作 SET操作成功完成时，返回OK，否则则返回nil 代码实现例如： 1234567RedisService redisService = SpringUtils.getBean(RedisService.class);String result = redisService.set(lockKey,requestId,SET_IF_NOT_EXIST, SET_WITH_WITH_EXPIRE_TIME,expireTime);if(\"OK\".equals(result))&#123; //执行独占资源逻辑 doOcuppiedWork();&#125; 3.6 如何应对缓存穿透和缓存雪崩问题 缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。 (1) 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 (2) 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 (3) 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。 缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。 (1) 给缓存的失效时间，加上一个随机值，避免集体失效。 (2) 使用互斥锁，但是该方案吞吐量明显下降了。 (3) 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。 3.7 Redis和数据库双写一致性问题 ​ 一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 3.8 如何使用Redis做异步队列 (1) 使用List作为队列，RPUSH生产消息，LPOP消费消息。 缺点：没有等待队列中有值就直接消费； 弥补：可以在应用层引入Sleep机制去调用LPOP重试 (2) BLPOP key [key …] timeout：阻塞直到队列有消息就能够返回或超时 缺点：只能供一个消费者消费 (3) pub/sub：主题发布-订阅模式 ​ 发送者（publish）发送消息，订阅者（subscribe）接收消息；订阅者可以订阅任意数量的频道（Topic）； 缺点：消息的发布是无状态的，无法保证可达性，即发送完该消息无法保证该消息被接收到。若想解决该问题需要使用专业的消息队列，例如Kafka等。 3.9 Redis如何做持久化 (1) RDB(快照)持久化:保存某个时间点的全量数据快照 (2) AOF(Append-Only-File)持久化：保持写状态 RDB和AOF的优缺点： 类别 优点 缺点 RDB 全量数据快照，文件小，恢复快 无法保存最近一次快照之后的数据，会丢失这部分的数据 AOF 可读性高，适合保存增量数据，数据不易丢失 文件体积大，恢复时间长 (3) RDB-AOF混合持久化方式 ​ 在Redis 4.0之后推出了混合持久化方式，而且作为默认的配置方式。先以RDB方式从管道写全量数据再使用AOF方式从管道追加。AOF文件先半段是RDB形式的全量数据，后半段是Redis命令形式的增量数据。 ​ BGSAVE做镜像全量持久化，AOF做增量持久化。因为BGSAVE需要耗费大量的时间，不够实时，在停机的时候会造成大量数据丢失，这时需要AOF配合使用。在Redis实例重启的时候，会使用BGSAVE持久化文件重新构建内容，再使用AOF重放近期的操作指令，来实现完整恢复重启之前的状态。 3.10 使用Pineline的好处 (1) Pineline和Linux的管道类似； (2) Redis基于请求/响应模型，单个请求处理需要一一应答； (3) Pineline批量执行指令，节省了多次I/O往返的时间； (4) 有顺序依赖的指令建议分批发送； 3.11Redis的同步机制 Redis使用主从同步 (1) 第一阶段:与master建立连接 (2) 第二阶段:向master发送同步请求(SYNC) (3) 第三阶段:接受master发来的RDB数据 (4) 第四阶段:载入RDB文件 4.Java底层知识: JVM4.1 Java平台无关性如何实现? ​ Java源码首先被编译成字节码, 再由不同平台进行解析, Java语言在不同的平台上运行时不需要进行重新编译, Java虚拟机在执行字节码的时候, 把字节码转换成具体平台上的机器指令 4.2 JVM整体组成 类加载器(ClassLoader):依据特定格式, 加载class文件到内存 执行引擎(Execution Engine):对命令进行解析 本地库接口(Native Interface):融合不同开发语言的原生库为Java所用 运行时数据区(Runtime Data Area):JVM内存空间结构模型 4.3 类从编译到执行的过程 (1) 编译器将Hello.java源文件编译成Hello.class字节码文件 (2) ClassLoder将字节码文件转为JVM中的Class对象 (3) JVM利用Class对象实例化为Hello对象 4.4 反射的实现与作用 ​ Java语言编译之后会生成一个.class文件, 反射就是通过字节码文件找到某一个类, 类中的方法以及属性等. 反射的实现主要借助以下四个类: Class: 类的对象, Constructor:类的构造方法, Field:类中的属性对象, Method:类中的方法对象 作用:反射机制指的是程序在运行时能获取自身的信息. 在Java中, 只要给定类的名字, 那么就可以通过反射机制来获取类的所有信息 4.5 类的装载过程 (1) 加载:通过ClassLoader加载class文件字节码, 生成Class对象 (2) 链接: 校验:检查加载的class的正确性和安全性 ​ 准备:为类变量分配存储空间并设置类变量初始值 ​ 解析:JVM将常量池内的符号引用转换为直接引用 (3) 初始化:执行类变量赋值和静态代码块 4.6 loadClass() 和 forName() 的区别 类的装载方式有两种:(1) 隐式装载: 程序在运行过程中当碰到通过new等方式生成对象时, 隐式调用类装载器加载对应的类到JVM中; (2) 显式装载: 通过class.forname()等方法, 显示加载需要的类 使用 loadClass() 方法获得的 Class 对象只完成了类加载过程中的第一步：加载，后续的操作均未进行。 使用 Class.forName() 方法获得 Class 对象是已经执行完初始化的了 4.7 JVM运行时数据区组成(Java内存模型) 程序计数器(Program Counter Register):当前线程所执行的行号指示器。是 JVM 内存区域最小的一块区域。执行字节码工作时就是利用程序计数器来选取下一条需要执行的字节码指令。 虚拟机栈(JVM Stacks):Java 方法执行的内存模型：存储局部变量表，操作数栈，动态链接，方法出口等信息。生命周期与线程相同。 本地方法栈(Native Method Stack):作用与虚拟机栈类似，不同点本地方法栈为 native 方法执行服务，虚拟机栈为虚拟机执行的 Java 方法服务。 堆(Heap):存放对象实例，所有的对象和数组都要在堆上分配。 是 JVM 所管理的内存中最大的一块区域。 方法区(Methed Area):用于存储虚拟机加载的类信息，常量，静态变量等数据。 线程私有的:程序计数器, 虚拟机栈, 本地方法栈 线程共享的:方法区, 堆, 直接内存 4.8 元空间(MetaSpace) 相比永久代(PermGen)的优势 JDK8后去除了永久代 区别:元空间使用本地内存, 而永久代使用的是JVM的内存 字符串常量池存放在永久代中, 容易出现性能问题和内存溢出 类和方法的信息大小难以确定, 给永久代的大小指定带来困难 永久代会为GC带来不必要的复杂性 方便HotSpot与其它JVM如Jrockit的集成 4.9 JVM三大性能调优参数-Xms -Xmx -Xss的含义 -Xss:规定了每个线程虚拟机栈(堆栈)的大小 -Xms:堆的初始值 -Xmx:堆能达到的最大值 4.10 Java内存模型中堆和栈的区别 静态存储:编译时确定每个数据目标在运行时的存储空间需求 栈式存储:数据区需求在编译时未知, 运行时模块入口前确定 堆式存储:编译时或运行时模块入口都无法确定, 动态分配 联系:引用对象, 数组时, 栈定义变量保存堆中目标的首地址 区别:(1) 管理方式: 栈自动释放, 堆需要GC ​ (2) 空间大小: 栈比堆小 ​ (3) 碎片相关: 栈产生的碎片远小于堆 ​ (4) 分配方式: 栈支持静态和动态分配, 而堆仅支持动态分配 ​ (5) 效率: 栈的效率比堆高 5.Java底层知识: GC相关5.1 垃圾回收算法 标记-清除算法 标记:从根集合进行扫描, 对存活的对象进行标记 清除:对堆内存从头到尾进行线性遍历, 回收不可达对象内存 复制算法 分为对象面和空闲面, 对象在对象面上创建, 存活的对象被从对象面复制到空闲面, 将对象面所有对象内存清除 特点:解决碎片化问题; 顺序分配内存, 简单高效; 适用于对象存活率低的场景 标记-整理算法 标记:从根集合进行扫描, 对存活的对象进行标记 清除:移动所有存活的对象, 且按照内存地址次序依次排列, 然后将末端内存地址以后的内存全部回收 特点:避免内存的不连续性; 不用设置两块内存互换; 适用于存活率高的场景 分代收集算法 垃圾回收算法的组合拳; 按照对象生命周期的不同划分区域以采用不同的垃圾回收算法 目的:提高JVM的回收效率 年轻代:尽可能快速的收集掉那些声明周期短的对象 对象如何晋升到老年代: (1) 经历一定Minor次数依然存活的对象 (2) Survivor区中存放不下的对象 (3) 新生成的大对象(-XX:+PretenuerSizeThreshold) 常用的调优参数:-XX:SurvivorRatio:Eden和Survivor的比值, 默认8:1 -XX:NewRatio:老年代和年轻代内存大小比例 -XX:MaxTenuringThreshoid:对象从年轻代晋升到老年代经过GC次数的最大阈值 老年代:存放生命周期较长的对象; 标记-清理算法, 标记-整理算法 Full GC比Minor GC慢, 但执行频率低 触发Full GC的条件:老年代空间不足; 永久代空间不足(JDK8之前);CMS GC时出现promotion failed, concurrent mode failure;Minor GC晋升到老年代的平均大小大于老年代的剩余空间;调用System.gc();使用RMI来进行RPC或管理JDK应用, 每小时执行一次Full GC 5.2 常见垃圾收集器 年轻代常见的垃圾收集器 (1) Serial收集器(-XX:+UseSerialGC, 复制算法):单线程收集, 进行垃圾收集时, 必须暂停所有工作线程; 简单高效, Client模式下默认的年轻代收集器 (2) ParNew收集器(-XX:UseParNewGC, 复制算法):多线程收集, 特点和Serial收集器一样; 单核执行效率不如Serial, 在多核下执行才有优势 (3) Parallel Scavenge收集器(-XX:+UseParallelGC, 复制算法):比起关注用户线程停顿时间, 更关注系统的吞吐量; 在多核下执行才有优势, Server模式下默认的年轻代收集器 老年代常见的垃圾收集器 (1) Serial Old收集器(-XX:+UseSerialOldGC, 标记-整理算法):单线程收集, 进行垃圾收集时, 必须暂停所有工作线程; 简单高效, Client模式下默认的老年代收集器 (2) Parallel Old收集器(-XX:+UseParallelOldGC, 标记-整理算法):多线程, 吞吐量优先 (3) CMS收集器(-XX:+UseConcMarkSweepGC, 标记-清除算法):初始标记:stop-the-world; 并发标记:并发追溯标记, 程序不会停顿; 并发预清理:查找执行并发标记阶段从年轻代晋升到老年代的对象; 重新标记:暂停虚拟机, 扫描CMS堆中的剩余对象; 并发清理:清理垃圾对象, 程序不会停顿; 并发重置:重置CMS收集器的数据结构 G1收集器(-XX:+UseG1GC, 复制+标记-整理算法) 将整个Java堆内存划分成多个大小相等的Region; 年轻代和老年代不再物理隔离 特点:并行和并发; 分代收集; 空间整合; 可预测的停顿 ​ 注:相互连线表示可以共存 5.3 Object的finalize()方法的作用是否与C++的析构函数是否相同 (1) 与C++的析构函数不同, 析构函数调用确定, 而它的是不确定的 (2) 将未被引用的对象放置于F-Queue队列 (3) 方法执行随时可能终止 (4) 给予对象最后一次重生的机会 5.4 Java中的各种引用有什么用 强引用:最普遍的引用: Oject obj=new Object(); 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象; 通过将对象设置为null来弱化引用, 使其被回收 软引用:对象处于有用但非必须的状态; 只要当内存空间不足时, GC会回收该引用的对象的内存; 可以用来实现高速缓存 12String str= new String(\"abc\"); //强引用SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str); //软引用 弱引用:非必须的对象, 比软引用更弱一些; GC时会被回收; 被回收的概率也不大,因为GC线程优先级比较低; 适用于引用偶尔被使用且不影响垃圾收集的对象 12String str=new String(\"abc\");WeakReference&lt;String&gt; weakRef=new WeakReference&lt;String&gt;(str); 虚引用:不会决定对象的生命周期; 任何时候都可能被垃圾收集器回收; 跟踪对象被垃圾收集器回收的活动, 起哨兵作用; 必须和引用队列ReferenceQueue联合使用 123String str=new String(\"abc\");ReferenceQueue queue=new ReferenceQueue();PhantomReference ref=new PhantomReference(str,queue); 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会 对象的一般状态 JVM停止运行时终止 软引用 在内存不足时 对象缓存 内存不足时终止 弱引用 在垃圾回收时 对象缓存 GC运行后终止 虚引用 Unknown 标记, 哨兵 Unknown 引用队列:无实际存储结构, 存储逻辑依赖于内部节点之间的关系来表达; 存储关联的且被GC的软引用, 弱引用以及虚引用 6.多线程与并发6.1 进程和线程的区别 (1) 线程不能看做独立应用, 而进程可看作独立应用 (2) 进程有独立的地址空间, 相互不影响, 线程只是进程的不同执行路径 (3) 线程没有独立的地址空间, 多进程的程序比多线程程序健壮 (4) 进程的切换比线程的切换开销大 进程是执行着的应用程序, 而线程是进程内部的一个执行序列. 一个进程可以有多个线程, 线程又叫做轻量级进程 6.2 Java进程和线程的关系 (1) Java对操作系统提供的功能进行封装, 包括进程和线程 (2) 运行一个程序会产生一个进程, 进程包含至少一个线程 (3) 每个进程对应一个JVM实例, 多个线程共享JVM里的堆 (4) Java采用单线程编程模型, 程序会自动创建主线程 (5) 主线程可以创建子线程, 原则上要后于子线程 6.3 Thread中的start和run方法的区别 调用start()方法会创建一个新的子线程并启动, run()方法只是Thread的一个普通方法的调用 6.4 Thread和Runable是什么关系 Thread是实现了Runnable接口的类, 使得run支持多线程; 因类的单一继承, 推荐多使用Runnable接口 6.5 如何给run()方法传参 (1) 构造函数传参 (2) 成员变量传参 (3) 回调函数传参 6.6 如何实现处理线程的返回值 (1) 主线程等待法 (2) 使用Thread类的join()阻塞当前线程以等待子线程处理完毕 (3) 通过Callable接口实现: 通过FutureTask或者线程池获取 6.7 线程的状态 新建(New):创建后尚未启动的线程的状态 运行(Runnable):包含Running和Ready 无限期等待(Waiting):不会被分配CPU执行时间, 需要显式的被唤醒 限期等待(Timed Waiting):在一定时间后会由系统自动的唤醒 阻塞(Blocked):等待获取排它锁 结束(Terminated):已终止线程的状态, 线程已经结束执行 6.8 sleep() 和 wait() 有什么区别 基本差别 sleep是Thread类的方法, wait是Object类中定义的方法 sleep()方法可以在任何地方使用, wait()方法只能在synchornized方法或synchronized块中使用 最主要的本质区别 sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 6.9 notify()与notifyAll()的区别 notifyAll会让所有等待池的线程全部进入锁池去竞争获取锁的机会; notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 6.10 sleep()和yield()有什么区别 (1) sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会 (2) 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态 (3) sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常 (4) sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性 6.11 如何中断线程 调用interupt(), 通知线程应该中断了(需要被调用的线程配合中断) (1) 如果线程处于被阻塞状态, 那么线程将立即退出被阻塞状态, 并抛出一个InterruptedException异常(在正常运行任务时, 经常检查本线程的中断标志位, 如果被设置了中断标志就自行停止线程) (2) 如果线程处于正常活动状态, 那么会将该线程的中断标志设置为true. 被设置中断标志的线程将继续正常运行, 不受影响 6.12 线程安全问题 主要诱因:存在共享资源(也称临界资源); 存在多条线程共同操作这些共享数据 解决方法:同一时刻有且只要一个线程在操作共享数据, 其他线程必须等到该线程处理完数据后再对共享数据进行操作 6.13 如何保证线程安全？ (1) 通过合理的时间调度，避开共享资源的存取冲突 (2) 在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源 6.14 如何确保N个线程可以访问N个资源同时又不导致死锁 指定获取锁的顺序, 并强制线程按照指定的顺序获取锁 6.15 synchronized和ReentrantLock(再入锁)的区别 (1) synchronized是关键字, ReentrantLock是类 (2) ReentrantLock可以对获取锁的等待时间进行设置, 避免死锁 (3) ReentrantLock可以获取各种锁的信息 (4) ReentrantLock可以灵活的实现多路通知 主要相同点:Lock能完成synchronized所实现的所有功能 主要不同点:Lock有比synchronized更精确的线程语义和更好的性能(竞争激烈的情况下); synchronized会自动释放锁, Lock需要手动在finally从句中释放 6.16 volatile和synchronized的区别 (1) volatile本质是在告诉JVM当前变量在寄存器(工作内存)中的值是不确定的, 需要从主内存中读取; synchronized则是锁定当前变量, 只有当前线程可以访问该变量, 其它线程被阻塞住直到该线程完成变量操作为止 (2) volatile仅能使用在变量级别; synchronized则可以使用在变量, 方法和类级别 (3) volatile仅能实现变量的修改可见性, 不能保证原子性; 而synchronized则可以保证变量修改的可见性和原子性 (4) volatile不会造成线程的阻塞; synchronized可能会造成线程阻塞 (5)volatile标记的变量不会被编译器优化; synchronized标记的变量可以被编译器优化 6.17 为什么使用线程池 (1) 降低资源消耗 (2) 提高响应速度 (3) 提高线程的可管理性 6.18 Java线程池 ThreadPoolExecutor的构造函数 corePoolSize: 核心线程数量 maximumPoolSize: 线程不够用时能够创建的最大线程数 workQueue: 任务等待队列 keepAliveTime: 抢占的顺序不一定, 随机 threadFactory: 创建线程, Executeors.defaultThreadFactory() 线程池的状态 RUNNING: 能接受新提交的任务, 并且也能处理阻塞队列中的任务 SHUTDOWN: 不再接受新提交的任务, 但可以处理存量任务 STOP: 不再接受新提交的任务, 也不处理存量任务 TIDYING: 所有的任务都已终止 TERMINATED: terminated()方法执行完后进入该状态 线程池的大小如何选定 CPU密集型: 线程数=核数或核数+1 I/O密集型: 线程数=CPU核数*(1+平均等待时间/平均工作时间) 6.19 Java中有几种线程池 newFixedThreadPool创建一个指定工作线程数量的线程池, 每当提交一个任务就创建一个工作线程, 如果工作线程数量达到线程池初始的最大数, 则将提交的任务存入到池队列中 newCachedThreadPool创建一个可缓存的线程池. 特点:(1) 工作线程的创建数量几乎没有限制(其实也是有限制的, 数目为Interger.MAX_VALUE), 这样可灵活的往线程池中添加线程 (2) 如果长时间没有往线程中提交任务, 即如果工作线程空闲了指定的时间(默认1分钟), 则改工作线程将自动终止. 终止后, 如果你又提交了新的任务, 则线程池重新创建一个工作线程 newSingleThreadExecutor创建一个单线程化的Executor, 即只创建唯一的工作者线程来执行任务, 如果这个线程异常结束, 会有另一个来取代它, 保证顺序执行 newScheduThreadPool创建一个定长的线程池, 而且支持定时的以及周期性的任务执行, 类似于Timer 7.异常与常用类库7.1 Error和Exception的区别 Error:程序无法处理的系统错误, 编译器不做检查; Exception:程序可以处理的异常, 捕获后可能恢复 前者是程序无法处理的错误, 后者是可以处理的异常 RuntimeException:不可预知的, 程序应当自行避免; 非RuntimeException:可预知的, 从编译器校验的异常 7.2 常见Error以及Exception RuntimeException:(1) NullPointerException-空指针引用异常 (2) ClassCastException-类型强制转换异常 (3) IllegalArgumentException-传递非法参数异常 (4) IndexOutOfBoundsException-下标越界异常 (5) NumberFormatException-数字格式异常 非RuntimeException:(1) ClassNotFoundException-找不到指定class的异常 (2) IOException-IO操作异常 Error:(1) NoClassDefFoundError-找不到class定义的异常 (2)StackoverflowError-深递归导致栈被耗尽而抛出的异常 (3)OutOfMemoryError-内存溢出异常 7.3 Java异常的处理原则 具体明确: 抛出的异常应能通过异常类名和message准确说明异常的类型和产生异常的原因 提早抛出: 应尽可能早的发现并抛出异常, 便于精确定位问题 延迟捕获: 异常的捕获和处理应尽可能延迟, 让掌握更多信息的作用域来处理异常 7.4 Collection体系","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Java并发编程","slug":"Java并发编程","date":"2021-05-08T13:19:59.135Z","updated":"2021-06-13T15:00:06.936Z","comments":true,"path":"multithreading/","link":"","permalink":"http://tonymua.top/multithreading/","excerpt":"1.多线程基础1.1 实现多线程的方法 实现Runnable接口 123456public class Test_01 implements Runnable&#123; @Override public void run() &#123; System.out.println(\"实现Runnable接口实现多线程\"); &#125;&#125;","text":"1.多线程基础1.1 实现多线程的方法 实现Runnable接口 123456public class Test_01 implements Runnable&#123; @Override public void run() &#123; System.out.println(\"实现Runnable接口实现多线程\"); &#125;&#125; 123456public class Test_02 extends Thread &#123; @Override public void run() &#123; System.out.println(\"继承Thread类实现多线程\"); &#125;&#125; 线程池创建线程 1234567891011121314151617181920212223242526static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 对于线程池而言，本质上是通过线程工厂创建线程的，默认采用DefaultThreadFactory，它会给线程池创建的线程设置一些默认值，如：线程的名字、是否守护线程，以及线程的优先级等。但无论怎么设置这些这些属性，最终还是通过new Thread()创建线程的，只不过这里的构造函数传入的参数要多一些，本质还是通过new Thread()实现的。 实现有返回值的Callable创建线程 12345678910111213141516public class Test_03 implements Callable &#123; @Override public Integer call() throws Exception &#123; int i = new Random().nextInt(); System.out.println(Thread.currentThread().getName() +\" : \"+ i); return i; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 100; i++) &#123; Future&lt;Integer&gt; future = executorService.submit(new Test_03()); &#125; executorService.shutdown(); &#125;&#125; Runnable创建线程是无返回值的，而Callable和与之相关的Future、FutureTask，它们可以把线程执行的结果作为返回值返回。 …… 实现线程只有一种方式 启动线程需要调用start()方法，而start方法最终会调用run()方法，分析run()方法 123456@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; target实际上就是一个Runnable，即使用Runnable接口实现线程时传给Thread类的对象。第二种，继承Thread方式，继承Thread之后，会把run()方法重写，最终还是会调用thread.start()方法启动线程，而start()方法最终也会调用这个已经被重写的run()方法来执行任务。创建线程本质就是构造一个Thread类，不同点在于实现线程运行内容的方式不同，可以通过实现Runnable接口，或继承Thread类重写run()方法。 1.2 实现Runnable接口比继承Thread类实现线程更好？ Java不支持多继承，一旦继承了Thread类，就无法再继承其它类，限制了代码的可扩展性。 Runnable里只有一个run()方法，定义了需要执行的内容，实现了Runnable与Thread类的解耦，Thread类负责线程启动和属性设置，权责分明。 1.3 如何正确停止线程？对于Java而言，最正确的停止线程的方式是使用interrupt，但interrupt仅仅起到通知被停止线程的作用，而对于被停止的线程而言，它拥有完全的自主权，即可以选择立即停止，也可以一段时间后停止，也可以不停止。Java希望程序间可以相互通知、相互协作的管理线程，如果贸然停止线程可能会造成一些安全性问题，为了避免造成问题就需要给对方一定的时间来整理收尾工作。 123while (!Thread.currentThread().isInterrupted() &amp;&amp; more work to do) &#123; do more work&#125; 一旦调用某个线程的interrupt后，该线程的中断标记位就会被设置成true，每个线程都有这样的标记位，当线程执行时应定期检查这个标记位。上面代码可以看到，while循环判断语句中，先通过Thread.currentThread().isInterrupt()判断是否被中断，随后检查是否还有工作要做。 1.4 sleep期间能否感受到中断？如果sleep、wait等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，线程是可以感受到中断信号的，并会抛出InterruptedException，同时清除中短信号，将中断标记位设为false。 处理方式： 方法签名抛异常，run()强制try/catch 123void subTask() throws InterruptedException &#123; Thread.sleep(1000);&#125; 要求每一个方法的调用方有义务去处理异常。调用方要不使用try/catch并在catch中正确处理异常，要不将异常声明到方法签名中。如果每层逻辑都遵守规范，便可以将中断信号传递到顶层，最终让run()方法可以捕获到异常。而对于run()方法而言，它本身没有抛出checkedException的能力，只能通过try/catch来处理异常。层层传递异常保障了异常不会被遗漏，而对于run()方法，就可以根据不同的业务逻辑来进行相应的处理。 再次中断 12345678private void reInterrupt() &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); e.printStackTrace(); &#125;&#125; 在catch语句中再次中断线程。如果线程在休眠期间被中断，那么会自动清除中断信号。如果这时手动添加中断信号，中断信号依然可以被捕捉到。 1.5 为什么用volatile标记位的停止方法是错误的？stop()会直接把线程停止，会导致出现数据完整性等问题。suspend()和resume()并不会释放锁，就开始进入休眠，但此时有可能仍持有锁，容易导致死锁问题。 volatile修饰标记位适用的场景 123456789101112131415161718192021222324252627public class VolatileCanStop implements Runnable &#123; private volatile boolean canceled = false; @Override public void run() &#123; int num = 0; while (!canceled &amp;&amp; num &lt; 1000000) &#123; if (num % 10 == 0) &#123; System.out.println(Thread.currentThread().getName() + \":\" + num + \"是10的倍数\"); &#125; num++; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; VolatileCanStop canStop = new VolatileCanStop(); Thread thread = new Thread(canStop); thread.start(); Thread.sleep(3000); canStop.canceled = true; &#125;&#125; 启动线程，经过3s，把volatile修饰的标记位设置为true，那么下一次while循环中判断出canceled的值为true，就跳出while循环，线程停止。 volatile修饰标记位不适用的场景 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class VolatileCanNotStop &#123; public static void main(String[] args) throws InterruptedException &#123; ArrayBlockingQueue storage = new ArrayBlockingQueue(8); Producer producer = new Producer(storage); Thread producerThread = new Thread(producer); producerThread.start(); Thread.sleep(500); Consumer consumer = new Consumer(storage); while (consumer.needMoreNums()) &#123; System.out.println(consumer.storage.take() + \"被消费了\"); Thread.sleep(100); &#125; System.out.println(\"消费者不需要更多数据了。\"); // 一旦消费不需要更多数据了，我们应该让生产者也停下来，但是实际情况却停不下来 producer.canceled = true; System.out.println(producer.canceled); &#125;&#125;class Producer implements Runnable &#123; public volatile boolean canceled = false; BlockingQueue storage; public Producer(BlockingQueue storage) &#123; this.storage = storage; &#125; @Override public void run() &#123; int num = 0; try &#123; while (!canceled &amp;&amp; num &lt;= 10000) &#123; if (num % 50 == 0) &#123; storage.put(num); System.out.println(Thread.currentThread().getName() + \":\" + num + \"是50的倍数，被放到仓库中了\"); &#125; num++; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"生产者结束运行\"); &#125; &#125;&#125;class Consumer &#123; BlockingQueue storage; public Consumer(BlockingQueue storage) &#123; this.storage = storage; &#125; public boolean needMoreNums() &#123; if (Math.random() &gt; 0.97) &#123; return false; &#125; return true; &#125;&#125; 线程被长时间阻塞的情况，就无法及时感受中断：尽管已经把canceled的标记位设置为true，但生产者仍然没有被停止，是因为生产者在执行storage.put(num)时发生阻塞，在它被叫醒之前是没有办法进入下次循环判断canceled的值的，这种情况下volatile没有办法让生产者停下来的，如果用interrupt语句来中断，即使生产者处于阻塞状态，仍然能够感受到中断信号，并做相应处理。 1.6 线程是如何在6种状态之间转换的？线程的6种状态 New(新建) Runnable(可运行) Blocked(被阻塞) Waiting(等待) Timed Waiting(计时等待) Terminated(被终止) New 新建New表示线程被创建但尚未启动的状态：new Thread()新建一个线程时，如果线程没有开始运行start()方法，所以也没有开始执行run()方法里面的代码，此时它的状态就是New。一旦线程调用了start()，就变成Runnable。 Runnable 可运行Java中的Runnable状态对应操作系统线程状态中的两种状态，分别是Running和Ready，即Java中处于Runnable状态的线程有可能正在执行，也有可能没有正在执行，正在等待被分配CPU资源。所以，如果一个正在运行的线程是Runnable状态，当它运行到任务的一半时，执行该线程的CPU被调度去做其他事情，导致该线程暂时不运行，它的状态仍为Runnable，因为它有可能随时被调度回来继续执行任务。 Blocked 被阻塞从Runnable状态进入Blocked状态只有一种可能，就是进入synchronized保护的代码块/方法时没有抢到monitor锁，Blocked仅仅针对synchronized monitor锁。 Waiting 等待线程进入Waiting 没有设置Timeout参数的Object.wait()方法 没有设置Timeout参数的Thread.join()方法 LockSupport.park()方法 Blocked与Waiting的区别是Blocked在等待其它线程释放monitor锁，而Waiting则是在等待某个条件，比如join的线程执行完毕，或者是notify()/notifyAll()。 Timed Waiting 限期等待Waiting和Time Waiting区别：有没有时间限制，Timed Waiting会等待超时，由系统自动唤醒，或者在超时前被唤醒信号唤醒。 线程进入Timed Waiting 设置了时间参数的Thread.sleep(long millis)方法 设置了时间参数的Object.wait(long timeout)方法 设置了时间参数的Thread.join(long millis)方法 设置了时间参数的LockSupport.parkNanos(long nanos)方法和LockSupport.parkUntil(long deadline)方法 Blocked—&gt;Runnable：线程获取monitor锁 Waiting—&gt;Runnable：执行了LockSupport.unpark()，或join的线程运行结束，或者被中断。 Waiting—&gt;Blocked：其它线程调用notify()或notifyAll()，因为唤醒Waiting线程的线程如果调用notify()或notifyAll()，必须首先持有该monitor锁，所以处于Waiting状态的线程被唤醒时拿不到该锁，就会进入Blocked状态，直到执行notify()/notifyAll()的唤醒线程执行完毕并释放monitor锁，才可能轮到它去抢夺这把锁，抢到就会从Blocked状态回到Runnable状态。 TimedWaiting类似，但如果它的超时时间到了且能直接获取到锁/join的线程运行结束/被中断/调用了LockSupport.unpark()，会直接恢复到Runnable状态。 Terminated线程进入Terminated run()方法执行完毕，线程正常退出。 出现一个没有捕获的异常，终止了run()方法，最终导致意外终止。 Tips 线程的状态是按照箭头方向走的，如线程从New不可以进入Blocked，它需要经历Runnable。 线程的生命周期不可逆：一旦进入Runnable就不能回到New状态；一旦被终止就不可能有任何状态的变化。所以一个线程只有一次New和Terminated状态，只有处于中间状态才可以相互转换。 1.7 为什么wait必须在synchronized保护的同步代码中使用？1.8 为什么wait/notify/notifyAll方法被定义在Object类中，而sleep定义在Thread类中？ Java中每个对象都有一把称之为monitor监视器的锁，由于每个对象都可以上锁，这就要求在对象头中有一个用来保存锁信息的位置。这个锁是对象级别的，而非线程级别的，wait/notify/notifyAll也都是锁级别的操作，它们的锁属于对象，所以把它们定义在Object类，因为Object类是所有对象的父类。 如果把wait/notify/notifyAll方法定义在Thread类中，会带有很大的局限性，如一个线程可能持有多个锁。如何明确当前线程等待的是哪把锁呢？既然是让当前线程去等待某个对象的锁，自然应该通过操作对象来实现。 1.9 wait/notify和sleep方法的异同相同点 都可以让线程阻塞 都可以响应interrupt中断：在等待的过程中如果收到中断信号，都可以进行响应，并抛出InterruptedException 不同点 wait方法必须在synchronized保护的代码中使用，而sleep方法并没这个要求。 在同步代码块中执行sleep方法，并不会释放monitor锁，但执行wait方法时会主动释放monitor锁。 sleep方法必须定义一个时间，时间到期后会主动会恢复，而对于没有参数的wait方法而言，意味着永久等待，直到被中断或被唤醒才能恢复，它并不主动恢复。 wait/notify是Object类的方法，而sleep是Thread类的方法。 2.线程安全如果某个对象是线程安全的，即使用时就不需要考虑方法间的协调问题。 2.1 3种典型的线程安全问题 运行结果错误 12345678910111213141516171819202122public class WrongResult &#123; volatile static int i; public static void main(String[] args) throws InterruptedException &#123; Runnable r = new Runnable() &#123; @Override public void run() &#123; for (int j = 0; j &lt; 10000; j++) &#123; i++; &#125; &#125; &#125;; Thread thread1 = new Thread(r); thread1.start(); Thread thread2 = new Thread(r); thread2.start(); thread1.join(); thread2.join(); System.out.println(i); &#125;&#125; i++并不是一个原子操作 发布或初始化导致线程安全问题 12345678910111213141516171819202122232425public class WrongInit &#123; private Map&lt;Integer, String&gt; students; public WrongInit() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; students = new HashMap&lt;&gt;(); students.put(1, \"王小美\"); students.put(2, \"钱二宝\"); students.put(3, \"周三\"); students.put(4, \"赵四\"); &#125; &#125;).start(); &#125; public Map&lt;Integer, String&gt; getStudents() &#123; return students; &#125; public static void main(String[] args) &#123; WrongInit wrongInit = new WrongInit(); System.out.println(wrongInit.getStudents().get(1)); &#125;&#125; students 这个成员变量是在构造函数中新建的线程中进行的初始化和赋值操作，而线程的启动需要一定的时间，但是我们的 main 函数并没有进行等待就直接获取数据，导致 getStudents 获取的结果为 null，这就是在错误的时间或地点发布或初始化造成的线程安全问题。 活跃性问题 分别为死锁、活锁和饥饿 死锁：两个线程之间相互等待对方资源，但同时又互不相让，都想自己先执行，如代码所示。 12345678910111213141516171819202122232425262728293031323334353637383940public class MayDeadLock &#123; Object lock1 = new Object(); Object lock2 = new Object(); public void thread1() throws InterruptedException &#123; synchronized (lock1)&#123; Thread.sleep(500); synchronized (lock2)&#123; System.out.println(\"线程1成功拿到两把锁\"); &#125; &#125; &#125; public void thread2() throws InterruptedException &#123; synchronized (lock2)&#123; Thread.sleep(500); synchronized (lock1)&#123; System.out.println(\"线程2成功拿到两把锁\"); &#125; &#125; &#125; public static void main(String[] args) &#123; MayDeadLock deadLock = new MayDeadLock(); new Thread(new Runnable() &#123; @SneakyThrows @Override public void run() &#123; deadLock.thread1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @SneakyThrows @Override public void run() &#123; deadLock.thread2(); &#125; &#125;).start(); &#125;&#125; 活锁：与死锁类似，不过活锁是活的，因为正在运行的线程并没有阻塞，它始终在运行，缺一直得不到结果。假设有一个消息队列里放着需要被处理的消息，而某个消息由于自身的错误无法被正确处理，同时队列的重试机制会把它放在队列头进行优先重试处理。 饥饿：线程需要某些资源始终得不到，尤其是CPU资源，就会导致线程一直不能运行。 在Java中有1-10的线程优先级，1最低，10最高。如果某个线程的优先级为1，该线程就有可能始终分配不到CPU资源，而导致长时间无法运行。 或者是某个线程始终持有某个文件的锁，其他线程想要修改文件必须先获取锁，这时想要修改文件的线程就会陷入饥饿。2.2 需要额外注意线程安全的场景 访问共享变量和资源 如访问共享对象的属性、访问static静态变量、访问共享的缓存等。 依赖时序的操作 123if (map.containsKey(key)) &#123; map.remove(obj)&#125; 不同数据之间存在绑定关系 不同的数据之间是成组出现的，存在着相互对应或绑定的关系，最典型的就是IP和端口号。 对方没有声明自己是线程安全的 2.3 为什么多线程会带来性能问题单线程是独立工作的，不需要与其他线程进行交互，但多线程之间则需要调度以及协作，调度与协作就会带来性能开销从而产生性能问题。 调度开销 上下文切换：线程数往往大于CPU核心数，操作系统会按照一定的调度算法，给每个线程分配时间片。而在进行调度时就会引起上下文切换，上下文切换会挂起当前正在执行的线程并保存当前的状态，然后寻找下一处即将恢复执行的代码，唤醒下一个线程。 缓存失效：进行了线程调度，切换到其他线程，CPU就会去执行不同的代码，原有的缓存就很有可能失效了，需要重新缓存新的数据。 给被调度到的线程设置最小执行时间，即只有执行完这段时间后，才可能进行下一次的调度，由此减少上下文切换的次数。 协作开销 为了避免共享数据错乱、保证线程安全，就有可能禁止编译器和CPU对其进行重排序等优化，也可能出于同步的目的，反复把线程工作内存的数据flush到主内存，然后再从主内存refresh到其他线程的工作内存中。 2.4 使用线程池的好处 线程池可以解决线程生命周期的系统开销问题，线程池里的线程可以复用，消除了线程创建带来的延迟，从而提高响应速度。 线程池可以统筹内存和CPU的使用，避免资源的使用不当。 线程池可以统一管理资源。 2.5 线程池各参数的含义 线程池的特点： 线程池希望保持较少的线程数，只有在负载变的很大时才增加线程。 线程池只有在任务队列满时才会创建多于corePoolSize的线程，如果使用的是无界队列(如LinkedBlockingQueue)，线程数不会超过corePoolSize。 设置corePoolSize和maxPoolSize为相同的值，可以创建固定大小的线程池。 2.6 线程池有哪几种拒绝策略？ AbortPolicy：拒绝任务时直接抛出一个类型为RejectedExecutionException的RuntimeException，可以感知到任务被拒绝了，可以根据业务逻辑选择重试或放弃提交等。 DiscardPolicy：当新任务被提交后直接被丢弃掉，不会有任何通知。 DiscardOldestOlicy：丢弃任务队列的头节点，通常是存活时间最长的任务，也不会有任何通知。 CallerRunsPolicy：把任务交给提交任务的线程执行，即谁提交任务，谁就负责执行任务。 提交的任务不会被丢弃 提交任务的线程负责执行任务，提交任务的线程被占用，不会再提交新的任务，线程池中的线程也可以利用这段时间执行掉一部分任务，相当于是给了线程池一定的缓冲期。 2.7 有哪6种常见的线程池？什么是Java8的ForkJoinPool? FixedThreadPool 核心线程数和最大线程数是一样的，可以看作是固定线程数的线程池，没有可用的线程的时候，任务会放在队列中等待，任务的长度无限制(LinkedBlockingQueue) CachedThreadPool 线程数几乎可以无限增加(Integer.MAX_VALUE，2^31-1)，该线程池的线程数量不固定，不够使用时自动增加，闲置时自动回收。队列为SynchronousQueue，队列容量为0，实际不存储任务，只对任务进行中转和传递。 ScheduledThreadPool 支持定时或周期的执行任务。 1234567ScheduledExecutorService service = Executors.newScheduledThreadPool(10);//延迟指定时间后执行一次任务，10秒执行一次service.schedule(new Task(), 10, TimeUnit.SECONDS);//以固定的频率执行任务service.scheduleAtFixedRate(new Task(), 10, 10, TimeUnit.SECONDS);//与第二种类似，不过scheduledAtFixedRate以开始时间为起点，时间到就开始第二次，而scheduledWithFixedDelay以任务结束时间为下一次循环的时间起点开始计算service.scheduleWithFixedDelay(new Task(), 10, 10, TimeUnit.SECONDS); SingleThreadExecutor 原理与FixedThreadPool一样，线程只有一个，如果线程在执行过程中发生异常，线程池也会重新创建一个线程来执行后续的任务。适合用于任务需要按被提交的顺序依次执行的场景。 SingleThreadScheduledExecutor 于ScheduledThreadPool类似，如源码所示：只是将ScheduledThreadPool的核心线程数设置为1 1new ScheduledThreadPoolExecutor(1) ForkJoinPool 2.8 线程池常用的阻塞队列 LinkedBlockingQueue 对于FixedThreadPool和SingleThreadExector，它们使用的是容量为Integer.MAX_VALUE的LinkedBlockingQueue，可以任务是无界队列。 SynchronousQueue 对于CachedThreadPool，最大线程数为Integer.MAX_VALUE，所以不需要任务队列来存储任务，一旦有任务提交就直接转发给线程或创建新线程来执行。 DelayedWorkQueue 对于ScheduledThreadPool和SingleThreadScheduledExecutor，DelayedWorkQueue内部元素并不是按照放入的时间排序，而是按照延迟的时间长短对任务进行排序，内部采用的是”堆”的数据结构。 2.9 为什么不应该自动创建线程池？ FixedThreadPool、SingleThreadPool 使用的队列是没有上限的LinkedBlockingQueue，如果处理任务过慢，队列中堆积的任务会越来越多，占用大量内存，导致OOM。 CachedThreadPool 不限制线程的数量，任务特别多时，有可能会创建非常多的线程，最终导致超过了操作系统的上限而无法创建线程，或导致内存不足。 ScheduledThreadPool、SingleThreadScheduledExecutor DelayedWorkQueue也是一个无界队列。 2.10 合适的线程数是多少？ CPU密集型任务 如加密、解密、压缩、计算等大量耗费CPU资源的任务，线程数为CPU核心数的1-2倍。 耗时IO型任务 如数据库、文件的读写、网络通信等并不消耗CPU资源的任务，线程数=CPU核心数*(1+平均等待时间/平均工工作时间) 线程的平均工作时间所占比例越高，就需要越少的线程。线程的平均等待时间所占比例越高，就需要越多的线程。 2.11 如何正确关闭线程？ shutdown() 安全的关闭的一个线程池，调用shutdown()之后，如果还有新任务被提交，线程池会根据拒绝策略直接拒绝后续提交的任务，执行完正在执行的任务和队列中等待的任务后关闭。 isShutdown() 判断线程是否已经开始了关闭工作，即是否执行了shutdown()或shutdownNow() isTerminated() 检测线程池是否真正”终结”了，即线程池已关闭，同时线程池中的所有任务都执行完毕了。 awaitTermination() 判断线程池状态，如给awaitTermination方法传入的参数为10秒，那么它会陷入10秒等待，直到 等待期间(包括进入等待之前)，线程池已关闭并所有任务都执行完毕，相当于线程池”终结”了，方法便返回true。 等待超时时间到后，线程池始终未”终结”，返回false。 等待期间线程被中断，方法抛出InterruptedException异常。 即调用awaitTermination方法后当前线程池会尝试等待一定指定的时间，如果在等待时间内，线程池已关闭并任务都执行完毕，方法返回true，否则返回false。 shutdownNow() 立刻关闭，执行shutdownNow()方法之后，首先会给线程池中的线程发送interrupt中断信号，尝试中断这些任务的执行，然后会将等待的所有任务转移到一个List中并返回。 3.各种各样的”锁”3.1 你知道哪几种锁？分别有什么特点？ 偏向锁/轻量级锁/重量级锁 特指synchronized锁的状态，通过在对象头中的mark word来表明锁的状态。 偏向锁 如果，这把锁一直不存在竞争，就没必要上锁，只需打个标记就行。对象被初始化，还没有线程来获取它的锁时，那么它就是可偏向的，当有第一个线程来访问它并尝试获取锁的时候，它就将这个线程记录下来，以后如果尝试获取锁的线程正是偏向锁的拥有者，就可以直接获取锁，开销很小，性能最好。 轻量级锁 synchronized中的代码是被多个线程交替执行的，并不存在实际的竞争、或只有短时间的竞争，用CAS就可以解决。轻量级锁是指当锁原来是偏向锁时，被另一个线程访问，说明存在竞争，那么偏向锁就会升级为轻量级锁，线程会通过自旋的形式获取锁，而不会陷入阻塞。 重量级锁 重量级锁是互斥锁，它是利用操作系统的同步机制实现的，开销相对较大。当多个线程直接实际竞争，且锁竞争时间长的时候，锁就会膨胀为重量级锁。重量级锁会让其它申请缺拿不到锁的线程进入到阻塞状态。 偏向锁性能最好，可以避免执行CAS操作。而轻量级锁利用自旋和CAS避免了重量级锁带来的线程阻塞和唤醒，性能中等。重量级锁则会把获取不到锁的线程阻塞，性能最差。 可重入锁/不可重入锁 可重入锁指的是线程当前已经持有这把锁了，能在不释放这个锁的情况下，再次获取这把锁。不可重入锁指的是虽然当前持有了这把锁，但如果想再次获取此锁，也必须先要释放锁后才能再次尝试获取。 共享锁/独占锁 共享锁指同一把锁可以被多个线程同时获得，而独占锁指这个锁只能同时被一个线程获得。如读写锁中的读锁是共享锁，而写锁是独占锁。 公平锁/非公平锁 公平锁 如果线程现在拿不到这把锁，那么线程都会进入等待，开始排队，在等待队列等待时间长的线程会优先拿到这把锁，先来先得。 非公平锁 在一定情况下，忽略掉已经在排队的线程，发生插队现象。 悲观锁/乐观锁 悲观锁 在获取资源之前，必须先拿到锁，以便达到”独占”的状态。 乐观锁 并不要求在获取资源前拿到锁，也不会锁住资源，利用CAS理念，在不独占资源的情况下，完成对资源的修改。 自旋锁/非自旋锁 自旋锁 如果线程现在拿不到锁，并不直接陷入阻塞或者释放CPU资源，而是开始利用循环，不停的尝试获取锁。 非自旋锁 拿不到锁就直接放弃，或者进行其它的处理逻辑，如阻塞、排队等。 可中断锁/不可中断锁 synchronized关键字修饰的锁代表的是不可中断锁，一旦线程申请了锁，就没有回头路，只能等拿到锁以后才能进行其它的逻辑处理。 ReentrantLock是一种典型的可中断锁，如使用lockInterruptibly方法在获取锁的过程中，突然不想获取了，可以在中断之后去做其它的事。 3.2 悲观锁与乐观锁 悲观锁 为了确保结果的正确性，会在每次获取并修改数据时，都把数据锁住，让其他线程无法访问。 线程A拿到了锁，并且正在操作同步资源，那么此时线程B就必须进行等待。 当线程A执行完毕后，CPU才会唤醒正在等待这把锁的线程B再次尝试获取锁 如果线程B获取到了锁，才可以对同步资源进行自己的操作。 乐观锁 认为自己在操作资源的时候不会有其他线程干扰，所以并不会锁住被操作对象。为了确保数据正确性，在更新之前，会去对比在修改数据期间，数据有没有被其他线程修改过。 例子： 悲观锁：synchronized关键字和Lock接口 以Lock接口为例，如Lock的实现类ReentrantLock，类中的lock()等方法就是执行加锁，而unlock()方法就是执行解锁()。处理资源之前必须要先加锁并拿到锁，等到处理完之后再解开锁。 乐观锁：原子类 如AtomicInteger在更新数据时，多个线程可以同时操作同一个原子变量。 两种锁各自的使用场景： 悲观锁适合于并发写入多、临界区代码复杂、竞争激烈等场景，此时悲观锁可以避免大量的无用的反复尝试等消耗。 乐观锁适用于读取多，修改少的场景，也适合虽然读写都很多，但是并发不激烈的场景。 3.3 synchronized背后的monitor锁获取和释放monitor锁的时机：线程在进入synchronized保护的代码块之前，会自动获取锁；并且无论是正常退出，还是抛出异常退出，在退出的时候都会自动释放锁。 查看反汇编命令：javac SynTest.java javap -verbose SynTest.class 同步代码块 123456789101112 ......3: monitorenter 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String lagou 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit ...... monitorenter可以理解为加锁，monitorexit理解为释放锁，每个对象维护着一个记录着被锁次数的计数器。未锁定的对象的该计数器未0。 monitorenter 如果该monitor的计数为0，则线程获得该monitor并将其计数设置为1，该线程就是这个monitor的所有者。 如果线程已经拥有了这个monitor，则它将重新进入，并且累加计数。 如果其他线程已经拥有了这个monitor，那么这个线程就会被阻塞，直到这个monitor的计数器变为0，代表这个monitor已经被释放了，于是当前这个线程就会再次尝试获取这个monitor。 monitorexit 作用：将monitor的计数器减1，直到减为0为止。代表这个monitor已经被释放了，已经没有任何线程拥有它了，也就代表着解锁。其他正在等待这个monitor的线程，此时可以再次尝试获取这个monitor的所有权。 同步方法 123456 public synchronized void synMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=0, locals=1, args_size=1...... 被synchronized修饰的方法会有一个ACC_SYNCHRONIZED标志，当某个线程要访问某个方法时，会首先检查方法是否有ACC_SYNCHRONIZED标志，如果有则需要先获得monitor锁，方法执行之后再释放monitor锁。3.4 synchronized与Lock 相同点 synchronized和Lock都是用来保护资源线程安全的 都可以保证可见性 synchronized和ReentrantLock(Lock的一个实现类)都拥有可重入的特点 不同点 用法区别 synchronized关键字可以加在方法上，不需要指定锁对象(此时的锁对象为this)；也可以修饰同步代码块并且自定义monitor对象。而Lock锁对象必须显示的开始加锁lock()和解锁unlock()，并且一般会在finally块中确保用unlock()来解锁，以防止发生死锁。 加解锁顺序不同 对于Lock而言如果有多把Lock锁，Lock可以不完全按照加锁的反序解锁 12345lock1.lock();lock2.lock();...lock1.unlock();lock2.unlock(); synchronized解锁的顺序和加锁的顺序必须完全相反，obj2先解锁，obj1后解锁。 12345synchronized(obj1)&#123; synchronized(obj2)&#123; ... &#125;&#125; synchronized锁不够灵活 一旦synchronized锁已经被某个线程获得了，此时其他线程如果还想获得，那么它只能被阻塞，直到持有锁的线程运行完毕或发生异常从而释放这个锁。Lock类在等待锁的过程中，如果使用的时lockInterruptibly方法，如果等待时间太长，可以中断退出，也可以使用tryLock()等方法尝试获取锁，如果获取不到可以执行其他逻辑。 synchronized锁只能同时被一个线程拥有，但Lock锁没有这个限制。 如在读写锁中的读锁，是可以被多个线程同时拥有的，但synchronized不行。 原理区别 synchronized是内置锁，由JVM实现获取锁和解锁，还分为偏向锁、轻量级锁、重量级锁。Lock根据实现不同，原理也不同，如ReentrantLock内部是通过AQS来获取和释放锁的。 是否可以设置公平/非公平 ReentrantLock可以根据需求来设置公平或非公平，synchronized则不能设置。 如何选择： 最好既不使用Lock也不使用synchronized，尽量使用java.util.concurrent包中的机制。 尽量使用synchronized，避免忘记在finally里忘记unlock。 需要Lock的特殊功能时，如尝试获取锁、可中断、超时功能等，才使用Lock。 3.5 Lock的常用方法 lock() 在线程获取锁时如果锁已被其他线程获取 12345678Lock lock = ...;lock.lock();try&#123; //获取到了被本锁保护的资源，处理任务 //捕获异常&#125;finally&#123; lock.unlock(); //释放锁&#125; tryLock() 用来尝试获取锁，如果当前锁没有被其他线程占用，则获取成功，返回true，否则返回false，代表获取锁失败，可以根据是否能获取到锁来决定后续程序行为。 12345678910Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则做其他事情&#125; tryLock(long time, TimeUnit unit) 和tryLock()类似，tryLock(long time, TimeUnit unit)会有一个超时时间，在拿不到锁时会等待一定的时间，时间期限结束后，还获取不到锁，就会返回false，如果在最开始或等待期间内获取到锁就返回true。 lockInterruptibly() 除非当前线程在获取锁期间被中断，否则会一直尝试获取直到获取到为止。相当于超时时间无限长的tryLock(long time, TimeUnit unit)。 123456789101112 public void lockInterruptibly() &#123; try &#123; lock.lockInterruptibly(); try &#123; System.out.println(\"操作资源\"); &#125; finally &#123; lock.unlock(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; unlock() 用于解锁，对ReentrantLock而言，执行unlock()的时候，内部会把锁的”被持有计数器”减1，直到减到0就代表当前这把锁已经完全释放了，如果减1后计数器不为0，说明这把锁之前被”重入”了，那么锁并没有真正释放，仅仅是减少了持有的次数。 3.6 公平锁与非公平锁公平锁：按照线程请求顺序来分配锁 非公平锁：不完全按照请求的顺序，在一定情况下，可以允许插队。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class FairAndUnfair &#123; static class PrintQueue &#123; private final Lock queueLock = new ReentrantLock(false);//false:非公平锁 true:公平锁 默认false public void printJob(Object document) &#123; queueLock.lock(); try &#123; Long duration = (long)(Math.random() * 10000); System.out.printf(\"%s: PrintQueue: Printing a Job during %d seconds\\n\", Thread.currentThread().getName(), (duration / 1000)); Thread.sleep(duration); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; queueLock.unlock(); &#125; queueLock.lock(); try &#123; Long duration = (long)(Math.random() * 10000); System.out.printf(\"%s: PrintQueue: Printing a Job during %d seconds\\n\", Thread.currentThread().getName(), (duration / 1000)); Thread.sleep(duration); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; queueLock.unlock(); &#125; &#125; &#125; static class Job implements Runnable &#123; private PrintQueue printQueue; public Job(PrintQueue printQueue) &#123; this.printQueue = printQueue; &#125; @Override public void run() &#123; System.out.printf(\"%s: Going to print a job\\n\", Thread.currentThread().getName()); printQueue.printJob(new Object()); System.out.println(); System.out.printf(\"%s: The document has been printed\\n\", Thread.currentThread().getName()); &#125; &#125; public static void main(String[] args) &#123; PrintQueue printQueue = new PrintQueue(); Thread thread[] = new Thread[10]; for (int i = 0; i &lt; 10; i++) &#123; thread[i] = new Thread(new Job(printQueue), \"Thread \" + i); &#125; for (int i = 0; i &lt; 10; i++) &#123; thread[i].start(); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 非公平情况下，存在抢锁”插队”现象，如Thread 0 在释放锁后又能优先获取到锁，虽然此时在等待队列中已经有Thread 1~Thread 9在排队了。 各自的优缺点 源码分析 ReentrantLock中包含一个Sync类，这个类继承自AQS(AbstractQueuedSynchronizer) 1234public class ReentrantLock implements Lock, java.io.Serializable &#123;private static final long serialVersionUID = 7373984872572414699L;/** Synchronizer providing all implementation mechanics */private final Sync sync; Sync有公平锁FairSync和非公平锁NonfairSync两个子类 12static final class NonfairSync extends Sync &#123;...&#125;static final class FairSync extends Sync &#123;...&#125; 公平锁与非公平获取锁的lock()方法唯一区别就在于公平锁在获取锁时多了一个限制条件：hasQueuedPredecessors()为false，这个方法就是在判断在等待队列中是否已经有线程在排队了。公平锁，一旦有线程在排队，当前线程就不再尝试获取锁了；对于非公平锁，无论是否有线程在排队，都会尝试获取一下锁，获取不到的话，再去排队。 tryLock()，一旦有线程释放了锁，那么正在tryLock的线程就能获取到锁，即使设置的是公平锁模式，即使在它之前已经有其他正在等待队列中等待的线程，即tryLock可以插队。调用的是nonfairTryAcquire()，表明是不公平的，和锁本身是否公平锁无关。 123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 3.7 读写锁保证多个线程同时读的效率，同时可以保证有写入操作时的线程安全。 读写锁的获取规则 如果一个线程已经占用了读锁，则此时其他线程如果要申请读锁，可以申请成功。 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁，因为读写不能同时操作。 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或读锁，都必须等待之前的线程释放锁，因为读写、写写不能同时操作。 要么是一个或多个线程同时有读锁，要么是一个线程有写锁，但是两者不会同时出现。即读读共享，其他都互斥。 1234567891011121314151617181920212223242526272829303132333435363738public class ReadWriteLockDemo &#123; private static final ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(false); private static final ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock.readLock(); private static final ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock.writeLock(); private static void read() &#123; readLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到读锁，正在读取\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放读锁\"); readLock.unlock(); &#125; &#125; private static void write() &#123; writeLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到写锁，正在写入\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放写锁\"); writeLock.unlock(); &#125; &#125; public static void main(String[] args) &#123; new Thread(() -&gt; read()).start(); new Thread(() -&gt; read()).start(); new Thread(() -&gt; write()).start(); new Thread(() -&gt; write()).start(); &#125;&#125; 运行结果： 12345678Thread-0得到读锁，正在读取Thread-1得到读锁，正在读取Thread-0释放读锁Thread-1释放读锁Thread-2得到写锁，正在写入Thread-2释放写锁Thread-3得到写锁，正在写入Thread-3释放写锁 读写锁适用于读多写少的情况 3.8 读锁应该插队么？什么是读写锁的升降级？ 公平锁 只要等待队列中有线程在等待，即hasQueueedPredecessors()返回true的时候，那么write和reader都会block，即不允许插队。 非公平锁 1234567final boolean writerShouldBlock() &#123; return false; // writers can always barge&#125;final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive();&#125; 写锁：随时可以插队 读锁： 允许插队 有可能导致需要拿到写锁的线程会陷入”饥饿”状态，它将在长时间内得不到执行。 不允许插队 即使是非公平锁，只要等待队列的头结点是尝试获取写锁的线程，那么读锁依然不能插队，目的是避免”饥饿”。 1234567891011121314151617181920212223242526272829303132333435363738public class ReadLockJumpQueue &#123; private static final ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); private static final ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock.readLock(); private static final ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock.writeLock(); private static void read() &#123; readLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到读锁，正在读取\"); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放读锁\"); readLock.unlock(); &#125; &#125; private static void write() &#123; writeLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到写锁，正在写入\"); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放写锁\"); writeLock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; read(), \"Thread-2\").start(); new Thread(() -&gt; read(), \"Thread-4\").start(); new Thread(() -&gt; write(), \"Thread-3\").start(); new Thread(() -&gt; read(), \"Thread-5\").start(); &#125;&#125; 运行结果： 12345678Thread-2得到读锁，正在读取Thread-4得到读锁，正在读取Thread-2释放读锁Thread-4释放读锁Thread-3得到写锁，正在写入Thread-3释放写锁Thread-5得到读锁，正在读取Thread-5释放读锁 锁的升降级 1234567891011121314151617181920212223242526272829303132public class CachedData &#123; Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; //在获取写锁之前，必须首先释放读锁。 rwl.readLock().unlock(); rwl.writeLock().lock(); try &#123; //这里需要再次判断数据的有效性,因为在我们释放读锁和获取写锁的空隙之内，可能有其他线程修改了数据。 if (!cacheValid) &#123; data = new Object(); cacheValid = true; &#125; //在不释放写锁的情况下，直接获取读锁，这就是读写锁的降级。 rwl.readLock().lock(); &#125; finally &#123; //释放了写锁，但是依然持有读锁 rwl.writeLock().unlock(); &#125; &#125; try &#123; System.out.println(data); &#125; finally &#123; //释放读锁 rwl.readLock().unlock(); &#125; &#125;&#125; 只有一处修改数据的代码，后面都是读取，如果一直使用写锁的话，就不能让多个线程同时来读取了，这个时候利用锁的降级，可以提高整体性能。 支持锁的降级，不支持升级 ReentrantReadWriteLock不支持读锁升级到写锁。 不可能有读锁和写锁同时持有的情况，升级写锁的过程中，需要等到所有的读锁都释放才能升级。另一种特殊情况，线程A、B都想升级到写锁，对于A而言，它需要等待其他线程(包括B)释放读锁，而线程B也是如此，则会发生死锁。 3.9 自旋锁 非自旋锁和自旋锁最大的区别，如果它遇到拿不到锁的情况，它会把线程阻塞，直到被唤醒；而自旋锁会不停地尝试。 自旋锁的好处 自旋锁用循环去不停地尝试获取锁，让线程始终处于Runnable状态，节省了线程切换带来的开销。 自己实现可重入的自旋锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ReentrantSpinLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); // 重入次数 private int count = 0; public void lock() &#123; Thread currentThread = Thread.currentThread(); if (currentThread == owner.get()) &#123; ++count; return; &#125; // 自旋获取锁 while (!owner.compareAndSet(null, currentThread)) &#123; System.out.println(\"自旋了！\"); &#125; &#125; public void unlock() &#123; Thread currentThread = Thread.currentThread(); // 只有持有锁的线程才能解锁 if (currentThread == owner.get()) &#123; if (count &gt; 0) &#123; --count; &#125; else &#123; // 此处无需CAS操作，因为没有竞争，因为只有线程持有者才能解锁 owner.set(null); &#125; &#125; &#125; public static void main(String[] args) &#123; ReentrantSpinLock spinLock = new ReentrantSpinLock(); Runnable runnable = new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \"开始尝试获取自旋锁\"); spinLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"获取到了自旋锁\"); Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; spinLock.unlock(); System.out.println(Thread.currentThread().getName() + \"释放了了自旋锁\"); &#125; &#125; &#125;; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); &#125;&#125; 运行结果： 123456789101112Thread-1开始尝试获取自旋锁Thread-0开始尝试获取自旋锁Thread-1获取到了自旋锁自旋了！自旋了！自旋了！......自旋了！自旋了！Thread-0获取到了自旋锁Thread-1释放了了自旋锁Thread-0释放了了自旋锁 缺点 虽然避免了线程切换的开销，但带来了新的开销，因为它需要不停地去尝试获取锁。 适用场景 自旋锁适用于并发度不是特别高，以及临界区比较短小的情况，这样可以避免线程切换来提高效率。可是如果临界区很大，线程一旦拿到锁，很久才会释放的话，那就不适合自旋锁，因为自旋会一直占用CPU却无法拿到锁，白白消耗资源。 3.10 JVM对锁的优化 自适应的自旋锁 自旋的缺点在于如果自旋时间过长，那么性能开销很大，浪费CPU资源。自适应意味着自旋的时间不再固定，而是根据最近自旋尝试的成功率、失败率，以及当前锁的拥有者的状态等多种因素来共同决定。如：最近尝试自旋获取某一把锁成功了，那么下次可能还会继续使用自旋，并且允许自旋更长时间；但如果最近自旋获取某一把锁失败了，那么可能会省略掉自旋的过程，以便减少无用的自旋，提高效率。 锁消除 123456@Overridepublic synchronized StringBuffer append(Object obj) &#123; toStringCache = null; super.append(String.valueOf(obj)); return this;&#125; 这个方法是被synchronized修饰的同步方法，因为它可能会被多个线程同时使用。但在大多数情况下，它只会在一个线程内使用，如果编译器能确定这个StringBuffer只会在一个线程内使用，那么编译器便会做出优化，把synchronized消除，省去加锁和解锁，以便增加整体的效率。 锁粗化 如果释放了锁，紧接着什么都没做，又重新获取锁，如： 12345678public void lockCoarsening() &#123; synchronized (this) &#123; //do something &#125; synchronized (this) &#123; //do something &#125;&#125; 可以把同步区域扩大，即最开始加一次锁，并且在最后直接解锁，减少性能开销。 如果在循环中也这样做，会导致其他线程长时间无法获得锁。锁粗化的功能默认打开，用-XX:-EliminateLocks可以关闭该功能。 12345for (int i = 0; i &lt; 1000; i++) &#123; synchronized (this) &#123; //do something &#125;&#125; 偏向锁/轻量级锁/重量级锁 这三种锁是特指synchronized锁的状态的，通过对象头中的mark word来表明锁的状态。 偏向锁 这把锁自始至终不存在竞争，那么没必要上锁，只要打个标记就行了。一个对象被初始化后，如果还没有任何线程来获取它的锁，它就是可偏向的，当第一个线程来访问它尝试获取锁的时候，它就记录下来这个线程，如果后面尝试获取锁的线程正是这个偏向锁的拥有者，就可以直接获取锁，开销小。 轻量级锁 synchronized中的代码块是被多个线程交替执行的，也就是不存在实际的竞争，或者只有短时间的竞争，用CAS就可以解决。轻量级锁指当锁原来是偏向锁的时候，被另一线程所访问，说明存在竞争，那么偏向锁升级为轻量级锁，线程会通过自旋的方式尝试获取锁，不会阻塞。 重量级锁 当多个线程直接有实际竞争，并且锁竞争时间比较长的时候，此时偏向锁和轻量级锁都不能满足需求，锁就会膨胀为重量级锁，会让其他申请却拿不到锁的线程进入阻塞状态。 3.10 HashMap为什么是线程不安全的？ 扩容期间取出的值不准确 HashMap扩容期间，会新建一个新的空数组，并用旧的项填充到这个新的数组中。如果这个填充的过程中，如果有线程取值，很可能会取到null值。 同时put碰撞导致数据丢失 如果有多个线程同时put，而且恰好两个put的key是一样的，它们发生了碰撞，也就是根据hash值计算出来的bucket位置一样，并且两个线程又同时判断该位置是空的，可以写入，所以这两个线程的两个不同的value便会添加到数组的同一位置，就丢失了一个数据。 可见性问题 线程1给某个key放入了一个新值，那么线程2在获取对应的key的值的时候，它的可见性是无法保证的。 死循环造成CPU100% 在扩容的时候，也就是内部新建新的HashMap的时候，扩容的逻辑会反转散列桶中的节点顺序，当多个线程同时进行扩容的时候，如果两个线程同时反转的话，便可能形成一个循环，并且这种循环是链表的循环，相当于A节点指向B节点，B节点又指回A节点，在下一次想要获取该key所对应的value的时候，便会在遍历链表的时候发生永远无法遍历结束的情况。 3.11 为什么Map桶中超过8个才转为红黑树？最开始的Map是空的，因为里面没有任何元素，往里放元素时会计算hash值，计算之后，第1个个value会占用一个桶(也称为槽点)位置，后续经过计算键值key计算hash值得到插入的数组索引i相同，那么会使用链表的形式往后延长，俗称拉链法。当链表长度大于或等于阈值(默认为8)，且数组长度大于或等于MIN_TREEIFY_CAPACITY(默认64)时，就会把链表转为红黑树。当红黑树的节点小于或等于6个以后，又会恢复为链表形态。 链表查找时间复杂度：O(n) 红黑树查找时间复杂度：O(log(n)) 单个TreeNode需要占用的空间大约是Node的两倍 时间与空间的平衡 如果hash计算结果离散的好，各个值都均匀分配，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为8时，概率仅为0.00000006，小于千万分之一概率，通常情况下并不会发生链表向红黑树的转换。 链表长度为8转为红黑树的设计，为了防止自定义实现了不好的hash算法导致链表长度过长，从而导致查询效率低。 3.12 Hashtable与ConcurrentHashMap的区别 出现版本不同 Hashtable在JDK1.0就存在了，并在JDK1.2实现了Map接口；ConcurrentHashMap在JDK1.5中才出现。 实现线程安全的方式不同 Hashtable通过synchronized关键字实现线程安全；ConcurrentHashMap利用了CAS+synchronized+Node(volatile)。 性能不同 随着线程数量的增加，Hashtable性能会急剧下降，每一次修改会锁住整个对象，而其他线程在此期间不能操作，还会带来额外的上下文切换；ConcurrentHashMap只会对一部分上锁而不是全部都上锁。 迭代时的修改不同 Hashtable(包括HashMap)不允许在迭代期间修改内容，否则会抛出ConcurrentModificationException异常，ConcurrentHashMap不会。 3.13 CopyOnWriteArrayListArrayList LinkedList 线程安全：Vector Collections.synchronized() Vector内部使用synchronized来保证线程安全，并且锁的粒度比较大，都是方法级别的锁，在并发高的时候，很容易发生竞争，并发效率相对较低。 适用场景： 读操作可以尽可能的快，而写即使慢一些也没关系 读多写少 读写规则： 读写锁的思想是：读读共享，其他都互斥，因为读操作不会修改原有的数据，因此并发读不会有安全问题；而写操作发生时，不允许读和写操作加入。CopyOnWriteArrayList读取是完全不用加锁的，并且写入也不会阻塞读取操作，也就是说可以在写入的同时进行读取，只有写入和写入之间需要进行同步，也就是不允许多个写入同时发生，但可以在写入时允许读取发生。 特点： CopyOnWrite 当容器需要被修改的时候，不直接修改当前容器，而是先将当前容器进行Copy，复制出一个新容器，然后修改新的容器，完成修改之后，再将容器的引用指向新的容器。读写分离的思想，读和写使用不同的容器。 迭代期间允许修改集合内容 ArrayList源码里的ListItr的next()方法中有一个checkForComodification()方法： 1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; modCount是保存修改次数，每次调用add、remove时都会增加，expectedComodification是迭代器的变量，创建迭代器时会初始化并记录当时的modCount，后面迭代期间如果发现modCount和expectedModCount不一致，就会抛出异常。CopyOnWriteArrayList的迭代器在迭代时，迭代器使用的依然是原数组，只不过迭代器的内容可能已经过时了。CopyOnWrite的迭代器一旦被建立，如果往之前的CopyOnWriteArrayList对象中去新增元素，在迭代器中既不会显示出元素的变更情况，同时也不会报错。 缺点： 内存占用问题 在元素较多或者复杂的情况下，复制的开销很大 数据一致性问题 由于CopyOnWrite容器的修改是先修改副本，所以这次修改对于其他线程来说，并不是实时能看到的，只有在修改完之后才能体现出来。 源码分析： 数据结构 1234567891011121314151617181920212223/** 可重入锁对象 */final transient ReentrantLock lock = new ReentrantLock();/** CopyOnWriteArrayList底层由数组实现，volatile修饰，保证数组的可见性 */private transient volatile Object[] array;/*** 得到数组*/final Object[] getArray() &#123; return array;&#125;/*** 设置数组*/final void setArray(Object[] a) &#123; array = a;&#125; /*** 初始化CopyOnWriteArrayList相当于初始化数组*/public CopyOnWriteArrayList() &#123; setArray(new Object[0]);&#125; add()方法 12345678910111213141516171819public boolean add(E e) &#123; // 加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 得到原数组的长度和元素 Object[] elements = getArray(); int len = elements.length; // 复制出一个新数组 Object[] newElements = Arrays.copyOf(elements, len + 1); // 添加时，将新元素添加到新数组中 newElements[len] = e; // 将volatile Object[] array 的指向替换成新数组 setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 在添加的时候首先上锁，并复制一个新数组，增加操作在新数组上完成，然后将array指向到新数组，最后解锁。上面的步骤实现了CopyOnWrite的思想：写操作是在原来容器的拷贝上进行的，并且在读取数据的时候不会锁住list。如果对容器拷贝操作的过程中有新的读线程进来，那么读到的还是旧的数据，因为那个时候对象的引用还没有被更改。 迭代器 COWIterator 类 1234private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements;&#125; snapshot：数组的快照，即创建迭代器那个时刻的数组情况 cursor：迭代器的游标 迭代器在被构建的时候，会把当时的elements赋值给snapshot，而之后的迭代器所有的操作都基于snapshot数组进行的，比如： 12345public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++];&#125; 可以看到，返回的内容是snapshot对象，所以，后续就算原数组被修改，这样snapshot既不会感知到，也不会受影响，执行迭代操作不需要加锁，也不会因此抛出异常。迭代器返回的结果，和创建迭代器的时候内容一致。 4.阻塞队列4.1 什么是阻塞队列？BlockingQueue，是一个接口，继承了Queue接口，是队列的一种，是线程安全的。 主要并发队列关系图 阻塞队列典型代表就是BlockingQueue接口的实现类，分别是ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、DelayQueue、PriorityBlockingQueue和LinkedTransferQueue。非阻塞队列的典型代表是ConcurrentLinkedQueue，这个类不会让线程阻塞，利用CAS保证线程安全。 Deque为双端队列，它从头和尾都能添加和删除元素；而普通的Queue只能从一端进入，另一端出去。 特点 阻塞功能使得生产者和消费者两端的能力得以平衡，当有任何一端速度过快时，阻塞队列便会把过快的速度给降下来。 take方法 获取并移除队列的头结点，在队列里有数据时可以正常移除，一旦执行take方法的时候，队列无数据，则阻塞，直到队列有数据。 put方法 put方法插入元素时，如果队列已满，那么就无法继续插入，则阻塞，直到队列有了空闲空间。 是否有界(容量有多大)无界队列意味着里面可以容纳非常多的元素，如LinkedBlockingQueue的上限是Integer.MAX_VALUE，约为2^31。有些阻塞队列是有界的，如ArrayBlockingQueue如果容量满了，也不会扩容，所以一旦满了，就无法再往里面放数据了。 4.2 阻塞队列常用方法第一组：无法正常执行的情况下抛出异常；第二组：在无法正常执行的情况下不抛出异常，但会用返回值提示运行失败；第三组：在遇到特殊情况时让线程阻塞，等到可以运行再继续执行。 带有超时时间的offer和poll 1offer(E e, long timeout, TimeUnit unit) 插入不成功时会等待指定的超时时间，时间到了依然没有插入成功，就会返回false 1poll(long timeout, TimeUnit unit) 如果移除时，如果队列是空的就会进行等待，超时时间到了，如果队列中依然没有元素可供移除，则会返回null为提示 4.3 几种常见的阻塞队列 ArrayBlockingQueue 有界队列，其内部是用数组存储元素的，利用ReentrantLock实现线程安全，在创建它的时候就需要指定它的容量，之后不可以再扩容了，可以在构造函数中指定是否公平。 非公平：存在插队的可能；公平：等待最长时间的线程会被优先处理 LinkedBlockingQueue 内部用链表实现，不指定容量时默认为Integer.MAX_VALUE，被称为无界队列。 SynchronousQueue 容量为0，所以没有地方来暂存元素，导致每次取数据都要先阻塞，直到有数据被放入；同理，每次放数据也会阻塞，直到有消费者来取。Synchronous的容量不是1而是0，它不需要去持有元素，它所做的就是直接传递。 PriorityBlockingQueue 支持优先级的无界阻塞队列，可以通过自定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。同时插入的对象必须是可比较大小的，即Comparable的，否则会抛出ClassCastException。 DelayQueue 具有”延迟”的功能，可以设定让队列中的任务延迟多久之后执行，如”30 分钟后未付款自动取消订单”。它是无界队列，放入的元素必须实现Delayed接口，而Delayed接口又继承了Comparable接口，拥有了比较和排序的能力。元素会根据延迟时间的长短放到队列的不同位置，越靠近头队列代表越早过期。 4.4 阻塞队列和非阻塞队列的并发安全原理 ArrayBlockingQueue 12345678// 用于存放元素的数组final Object[] items;// 下一次读取操作的位置int takeIndex;// 下一次写入操作的位置int putIndex;// 队列中的元素数量int count; 1234// 以下3个是控制并发用的工具final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull; 这三个变量非常关键，第一个是ReentrantLock，下面两个Condition是由ReentrantLock产生出来的。读操作和写操作都需要先获取到ReentrantLock独占锁才能进行下一步操作。进行读操作时如果队列为空，线程就会进入到读线程专属的noEmpty的Condition的队列中去排队，等待写线程写入新的元素；同理如果队列已满，写操作的线程会进入到写线程专属的notFull队列中去排队，等待读线程将队列元素移除并腾出空间。 put方法： 123456789101112public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; LinkedBlockingQueue的内部有两把锁，分别锁住队列的头和尾，比共用一把锁的效率高。 非阻塞队列ConcurrentLinkedQueue offer方法： 12345678910111213141516171819202122232425262728public boolean offer(E e) &#123; checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; // p is last node if (p.casNext(null, newNode)) &#123; // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become \"live\". if (p != t) // hop two nodes at a time casTail(t, newNode); // Failure is OK. return true; &#125; // Lost CAS race to another thread; re-read next &#125; else if (p == q) // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; else // Check for tail updates after two hops. p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 整个是以一个大的for循环，p.casNext()方法 123boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);&#125; 这里运用了UNSAFE.compareAndSwapObject方法来完成CAS操作，而compareAndSwapObject是一个native方法，最终会利用CPU的CAS指令保证其不可中断。非阻塞队列ConcurrentLinkedQueue使用CAS非阻塞算法+不停重试，来实现线程安全，适合用在不需要阻塞功能，且并发不是特别剧烈的场景。 4.5 如何选择合适的阻塞队列？ 线程池对于阻塞队列的选择 从以下5个角度考虑，来选择合适的阻塞队列。 功能 是否需要阻塞队列来排序，如优先级排序、优先执行等。 容量 是否需要有存储要求，还是只需要”直接传递”。 能否扩容 业务可能有高峰期、低谷期，如果需要动态扩容，就不能选择ArrayBlockingQueue。 内存结构 如ArrayBlockingQueue的内部结构是”数组”的形式，LinkedBlockingQueue的内部是链表实现的，ArrayBlockingQueue没有链表所需要的”节点”，空间链表利用率更高。 性能 如LinkedBlockingQueue拥有两把锁，操作粒度更细，并发程度高的时候，相对于只有一把锁的ArrayBlockingQueue性能会更好。SynchronousQueue性能往往优于其他实现，因为它只需要”直接传递”，而不需要存储的过程。 5.原子类5.1 原子类如何利用CAS保证线程安全？原子类的作用和锁有类似之处，都是为了保证并发情况下线程安全。 粒度更细：原子变量可以把竞争范围缩小到变量级别，通常情况下，锁的粒度都要大于原子变量的粒度。 效率更高：除高度竞争的情况下，原子类的效率通常比使用同步互斥锁的效率更高，因为原子类利用了CAS操作，不会阻塞线程。 6类原子类纵览 类型 具体类 特点 Atomic* 基本类型原子类 AtomicInteger、AtomicLong、AtomicBoolean Atomic*Array 数组类型原子类 AtomicIntegerArray(整形数组原子类)、AtomicLongArray(长整形数组原子类)、AtomicReferenceArray(引用类型数组原子类) Atomic*Reference 引用类型原子类 AtomicReference、AtomicStampedReference(对AtomicReference的升级，在此基础上还加了时间戳，用于解决CAS的ABA问题)、AtomicMarkableReference(和AtomicReference类似，多了一个绑定的布尔值，可以用于表示该对象已删除等场景) AtomicInteger可以让一个整数保证原子形，AtomicReference可以让一个对象保证原子性。 Atomic*FieldUpdater升级类型原子类 AtomicIntegerFieldUpdater(原子更新整形的更新器)、AtomicLongFieldUpdater(原子更新长整形的更新器)、AtomicReferenceFieldUpdater(原子更新引用的更新器) 可以把已经声明的变量进行升级，使其拥有CAS操作的能力。 Adder累加器 LongAdder、DoubleAdder Accumulator积累器 LongAccumulator、DoubleAccumulator 12345678910111213141516171819202122232425262728293031public class AtomicIntegerFieldUpdaterDemo implements Runnable &#123; public static class Score &#123; volatile int score; &#125; static Score math; static Score computer; static AtomicIntegerFieldUpdater&lt;Score&gt; scoreUpdater = AtomicIntegerFieldUpdater.newUpdater(Score.class, \"score\"); @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; computer.score++; scoreUpdater.getAndIncrement(math); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; math = new Score(); computer = new Score(); AtomicIntegerFieldUpdaterDemo updaterDemo = new AtomicIntegerFieldUpdaterDemo(); Thread thread1 = new Thread(updaterDemo); Thread thread2 = new Thread(updaterDemo); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(\"普通变量的结果：\"+ computer.score); System.out.println(\"升级后的结果：\"+ math.score); &#125;&#125; 以AtomicInteger为例，分析其如何利用CAS实现原子操作？ getAndAdd()方法 1234//JDK 1.8实现public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; Unsafe类 Unsafe类是CAS的核心类。Java无法直接访问底层操作系统，而需要通过native方法实现。在JDK中有一个Unsafe类，提供了硬件级别的原子操作，可以利用它直接操作内存数据。 1234567891011121314public class AtomicInteger extends Number implements java.io.Serializable &#123; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; public final int get() &#123;return value;&#125; ...&#125; static代码块会在类加载的时候执行，执行时会调用Unsafe的objectFieldOffset方法，从而得到当前这个原子类的value的偏移量(在内存中的偏移地址)，并且赋给valueOffset变量，并且赋值给valueOffset变量，Unsafe根据内存偏移地址获取数据的原值，这样就可以通过Unsafe来实现CAS了。 value是用volatile修饰的，它就是我们原子类存储的值的变量，由于它被volatile修饰，我们就可以保证在多线程之间看到的value是同一份，保证了可见性。 Unsafe的getAndAddInt方法： 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2);//获取var1中的var2偏移处的值 var1:当前原子类 var2:最开始获取到的offset &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//var1:object 当前原子类对象 var2:offset 即偏移量，借助它就可以获取到value的数值 var3:expectedValue 代表\"期望值\"，传入的是刚才获取到的var5 var5+var4:newValue 是希望修改的数值，等于之前取到的数值var5+var4，var4是希望原子类所改变的数值，如+1或-1。 return var5;&#125; compareAndSwapInt方法的作用：判断如果现在原子类里的value的值和之前获取到的var5相等的话，那么就把计算出来的var5+var4给更新上去。一旦CAS操作成功，就会退出这个while循环，但也有可能操作失败。如果操作失败就意味着在获取到var之后，并在CAS操作之前，value的数值已经发生变化了，证明有其他线程修改过这个变量。会再次执行循环体里面的代码，重新获取var5，即获取最新的原子变量的数值，并再次利用CAS尝试更新，直到更新成功。 5.2 AtomicInteger在高并发下性能不好，如何解决？为什么？123456789101112131415161718192021222324252627282930public class AtomicLongDemo &#123; static class Task implements Runnable &#123; private final AtomicLong counter; public Task(AtomicLong counter) &#123; this.counter = counter; &#125; @Override public void run() &#123; counter.incrementAndGet(); System.out.println(Thread.currentThread().getName()+\"...\"+counter.get()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AtomicLong counter = new AtomicLong(0); ExecutorService poolExecutor = new ThreadPoolExecutor(20, 40, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); StopWatch stopWatch = new StopWatch(); stopWatch.start(); for (int i = 0; i &lt; 100; i++) &#123; poolExecutor.submit(new Task(counter)); &#125; Thread.sleep(2000); System.out.println(\"result:\"+counter.get()); stopWatch.stop(); System.out.println(stopWatch.getTotalTimeMillis()); &#125;&#125; 每一个线程是运行在自己的core中的，并且它们都有一个本地内存是自己独用的。在本地内存下方有两个CPU核心共用的共享内存。对于AtomicLong内部的value属性而言，它是被volatile修饰的，需要保证自身可见性。每次它的数值变化的时候，都需要进行flush到共享内存和refresh到本地内存。 flush和refresh操作耗费了很多资源，而且CAS也会经常失败。 LongAdder LongAdder引入了分段累加的概念，内部一共有两个参数参与计数： base，是一个变量，用在竞争不激烈的情况下，可以直接把来家结果改到base变量上。 Cell[]，是一个数组，一旦竞争激烈，各个线程会分散累加到自己所对应的那个Cell[]数组的某一个对象中，而大家不会共用同一个。 竞争激烈的时候，LongAdder会通过计算出每个线程的hash值来给线程分配到不同的Cell上去，每个Cell相当于是一个独立的计数器，Cell之间并不存在竞争，所以自加过程中，大大减少了flush和refresh，以及降低了冲突的概率。空间换时间。 1234567891011public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 如何选择 如何仅仅是需要用到加和减操作的场景，那么可以直接使用LongAdder。 如果需要利用CAS比如compareAndSet等操作的话，就需要使用AtomicLong来完成。 5.3 原子类与volatile 线程1和线程2分别在不同的CPU核心，每一个核心都有自己的本地内存，并且在下方也有它们的共享内存。在变量加上volatile关键字，线程1的更改会被flush到共享内存，然后又被refresh到线程2的本地内存，保证了可见性。 但对于value++这种，即使用volatile修饰value也是不能保证线程安全的，无法保证其原子性。此时可以使用原子类。 原子类和volatile的使用场景 通常情况下，volatile可以用来修饰boolean类型的标记位，对于标记位来讲，直接的赋值操作本身就具有原子性，再加上volatile保证了可见性，那么就是线程安全的了。而对于会被多个线程同时操作的计数器counter的场景，即不仅仅是赋值操作，还需要读取当前值，然后在此基础上进行一定的修改，再把它给赋值回去，此时需要使用原子类保证线程安全。 5.4 Adder与Accumlator的区别高并发场景下AtomicLong CAS冲突概率大，会导致经常自旋。而LongAdder引入了分段锁的概念，竞争不激烈的时候，所有线程都是通过CAS对同一个Base变量进行修改，但竞争激烈的时候，LongAdder会把不同线程对应到不同的Cell上进行修改，降低了冲突的概率。 LongAccumulator就是个更通用版本的Adder，提供了自定义的函数操作。 12345678910111213public class LongAccumulatorDemo &#123; public static void main(String[] args) throws InterruptedException &#123; LongAccumulator accumulator = new LongAccumulator((x, y) -&gt; x + y, 0); ExecutorService executorService = new ThreadPoolExecutor(8, 16, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); IntStream.range(1,10).forEach(i-&gt;executorService.submit(()-&gt;&#123; accumulator.accumulate(i); System.out.println(Thread.currentThread().getName()+\"...\"+accumulator.get()); &#125;)); Thread.sleep(2000); System.out.println(accumulator.getThenReset()); &#125;&#125; 自定义函数： 1234LongAccumulator counter = new LongAccumulator((x, y) -&gt; x + y, 0);LongAccumulator result = new LongAccumulator((x, y) -&gt; x * y, 0);LongAccumulator min = new LongAccumulator((x, y) -&gt; Math.min(x, y), 0);LongAccumulator max = new LongAccumulator((x, y) -&gt; Math.max(x, y), 0); 适用场景 需要大量的计算，并且当需要并行计算的时候。 计算的执行顺序并不关键。 6.ThreadLocal6.1 ThreadLocal适用场景 场景1 保存每个线程独享的对象，为每个线程都创建一个副本，这样每个线程都可以修改自己拥有的副本，而不会影响其他线程的副本，确保了线程安全。 这种场景下，每个Thread内都有自己的实例副本，且该副本只能由当前Thread访问到并使用，相当于每个线程内部的本地变量。因为每个线程独享副本，而不是共用的，所以不存在多线程间共享的问题。 这种场景通常用于保存线程不安全的工具类，如SimpleDateFormat。 1234567891011121314151617181920212223242526public class ThreadLocalDemo05 &#123; static ThreadLocal&lt;SimpleDateFormat&gt; formatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(\"mm:ss\"); &#125; &#125;; public static ExecutorService executorService = new ThreadPoolExecutor(16, 32, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); public String date(int seconds) &#123; Date date = new Date(1000 * seconds); SimpleDateFormat simpleDateFormat = formatThreadLocal.get(); return simpleDateFormat.format(date); &#125; public static void main(String[] args) throws InterruptedException &#123; IntStream.range(1, 1000).forEach(i -&gt; executorService.submit(() -&gt; &#123; String date = new ThreadLocalDemo05().date(i); System.out.println(Thread.currentThread().getName() + \":\" + date); &#125;)); Thread.sleep(2000); executorService.shutdown(); &#125;&#125; 场景2 每个线程内需要独立保存信息，以便其他方法更方便的获取该信息的场景。每个线程获取到的信息可能都是不一样的，前面执行的方法保存了信息之后，后续方法可以通过ThreadLocal直接获取到，避免了传参，类似于全局变量的概念。 每个线程内需要保存类似于全局变量的信息(列如拦截器中获取的用户信息)，可以让不同方法直接使用，避免参数传递的麻烦却不想被多线程共享(因为不同线程获取到的用户信息不一样)。 例如，用ThreadLocal保存一些业务内容(用户权限信息)，这些信息在同一个线程内相同，但在不同的线程使用的业务内容是不相同的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ThreadLocalDemo07 &#123; public static void main(String[] args) &#123; new Service1().service1(); &#125;&#125;class User &#123; String username; public User() &#123;&#125; public User(String username) &#123; this.username = username; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125;&#125;class userContextHolder &#123; public static ThreadLocal&lt;User&gt; holder = new ThreadLocal&lt;&gt;();&#125;class Service1 &#123; public void service1() &#123; User user = new User(\"张三\"); userContextHolder.holder.set(user); new Service2().service2(); &#125;&#125;class Service2 &#123; public void service2() &#123; User user = userContextHolder.holder.get(); System.out.println(\"Service2拿到用户名：\" + user.getUsername()); new Service3().service3(); &#125;&#125;class Service3 &#123; public void service3() &#123; User user = userContextHolder.holder.get(); System.out.println(\"Service3拿到用户名：\" + user.getUsername()); userContextHolder.holder.remove(); &#125;&#125; 6.2 ThreadLocal是用来解决共享资源的多线程访问的问题吗？不是，虽然ThreadLocal是用于解决多线程情况下的线程安全问题，但其资源并不是共享的，而是每个线程独占的。 如果把放到ThreadLocal中的资源用static修饰，让它变为一个共享资源的话，那么即便使用ThreadLocal，同样有线程安全问题。 ThreadLocal和synchronized是什么关系？ ThreadLocal是通过让每个线程独享自己的副本，避免了资源的竞争。 synchronized主要用于临界资源的分配，在同一时刻限制最多只有一个线程能够访问该资源 相比于ThreadLocal而言，synchronized的效率会更低一些，但花费的内存也更少。但对于ThreadLocal而言，它还有不同的使用场景。比如避免传参。 6.3 ThreadLocal的结构Thread、ThreadLocal及ThreadLocalMap三者之间的关系 每个Thread对象中都持有一个ThreadLocalMap类型的成员变量，这个ThreadLocalMap自身类似一个Map，里面会有一个个key-value形式的，key就是ThreadLocal的引用，value就是希望ThreadLocal存储的内容。 get方法 1234567891011121314151617public T get() &#123; //获取到当前线程 Thread t = Thread.currentThread(); //获取到当前线程内的ThreadLocalMap对象，每个线程内都有一个ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) &#123; //获取ThreadLocalMap中的Entry对象并拿到value，每个线程内都有一个ThreadLocalMap对象 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; //如果线程内之前没创建过ThreadLocalMap，就创建 return setInitialValue();&#125; getMap方法 12345 ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125;ThreadLocal.ThreadLocalMap threadLocals = null; set方法 1234567891011public void set(T value) &#123; //获取到当前线程 Thread t = Thread.currentThread(); //获取当前线程内的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) //第一个参数this：当前ThreadLocal的引用，key的类型则是ThreadLocal；第二个参数即为所传入的value map.set(this, value); else createMap(t, value);&#125; ThreadLocalMap类，即Thread.threadLocals 123456789101112131415static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private static final int INITIAL_CAPACITY = 16; private Entry[] table; ......&#125; 在ThreadLocalMap中会有一个Entry类型的数组，名字叫table。可以理解为一个map，其键值对为： 键，当前的ThreadLocal 值，实际需要存储的变量，比如user用户对象或者simpleDateFormat对象 HashMap在面对hash冲突的时候，采用的是拉链法，它会先把对象hash到一个对应的格子中，如果有冲突就用链表的形式往下链；但ThreadLocalMap采用的是线性探测法，如果发生冲突，并不会用链表的形式往下链，而是会继续寻找下一个空的格子。 6.4 为何每次用完 ThreadLocal 都要调用 remove()？内存泄漏：当某一个对象不再有用的时候，占用的内存却不能被回收。 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry是extends WeakReference。弱引用的特点：如果这个对象只被弱引用关联，而没有任何强引用关联，那么这个对象就可以被回收，所以弱引用不会阻止GC。 但是这个Entry包含了一个对value的强引用。value=v这行代码就代表了强引用的发生。 Thread Ref → Current Thread → ThreadLocalMap → Entry → Value → 可能泄漏的value实例。 这条链路是随着线程的存在而一直存在，如果线程迟迟不会终止，那么当垃圾回收进行可达性分析的时候，这个value就是可达的，所以不会被回收。但与此同时可能已经完成了业务逻辑处理，不再需要这个value了，此时就发生了内存泄漏。 在执行ThreadLocal的set、remove、rehash等方法时，都会扫描key为null的Entry，如果发现某个Entry的key为null，则代表它所对应的value也没有作用了，所以就会把对应的value设置为null，这样，value对象就可以被正常回收了。但假设ThreadLocal已经不被使用了，那么实际上set、remove、rehash方法也不会被调用。 如何避免内存泄漏 调用 ThreadLocal 的 remove 方法。调用这个方法就可以删除对应的 value 对象，可以避免内存泄漏。 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 7.Future7.1 Callable和Runnable的不同 Runnable的不足 不能返回一个返回值 不能抛出checked Exception 123456789101112131415161718192021222324public class RunThrowException &#123; /** * 普通方法内可以 throw 异常，并在方法签名上声明 throws */ public void normalMethod() throws Exception &#123; throw new IOException(); &#125; Runnable runnable = new Runnable() &#123; /** * run方法上无法声明 throws 异常，且run方法内无法 throw 出 checked Exception，除非使用try catch进行处理 */ @Override public void run() &#123; try &#123; throw new IOException(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Runnable规定了run()方法的返回类型是void，而且没有声明抛出任何异常。所以，当实现并重写这个方法的时候，既不能改变返回值类型，也不能更改对于异常抛出的描述。 123public interface Runnable &#123; public abstract void run();&#125; Callable接口 call方法已经声明了throws Exception，前面还有一个V泛型的返回值。 123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; Callable和Runnable的不同之处 方法名：Callable规定的执行方法是call()，而Runnable规定的执行方法是run() 返回值：Callable的任务执行后有返回值，而Runnable的任务执行后是没有返回值的 抛出异常：call()方法可抛出异常，而run方法是不能抛出检查异常的 和Callable配合使用的Future类，通过Future可以了解任务的执行情况，或者取消任务的执行，还可获取任务的执行结果等。 7.2 Future的主要功能Future的作用 比如当做一定较耗时的任务时，可以把任务放到子线程去执行，再通过Future去控制子线程执行的过程，最后获取到计算结果。通过异步的思想，提高程序的运行效率。 Callable和Future的关系 Callable接口相比于Runnable可以通过Future类的get方法返回结果。因此，Future类相当于一个存储器，它存储了Callable的call方法的任务结果。 12345678910111213public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; get() 获取结果 获取任务执行的结果 当执行get的时候，任务已经执行完毕了。可以立刻返回，获取到任务执行的结果。 任务还未开始或任务正在执行中，调用get时，都会把当前线程阻塞，直到任务完成再把结果返回回来。 任务执行过程中抛出异常，调用get时，就会抛出ExecutionException，且无论执行call方法时里面抛出的异常类型是什么，在执行get方法时所获得的异常都是ExecutionException。 任务被取消了，如果任务被取消，调用get方法时则会抛出CancellationException。 任务超时，调用带延迟参数的get方法之后，如果call方法在规定时间内仍没有完成任务，get方法则会抛出TimeoutException，代表超时了。 123456789101112131415161718192021222324/* *一个Future的使用 */public class OneFuture &#123; static class CallableTask implements Callable&#123; @Override public Object call() throws Exception &#123; Thread.sleep(3000); return new Random().nextInt()+Thread.currentThread().getName(); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); Future future = executorService.submit(new CallableTask()); try &#123; System.out.println(future.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; executorService.shutdown(); &#125;&#125; isDone() 判断是否执行完毕 判断当前线程是否执行完毕，返回true代表已经执行完毕，返回false则代表还没完成。但这里如果返回true，并不代表这个任务是成功执行的，比如说任务执行到一半抛出了异常，仍然会返回true，所以isDone方法在返回true的时候，不代表这个任务是成功执行的，只代表它执行完毕了。 123456789101112131415161718192021222324252627282930313233public class GetException &#123; static class CallableTask implements Callable&#123; @Override public Object call() throws Exception &#123; throw new IllegalArgumentException(\"Callable抛出异常！\"); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(20); Future future = executorService.submit(new CallableTask()); try &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(i); Thread.sleep(500); &#125; System.out.println(future.isDone()); future.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;01234truejava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Callable抛出异常！ at java.util.concurrent.FutureTask.report(FutureTask.java:122)...... 这段代码的运行结果证明了： 即便任务抛出异常，isDone方法依然会返回true。 虽然call方法抛出的异常是IllegalArgumentException，但对于get而言，它抛出的异常依然是ExecutionException。 虽然在任务执行一开始就抛出了异常，但真正要等到执行get的时候，才看到了异常。 cancel 取消任务的执行 任务还未执行，任务会被正常取消，未来也不会被执行，返回true。 任务已经完成或被取消过，返回false。 任务正在执行，会根据传入的参数mayInterruptIfRunning，如果传入的参数是true，执行任务的线程会收到一个中断的信号。如果传入的是false，就代表不中断正在运行的任务，同时返回false。 true：明确知道这个任务能够处理中断 false：明确知道这个任务不能处理中断；不知道这个任务是否支持取消(是否能够响应中断)；如果这个任务一旦开始运行，就希望它完全的执行完毕。 isCancelled() 判断是否被取消 用FutureTask创建Future 12345678910111213141516171819202122232425public class FutureTaskDemo &#123; public static void main(String[] args) &#123; Task task = new Task(); FutureTask futureTask = new FutureTask(task); new Thread(futureTask).start(); try &#123; System.out.println(\"task运行结果：\"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Task implements Callable&#123; @Override public Object call() throws Exception &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在计算！\"); int sum = 0; for (int i = 0; i &lt; 100; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 7.3 Future注意点 当for循环批量获取Future的结果时容易block，get方法调用时应该使用timeout限制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class FutureDemo &#123; static class SlowTask implements Callable &#123; @Override public Object call() throws Exception &#123; Thread.sleep(5000); return \"速度慢的任务\" + Thread.currentThread().getName(); &#125; &#125; static class FastTask implements Callable &#123; @Override public Object call() throws Exception &#123; return \"速度快的任务\" + Thread.currentThread().getName(); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = new ThreadPoolExecutor(10, 10, 10, TimeUnit.MICROSECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); List&lt;Future&gt; futures = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 4; i++) &#123; Future future; if (i == 0 || i == 1) &#123; future = executorService.submit(new SlowTask()); &#125; else &#123; future = executorService.submit(new FastTask()); &#125; futures.add(future); &#125; for (int i = 0; i &lt; 4; i++) &#123; Future future = futures.get(i); try &#123; String result = (String)future.get(); System.out.println(result); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; executorService.shutdown(); &#125;&#125;速度慢的任务pool-1-thread-1速度慢的任务pool-1-thread-2速度快的任务pool-1-thread-3速度快的任务pool-1-thread-4 第三个任务量比较小，可以很快返回结果，紧接着第四个任务也会返回结果。但由于前两个任务速度很慢，所以get方法执行时，会卡在第一个任务上。所以，即使第三、四个任务很早就得到结果了，但在此使用for循环的方式去获取结果，依然无法及时获取第三、四个任务的结果。直到5秒后，第一个任务出结果了，我们才能获取到，紧接着获取剩下任务的结果。 此时可以使用Future的带超时参数的get(long timeout, TimeUnit unit)方法，如果在限定时间内没能返回结果，即抛出TimeoutException。 Future的生命周期不可后退 Future的生命周期不可后退，一旦完成了任务，它就永久停在了”已完成”的状态，不能重头再来，即不能让一个已经完成计算的Future再次重新执行任务。 Future产生新的线程了吗 Callable和Future本身并不能产生新的线程，它们需要借助其它的比如Thread类或者线程池才能执行任务。例如：在把Callable提交到线程池后，真正执行Callable的其实还是线程池中的线程，而线程池中的线程是由ThreadFactory产生的。 7.4 CountDownLatch、Completable 线程池实现 12345678910111213141516171819202122232425262728293031323334public class ThreadPoolDemo &#123; ExecutorService threadPool = Executors.newFixedThreadPool(3); public static void main(String[] args) throws InterruptedException &#123; ThreadPoolDemo threadPoolDemo = new ThreadPoolDemo(); System.out.println(threadPoolDemo.getPrices()); &#125; private Set&lt;Integer&gt; getPrices() throws InterruptedException &#123; Set&lt;Integer&gt; prices = Collections.synchronizedSet(new HashSet&lt;Integer&gt;()); threadPool.submit(new Task(123, prices)); threadPool.submit(new Task(456, prices)); threadPool.submit(new Task(789, prices)); Thread.sleep(3000); return prices; &#125; private class Task implements Runnable &#123; Integer productId; Set&lt;Integer&gt; prices; public Task(Integer productId, Set&lt;Integer&gt; prices) &#123; this.productId = productId; this.prices = prices; &#125; @Override public void run() &#123; int price=0; try &#123; Thread.sleep((long) (Math.random() * 4000)); price= (int) (Math.random() * 4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; prices.add(price); &#125; &#125;&#125; CountDownLatch 1234567891011121314151617181920212223242526272829303132333435363738394041public class CountDownLatchDemo &#123; ExecutorService threadPool = Executors.newFixedThreadPool(3); public static void main(String[] args) throws InterruptedException &#123; CountDownLatchDemo countDownLatchDemo = new CountDownLatchDemo(); System.out.println(countDownLatchDemo.getPrices()); &#125; private Set&lt;Integer&gt; getPrices() throws InterruptedException &#123; Set&lt;Integer&gt; prices = Collections.synchronizedSet(new HashSet&lt;Integer&gt;()); CountDownLatch countDownLatch = new CountDownLatch(3); threadPool.submit(new Task(123, prices, countDownLatch)); threadPool.submit(new Task(456, prices, countDownLatch)); threadPool.submit(new Task(789, prices, countDownLatch)); countDownLatch.await(3, TimeUnit.SECONDS); return prices; &#125; private class Task implements Runnable &#123; Integer productId; Set&lt;Integer&gt; prices; CountDownLatch countDownLatch; public Task(Integer productId, Set&lt;Integer&gt; prices, CountDownLatch countDownLatch) &#123; this.productId = productId; this.prices = prices; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; int price = 0; try &#123; Thread.sleep((long) (Math.random() * 4000)); price = (int) (Math.random() * 4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; prices.add(price); countDownLatch.countDown(); &#125; &#125;&#125; 执行countDownLatch.await(3, TimeUnit.SECONDS)等待时，如果三个任务都非常快速得执行完毕了，那么都已经执行了countDown方法，相当于把计数减1。如果有一个线程没有执行countDown方法，来不及在3秒内执行完毕，那么这个带超时参数的await方法也会在3秒以后，及时的放弃这一次等待，于是就把prices返回了。 CompletableFuture 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CompletableFutureDemo &#123; private class Task implements Runnable &#123; Integer productId; Set&lt;Integer&gt; prices; public Task(Integer productId, Set&lt;Integer&gt; prices) &#123; this.productId = productId; this.prices = prices; &#125; @Override public void run() &#123; int price = 0; try &#123; Thread.sleep((long)(Math.random() * 4000)); price = (int)(Math.random() * 4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; prices.add(price); &#125; &#125; private Set&lt;Integer&gt; getPrices() &#123; Set&lt;Integer&gt; prices = Collections.synchronizedSet(new HashSet&lt;Integer&gt;()); CompletableFuture&lt;Void&gt; task1 = CompletableFuture.runAsync(new Task(123, prices)); CompletableFuture&lt;Void&gt; task2 = CompletableFuture.runAsync(new Task(456, prices)); CompletableFuture&lt;Void&gt; task3 = CompletableFuture.runAsync(new Task(789, prices)); CompletableFuture&lt;Void&gt; allTasks = CompletableFuture.allOf(task1, task2, task3); try &#123; allTasks.get(3, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; return prices; &#125; public static void main(String[] args) &#123; CompletableFutureDemo completableFutureDemo = new CompletableFutureDemo(); System.out.println(completableFutureDemo.getPrices()); &#125;&#125; CompletableFuture的runAsync()方法，这个方法会异步的去执行任务。 8.线程协作8.1 信号量 控制需要限制并发访问量的资源。 使用流程 初始化一个信号量，并传入许可证的数量。public Semaphore(int permits, boolean fair)，传入两个参数，第一个参数是许可证的数量，另一个参数是是否公平，如果为true，代表是公平的策略，会把之前已经在等待的线程放入到队列中，当有新的许可证时，会按照顺序发放；如果为false，则代表非公平策略，也就有可能插队。 在调用慢服务之前，线程调用acquire()或者acquireUninterruptibly()获取许可证。如果此时信号量没有剩余的许可证，那么线程会等在acquire()的这一行代码中，不会进一步执行下面调用服务的方法。 acquire()和acquireUninterruptibly()的区别：是否能够中断。acquire()支持中断，即在获取信号量期间，假如这个线程被中断了，那么它就会跳出acquire()，不再继续尝试获取了，而acquireUninterruptibly()方法是不会中断的。 任务执行完毕之后，调用release()释放许可证。 其他的主要方法 public boolean tryAcquire() 尝试获取许可证，获取不到不会阻塞，可以去做其他事。 public boolean tryAcquire(long timeout, TimeUnit unit) 超时时间到，依然获取不到许可证，认为获取失败，返回false。 availablePermits() 查询可用许可证的数量，返回一个整形的结果。 12345678910111213141516171819202122232425262728293031323334353637public class SemaphoreDemo2 &#123; static Semaphore semaphore = new Semaphore(5); static ThreadLocal&lt;StopWatch&gt; stopWatchThreadLocal = ThreadLocal.withInitial(() -&gt; new StopWatch()); private static class Task implements Runnable &#123; @Override public void run() &#123; try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"获取到许可证，开始执行任务！\"); StopWatch stopWatch = stopWatchThreadLocal.get(); stopWatch.start(); try &#123; Thread.sleep(3000); stopWatch.stop(); System.out.println(\"慢服务执行完毕，耗时：\" + stopWatch.getTotalTimeMillis() + \"---\" + Thread.currentThread().getName() + \"释放了许可证！\"); semaphore.release(); stopWatchThreadLocal.remove(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = new ThreadPoolExecutor(50, 50, 5, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 1000; i++) &#123; executorService.submit(new Task()); &#125; executorService.shutdown(); &#125;&#125; 特殊用法：一次获取或释放多个许可证 semphore.acquire(2) semaphore.release(3) 注意点 获取和释放的许可证数量尽量保持一致 在初始化时可以设置公平性，true会让它更公平，false则会让总的吞吐量更高 信号量是支持跨线程、跨线程池的，并且并不是哪个线程获得的许可证，就必须由这个线程去释放，对于获取和释放许可证的线程是没有要求的。 8.2 CountDownLatch 是如何安排线程执行顺序的？ 主要方法 构造函数 public CountDownLatch(int count){ } count是需要倒数的值 await() 调用await()方法的线程开始等待，直到倒数结束，也就是count值为0的时候才会继续执行。 await(long timeout, TimeUnit unit) 和await()类似，但这里可以设置超时时间，如果超时就不等待了。 countDown() 把数值倒数1，也就是将count值减1，直到减为0时，之前等待的线程会被唤起。 用法 12345678910111213141516171819202122232425262728293031323334public class RunDemo3 &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = new ThreadPoolExecutor(5, 5, 5, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); CountDownLatch downLatch1 = new CountDownLatch(5); CountDownLatch downLatch2 = new CountDownLatch(1); for (int i = 0; i &lt; 5; i++) &#123; int finalI = i + 1; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(finalI + \"号运动员准备完毕，等待裁判员的发令枪\"); downLatch2.await(); Thread.sleep((long)(Math.random() * 10000)); System.out.println(finalI + \"号运动员完成了比赛\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; downLatch1.countDown(); &#125; &#125; &#125;; executorService.submit(runnable); &#125; Thread.sleep(5000); System.out.println(\"5秒准备时间已过，发令枪响，比赛开始！\"); downLatch2.countDown(); System.out.println(\"等待5个运动员都跑完....\"); downLatch1.await(); System.out.println(\"所有人都跑完了，比赛结束\"); executorService.shutdown(); &#125;&#125; 注意点 CountDownLatch是不能够重用的，比如已经完成了倒数，不可以在下一次继续去重新倒数。可以考虑使用CyclicBarrier或创建一个新的CountDownLatch实例。 8.3 CyclicBarrier和CountdownLatchCyclicBarrier可以构造出一个集结点，当某一个线程执行await()的时候，它就会到这个集结点开始等待，等待这个栅栏被撤销。直到预定数量的线程都到了这个集结点之后，这个栅栏就会撤销，之前等待的线程就在此刻统一出发，继续去执行剩下的任务。 12345678910111213141516171819202122232425262728293031323334353637public class CyclicBarrierDemo &#123; static class Task implements Runnable &#123; private int id; private CyclicBarrier cyclicBarrier; public Task(int id, CyclicBarrier cyclicBarrier) &#123; this.id = id; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; try &#123; System.out.println(\"同学\" + id + \"现在从大门出发，前往自行车驿站\"); Thread.sleep((long)(Math.random() * 10000)); System.out.println(\"同学\" + id + \"到了自行车驿站，开始等待其他人到达\"); cyclicBarrier.await(); System.out.println(\"同学\" + id + \"开始骑车\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new Runnable() &#123; // 当线程达到集结点，执行下一次动作之前，会执行一次这个动作 @Override public void run() &#123; System.out.println(\"凑齐3人了，GO！\"); &#125; &#125;); for (int i = 0; i &lt; 6; i++) &#123; new Thread(new Task(i + 1, cyclicBarrier)).start(); &#125; &#125;&#125; 执行动作barrierAction public CyclicBarrier(int parties, Runnable barrierAction): 当parties线程到达集结点时，继续往下执行前，会执行这一次这个动作。 1234567891011121314151617181920同学1现在从大门出发，前往自行车驿站同学5现在从大门出发，前往自行车驿站同学6现在从大门出发，前往自行车驿站同学4现在从大门出发，前往自行车驿站同学3现在从大门出发，前往自行车驿站同学2现在从大门出发，前往自行车驿站同学5到了自行车驿站，开始等待其他人到达同学2到了自行车驿站，开始等待其他人到达同学6到了自行车驿站，开始等待其他人到达凑齐3人了，GO！同学6开始骑车同学5开始骑车同学2开始骑车同学3到了自行车驿站，开始等待其他人到达同学4到了自行车驿站，开始等待其他人到达同学1到了自行车驿站，开始等待其他人到达凑齐3人了，GO！同学1开始骑车同学3开始骑车同学4开始骑车 CyclicBarrier和CountDownLatch的异同 相同点：都能阻塞一个或一组线程，直到某个预设条件达成，再统一出发。 不同点： 作用对象不同： CyclicBarrier要等固定数量的线程都到达了栅栏位置才能继续执行，而CountDownLatch只需等待数字到0，也就是说CountDownLatch作用于事件，但CyclicBarrier作用于线程；CountDownLatch是在调用了countDown方法之后把数字减1，而CyclicBarrier是在某线程开始等待后把计数减1。 可重用性不同： CountDownLatch在倒数0并且触发门闩打开后，就不能再次使用了，除非新建一个新的实例；而CyclicBarrier可以重复使用。CyclicBarrier还可以随时调用reset方法进行重置，如果重置时有线程已经调用了await方法并开始等待，那么这些线程则会抛出BrokenBarrierException异常。 执行动作不同： CyclicBarrier有执行动作barrierAction，而CountDownLatch没这个功能。 8.4 Condition、object都wait()何notify()的关系假设线程1需要等待某些条件满足后，才能继续运行，如等待某个时间点到达或者等待某些任务处理完毕。此时，就可以执行Condition的await方法，一旦执行了该方法，这个线程就会进入WATTING状态。通常还有另外一个线程2，它去达成对应的条件，直到这个条件达成之后，那么线程2调用signal方法或signalAll方法，代表”条件达成，之前等待这个条件的线程现在可以苏醒了“。这个时候，JVM就会找到等待该Condition的线程，并予以唤醒，线程1在此时就会被唤醒，线程状态又会回到Runnable。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ConditionDemo &#123; private ReentrantLock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); void task1() throws InterruptedException &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \":条件不满足，开始await\"); condition.await(); System.out.println(Thread.currentThread().getName() + \"条件满足了，开始执行后续的任务\"); &#125; finally &#123; lock.unlock(); &#125; &#125; void task2() throws InterruptedException &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \":需要5秒钟的准备时间\"); Thread.sleep(5000); System.out.println(Thread.currentThread().getName() + \":准备工作完成，唤醒其他的线程\"); condition.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ConditionDemo conditionDemo = new ConditionDemo(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; conditionDemo.task2(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); conditionDemo.task1(); &#125;&#125;main:条件不满足，开始awaitThread-0:需要5秒钟的准备时间Thread-0:准备工作完成，唤醒其他的线程main条件满足了，开始执行后续的任务 注意点 线程2解锁后，线程1才能获得锁并继续执行 调用signal之后，还需要等待子线程完全退出这个锁，即执行unlock之后，这个主线程才有可能去获取到这把锁，并且当获取锁成功之后才能继续执行后面的任务。 signalAll()和signal()区别 signalAll()会唤醒所有正在等待的线程，而signal()只会唤醒一个线程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/* * Condition实现简易版阻塞队列 */public class MyBlockingQueueForCondition &#123; private Queue queue; private int max = 16; private ReentrantLock lock = new ReentrantLock(); private Condition notEmpty = lock.newCondition(); private Condition notFull = lock.newCondition(); public MyBlockingQueueForCondition(int maxSize) &#123; this.max = maxSize; queue = new LinkedList(); &#125; public void put(Object object) throws InterruptedException &#123; lock.lock(); try &#123; while (queue.size() == max) &#123; notFull.await(); &#125; queue.add(object); notEmpty.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (queue.size() == 0) &#123; notEmpty.await(); &#125; Object item = queue.remove(); notFull.signalAll(); return item; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;/* * 使用wait/notify来实现简易版阻塞队列 */public class MyBlockingQueueForWaitNotify &#123; private int maxSize; private LinkedList&lt;Object&gt; queue; public MyBlockingQueueForWaitNotify(int maxSize) &#123; this.maxSize = maxSize; queue = new LinkedList&lt;&gt;(); &#125; public synchronized void put(Object object) throws InterruptedException &#123; while (queue.size() == maxSize) &#123; this.wait(); &#125; queue.add(object); this.notifyAll(); &#125; public synchronized Object take() throws InterruptedException &#123; while (queue.size() == 0) &#123; this.wait(); &#125; Object item = queue.remove(); this.notifyAll(); return item; &#125;&#125; Condition把Object的wait/notify/notifyAll转化为了一种相应的对象，其实现的效果基本一样，但是把更复杂的用法，变成了更直观可控的对象方法，是一种升级。await方法会自动释放持有的Lock锁，否则会抛出异常，和Object的wait一样，不需要自己手动释放锁。另外，调用await的时候必须持有锁，否则会抛出异常，这一点和Object的wait一样。 9.Java内存模型9.1 什么是Java内存模型？JVM内存结构 堆 堆是存放类实例和数组的，通常是内存中最大的一块。比如new Object()就会产生一个实例；而数组也是保存在堆上，因为在Java中，数组也是对象。 虚拟机栈 保存局部变量和部分结果，并在方法调用和返回中起作用。 方法区 它存储每个类的结构，例如运行时常量池、字段和方法数据，以及方法和构造函数的代码，包括用于类初始化以及接口初始化的特殊方法。 本地方法栈 与虚拟机栈类似，区别在于虚拟机栈为虚拟机执行的Java方法服务，而本地方法栈则是为Native方法服务。 程序计数器 最小的一块内存区域，它的作用通常是保存当前正在执行的JVM指令地址。 运行时常量池 是方法区的一部分，包含多种常量，范围从编译时已知的数字到必须在运行时解析的方法和字段引用。 为什么需要JMM(Java Memory Model, Java内存模型) 程序最终执行的效果依赖于具体的处理器，而不同的处理器的规则又不一样，需要一个标准，让多线程运行结果可以预期，这个标准就是JMM。 JMM是什么 JMM是规范 JMM是和多线程相关的一组规范，需要各个JVM的实现来遵守JMM规范。因此JMM与处理器、缓存、并发、编译器有关，它解决了CPU多级缓存、处理器优化、质量重排序等导致的结果不可预期的问题。 JMM是工具类和关键字的原理 如volatile、synchronized、Lock等原理都涉及JMM。重排序、原子性、内存可见性。 9.2 什么是指令重排序？为什么要进行重排序？假设我们写了一个Java程序，实际上语句的运行顺序可能可写的代码顺序不一致。编译器、JVM或者CPU都有可能出于优化等目的，对于实际指令执行的顺序进行调整。 重排序的好处：提高处理速度 重排序的3种情况 编译器优化 编译器(包括JVM、JIT编译器等)；重排序并不意味着可以任意排序，它需要保证重排序后，不改变单线程内的语义。 CPU重排序 CPU同样会有优化行为，即使之前的编译器不发生冲排，CPU也可能进行重排。 内存的”重排序” 内存系统不存在真正的重排序，但是内存会带来看上去和重排序一样的效果。由于内存有缓存的存在，在JMM里表现为主内存和本地内存，而主内存和本地内存的内容可能不一致，所以这也会导致程序表现出乱序的行为。 9.3 Java中的原子操作有哪些注意事项？原子操作指一系列操作要么全部发生，要么全部不发生，不会出现执行一半的情况。 Java中的原子操作有哪些 除了long和double之外的基本类型(int、byte、boolean、short、char、float)的读/写操作，都天然的具备原子性 所有引用reference的读/写操作 加了volatile后，所有变量的读/写操作(包含long/double) java.concurrent.Atomic包中的一部分类的一部分方法，比如AtomicInteger的incrementAndGet long和double的原子性 long和double的值需要占用64位的内存空间，而对于64位值的写入，可以分为两个32位的操作进行。因此，本来是一个整体的赋值操作，就可能被拆分为低32位和高32位两个操作。如果在这两个操作之间发生了其他线程对这个值的读操作，就可能会读到一个错误、不完整的值。 JVM的开发者可以自由选择是否把64位的long和double的读写操作作为原子操作去实现，并且规范推荐JVM将其实现为原子操作。 原子操作 + 原子操作 != 原子操作 9.4 什么是内存可见性123456789101112131415161718192021222324252627282930313233343536373839404142434445/* * 内存可见性问题 */public class VisibilityProblem &#123; int a = 10; int b = 20; private synchronized void change() &#123; a = 30; b = a; &#125; private synchronized void print() &#123; System.out.println(\"b=\" + b + \";a=\" + a); &#125; public static void main(String[] args) &#123; while (true) &#123; VisibilityProblem visibilityProblem = new VisibilityProblem(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; visibilityProblem.change(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; visibilityProblem.print(); &#125; &#125;).start(); &#125; &#125;&#125; 第1种情况：假设第1个线程，也就是执行change的线程先运行，并且运行完毕了，然后，第2个线程开始运行，打印出b=30;a=30 第2种情况：与第1种情况相反。因为线程先start，并不代表它真的先执行，所以第2种情况是第2个线程先打印b=20;a=10，然后第1个线程再去进行change 第3种情况：它们几乎同时运行，所以会出现交叉的情况。如第1个线程的change执行到一半，已经把a的值改为30了，而b的值还未来得及修改，此时第2个线程就开始打印，即打印结果为b=20;a=30 第4种情况：发生可见性问题，a的值已经被第1个线程修改了，但是其他线程却看不到，由于a的最新值没能及时同步过来，打印出b=30;a=10 volatile关键字解决可见性问题 synchronized不仅保证了原子性，还保证了可见性 synchronized不仅保证了临界区内最多同时只有一个线程执行操作，同时还保证了在前一个线程释放锁之后，之前所做的所有修改，都能被获得同一个锁的下一个线程所看到，也就是能读取到最新的值。 9.5 主内存与工作内存的关系CPU有多级缓存，导致读的数据过期 为了提高CPU的整体运行效率，减少空闲时间，在CPU和内存之间会有cache层(缓存层)。虽然缓存的容量比内存小，但是缓存的速度却比内存的速度要快得多，其中L1缓存的速度仅次于寄存器的速度。 线程间对于共享变量的可见性问题，并不是由多核引起的，而是由多级缓存引起的。每个核心在获取在获取数据时，都会将数据从内存一层层往上读取，同样，后续对于数据的修改也是先写入到自己的L1缓存中，然后等待时机再逐层往下同步，直到最终刷回内存。 假设core1修改了变量a的值，并写入到了core1的L1缓存里，但是还没来得及继续往下同步，由于core1有它自己的L1缓存，core4是无法直接获取core1的L1缓存的值，那么此时对于core4而言，变量a的值就不是core1修改后的最新的值，core4读取到的可能是一个过期的值，从而引起多线程时的可见性问题发生。 JMM的抽象：主内存和工作内存 每个线程都只能直接接触到工作内存，无法直接操作主内存，而工作内存中所保存的正是主内存的共享变量的副本，主内存和工作内存之间的通信是JMM控制的。 主内存和工作内存的关系 所有的变量都存储在主内存中，同时每个线程拥有自己独立的工作内存，而工作内存中的变量的内容内容是主内存中该变量的拷贝。 线程不能直接读/写主内存中的变量，但可以操作自己工作内存中的变量，然后再同步到主内存中，这样，其他线程就可以看到本次修改。 主内存是由多个线程所共享的，但线程之间不共享各自的工作内存，如果线程间需要通信，则必须借助主内存主内存来完成。 9.6 什么是happens-before规则？Happens-before关系是用来描述可见性相关问题的：如果第一个操作happens-before第二个操作，那么可以认为第一个操作对于第二个操作一定是可见的。 Happens-before的规则 单线程规则 在一个单独的线程中，按照程序代码的顺序，先执行的操作happens-before后执行的操作。 但只要重排序后的结果依然符合happens-before关系，也就是能保持可见性的话，并不会限制重排序的发生。 锁操作规则(synchronized和Lock接口) 如果操作A是解锁，而操作B是对同一个锁的加锁，那么hb(A,B)。 volatile变量规则 对于一个volatile变量的写操作happens-before后面对该变量的读操作。 线程启动规则 Thread对象的start方法happens-before此线程run方法中的每一个操作。 线程join规则 join可以让线程之间等待，假设线程A通过调用threadB.start()启动了一个新线程B，然后调用threadB.join()，那么线程A将一直等待到线程B的run方法结束(不考虑中断等特殊情况)，然会join方法才返回。在join方法返回后，线程A中的所有后续操作都可以看到线程B的run方法执行的所有操作的结果，也就是线程B的run方法里面的操作hanppens-before线程A的join之后的语句。 中断规则 对线程interrupt方法的调用happens-before检测该线程的中断事件。 并发工具类的规则 线程安全的并发容器(如ConcurrentHashMap)在get某个值时一定能看到在此之前发生的put等存入操作的结果。 信号量(Semaphore)会释放许可证，也会获取许可证。释放许可证的操作happens-before获取许可证的操作。 Future：当Future的get方法得到结果的时候，一定可以看到之前任务中所有的操作。 线程池：提交任务的操作happens-before任务的执行。 9.7 volatile的作用是什么？与synchronized有什么异同？volatile是Java中的一个关键字，是一种同步机制。当某个变量是共享变量，且这个变量被volatile修饰，那么在修改了这个变量的值之后，再读取该变量的值时，可以保证获取到的是修改后的最新的值。 相比于synchronized或者Lock，volatile更加轻量，因为使用volatile不会发生上下文切换等开销很大的情况，不会让线程阻塞。 volatile不适用于a++ volatile不适合运用于需要保证原子性的场景。 1234567891011121314151617181920212223242526272829/** * a++ 不适合使用volatile */public class DontVolatile implements Runnable &#123; volatile int a; AtomicInteger realA = new AtomicInteger(); public static void main(String[] args) throws InterruptedException &#123; DontVolatile dontVolatile = new DontVolatile(); Thread thread1 = new Thread(dontVolatile); Thread thread2 = new Thread(dontVolatile); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(dontVolatile.a); System.out.println(dontVolatile.realA); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; a++; realA.incrementAndGet(); &#125; &#125;&#125;19262000 适用场合1：布尔标记位 第一个例子的操作是a++，这是个复合操作，不具备原子性，而下面这个例子只是把flag设置为true，这样的赋值操作本身就是具备原子性的，所以适合使用volatile。 1234567891011121314151617181920212223242526272829303132/** * 可以使用volatile的场景 布尔标记位 */public class YesVolatile1 implements Runnable &#123; volatile boolean flag = false; AtomicInteger realA = new AtomicInteger(); public static void main(String[] args) throws InterruptedException &#123; YesVolatile1 yesVolatile1 = new YesVolatile1(); Thread thread1 = new Thread(yesVolatile1); Thread thread2 = new Thread(yesVolatile1); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(yesVolatile1.flag); System.out.println(yesVolatile1.realA); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; realA.incrementAndGet(); setDone(); &#125; &#125; private void setDone() &#123; flag = true; &#125;&#125;true2000 适用场合2：作为触发器，保证其他变量的可见性 1234567891011121314Map configOptions;char[] configText;volatile boolean initialized = false;. . .// In thread AconfigOptions = new HashMap();configText = readConfigFile(fileName);processConfigOptions(configText, configOptions);initialized = true;. . .// In thread Bwhile (!initialized) sleep();// use configOptions happens-before具有传递性，根据happens-before的单线程规则，线程A中configOptions的初始化happens-before对iniialized变量的写入，而线程B中对initialized的读取happens-before对configOptions变量的使用，同时根据happens-before关系的volatile规则，线程A中对initialized的写入为true的操作happens-before线程B中随后对initialized变量的读取。 volatile的作用 保证可见性 对于一个volatile变量的写操作happen-before后面对该变量的读操作，即如果变量被volatile修饰，那么每次修改之后，接下来在读取这个变量的时候一定能读到该变量的最新值。 禁止重排序 as-if-serial：不管怎么重排序，单线程的执行结果不变。多线程情况下的重排序可能会导致严重的线程安全问题。使用volatile关键字可以在一定程度上禁止这种重排序。 volatile和synchronized的关系 相似性：volatile可以看作是一个轻量版的synchronized，如果一个共享变量如果自始至终只被各个线程赋值和读取，而没有其他操作的话，那么就可以用volatile来代替synchronized或者代替原子变量。 不可代替：volatile是不能代替synchronized的，volatile并没有提供原子性和互斥性的。 性能方面：volatile的读写操作都是无锁的，比synchronized性能更好。 9.8 单例模式的双重检查锁模式为什么必须加volatile？单例模式：保证一个类只有一个实例，并且提供一个可以全局访问的入口。 为什么需要使用单例模式？ 为了节省内存、节省计算。 保证结果正确。 方便管理。 有一个私有的Singleton类型的singleton对象；同时构造方法也是私有的，为了防止他人调用构造函数来生成实例；还有一个public的getInstance方法，可通过这个方法获取到单例。 双重检查锁模式的写法 12345678910111213141516171819/** * volatile 双重检查锁 */public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 进行了两次if(singleton==null)检查，即”双重检查锁”。假设有两个线程同时到达synchronized语句块，那么实例化代码只会由其中先抢到锁的线程执行一次，而后抢到锁的线程会在第二个if判断中发现singleton不为null，所以跳过创建实例的语句。再后面的其他线程再来调用getInstance方法时，只需判断第一次的if(singleton==null)，然后跳过整个if块，直接return实例化后的对象。 为什么需要双重检查？ 如果有两个线程同时调用getInstance方法，由于singleton是空的，因此两个线程可以通过第一重if的检查，然后由于锁的存在，会有一个线程先进入同步语句，并进入第二重检查，而另外一个线程就在外面等待。不过当第一个线程执行完new Singleton()语句后，就会退出synchronized保护的区域，这时如果没有第二重if(singleton==null)判断的话，那么第二个线程也会创建一个实例，破环了单例。 如果去掉第一个检查，那么所有线程都会串行执行，效率低下。 双重检查模式中为什么需要使用volatile关键字？ singleton = new Singleton() 并非是一个原子操作，在JVM中至少做了以下3件事。 给singleton分配内存空间 调用Singleton的构造函数，来初始化singleton 将singleton对象指向分配的内存空间(执行完这步singleton就不是null了) 因为存在指令排序的优化，所以第2，3步的顺序是不能保证的，最终的执行顺序可能是1-2-3，也有可能是1-3-2。 如果是1-3-2： 使用volatile之后，相当于是表明了该字段的更新可能是在其他线程中发生的，在JDK5及后续版本所使用的JMM中，在使用了volatile后，会在一定程度禁止相关语句的重排序。 10.CAS10.1 什么是CAS?CAS(Compare And Swap)，是一种思想，为了保证并发安全，可以使用互斥锁，而CAS的特点就是避免使用互斥锁，当多个线程同时使用CAS更新同一个变量时，只有其中一个线程能够操作成功，而其他线程都会更新失败。不过和同步互斥锁不同的是，更新失败的线程并不会被阻塞，而是被告知这次由于竞争而导致的操作失败，但还可以再次尝试。 CAS的思路 CAS相关的指令是具备原子性的，”比较和交换“操作在执行期间不会被打断。 CAS有3个操作数：内存值V，预期值A、要修改的值B。当预期值A和当前的内存值V相同时，才将内存值修改为B。 CAS会提前假定当前内存值V应该等于值A，而值A往往是之前读取到当时的内存值V，如果发现当前的内存值V恰好是值A的话，那CAS就会把内存值V改成B。如果执行CAS时发现此时的内存值V不等于值A，则说明在刚才计算B的期间内，内存值已经被其他线程修改过了，那么本次CAS就不应该再修改了。 例子 1234567891011121314151617181920212223242526272829303132/** * 模拟CAS操作 等价代码 */public class SimulatedCAS implements Runnable &#123; private int value; public synchronized int compareAngSwap(int expectedValue, int newValue) &#123; int oldValue = value; if (oldValue == expectedValue) &#123; value = newValue; System.out.println(Thread.currentThread().getName() + \"执行成功！\"); &#125; return oldValue; &#125; public static void main(String[] args) throws InterruptedException &#123; SimulatedCAS simulatedCAS = new SimulatedCAS(); simulatedCAS.value = 100; Thread thread1 = new Thread(simulatedCAS); Thread thread2 = new Thread(simulatedCAS); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(simulatedCAS.value); &#125; @Override public void run() &#123; compareAngSwap(100, 150); &#125;&#125; 10.2 CAS的应用并发容器 ConcurrentHashMap putVal方法部分代码 123456789101112131415 final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125;...... &#125; casTabAt 1234static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; U是Unsafe类型的，Unsafe类包含compareAndSwapInt、compareAndSwapLong、compareAndSwapObject等和CAS密切相关的native层的方法，其底层正是利用CPU对CAS指令的支持实现的。 ConcurrentLinkedQueue 非阻塞并发队列ConcurrentLinkedQueue的offer方法里也有CAS的身影，offer方法： 12345678910111213141516171819public boolean offer(E e) &#123; checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; if (p.casNext(null, newNode)) &#123; if (p != t) casTail(t, newNode); return true; &#125; &#125; else if (p == q) p = (t != (t = tail)) ? t : head; else p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 数据库 在更新数据时，可以利用version字段在数据库中实现乐观锁和CAS操作，而在获取和修改数据时都不需要加悲观锁。 12345UPDATE studentSET name = ‘小王’, version = 2 WHERE id = 10 AND version = 1 先去比较version是不是最开始获取到的1，如果和初始值相同才去进行name字段的修改，同时也要把version的值加1。 原子类 在原子类中，如AtomicInteger，也使用了CAS。如AtomicInteger的getAndAdd方法。 1234567891011public final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta;&#125;public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v;&#125; var1 o object 将要修改的对象，传入的是this，也就是atomicInteger这个对象本身 var2 offset offset 偏移量，借助它就可以获取到oldvalue的数值 var5 v expectedValue 代表”期望值” var5+var4 v+delta newValue 希望修改为的新值，var4就是希望原子类所改变的数值，比如可以传入+1，也可以传入-1 Unsafe的getAndAddInt方法是通过循环+CAS的方式来实现的，在此过程中，它会通过compareAndSwapInt方法来尝试更新value的值，如果更新失败就重新获取，然后再次更新，直到更新成功。 10.3 CAS有什么缺点？ABA问题 CAS检查的并不是值有没有发生过变化，而是去比较这当前值和预期值是不是相等，如果变量的值从旧值A变成了新值B再变回旧值A，由于最开始是值A和现在的值A是相等的，所以CAS会认为变量的值在此期间没有发生过变化。所以，CAS并不能检测在此期间值是不是被修改过，它只能检查出现在的值和最初的值是不是一样。 在变量自身之外，再添加一个版本号，A-&gt;B-&gt;A，1A-&gt;2B-&gt;3A，可以通过版本号来判断值是否变化过。 atomic包中提供了AtomicStampedReference这个类，它是专门用来解决ABA问题，解决思路正是利用版本号，AtomicStampedReference会维护一种类似&lt;Object,int&gt;的数据结构，其中的int就是用于计数的，也就是版本号。 自旋时间过长 由于单次CAS不一定能执行成功，所以CAS往往是配合着循环来实现的，有的时候甚至是死循环，不停重试，直到竞争不激烈的时候，才能修改成功。 如果是高并发场景，有可能导致CAS一直操作不成功，循环的时间会越来越长。CPU资源一直在被消耗，会对性能产生很大的影响，高并发情况下，通常CAS的效率是不高的。 范围不能灵活控制 通常执行CAS的时候，是针对某一个，而不是多个共享变量的，多个变量之间是独立的，简单的把原子操作组合到一起，并不具备原子性。 有一个解决方案就是利用一个新的类，来整合刚才这一组共享变量，这个新的类中的多个成员变量就是刚才的那多个共享变量，然后再利用atomic包中的AtomicReference来把这个新对象整体进行CAS操作。 相比之下，如使用synchronized关键字时，如果想把更加的代码加锁，只需把更多的代码放到同步代码块里面就可以了。 11.死锁问题11.1 写一个必然死锁的例子什么是死锁？ 发生在并发中，两个或多个线程(或进程)被无限期的阻塞，相互等待对方手中资源。 例子 两个线程： 多个线程： 死锁的影响 数据库中： 在执行一个事务的时候可能需要获取多把锁，并一直持有这些锁直到事务完成。在某个事务中持有的锁可能在其他事务中也需要，因此在两个事务之间有可能会发生死锁的情况。当数据库检测到这一组事务发生了死锁，根据策略的不同，可能会选择放弃一个事务，被放弃的事务就会释放掉它所持有的锁，从而使其它事务继续进行。此时程序可以重新执行被强行终止的事务。 JVM中： JVM并不会自动进行处理，发生几率不高但危害大，在巨量的次数面前，整个系统发生问题的几率也会被放大。 发生死锁的例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 必然死锁的例子 */public class MustDeadLock implements Runnable &#123; public int flag; static Object object1 = new Object(); static Object object2 = new Object(); @Override public void run() &#123; System.out.println(\"线程\" + Thread.currentThread().getName() + \"的flag为\" + flag); if (flag == 1)&#123; synchronized (object1)&#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (object2)&#123; System.out.println(\"线程\" + Thread.currentThread().getName()+\"获取到了两把锁！\"); &#125; &#125; &#125; if (flag == 2)&#123; synchronized (object2)&#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (object1)&#123; System.out.println(\"线程\" + Thread.currentThread().getName()+\"获取到了两把锁！\"); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; MustDeadLock mustDeadLock1 = new MustDeadLock(); MustDeadLock mustDeadLock2 = new MustDeadLock(); mustDeadLock1.flag = 1; mustDeadLock2.flag = 2; Thread thread1 = new Thread(mustDeadLock1,\"thread1\"); Thread thread2 = new Thread(mustDeadLock2,\"thread2\"); thread1.start(); thread2.start(); &#125;&#125;线程thread1的flag为1线程thread2的flag为2 当第1个线程运行的时候，它会发现自己的flag是1，所以它会尝试先获得object1这把锁，然后休眠500毫秒。 在线程1启动并休眠的期间，线程2同样会启动。由于线程2的flag是2，所以线程2首先会去获取object2这把锁，然后休眠500毫秒。 当线程1的500毫秒休眠时间结束，它会尝试去获取object2这把锁，此时object2这把锁正在被线程2持有，所以线程1无法获取到object2。 紧接着线程2也会苏醒过来，它将尝试获取object1这把锁，此时object1已被线程1持有。 线程1卡在获取object2这把锁的位置，而线程2卡在获取object1这把锁的位置。 11.2 发生死锁的4个必要条件 互斥条件 每个资源每次只能被一个线程(或进程)使用。 请求与保持条件 当一个线程因请求资源而阻塞时，则需对已获得的资源保持不放。 不剥夺条件 线程已获得的资源，在未使用完之前，不会被强行剥夺。 循环等待条件 只有若干个线程之间形成一种头尾相接的循环等待资源关系时，才有可能形成死锁。 11.3 如何定位死锁？ 命令：jstack 1234567891011121314151617181920212223242526272829D:\\IDEAProbject\\JavaStudyDemo\\Multithreading&gt;jps3044 Launcher4084 MustDeadLock11816 JpsD:\\IDEAProbject\\JavaStudyDemo\\Multithreading&gt;jstack 4084Found one Java-level deadlock:=============================\"thread2\": waiting to lock monitor 0x000000001c601e68 (object 0x0000000776319ce0, a java.lang.Object), which is held by \"thread1\"\"thread1\": waiting to lock monitor 0x000000001c6047a8 (object 0x0000000776319cf0, a java.lang.Object), which is held by \"thread2\"Java stack information for the threads listed above:===================================================\"thread2\": at com.example.MustDeadLock.run(MustDeadLock.java:34) - waiting to lock &lt;0x0000000776319ce0&gt; (a java.lang.Object) - locked &lt;0x0000000776319cf0&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:748)\"thread1\": at com.example.MustDeadLock.run(MustDeadLock.java:22) - waiting to lock &lt;0x0000000776319cf0&gt; (a java.lang.Object) - locked &lt;0x0000000776319ce0&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock. 代码：ThreadMXBean 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 必然死锁的例子 */public class MustDeadLock implements Runnable &#123; public int flag; static Object object1 = new Object(); static Object object2 = new Object(); @Override public void run() &#123; System.out.println(\"线程\" + Thread.currentThread().getName() + \"的flag为\" + flag); if (flag == 1) &#123; synchronized (object1) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (object2) &#123; System.out.println(\"线程\" + Thread.currentThread().getName() + \"获取到了两把锁！\"); &#125; &#125; &#125; if (flag == 2) &#123; synchronized (object2) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (object1) &#123; System.out.println(\"线程\" + Thread.currentThread().getName() + \"获取到了两把锁！\"); &#125; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; MustDeadLock mustDeadLock1 = new MustDeadLock(); MustDeadLock mustDeadLock2 = new MustDeadLock(); mustDeadLock1.flag = 1; mustDeadLock2.flag = 2; Thread thread1 = new Thread(mustDeadLock1, \"thread1\"); Thread thread2 = new Thread(mustDeadLock2, \"thread2\"); thread1.start(); thread2.start(); Thread.sleep(2000); ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); long[] deadlockedThreads = threadMXBean.findDeadlockedThreads(); if (deadlockedThreads != null &amp;&amp; deadlockedThreads.length &gt; 0) &#123; for (int i = 0; i &lt; deadlockedThreads.length; i++) &#123; ThreadInfo threadInfo = threadMXBean.getThreadInfo(deadlockedThreads[i]); System.out.println(threadInfo); &#125; &#125; &#125;&#125;线程thread1的flag为1线程thread2的flag为2\"thread2\" Id=21 BLOCKED on java.lang.Object@27d6c5e0 owned by \"thread1\" Id=20\"thread1\" Id=20 BLOCKED on java.lang.Object@4f3f5b24 owned by \"thread2\" Id=21 11.4 解决死锁问题的策略 避免策略 优化代码逻辑，从根本上消除发生死锁的可能性，如调整锁的获取顺序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * 调整锁的获取顺序来避免死锁问题 */public class TransferMoney implements Runnable &#123; static class Account &#123; int balance; public Account(int balance) &#123; this.balance = balance; &#125; &#125; int flag; static Account a = new Account(500); static Account b = new Account(500); @Override public void run() &#123; if (flag == 1) &#123; transferMoney(a, b, 200); &#125; if (flag == 0) &#123; transferMoney(b, a, 200); &#125; &#125; public static void transferMoney(Account from, Account to, int account) &#123; int fromHash = System.identityHashCode(from); int toHash = System.identityHashCode(to); // 模拟网络延迟 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (fromHash &gt; toHash) &#123; // 先获取两把锁，然后开始转账 synchronized (to) &#123; synchronized (from) &#123; if (from.balance - account &lt; 0) &#123; System.out.println(\"余额不足，转账失败！\"); return; &#125; from.balance -= account; to.balance += account; System.out.println(\"成功转账\" + account + \"元！\"); &#125; &#125; &#125; if (toHash &gt; fromHash) &#123; // 先获取两把锁，然后开始转账 synchronized (from) &#123; synchronized (to) &#123; if (from.balance - account &lt; 0) &#123; System.out.println(\"余额不足，转账失败！\"); return; &#125; from.balance -= account; to.balance += account; System.out.println(\"成功转账\" + account + \"元！\"); &#125; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; TransferMoney r1 = new TransferMoney(); TransferMoney r2 = new TransferMoney(); r1.flag = 1; r2.flag = 0; Thread t1 = new Thread(r1); Thread t2 = new Thread(r2); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"a的余额\" + a.balance); System.out.println(\"b的余额\" + b.balance); &#125;&#125; 业务实际上不在乎获取锁的顺序，调整获取锁的顺序，使先获取的账户是”转入”或”转出”无关，而是使用HashCode的值来决定顺序，从而保证线程安全。但依然有极小的概率会发生HashCode相同的情况，在实际生产中，需要排序的往往是一个实体类，而一个实体类一般都会具有主键ID，主键ID具有唯一、不重复的特点，直接使用主键ID排序，按照主键ID的大小来决定获取锁的顺序，以确保避免死锁。 检测与恢复策略 先允许系统发生死锁，然后再解除。例如系统可以在每次调用锁的时候，都记录下来调用信息，形成一个”锁的调用链图”，然后隔一段时间就用死锁检测算法来检测一下，搜索这个图中是否存在环路，一旦发生死锁，就可以用死锁恢复机制，解开死锁，进行恢复。 线程终止 系统逐个去终止已经陷入死锁的线程，线程被终止，同时释放资源，死锁就会被解开。有各种各样的算法和策略，根据实际业务进行调整。 优先级 先终止优先级低的线程。 已占用资源、还需要的资源 如果某线程已经占有了一大堆资源，只需要最后一点点资源就可以顺利完成任务，那么系统会优先终止别的线程来优先促成该线程的完成。 已经运行时间 如果某线程已经运行很多天了，很快就要完成任务了，可以让那些刚刚开始运行的线程终止，并在之后把它们重新启动，这样成本更低。 资源抢占 不需要把整个线程终止，而是只需要把它已经获得的资源进行剥夺，如让线程回退几步、释放资源，这样就不需要终止掉整个线程，成本更低。但如果算法不好的话，我们抢占的那个线程可能一直是同一个线程，就会造成饥饿线程，即这个线程一直被剥夺它已经得到的资源，那么它就长期得不到运行。 鸵鸟策略 如果系统发生死锁的概率极低，并且一旦发生其后果不是特别严重，可以先选择忽略它，直到发生死锁后，再人工修复。 12.final关键字12.1 final的三种用法final修饰变量 final修饰的变量，一旦被赋值就不能被修改了。 目的：1.设计角度 2.线程安全 赋值时机： 成员变量，类中的非static修饰的属性 在变量的等号右边直接赋值 123public class FinalFieldAssignment1 &#123; private final int finalVar = 0;&#125; 在构造函数中赋值 123456class FinalFieldAssignment2 &#123; private final int finalVar; public FinalFieldAssignment2() &#123; finalVar = 0; &#125;&#125; 在类的构造代码块中赋值(不常用) 123456class FinalFieldAssignment3 &#123; private final int finalVar; &#123; finalVar = 0; &#125;&#125; 静态变量，类中的被static修饰的属性 在声明变量的等号右边直接赋值 123public class StaticFieldAssignment1 &#123; private static final int a = 0;&#125; 在一个静态的static初始代码块中赋值 123456class StaticFieldAssignment2 &#123; private static final int a; static &#123; a = 0; &#125;&#125; static的final变量不能在构造函数中进行赋值 局部变量，方法中的变量 使用前赋值即可 final修饰参数，意味着在方法内部无法对参数进行修改。 123456public class FinalPara &#123; public void withFinal(final int a) &#123; System.out.println(a);//可以读取final参数的值// a = 9; //编译错误，不允许修改final参数的值 &#125;&#125; final修饰方法 提高效率，早期的Java版本，会把final修饰的方法转为内嵌调用，消除方法调用的开销。 final修饰的方法不可以被重写。 final的private方法 12345678public class PrivateFinalMethod &#123; private final void privateEat() &#123; &#125;&#125;class SubClass2 extends PrivateFinalMethod &#123; private final void privateEat() &#123;//编译通过，但这并不是真正的重写 &#125;&#125; 类中的所有private方法都是隐式的指定为自动被final修饰的，由于这个方法是private类型的，所以对于子类而言，根本获取不到父类这个方法，更别说重写了。所以其实子类并没有真正意义上的去重写父类的privateEat方法，只是方法名碰巧一样而已。 final修饰类 final修饰的类不可被继承 类是final的，不代表里面的属性就会自动加上final。 final的类里面，所有的方法，不论是public、private还是其他权限修饰符修饰的，都会自动的、隐式的被指定为是final的。 12.2 为什么加了final却依然无法拥有”不变性”？如果对象在被创建之后，其状态就不能修改了，那么它就具备”不变性”。 final修饰对象时，只是引用不可变。当用final去修饰一个指向对象类型(而不是指向8种基本数据类型)的变量的时候，那么final起到的作用只是保证则个变量的引用不可变，而对象本身的内容依然是可变化的。 123456789101112131415161718192021222324class Test &#123; int p = 20; public static void main(String args[])&#123; final Test t = new Test(); t.p = 30; System.out.println(t.p); &#125;&#125;30class Test &#123; public static void main(String args[]) &#123; final int arr[] = &#123;1, 2, 3, 4, 5&#125;; // 注意，数组 arr 是 final 的 for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = arr[i]*10; System.out.println(arr[i]); &#125; &#125;&#125;1020304050 final修饰一个指向对象的变量的时候，对象本身的内容依然是可以变化的。 final和不可变的关系 final可以确保变量的引用保持不变，但是不变性意味着对象一旦创建完毕就不能改变其状态，它强调的是对象内容本身，而不是引用。 1234567891011public class ImmutableDemo &#123; private final Set&lt;String&gt; lessons = new HashSet&lt;&gt;(); public ImmutableDemo() &#123; lessons.add(\"第01讲：为何说只有 1 种实现线程的方法？\"); lessons.add(\"第02讲：如何正确停止线程？为什么 volatile 标记位的停止方法是错误的？\"); lessons.add(\"第03讲：线程是如何在 6 种状态之间转换的？\"); &#125; public boolean isLesson(String name) &#123; return lessons.contains(name); &#125;&#125; 包含对象类型的成员变量的类的对象，具备不可变性的例子：对于ImmutableDemo类而言，它只有这么一个成员变量，而这个成员变量一旦构造完毕后又不能改变。 12.3 为什么String被设计为是不可变的？12345String s = \"lagou\";s = \"la\";String lagou = \"lagou\";lagou = lagou.subString(0, 4); 只不是建了一个新的字符串而已，并把引用重新指向。 123456public final class String implements Java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; //...&#125; private final的char数组value，存储着字符串的每一位字符，value一旦被赋值，引用就不能修改了；并且在String的源码中，除构造函数之外，并没有任何其他方法会修改value数组里面的内容，而value的权限是private，外部的类也访问不到，所以value是不可变的。String类是被final修饰的，所以这个String类是不会被继承的。 String不变的好处 字符串常量池 用作HashMap的key 对于key来说，最重要的就是不可变，这样才能利用它去检索存储在HashMap里面的value。由于HashMap的工作原理是Hash，也就是散列，所以需要对象始终拥有相同的Hash值才能正常运行。 缓存HashCode 12/** Cache the hash code for the String */private int hash; 在String类中有一个hash属性，保存的是String对象的HashCode。因为String是不可变的，所以对象一旦被创建之后，HashCode的值也就不可能变化了，就可以把HashCode缓存起来。以后每次想用到HashCode的时候，不需要重新计算，直接返回缓存过的hash的值就可以了，所以使得字符串非常适合用作HashMap的key。 线程安全 线程安全，具备不变性的对象一定是线程安全的，避免了很多不必要的同步操作。 13.AQS13.1 为什么需要AQS? AQS在ReentrantLock、ReentrantReadWriteLock、Semaphore、CountDownLatch、ThreadPoolExcutor中都有运用(JDK1.8)，AQS是这些类的底层原理。 AQS是一个用于构建锁、同步器等线程协作工具类的框架，有了AQS之后，可以让更上层的开发极大的减少工作量，避免重复造轮子，同时也避免了上层因处理不当而导致的线程安全问题，因为AQS把这些事情都做好了。总之，有了AQS之后，构建线程协作工具类就容易多了。 13.2 AQS内部原理状态 1234/** * The synchronization state. */private volatile int state; state的含义并不是一成不变的，它会根据具体实现类的作用不同而表示不同的含义。 比如在信号量里，state表示的是剩余许可证的数量。当某一个线程衢州一个许可证之后，state会减1。 在CountDownLatch工具类里，state表示的是需要”倒数”的数量。每次调用CountDown方法时，state就会减1，直到减为0就代表这个”门闩”被放开。 在ReentrantLock中表示的是锁的占有情况。最开始是0，表示没有任何线程占有锁，如果state变成1，就代表这个锁已经被某一个线程所持有了。因为ReentrantLock是可重入的，同一个线程可以再次拥有这把锁就叫重入。如果这个锁被同一个线程多次获取，那么state就会逐渐的往上加，state的值表示重入的次数。在释放的时候也是逐步递减。 compareAndSetState： 1234protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 利用了Unsafe里面的CAS操作，利用CPU指令的原子性保证了这个操作的原子性。 setState： 123protected final void setState(int newState) &#123; state = newState;&#125; 对于基本类型的变量进行直接赋值时，如果加了volatile就可以保证它的线程安全。 FIFO队列 先进先出队列，主要的作用是存储等待的线程。当多个线程去竞争同一把锁的时候，就需要用排队机制把那些没拿到锁的线程串在一起；而当前面的线程释放锁之后，这个管理器就会挑选一个合适的线程来尝试抢刚刚释放的那把锁。 队列内部是双向链表的形式： 在队列中，分别用head和tail来表示头节点和尾节点，两者在初始化的时候指向一个空节点。头节点可以理解为”当前持有锁的线程”，而在头节点之后的线程被阻塞了，它们会等待被唤醒，唤醒也是由AQS负责操作的。 获取/释放方法 获取方法 获取操作通常会依赖state变量的值，获取方法在不同类中代表不同的含义，但往往和state值相关，也经常会让线程进入阻塞状态。 如ReentrantLock中的lock方法，执行时如果发现state不等于0且当前线程不是持有锁的线程，那么就代表这个锁已经被其他线程所持有了，这个时候，当然获取不到锁，于是就让该线程进入阻塞状态。 Semaphore中的acquire，作用是获取许可证。如果state是正数，那么代表还有剩余的许可证，数量足够就可以获取成功；但如果state是0，则代表已经没有更多的空余许可证了，会进入阻塞状态。 CountDownLatch获取方法就是await方法，作用是”等待，直到倒数结束”。执行await的时候会判断state的值，如果state不等于0，线程就进入阻塞状态，直到其他线程执行倒数方法把state减为0，此时就代表这个门闩放开了，所以之前阻塞的线程就会被唤醒。 释放方法 释放方法通常是不会阻塞线程的。 比如在Semaphore信号量，释放就是release方法，release()方法的作用是去释放一个许可证，会让state加1；而在CountDownLatch里面，释放就是countDown方法，作用是倒数一个数，让state减1。 13.3 AQS在CountDownLatch中应用原理AQS用法 新建一个自己的线程协作工具类，在内部写一个Sync类，该类继承AbstractQueueSynchronizer，即AQS。 在Sync类中，根据是否是独占来重写对应的方法。独占，则重写tryAcquire和tryRelease等方法；非独占，则重写tryAcquireShared和tryReleaseShared等方法。 在自己的线程协作工具类中，实现获取/释放的相关方法，并在里面调用AQS对应的方法，独占调用acquire或release等方法；非独占调用acquireShared或releaseShared或acquireSharedInterruptibly。 AQS在CountDownLatch的应用 在CountDownLatch里面有一个子类Sync，这个类正是继承自AQS。 12345678910111213141516171819202122232425262728293031public class CountDownLatch &#123; /** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */ private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; &#125; private final Sync sync; //省略其他代码...&#125; 构造函数： 1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count);&#125; CountDown构造函数将传入的count最终传递到AQS内部的state变量，给state赋值，state就代表还需要倒数的次数。 getCount： 123public long getCount() &#123; return sync.getCount();&#125; 最终获取到的就是Sync中state的值。 countDown： 1234567891011public void countDown() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; Sync中的tryReleaseShared()，doReleaseShared()对之前阻塞的线程进行唤醒。 await： 该方法时CountDownLatch的”获取”方法，调用await会把线程阻塞，直到倒数为0才能继续执行。 1234567891011public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; Sync中的tryAcquireShared()，doAcquireSharedInterruptibly()会让线程进入阻塞状态。 总结 当线程调用CountDownLatch的await方法时，便会尝试获取”共享锁”，不过一开始通常获取不到锁，于是线程被阻塞。”共享锁”可以获取到的条件是”锁计数器”的值为0，而”锁计数器”的初始值为count，当每次调用CountDownLatch对象的countDown方法时，也可以把”锁计数器”-1。直到”锁计数器”为0，于是之前等待的线程就会继续运行了，并且此时如果再有线程想调用await方法时也会立刻放行，不会再去做任何阻塞操作了。","categories":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/tags/多线程/"},{"name":"并发编程","slug":"并发编程","permalink":"http://tonymua.top/tags/并发编程/"}]},{"title":"Java常见小案例(不定时补充)","slug":"Java常用小案例(待补充)","date":"2021-05-08T13:19:59.133Z","updated":"2020-04-29T02:44:37.933Z","comments":true,"path":"15205/","link":"","permalink":"http://tonymua.top/15205/","excerpt":"1.不死神兔问题(斐波那契数列) 有一对兔子,从出生后第三个月起每个月都生一对兔子,小兔子长到第三个月后每个月又生一对兔子.假如兔子都不死,第N个月有多少兔子? 123456789101112131415161718//1 1 2 3 5 8 13 21 a[n]=a[n-1]+a[n-1-1]public class Test_01 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入月份:\"); Scanner scanner=new Scanner(System.in); int n=scanner.nextInt();//获取输入的整数 System.out.println(\"第\"+n+\"个月的兔子数为\"+function(n)); scanner.close(); &#125; //返回兔子数量 public static int function(int n) &#123; if (n==1||n==2) &#123; return 1; &#125; return function(n-1)+function(n-2);//递归 &#125;&#125;","text":"1.不死神兔问题(斐波那契数列) 有一对兔子,从出生后第三个月起每个月都生一对兔子,小兔子长到第三个月后每个月又生一对兔子.假如兔子都不死,第N个月有多少兔子? 123456789101112131415161718//1 1 2 3 5 8 13 21 a[n]=a[n-1]+a[n-1-1]public class Test_01 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入月份:\"); Scanner scanner=new Scanner(System.in); int n=scanner.nextInt();//获取输入的整数 System.out.println(\"第\"+n+\"个月的兔子数为\"+function(n)); scanner.close(); &#125; //返回兔子数量 public static int function(int n) &#123; if (n==1||n==2) &#123; return 1; &#125; return function(n-1)+function(n-2);//递归 &#125;&#125; 2.遍历101-200之间的所有素数123456789101112131415161718192021public class Test_02 &#123; public static void main(String[] args) &#123; int i; int j; int sum=0; boolean flag; for (i = 101; i &lt; 200; i++) &#123; flag=true; for (j = 2; j &lt;Math.sqrt(i); j++) &#123; if (i%j==0) &#123; flag=false; &#125; &#125; if (flag) &#123; System.out.println(i); sum++; &#125; &#125; System.out.println(\"共有\"+sum+\"个素数\"); &#125;&#125; 3.水仙花数问题 打印出所有的水仙花数,即一个三位数,其各位数字立方和等于该数本身.例如:153=13+53+3*3 123456789101112131415public class Test_03 &#123; public static void main(String[] args) &#123; int sum=0; for (int i = 100; i &lt; 1000; i++) &#123; int a=i%10;//求得各位 int b=i/10%10;//求得十位 int c=i/10/10%10;//求得百位 if (a*a*a+b*b*b+c*c*c==i) &#123; System.out.println(i+\" \"); sum++; &#125; &#125; System.out.println(\"共有\"+sum+\"个水仙花数\"); &#125;&#125; 4.分解质因数1234567891011121314151617181920212223//将一个正整数分解质因数 例如:输入90 打印输出90=2*3*3*5public class Test_04 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入一个正整数\"); Scanner scanner=new Scanner(System.in); int input=scanner.nextInt();//获取输入的正整数 System.out.println(input+\"=\"); if (input&lt;=1) &#123; System.out.println(input+\"是无效的分解数\"); &#125; for (int i = 2; i &lt; input+1; i++) &#123; while (input!=i) &#123; if (input%i==0) &#123; System.out.println(i+\"*\"); input=input/i; &#125;else &#123; break; &#125; &#125; &#125; System.out.println(input); &#125;&#125; 5.按分数划分等级(switch)1234567891011121314151617181920212223242526272829public class Test_05 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入分数\"); Scanner scanner=new Scanner(System.in); int score=scanner.nextInt(); if (score&gt;100||score&lt;0) &#123; System.out.println(\"输入的分数有误\"); return; &#125; switch (score/10) &#123; case 10: case 9: System.out.println(\"A\"); break; case 8: System.out.println(\"B\"); break; case 7: System.out.println(\"C\"); break; case 6: System.out.println(\"D\"); break; default: System.out.println(\"E\"); break; &#125; &#125;&#125;","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"}]},{"title":"Java基础常见面试题","slug":"Java基础常见面试题","date":"2021-05-08T13:19:59.132Z","updated":"2020-04-29T02:44:38.021Z","comments":true,"path":"51576/","link":"","permalink":"http://tonymua.top/51576/","excerpt":"1.面向对象: 面向对象是一种思想，能让复杂问题简单化，程序员不需要了解具体的实现过程，只需要指挥对象去实现功能。如把需要洗的衣服交给洗衣机去洗. 多态: 允许不同类的对象对同一消息做出响应(发送消息就是函数调用) 2.封装继承多态举例: 封装：就像一个盒子，你不需要知道里面有什么东西，只知道它有那些用处就行 继承：就像父子关系，儿子是父亲的继承 多态：好比一个父亲有多个儿子，各个儿子有不同的特征 3.Array与ArrayList的区别:","text":"1.面向对象: 面向对象是一种思想，能让复杂问题简单化，程序员不需要了解具体的实现过程，只需要指挥对象去实现功能。如把需要洗的衣服交给洗衣机去洗. 多态: 允许不同类的对象对同一消息做出响应(发送消息就是函数调用) 2.封装继承多态举例: 封装：就像一个盒子，你不需要知道里面有什么东西，只知道它有那些用处就行 继承：就像父子关系，儿子是父亲的继承 多态：好比一个父亲有多个儿子，各个儿子有不同的特征 3.Array与ArrayList的区别: Array可以包含基本类型和对象类型, ArrayList只可以包含对象类型. Array大小不可改变, ArrayList的大小是可以动态变化的 ArrayList提供了更多的方法和特性, 如addAll(), removeAll() 4.ArrayList, Vector, LinkedList: ArrayList与Vector都是使用数组方式存储数据, LinkedList使用双向链表存储数据 ArrayList与Vector索引(查找)数据快插入和删除数据慢, Vector线程安全, 性能较差; LinkedList索引数据慢插入和删除数据快 注: ArrayList在并发add()时可能会出现数组下标越界 5.String, StringBuffer, StringBuilder: String: 字符串不可改变 StringBuffer: 字符串可变, 线程安全, 效率低 StringBuilder: 字符串可变, 线程不安全, 效率高 注: （1）如果要操作少量的数据用 String； ​ （2）多线程操作字符串缓冲区下操作大量数据 StringBuffer； ​ （3）单线程操作字符串缓冲区下操作大量数据 StringBuilder。 6.String为啥不可变: JDK中String被声明为一个fina类, 且内部的value字节数组也是final的; 安全, 多线程安全, 保证了hash码的唯一性 7.==比较的是什么: ‘’==’’ 对比两个对象基于内存引用, 如果两个对象的引用完全相同(指向同一个对象), ‘’==’’ 操作将返回true, 否则返回false ‘’==’’ 如果两边是基本类型, 就是比较数值是否相等 8.==与equals的区别: equals方法不能作用于基本数据类型的变量 没有重写equals方法时，是判断两个对象地址值是否相等。 重写了equals方法时，是判断两个对象所指向的内容是否相等。（如String、Date都重写了equals方法） 9.是否可以在static环境中访问非static变量: 不可以, static变量在Java中是属于类的,它在所有的实例中的值是一样的, 当类被Java虚拟机载入的时候, 会对static变量进行初始化. 如果尝试不用实例来访问非static的变量, 编译器会报错, 因为这些变量还没有被创建出来, 还没有与任何实例关联上 10.接口与抽象类的区别: 类可以实现很多个接口, 但只能继承一个抽象类 Java接口中声明的变量默认都是final的, 抽象类可以包含非final的变量 接口中所有的方法隐含的都是抽象的, 而抽象类则可以同时包含抽象和非抽象的方法 Java接口中的成员函数默认是public的, 抽象类的成员函数可以是private, protected或者public的 接口是绝对抽象的, 不可以被实例化. 抽象类页不可以被实例化, 但是, 如果它包含main()方法的话是可以被调用的 类如果要实现一个接口，它必须要实现接口声明的所有方法。但是，类可以不实现抽象类声明的所有方法，当然，在这种情况下，类也必须得声明成是抽象的。 11.Java里的final关键字怎么用: 当用final修饰一个类时, 表示这个类不能被继承 对于一个final变量, 如果是基本数据类型的变量, 则在其数值一旦在初始化之后便不能更改; 如果是引用类型的变量, 则在对其初始化之后便不能再让其指向另一个对象 注:使用final方法的原因有两个, 第一个原因是把方法锁定, 以防任何继承类修改它的含义; 第二个原因是效率, 在早期的Java实现版本中, 会将final方法转为内置方法 12.final, finally, finalize的区别: final用于声明属性, 方法和类, 分别表示属性不可改变, 方法不可覆盖, 类不可继承 finally是异常处理语句结构的一部分, 表示总是执行 finalize是Object类的一个方法, 在垃圾收集器执行的时候会调用被回收对象的此方法, 可以覆盖此方法提供垃圾收集时的其他资源回收, 例如关闭文件等 13.四种权限修饰符: 修饰符 同类中 同一个包中(子类和无关类) 不同包(子类) 不同包(无关类) public Y Y Y Y protected Y Y Y N 默认 Y Y N N private Y N N N 14.列举你所知道的Object类的方法: ​ Object()默认构造方法。 clone() 创建并返回此对象的一个副本。 equals(Object obj) 指示某个其他对象是否与此对象“相等”。 finalize()当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。getClass()返回一个对象的运行时类。 hashCode()返回该对象的哈希码值。 notify()唤醒在此对象监视器上等待的单个线程。 notifyAll()唤醒在此对象监视器上等待的所有线程。 toString()返回该对象的字符串表示。 wait()导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。 wait(long timeout)导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。 wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。 15.Java支持的数据类型有哪些? 什么是自动拆装箱? Java语言支持的8种基本数据类型是:byte short int long float double boolean char 自动装箱是Java编译器在基本数据类型和对应的对象包装数据类型之间做的一个转化, 分别对应的为: Byte Short Integer Long Float Double Boolean Character 16.Java集合类框架的基本接口有哪些? Collection: 代表一组对象, 每一个对象都是它的子元素 Set: 不包含重复元素的Collection List: 有顺序的Collection, 并可以包含重复元素 Map: 可以把键(key)映射到值(value)的对象, 键不能重复 17.Collection和Collections的区别: Collection是集合类的上级接口, 继承于它的接口主要有Set和List; Collections是针对集合类的一个帮助类, 他提供一系列静态方法实现对各种集合的搜索, 排序, 线程安全化等操作 18.List, Set, Map是否继承自Collection接口? List, Set是, Map不是 19.什么是迭代器: Iterator接口提供了很多对集合元素进行迭代的方法。每一个集合类都包含了可以返回迭代器实例的迭代方法。迭代器可以在迭代的过程中删除底层集合的元素。 20.Iterator和ListIterator的区别是什么: Iterator可用来遍历Set和List集合, 但是ListIterator只能用来遍历List Iterator对集合只能是向前遍历, ListIterator既可以向前也可以向后 ListIterator实现了iterator接口, 并包含其他功能, 比如:增加元素, 替换元素等 21.map的分类和常见的情况 Java为数据结构中的映射定义了一个接口java.util.Map;它有四个实现类,分别是HashMap Hashtable LinkedHashMap 和TreeMap Map主要用于存储健值对，根据键得到值，因此不允许键重复(重复了覆盖了),但允许值重复 Hashmap它根据键的HashCode值存储数据,根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。 HashMap最多只允许一条记录的键为Null;允许多条记录的值为 Null; HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap;可能会导致数据的不一致。如果需要同步，可以用 Collections的synchronizedMap方法使HashMap具有同步的能力，或者使用ConcurrentHashMap。 Hashtable与 HashMap类似,它继承自Dictionary类, 不同的是:它不允许记录的键或者值为空; 它支持线程的同步，即任一时刻只有一个线程能写Hashtable,因此也导致了 Hashtable在写入时会比较慢。 LinkedHashMap 是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关 TreeMap实现SortMap接口，能够把它保存的记录根据键排序, 默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的 22.为什么重写equals还要重写hashcode? 如果两个对象相同(即equals返回true)hashcode一定相等；但是hashcod相等时, 两个对象却不一定equals 为了提高程序的执行效率; 先进行hashcode比较, 如果不同, 就没有必要进行equals比较了, 这样就大大的减少了equals的使用次数, 从而效率得到提高 23.Java中的异常处理关键字是什么？ ​ try来执行一段程序，如果出现异常，系统会抛出（throws）一个异常，这时候你可以通过它的类型来捕捉（catch）它，或最后（finally）由缺省处理器来处理。用try来指定一块预防所有”异常”的程序。紧跟在try程序后面，应包含一个catch子句来指定你想要捕捉的”异常”的类型。 throw: 用来明确地抛出一个”异常”。 throws: 用来标明一个成员函数可能抛出的各种”异常”。 finally: 为确保一段代码不管发生什么”异常”都被执行一段代码。 24.请问运行时异常与受检异常有什么区别？ 运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。 25.error和exception有什么区别? error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception 表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 26.如何保证线程安全？ 通过合理的时间调度，避开共享资源的存取冲突 在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源 27.举例说明同步和异步 如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。 28.请简述一下线程的sleep()方法和yield()方法有什么区别？ sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态 sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常 sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性 29.创建线程有几种不同的方式？ 继承Thread类 实现Runnable接口 30.请说明一下sleep() 和 wait() 有什么区别？ sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 31.请说明一下锁和同步的区别 synchronized既可以加在方法上，也可以加载特定代码块上，而lock需要显示地指定起始位置和终止位置。 synchronized是托管给JVM执行的，lock的锁定是通过代码实现的，它有比synchronized更精确的线程语义。 synchronized获取锁和释放锁的方式都是在块结构中，当获取多个锁时，必须以相反的顺序释放，并且是自动解锁。而Lock则需要开发人员手动释放，并且必须在finally中释放，否则会引起死锁。 32.请你谈谈关于Synchronized和lock synchronized是Java中的关键字，synchronized是内置的语言实现；synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；Lock是一个接口，Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁 Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"HashMap分析","slug":"HashMap分析","date":"2021-05-08T13:19:59.130Z","updated":"2020-07-05T14:21:39.646Z","comments":true,"path":"HashMap/","link":"","permalink":"http://tonymua.top/HashMap/","excerpt":"1.概述HashMap位于java.util包中，HashMap基于Map接口实现，元素以键值对的方式存储，并且允许使用null键和null值，因为key不允许重复，因此只能有一个键为null,另外HashMap不能保证放入元素的顺序，它是无序的，和放入的顺序并不能相同。HashMap是线程不安全的。它的底层为哈希表结构（链表散列：数组+链表）实现，结合数组和链表的优点。JDK1.8之后，当链表长度超过 8 时，链表转换为红黑树。","text":"1.概述HashMap位于java.util包中，HashMap基于Map接口实现，元素以键值对的方式存储，并且允许使用null键和null值，因为key不允许重复，因此只能有一个键为null,另外HashMap不能保证放入元素的顺序，它是无序的，和放入的顺序并不能相同。HashMap是线程不安全的。它的底层为哈希表结构（链表散列：数组+链表）实现，结合数组和链表的优点。JDK1.8之后，当链表长度超过 8 时，链表转换为红黑树。 HashMap主要属性： 1234567891011121314151617181920212223public class HashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; //HashMap的初始容量大小为16(1&lt;&lt;4)，指的是存储元素的数组大小，即桶的数量 //为啥是16呢? 因为在使用2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。这是为了实现均匀分布。 static final int DEFAULT_INITIAL_CAPACITY = 16; //HashMap的最大容量(1&lt;&lt;30) //使用位与运算速度更快 static final int MAXIMUM_CAPACITY = 1073741824; //默认负载因子0.75 //当HashMap中的数据量/HashMap的总容量=0.75或者指定值时，HashMap的总容量自动扩展一倍 //负载因子代表了hash表中元素的填满程度。加载因子越大，填满的元素越多，但是冲突的机会增大了，链表越来越长，查询速度会降低。反之，如果加载因子过小，冲突的机会减小了，但是hash表过于稀疏。冲突越大，查找的成本就越高。 static final float DEFAULT_LOAD_FACTOR = 0.75F; //由链表转换成树的阈值:8 //在存储数据时，当某一个桶中链表的长度&gt;=8时，链表结构会转换成红黑树结构(其实还要求桶的中数量&gt;=64) static final int TREEIFY_THRESHOLD = 8; //红黑树转为链表的阈值:6 //当在扩容(resize())时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量&lt;6时，则将红黑树转换成链表 static final int UNTREEIFY_THRESHOLD = 6; //最小树形化容量阈值:64 //当哈希表中的容量&gt;该值时，才允许链表转换成红黑树 static final int MIN_TREEIFY_CAPACITY = 64; ...... &#125; 2.NodeJDK 1.8采用的是Node数组，实质上还是Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体，以此来解决Hash冲突的问题。一个桶中链表的长度&lt;8时:一个桶中链表的长度&gt;=8时:数组存储区间是连续的，占用内存严重，故空间复杂度很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难；链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O(n)。链表的特点是：寻址困难，插入和删除容易。HashMap的设计正是分别结合了数组和链表的优点。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 3.hash算法首先获取对象的hashCode()值，然后将hashCode值右移16位，然后将右移后的值与原来的hashCode做异或(^)运算，返回结果。(其中h&gt;&gt;&gt;16，在JDK1.8中，优化了高位运算的算法，使用了零扩展，无论正数还是负数，都在高位插入0) 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 4.put()HashMap并没有直接提供putVal接口给用户调用，而是提供的put方法，而put方法就是通过putVal来插入元素的。 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向6，如果table[i]不为空，转向3； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向4，这里的相同指的是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向5； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;//put函数的核心处理函数 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //HashMap是懒加载，所有的put先检查table数组是否已经初始化，没有初始化则进行扩容数组初始化table数组，保证table数组一定初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //通过hash算法(n - 1) &amp; hash找到数组下标得到数组元素，为空则新建 //(n-1)&amp;hash就等价于hash%n。&amp;运算的效率高于%运算。 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //找到数组元素，hash相等同时key相等，则直接覆盖，执行赋值操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // hash值不相等，即key不相等 //判断链表是否是红黑树 else if (p instanceof TreeNode) //放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //遍历当前的链表，一直遍历到链表末尾 for (int binCount = 0; ; ++binCount) &#123; //到达链表的尾部 if ((e = p.next) == null) &#123; //在尾部插入结点(JDK1.8之前采用头插法，JDK1.8之后采用尾插法，使用尾插，在扩容时会保持链表元素原本的顺序，就不会出现链表成环) p.next = newNode(hash, key, value, null); //当链表长度超过8(阈值)，就会将链表便转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //记录修改次数 ++modCount; //判断是否需要扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; HashMap的数据存储实现流程 根据key计算得到key.hash = (h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)； 根据key.hash计算得到桶数组的索引index = key.hash &amp; (table.length - 1)，这样就找到该key的存放位置了 ① 如果该位置没有数据，用该数据新生成一个节点保存新数据，返回null； ② 如果该位置有数据是一个红黑树，那么执行相应的插入 / 更新操作； ③ 如果该位置有数据是一个链表，分两种情况一是该链表没有这个节点，另一个是该链表上有这个节点，注意这里判断的依据是key.hash是否一样： 如果该链表没有这个节点，那么采用尾插法新增节点保存新数据，返回null；如果该链表已经有这个节点了，那么找到该节点并更新新数据，返回老数据。 注意： HashMap的put会返回key的上一次保存的数据，比如： 1234HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();System.out.println(map.put(\"a\", \"A\")); // 打印nullSystem.out.println(map.put(\"a\", \"AA\")); // 打印ASystem.out.println(map.put(\"a\", \"AB\")); // 打印AA 5.get()HashMap同样并没有直接提供getNode接口给用户调用，而是提供的get方法，而get方法就是通过getNode来取得元素的。 123456789101112131415161718192021222324252627282930public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //若table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //永远检查第一个node，桶中第一项(数组元素)相等 //在Hashmap1.8中，无论是存元素还是取元素，都是优先判断bucket上第一个元素是否匹配，而在1.7中则是直接遍历查找 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) //一次就匹配到了，直接返回， //否则进行搜索 return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) //红黑树搜索/查找 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //链表搜索(查找) if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 基本流程: 根据key计算hash; 检查数组是否为空，为空返回null; 根据hash计算bucket位置，如果bucket第一个元素是目标元素，直接返回。否则执行4; 如果bucket上元素大于1并且是树结构，则执行树查找。否则执行5; 如果是链表结构，则遍历寻找目标 6.resize()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table;//定义了一个临时Node类型的数组 int oldCap = (oldTab == null) ? 0 : oldTab.length;//判断目前的table数组是否为空，记录下当前数组的大小 int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123;//如果oldCap不为空的话，就是hash桶数组不为空 //如果已达到最大容量不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //通过位运算扩容到原来的两倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold //用构造器初始化了阈值，将阈值直接赋值给容量 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) //初始化新的Node类型数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //将新数组的值复制给旧的hash桶数组 table = newTab; //当原来的table不为空，需要将数据迁移到新的数组里面去 if (oldTab != null) &#123; //开始对原table进行遍历 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //取出这个数组第一个不为空的元素 if ((e = oldTab[j]) != null) &#123; //将旧的hash桶数组在j结点处设置为空，把空间释放掉，方便gc oldTab[j] = null; //如果e后面没有Node结点 if (e.next == null) //计算相应的hash值，把节点存储到新table的对应位置处 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode)///如果e是红黑树的类型，按照红黑树的节点移动 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next;//将Node结点的next赋值给next //如果结点e的hash值与原hash桶数组的长度作与运算为0 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //如果结点e的hash值与原hash桶数组的长度作与运算不为0 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 7.面试题 Object若不重写hashcode()的话，hashcode是如何计算出来的？Object的hashcode()方法是本地方法，该方法直接返回对象的内存地址，如果不重写hashcode()，则任何对象的hashcode都不相等。(然而hashmap想让部分值的hashcoe值相等，所以需要重写) 为什么重写equals()还要重写hashcode()？HashMap中比较key先求出key的hashcode()，比较其值是否相等，相等则比较equals()，若相等则认为它们是相等的，若equals()不相等则认为它们是不相等的。如果只重写equals()不重写hashcode()，就会导致相同的key值被认为不同(如果不重写hashcode()，则任何对象的hashcode都不相等)，就会在HashMap中存储相同的key值(map中key值不能相同)。①如果两个对象相同（equals()比较返回true)，那么它们的hashcode值一定相同；②如果两个对象的hashcode值相同，它们并不一定相同(equals()比较返回false)","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://tonymua.top/categories/源码分析/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://tonymua.top/tags/HashMap/"},{"name":"源码","slug":"源码","permalink":"http://tonymua.top/tags/源码/"},{"name":"底层","slug":"底层","permalink":"http://tonymua.top/tags/底层/"}]},{"title":"Git入门(二)","slug":"Git入门(二)","date":"2021-05-08T13:19:59.129Z","updated":"2020-04-29T02:44:38.019Z","comments":true,"path":"12318/","link":"","permalink":"http://tonymua.top/12318/","excerpt":"1.远程仓库1.1 添加远程库​ 现在我们已经在本地创建了一个Git仓库，又想让其他人来协作开发，此时就可以把本地仓库同步到远程仓库，同时还增加了本地仓库的一个备份。 常用的远程仓库就是github：https://github.com/，接下来我们演示如何将本地代码同步到github。 1.1.1 在github上创建仓库","text":"1.远程仓库1.1 添加远程库​ 现在我们已经在本地创建了一个Git仓库，又想让其他人来协作开发，此时就可以把本地仓库同步到远程仓库，同时还增加了本地仓库的一个备份。 常用的远程仓库就是github：https://github.com/，接下来我们演示如何将本地代码同步到github。 1.1.1 在github上创建仓库 ​ 点击“create repository”按钮仓库就创建成功了。 ​ Github支持两种同步方式“https”和“ssh”。如果使用https很简单基本不需要配置就可以使用，但是每次提交代码和下载代码时都需要输入用户名和密码。如果使用ssh方式就需要客户端先生成一个密钥对，即一个公钥一个私钥。然后还需要把公钥放到githib的服务器上。这两种方式在实际开发中都用应用，所以我们都需要掌握。接下来我们先看ssh方式。 1.1.2 ssh协议​ SSH 为 Secure Shell（安全外壳协议）的缩写，由 IETF 的网络小组（Network Working Group）所制定。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用SSH 协议可以有效防止远程管理过程中的信息泄露问题。 ssh密钥生成及配置 1.1.3 同步到远程仓库1.1.3.1 使用git bash在仓库所在的目录（E:\\temp\\git\\repository）点击右键选择“Git Bash Here”，启动git bash程序。 然后在git bash中执行如下语句： git remote add origin git@github.com:tonymua/mytest.git git push -u origin master 注意：其中阴影字体部分需要替换成个人的用户名。 1.1.3.2 使用TortoiseGit同步​ 1. 由于TortoiseGit使用的ssh工具是“PuTTY”git Bash使用的ssh工具是“openSSH”，如果想让TortoiseGit也使用刚才生成的密钥可以做如下配置： 同步。在本地仓库的文件夹中单击右键，选择“Git同步” 1.2 从远程仓库克隆​ 克隆远程仓库也就是从远程把仓库复制一份到本地，克隆后会创建一个新的本地仓库。选择一个任意部署仓库的目录，然后克隆远程仓库。 1.2.1 使用git bashgit clone git@github.com:tonymua/mytest.git 1.2.2 使用TortoiseGit在任意目录点击右键：”拉取” 1.3 从远程仓库取代码Git中从远程的分支获取最新的版本到本地有这样2个命令： git fetch：相当于是从远程获取最新版本到本地，不会自动merge（合并代码） git pull：相当于是从远程获取最新版本并merge到本地 上述命令其实相当于git fetch 和 git merge 在实际使用中，git fetch更安全一些 因为在merge前，我们可以查看更新情况，然后再决定是否合并 如果使用TortoiseGit的话可以从右键菜单中点击“拉取”（pull）或者“获取”（fetch） 1.4 搭建私有Git服务器1.4.1 服务器搭建​ 远程仓库实际上和本地仓库没啥不同，纯粹为了7x24小时开机并交换大家的修改。GitHub就是一个免费托管开源代码的远程仓库。但是对于某些视源代码如生命的商业公司来说，既不想公开源代码，又舍不得给GitHub交保护费，那就只能自己搭建一台Git服务器作为私有仓库使用。 搭建Git服务器需要准备一台运行Linux的机器，在此我们使用CentOS。以下为安装步骤： 安装git服务环境准备 yum -y install curl curl-devel zlib-devel openssl-devel perl cpio expat-devel gettext-devel gcc cc 下载git-2.5.0.tar.gz 1）解压缩 2）cd git-2.5.0 3）autoconf 4）./configure 5）make 6）make install 添加用户 adduser -r -c ‘git version control’ -d /home/git -m git 此命令执行后会创建/home/git目录作为git用户的主目录。 设置密码 passwd git 输入两次密码 切换到git用户 su git 创建git仓库 git –bare init /home/git/first 注意：如果不使用“–bare”参数，初始化仓库后，提交master分支时报错。这是由于git默认拒绝了push操作，需要.git/config添加如下代码： [receive] ​ denyCurrentBranch = ignore 推荐使用：git –bare init初始化仓库。 1.4.2 连接服务器私有git服务器搭建完成后就可以向连接github一样连接使用了，但是我们的git服务器并没有配置密钥登录，所以每次连接时需要输入密码。 使用命令连接： $ git remote add origin ssh://git@192.168.25.156/home/git/first 这种形式和刚才使用的形式好像不一样，前面有ssh://前缀，好吧你也可以这样写： $ git remote add origin git@192.168.25.156:first 使用TortoiseGit同步的话参考上面的使用方法。 2.分支管理2.1 建合并分支​ 在我们每次的提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD指针严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 所以Git合并分支也很快！就改改指针，工作区内容也不变！合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 2.2 使用TortoiseGit实现分支管理2.2.1 创建分支在本地仓库文件夹中点击右键，然后从菜单中选择“创建分支”： 如果想创建完毕后直接切换到新分支可以勾选“切换到新分支”选项或者从菜单中选择“切换/检出”来切换分支： 2.2.2 合并分支分支切换到dev后就可以对工作区的文件进行修改，然后提交到dev分支原理的master分支不受影响。例如我们修改mytest.txt中的内容，然后提交到dev分支。 切换到master分支后还是原理的内容： 将dev分支的内容合并到master分支，当前分支为master。从右键菜单中选择“合并”： 再查看mytest.txt的内容就已经更新了 2.3 解决冲突两个分支中编辑的内容都是相互独立互不干扰的，那么如果在两个分支中都对同一个文件进行编辑，然后再合并，就有可能会出现冲突。 例如在master分支中对mytest.txt进行编辑：然后提交到版本库。 切换到dev分支，对mytest.txt进行编辑：提交 最后进行分支合并，例如将dev分支合并到master分支。需要先切换到master分支然后进行分支合并。 冲突需要手动解决。 在冲突文件上单机右键选择“解决冲突”菜单项：把冲突解决完毕的文件提交到版本库就可以了。 3.在IntelliJ IDEA中使用Git3.1 在Idea中配置Git如果Git安装在默认路径下，那么idea会自动找到git的位置，如果更改了Git的安装位置则需要手动配置下Git的路径。 选择File→Settings打开设置窗口，找到Version Control下的git选项： 选择git的安装目录后可以点击“Test”按钮测试是否正确配置。 3.2 将工程添加至Git 在idea中创建一个工程，例如创建一个java工程 创建本地仓库 在菜单中选择“vcs”→Import into Version Control→Create Git Repository… 选择工程所在的上级目录。本例中应该选择idea-projects目录，然后点击“OK”按钮，在工程的上级目录创建本地仓库，那么ideaproject目录就是本地仓库的工作目录，此目录中的工程就可以添加到本地仓库中。也就是可以把idea-git-test工程添加到本地仓库中。 选择之后在工具栏上就多出了git相关工具按钮 将工程添加至本地仓库 直接点击commit按钮，将工程提交至本地仓库。 然后点击“commit”按钮，将工程添加至本地仓库。 推送到远程 在github上创建一个仓库然后将本地仓库推送到远程。 在工程上点击右键，选择git→Repository→push， 或者在菜单中选择vcs→git→push 点击“Define remote”链接，配置https形式的URL，git形式的无法通过。然后点击OK 点击“push”按钮就讲本地仓库推送到远程，如果是第一次配置推送需要输入github的用户名和密码。 3.3 从远程仓库克隆关闭工程后，在idea的欢迎页上有“Check out from version control”下拉框，选择git 此处仍然推荐使用htts形式的url，点击“test”按钮后显示连接成功。 点击OK按钮后根据提示将远程仓库克隆下来，然后倒入到idea中。 3.4 从服务端拉取代码如果需要从服务端同步代码可以使用工具条中的“update”按钮","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Git入门(一)","slug":"Git入门(一)","date":"2021-05-08T13:19:59.127Z","updated":"2020-04-29T02:44:38.018Z","comments":true,"path":"61626/","link":"","permalink":"http://tonymua.top/61626/","excerpt":"1.Git与svn对比1.1 SVN​ SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就郁闷了。下图就是标准的集中式版本控制工具管理方式：","text":"1.Git与svn对比1.1 SVN​ SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就郁闷了。下图就是标准的集中式版本控制工具管理方式： ​ 集中管理方式在一定程度上看到其他开发人员在干什么，而管理员也可以很轻松掌握每个人的开发权限。 但是相较于其优点而言，集中式版本控制工具缺点很明显： 服务器单点故障 容错性差 2.2 Git​ Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。下图就是分布式版本控制工具管理方式： 2.Git工作流程一般工作流程如下： 1．从远程仓库中克隆 Git 资源作为本地仓库。 2．从本地仓库中checkout代码然后进行代码修改 3．在提交前先将代码提交到暂存区。 4．提交修改。提交到本地仓库。本地仓库中保存修改的各个历史版本。 5．在修改完成后，需要和团队成员共享代码时，可以将代码push到远程仓库。 下图展示了 Git 的工作流程： 3.使用git管理文件版本3.1 创建版本库​ 什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。由于git是分布式版本管理工具，所以git在不需要联网的情况下也具有完整的版本管理能力。 3.1.1 使用GitBash在当前目录中点击右键中选择Git Bash来启动, 或者在开始菜单中启动。 注意如果是从开始菜单启动的gitbash需要切换目录到仓库所在的目录。 创建仓库执行命令：git init 概念： 版本库：“.git”目录就是版本库，将来文件都需要保存到版本库中。 工作目录：包含“.git”目录的目录，也就是.git目录的上一级目录就是工作目录。只有工作目录中的文件才能保存到版本库中。 3.2 添加文件3.2.1 添加文件过程在E:\\temp\\git\\repository目录下创建一个mytest.txt文件 提交文件：在mytest.txt上再次点击右键选择“提交”，此时将文件保存至版本库中。 3.2.2 工作区和暂存区Git和其他版本控制系统如SVN的一个不同之处就是有暂存区的概念。 什么是工作区（Working Directory）？ 工作区就是你在电脑里能看到的目录，比如我的reporstory文件夹就是一个工作区。 有的同学可能会说repository不是版本库吗怎么是工作区了？其实repository目录是工作区，在这个目录中的“.git”隐藏文件夹才是版本库。这回概念清晰了吧。 Git的版本库里存了很多东西，其中最重要的就是称为（或者叫）的暂存区，还有为我们自动创建的第一个分支，以及指向的一个指针叫HEAD。如下图所示： 把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。 你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 3.3 修改文件3.3.1 提交修改​ 被版本库管理的文件不可避免的要发生修改，此时只需要直接对文件修改即可。修改完毕后需要将文件的修改提交到版本库。 修改test.txt文件后点击右键，然后选择“提交” 3.3.2 查看修改历史在开发过程中可能会经常查看代码的修改历史，或者叫做修改日志。来查看某个版本是谁修改的，什么时间修改的，修改了哪些内容。 可以在文件上点击右键选择“显示日志”来查看文件的修改历史。 3.3.3 差异比较当文件内容修改后，需要和修改之前对比一下修改了哪些内容此时可以使用“比较差异功能” 3.3.4 还原修改当文件修改后不想把修改的内容提交，还想还原到未修改之前的状态。此时可以使用“还原”功能 注意：此操作会撤销所有未提交的修改，所以当做还原操作是需要慎重慎重！！！ 3.4 删除文件需要删除无用的文件时可以使用git提供的删除功能直接将文件从版本库中删除。 3.5 案例：将java工程提交到版本库 第一步：将参考资料中的java工程HelloProjet复制到工作目录中 第二步：将工程添加到暂存区 ​ 点击确定完成暂存区添加 忽略文件或文件夹 ​ 在此工程中，并不是所有文件都需要保存到版本库中的例如“out”目录及目录下的文件就可以忽略。好在Git考虑到了大家的感受，这个问题解决起来也很简单，在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 如果使用TortoiseGit的话可以使用菜单项直接进行忽略 选择保留本地文件。完成后在此文件夹内会多出一个.gitignore文件，这个文件就是文件忽略文件，当然也可以手工编辑。其中的内容就是把out目录忽略掉。 提交 3.6 忽略文件语法规范空行或是以 # 开头的行即注释行将被忽略。 可以在前面添加正斜杠 / 来避免递归,下面的例子中可以很明白的看出来与下一条的区别。 可以在后面添加正斜杠 / 来忽略文件夹，例如 build/ 即忽略build文件夹。 可以使用 ! 来否定忽略，即比如在前面用了 *.apk ，然后使用 !a.apk ，则这个a.apk不会被忽略。 * 用来匹配零个或多个字符，如 *.[oa] 忽略所有以”.o”或”.a”结尾， *~ 忽略所有以 ~ 结尾的文件（这种文件通常被许多编辑器标记为临时文件）； [] 用来匹配括号内的任一字符，如 [abc] ，也可以在括号内加连接符，如 [0-9] 匹配0至9的数； ? 用来匹配单个字符。 看了这么多，还是应该来个栗子： # 忽略 .a 文件 *.a # 但否定忽略 lib.a, 尽管已经在前面忽略了 .a 文件 !lib.a # 仅在当前目录下忽略 TODO 文件， 但不包括子目录下的 subdir/TODO /TODO # 忽略 build/ 文件夹下的所有文件 build/ # 忽略 doc/notes.txt, 不包括 doc/server/arch.txt doc/*.txt # 忽略所有的 .pdf 文件 在 doc/ directory 下的 doc/*/.pdf","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Git","slug":"Git","date":"2021-05-08T13:19:59.126Z","updated":"2020-08-05T07:34:41.314Z","comments":true,"path":"git_shell/","link":"","permalink":"http://tonymua.top/git_shell/","excerpt":"Git1.创建版本库 git init 把这个目录变成Git可以管理的仓库 git add readme.md 把文件添加到仓库 git commit -m “wrote a readme file” -m后面输入的是本次提交的说明","text":"Git1.创建版本库 git init 把这个目录变成Git可以管理的仓库 git add readme.md 把文件添加到仓库 git commit -m “wrote a readme file” -m后面输入的是本次提交的说明 2.版本回退 修改readme.md内容git add readme.txtgit commit -m “append GPL”ps: git log可以查看版本历史记录 git reset –hard HEAD^ps: HEAD^表示上一个版本 HEAD^表示上上个版本 HEAD~100表示往上100个版本 命令行窗口还没有被关掉时，找到某个版本的commit id，也能进行回退。git reset –hard xxxxxxxx命令行窗口被被关掉时，使用git reflog查看记录的每一次命令 3.工作区和暂存区 工作区电脑里能看到的目录，比如gittest文件夹就是一个工作区 版本库工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。git add . 添加所有数据git commit -m “understand how stage works” 4.管理修改 对readme.txt做一个修改git add readme.md再修改readme.mdgit commit -m “git tracks changes” 提交 git status然而，第二次修改并没有被提交，第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git commitGit管理的是修改，当你用git add命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，git commit只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。git diff HEAD – readme.md 查看工作区和版本库里面最新版本的区别 提交第二次修改第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commit 5.撤销修改 git checkout – readme.md 丢弃工作区的修改一种是readme.md自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；一种是readme.md已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。总之，就是让这个文件回到最近一次git commit或git add时的状态。 git add后修改git reset HEAD readme.md 把暂存区的修改撤销掉git checkout – readme.md 丢弃工作区的修改 6.删除文件 先添加一个新文件test.txt到Git并且提交git add test.txtgit commit -m “add test.txt” 直接在文件管理器中把没用的文件删了，或者用rm命令删除rm test.txt从版本库中删除该文件，那就用命令git rm删掉，并且git commitgit rm test.txtgit commit -m “remove test.txt”删错了，因为版本库里还有，所以可以把误删的文件恢复到最新版本git checkout – test.txt 7.远程仓库 添加远程库在GitHub创建一个Git仓库git remote add origin git@github.com:xxxxxxxx 关联git push -u origin master 把本地库的所有内容推送到远程库上 从远程库克隆git clone git@github.com:xxxxxxxxx 8.分支管理 创建与合并分支git switch -c dev 创建dev分支，然后切换到dev分支git branch 查看当前分支修改readme.md git add readme.md git commit -m “branch test”git switch master 切换回master分支再查看readme.md文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变。git merge dev 把dev分支的工作成果合并到master分支上git branch -d dev 删除dev分支 解决冲突git switch -c feature1 准备新的feature1分支修改readme.mdgit add readme.mdgit commit -m “AND simple” 在feature1分支上提交git switch master 切换到master分支在master分支上把readme.md进行不同修改git add readme.mdgit commit -m “&amp; simple” 在master分支上提交这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突。git status 查看冲突的文件手动修改文件解决冲突后再提交git add readme.txtgit commit -m “conflict fixed”git branch -d feature1 删除feature1分支准备合并dev分支，请注意--no-ff参数，表示禁用Fast forward Bug分支git stash 把当前工作现场“储藏”起来，等以后恢复现场后继续工作git switch -c issue-101修改Bug，然后提交git add readme.txtgit commit -m “fix bug 101”修复完成后，切换到master分支，并完成合并，最后删除issue-101分支git switch mastergit merge –no-ff -m “merged bug fix 101” issue-101git switch devgit stash pop 删除stash复制一个特定的提交到当前分支git loggit cherry-pick 4e4858db453de3da86ee2eafc2 多人协作git remote -v 查看远程库的详细信息多人协作的工作模式通常是这样： 首先，可以试图用git push origin推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin推送就能成功！如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to origin/。 忽略特殊文件在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：https://github.com/github/gitignore把.gitignore也提交到Git","categories":[{"name":"Git","slug":"Git","permalink":"http://tonymua.top/categories/Git/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://tonymua.top/tags/shell/"},{"name":"Git","slug":"Git","permalink":"http://tonymua.top/tags/Git/"}]},{"title":"Druid连接池的配置与使用","slug":"Druid连接池的配置与使用","date":"2021-05-08T13:19:59.124Z","updated":"2020-04-29T02:44:37.931Z","comments":true,"path":"30630/","link":"","permalink":"http://tonymua.top/30630/","excerpt":"Druid连接池的配置与使用Druid（德鲁伊）连接池 是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池(据说是目前最好的连接池)。github地址：https://github.com/alibaba/druid/ maven仓库地址：http://www.mvnrepository.com/artifact/com.alibaba/druid Druid连接池的使用步骤1.导入jar包https://pan.baidu.com/s/1jOaM-nFfxx7PcQ6_Nvu-Uw提取码: eyl0","text":"Druid连接池的配置与使用Druid（德鲁伊）连接池 是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池(据说是目前最好的连接池)。github地址：https://github.com/alibaba/druid/ maven仓库地址：http://www.mvnrepository.com/artifact/com.alibaba/druid Druid连接池的使用步骤1.导入jar包https://pan.baidu.com/s/1jOaM-nFfxx7PcQ6_Nvu-Uw提取码: eyl0 2.配置文件 Druid.properties123456789101112131415#驱动的名字:com.mysql.jdbc.DriverdriverClassName=com.mysql.jdbc.Driver#数据库的地址:jdbc:mysql://localhost:3306/bankurl=jdbc:mysql://localhost:3306/bank#数据库管理账号和密码username=rootpassword=547717253#初始链接数:10initialSize=10#最大并行链接数:50maxActive=50#最小空闲数:5minIdle=5#最大等待时间(毫秒):60000maxWait=60000 3.DruidUtils1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class DruidUtils &#123; /** * 定义一个连接池 */ private static DataSource dataSource; /** 初始化连接池 */ static &#123; try &#123; InputStream is = DruidUtils.class.getClassLoader().getResourceAsStream(\"Druid.properties\"); Properties prop = new Properties(); prop.load(is); dataSource = DruidDataSourceFactory.createDataSource(prop); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 通过连接池获取连接 */ public static Connection getConnection() throws SQLException &#123; return dataSource.getConnection(); &#125; /** * 关闭连接，归还资源 */ public static void release(Connection conn , PreparedStatement ps , ResultSet rs)&#123; closeRs(rs); closeSt(ps); closeConn(conn); &#125; public static void release(Connection conn , PreparedStatement ps)&#123; closeSt(ps); closeConn(conn); &#125; private static void closeRs(ResultSet rs)&#123; try &#123; if(rs != null)&#123; rs.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; rs = null; &#125; &#125; private static void closeSt(PreparedStatement ps)&#123; try &#123; if(ps != null)&#123; ps.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; ps = null; &#125; &#125; private static void closeConn(Connection conn)&#123; try &#123; if(conn != null)&#123; conn.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; conn = null; &#125; &#125;&#125; 4.测试12345678910111213141516171819public class DruidDemo &#123; @Test public void testDruid() &#123; Connection conn = null; PreparedStatement ps = null; try &#123; conn = DruidUtils.getConnection(); String sql = \"insert into account values(null,?,?)\"; ps = conn.prepareStatement(sql); ps.setString(1, \"test\"); ps.setInt(2, 2000); ps.executeUpdate(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally &#123; DruidUtils.release(conn, ps); &#125; &#125;&#125;","categories":[],"tags":[{"name":"javaee","slug":"javaee","permalink":"http://tonymua.top/tags/javaee/"}]},{"title":"Docker入门","slug":"Docker入门","date":"2021-05-08T13:19:59.123Z","updated":"2020-04-29T02:44:38.067Z","comments":true,"path":"11205/","link":"","permalink":"http://tonymua.top/11205/","excerpt":"1.Docker简介1.1 什么是虚拟化​ 在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。 ​ 在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件对资源充分利用 虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。","text":"1.Docker简介1.1 什么是虚拟化​ 在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。 ​ 在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件对资源充分利用 虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。 1.2 什么是Docker​ Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。 ​ Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。 ​ 在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。 为什么选择Docker? （1）上手快 ​ 用户只需要几分钟，就可以把自己的程序“Docker化”。Docker依赖于“写时复制”（copy-on-write）模型，使修改应用程序也非常迅速，可以说达到“随心所致，代码即改”的境界。随后，就可以创建容器来运行应用程序了。大多数Docker容器只需要不到1秒中即可启动。由于去除了管理程序的开销，Docker容器拥有很高的性能，同时同一台宿主机中也可以运行更多的容器，使用户尽可能的充分利用系统资源。 （2）职责的逻辑分类 ​ 使用Docker，开发人员只需要关心容器中运行的应用程序，而运维人员只需要关心如何管理容器。Docker设计的目的就是要加强开发人员写代码的开发环境与应用程序要部署的生产环境一致性。从而降低那种“开发时一切正常，肯定是运维的问题（测试环境都是正常的，上线后出了问题就归结为肯定是运维的问题）” （3）快速高效的开发生命周期 ​ Docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性，易于构建，并易于协作。（通俗一点说，Docker就像一个盒子，里面可以装很多物件，如果需要这些物件的可以直接将该大盒子拿走，而不需要从该盒子中一件件的取。） （4）鼓励使用面向服务的架构 ​ Docker还鼓励面向服务的体系结构和微服务架构。Docker推荐单个容器只运行一个应用程序或进程，这样就形成了一个分布式的应用程序模型，在这种模型下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序都变得非常简单，同时也提高了程序的内省性。（当然，可以在一个容器中运行多个应用程序） 1.3 容器与虚拟机比较​ 容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。与传统的虚拟机相比，Docker优势体现为启动速度快、占用体积小。 1.4 Docker 组件1.4.1 Docker服务器与客户端​ Docker是一个客户端-服务器（C/S）架构程序。Docker客户端只需要向Docker服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。Docker提供了一个命令行工具Docker以及一整套RESTful API。你可以在同一台宿主机上运行Docker守护进程和客户端，也可以从本地的Docker客户端连接到运行在另一台宿主机上的远程Docker守护进程。 1.4.2 Docker镜像与容器​ 镜像是构建Docker的基石。用户基于镜像来运行自己的容器。镜像也是Docker生命周期中的“构建”部分。镜像是基于联合文件系统的一种层式结构，由一系列指令一步一步构建出来。例如：添加一个文件；执行一个命令；打开一个窗口。也可以将镜像当作容器的“源代码”。镜像体积很小，非常“便携”，易于分享、存储和更新。 ​ Docker可以帮助你构建和部署容器，你只需要把自己的应用程序或者服务打包放进容器即可。容器是基于镜像启动起来的，容器中可以运行一个或多个进程。我们可以认为，镜像是Docker生命周期中的构建或者打包阶段，而容器则是启动或者执行阶段。 容器基于镜像启动，一旦容器启动完成后，我们就可以登录到容器中安装自己需要的软件或者服务。所以Docker容器就是：一个镜像格式；一些列标准操作；一个执行环境。 Docker借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地，Docker将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而Docker运输软件。和集装箱一样，Docker在执行上述操作时，并不关心容器中到底装了什么，它不管是web服务器，还是数据库，或者是应用程序服务器什么的。所有的容器都按照相同的方式将内容“装载”进去。 Docker也不关心你要把容器运到何方：我们可以在自己的笔记本中构建容器，上传到Registry，然后下载到一个物理的或者虚拟的服务器来测试，在把容器部署到具体的主机中。像标准集装箱一样，Docker容器方便替换，可以叠加，易于分发，并且尽量通用。 1.4.3 Registry（注册中心）​ Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker公司运营公共的Registry叫做Docker Hub。用户可以在Docker Hub注册账号，分享并保存自己的镜像（说明：在Docker Hub下载镜像巨慢，可以自己构建私有的Registry）。 2.Docker安装与启动2.1 安装Docker（1）yum 包更新到最新 1sudo yum update （2）安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 （3）设置yum源为阿里云 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo （4）安装docker 1sudo yum install docker-ce （5）安装后查看docker版本 1docker -v 2.2 设置ustc的镜像​ ustc是老牌的linux镜像服务提供者了，还在遥远的ubuntu 5.04版本的时候就在用。ustc的docker镜像加速器速度很快。ustc docker mirror的优势之一就是不需要注册，是真正的公共服务。 https://lug.ustc.edu.cn/wiki/mirrors/help/docker 编辑该文件： 1vi /etc/docker/daemon.json 在该文件中输入如下内容： 123&#123;\"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]&#125; 2.3 Docker的启动与停止systemctl命令是系统服务管理器指令 启动docker： 1systemctl start docker 停止docker： 1systemctl stop docker 重启docker： 1systemctl restart docker 查看docker状态： 1systemctl status docker 开机启动： 1systemctl enable docker 查看docker概要信息 1docker info 查看docker帮助文档 1docker --help 3.常用命令3.1 镜像相关命令3.1.1 查看镜像1docker images REPOSITORY：镜像名称 TAG：镜像标签 IMAGE ID：镜像ID CREATED：镜像的创建日期（不是获取该镜像的日期） SIZE：镜像大小 这些镜像都是存储在Docker宿主机的/var/lib/docker目录下 3.1.2 搜索镜像如果你需要从网络中查找需要的镜像，可以通过以下命令搜索 1docker search 镜像名称 NAME：仓库名称 DESCRIPTION：镜像描述 STARS：用户评价，反应一个镜像的受欢迎程度 OFFICIAL：是否官方 AUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的 3.1.3 拉取镜像拉取镜像就是从中央仓库中下载镜像到本地 1docker pull 镜像名称 例如，我要下载centos7镜像 1docker pull centos7 3.1.4 删除镜像按镜像ID删除镜像 1docker rmi 镜像ID 删除镜像时必须将里面的容器全部停掉 删除所有镜像 1docker rmi `docker images -q` 3.2 容器相关命令3.2.1 查看容器查看正在运行的容器 1docker ps 查看所有容器 1docker ps -a 查看最后一次运行的容器 1docker ps -l 查看停止的容器 1docker ps -f status=exited 3.2.2 创建与启动容器创建容器常用的参数说明： 创建容器命令：docker run -i：表示运行容器 -t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。 –name :为创建的容器命名。 -v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。 -d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。 -p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射 （1）交互式方式创建容器 1docker run -it --name=容器名称 镜像名称:标签 /bin/bash 命令窗口1: 命令窗口2: 退出当前容器 1exit 以交互方式创建的容器在退出的时候容器运行就停止了。 （2）守护式方式创建容器： 1docker run -di --name=容器名称 镜像名称:标签 登录守护式容器方式： 1docker exec -it 容器名称 (或者容器ID) /bin/bash 创建守护式容器后，退出时容器继续运行 3.2.3 停止与启动容器停止容器： 1docker stop 容器名称（或者容器ID） 启动容器： 1docker start 容器名称（或者容器ID） 3.2.4 文件拷贝如果我们需要将文件拷贝到容器内可以使用cp命令 1docker cp 需要拷贝的文件或目录 容器名称:容器目录 也可以将文件从容器内拷贝出来 1docker cp 容器名称:容器目录 需要拷贝的文件或目录 3.2.5 目录挂载​ 我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。创建容器 添加-v参数 后边为 宿主机目录:容器目录，例如： 1docker run -di -v /usr/local/myhtml:/usr/local/myhtml --name=mycentos3 centos:7 如果你共享的是多级的目录，可能会出现权限不足的提示。 这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数 –privileged=true 来解决挂载的目录没有权限的问题 3.2.6 查看容器IP地址我们可以通过以下命令查看容器运行的各种数据 1docker inspect 容器名称（容器ID） 也可以直接执行下面的命令直接输出IP地址 1docker inspect --format='&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' 容器名称（容器ID） 3.2.7 删除容器删除指定的容器： 1docker rm 容器名称（容器ID） 4 应用部署4.1 MySQL部署（1）拉取mysql镜像 1docker pull centos/mysql-57-centos7 （2）创建容器 1docker run -di --name=tensquare_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=547717253 mysql -p 代表端口映射，格式为 宿主机映射端口:容器运行端口 -e 代表添加环境变量 MYSQL_ROOT_PASSWORD 是root用户的登陆密码 （3）远程登录mysql 连接宿主机的IP ,指定端口为33306 4.2 tomcat部署（1）拉取镜像 1docker pull tomcat:7-jre7 （2）创建容器 创建容器 -p表示地址映射 12docker run -di --name=mytomcat -p 9000:8080 -v /usr/local/webapps:/usr/local/tomcat/webapps tomcat:7-jre7 4.3 Nginx部署（1）拉取镜像 1docker pull nginx （2）创建Nginx容器 1docker run -di --name=mynginx -p 80:80 nginx 4.4 Redis部署（1）拉取镜像 1docker pull redis （2）创建容器 1docker run -di --name=myredis -p 6379:6379 redis 5 迁移与备份5.1 容器保存为镜像我们可以通过以下命令将容器保存为镜像 1docker commit myredis myredis_i 5.2 镜像备份我们可以通过以下命令将镜像保存为tar 文件 1docker save -o myredis.tar myredis_i 5.3 镜像恢复与迁移先删除myredis_i创建的容器myredis，然后再删除myredis_i镜像。 然后执行此命令进行恢复 1docker load -i mynginx.tar 执行后再次查看镜像，可以看到镜像已经恢复 6 Dockerfile6.1 什么是Dockerfile​ Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像（centos或者ubuntu，即操作系统级别的镜像）并最终创建一个新的镜像。 (1) 对于开发人员：可以为开发团队提供一个完全一致的开发环境；(2) 对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了；(3) 对于运维人员：在部署时，可以实现应用的无缝移植。 6.2 常用命令 命令 作用 FROM image_name:tag 定义了使用哪个基础镜像启动构建流程 MAINTAINER user_name 声明镜像的创建者 ENV key value 设置环境变量 (可以写多条) RUN command 是Dockerfile的核心部分(可以写多条) ADD source_dir/file dest_dir/file 将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压 COPY source_dir/file dest_dir/file 和ADD相似，但是如果有压缩文件并不能解压 WORKDIR path_dir 设置工作目录 6.3 使用脚本创建镜像(例:构建JDK8)步骤： （1）创建目录 1mkdir –p /usr/local/dockerjdk8 （2）下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的/usr/local/dockerjdk8目录 （3）创建文件Dockerfile vi Dockerfile 123456789101112131415#依赖镜像名称和IDFROM centos:7#指定镜像创建者信息MAINTAINER ITCAST#切换工作目录WORKDIR /usrRUN mkdir /usr/local/java#ADD 是相对路径jar,把java添加到容器中ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/#配置java环境变量ENV JAVA_HOME /usr/local/java/jdk1.8.0_171ENV JRE_HOME $JAVA_HOME/jreENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH $JAVA_HOME/bin:$PATH （4）执行命令构建镜像 1docker build -t='jdk1.8' . 注意后边的空格和点，不要省略 （5）查看镜像是否建立完成 1docker images 7 Docker私有仓库7.1 私有仓库搭建与配置(1) 拉取私有仓库镜像（此步省略） 1docker pull registry (2) 启动私有仓库容器 1docker run -di --name=registry -p 5000:5000 registry (3) 打开浏览器 输入地址http://192.168.179.101:5000/v2/_catalog看到`{&quot;repositories&quot;:[]}`表示私有仓库搭建成功并且内容为空 （4）修改daemon.json 1vi /etc/docker/daemon.json 添加以下内容，保存退出。 123&#123;\"insecure-registries\":[\"192.168.179.101:5000\"]&#125; 此步用于让 docker信任私有仓库地址 （5）重启docker 服务 1systemctl restart docker 7.2 镜像上传至私有仓库（1）标记此镜像为私有仓库的镜像 1docker tag redis 192.168.179.101:5000/redis 2）再次启动私服容器 1docker start registry （3）上传标记的镜像 1docker push 192.168.179.101:5000/redis","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]}],"categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://tonymua.top/categories/计算机网络/"},{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/categories/数据库/"},{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/categories/Spring/"},{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/categories/多线程/"},{"name":"项目","slug":"项目","permalink":"http://tonymua.top/categories/项目/"},{"name":"shell","slug":"shell","permalink":"http://tonymua.top/categories/shell/"},{"name":"前端","slug":"前端","permalink":"http://tonymua.top/categories/前端/"},{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"},{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/categories/Redis/"},{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/categories/JVM/"},{"name":"源码分析","slug":"源码分析","permalink":"http://tonymua.top/categories/源码分析/"},{"name":"Git","slug":"Git","permalink":"http://tonymua.top/categories/Git/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://tonymua.top/tags/计算机网络/"},{"name":"HTTP","slug":"HTTP","permalink":"http://tonymua.top/tags/HTTP/"},{"name":"TCP","slug":"TCP","permalink":"http://tonymua.top/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://tonymua.top/tags/UDP/"},{"name":"MySQL","slug":"MySQL","permalink":"http://tonymua.top/tags/MySQL/"},{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"},{"name":"代理模式","slug":"代理模式","permalink":"http://tonymua.top/tags/代理模式/"},{"name":"javaee","slug":"javaee","permalink":"http://tonymua.top/tags/javaee/"},{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"},{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/tags/多线程/"},{"name":"并发编程","slug":"并发编程","permalink":"http://tonymua.top/tags/并发编程/"},{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"},{"name":"项目部署","slug":"项目部署","permalink":"http://tonymua.top/tags/项目部署/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://tonymua.top/tags/Spring-Boot/"},{"name":"微信公众号","slug":"微信公众号","permalink":"http://tonymua.top/tags/微信公众号/"},{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"},{"name":"Vue","slug":"Vue","permalink":"http://tonymua.top/tags/Vue/"},{"name":"算法","slug":"算法","permalink":"http://tonymua.top/tags/算法/"},{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"},{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"http://tonymua.top/tags/AOP/"},{"name":"面向切面编程","slug":"面向切面编程","permalink":"http://tonymua.top/tags/面向切面编程/"},{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"},{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/tags/Redis/"},{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://tonymua.top/tags/垃圾回收/"},{"name":"GC","slug":"GC","permalink":"http://tonymua.top/tags/GC/"},{"name":"HashMap","slug":"HashMap","permalink":"http://tonymua.top/tags/HashMap/"},{"name":"源码","slug":"源码","permalink":"http://tonymua.top/tags/源码/"},{"name":"底层","slug":"底层","permalink":"http://tonymua.top/tags/底层/"},{"name":"shell","slug":"shell","permalink":"http://tonymua.top/tags/shell/"},{"name":"Git","slug":"Git","permalink":"http://tonymua.top/tags/Git/"}]}