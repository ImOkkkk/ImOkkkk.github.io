{"meta":{"title":"liuwy1998 BLOG","subtitle":"When they go low,we go high.","description":"Java开发, 后端开发","author":"liuwy1998","url":"http://tonymua.top","root":"/"},"pages":[{"title":"about","date":"2020-04-30T00:02:54.000Z","updated":"2020-04-30T00:03:10.835Z","comments":true,"path":"about/index.html","permalink":"http://tonymua.top/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-04-30T00:00:30.000Z","updated":"2020-04-30T00:01:25.532Z","comments":true,"path":"tags/index.html","permalink":"http://tonymua.top/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-04-30T00:00:45.000Z","updated":"2020-04-30T00:01:46.812Z","comments":true,"path":"categories/index.html","permalink":"http://tonymua.top/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"代理模式(JDK Proxy与CGLIB Proxy)","slug":"代理模式","date":"2021-05-23T14:15:34.269Z","updated":"2021-05-23T14:36:45.692Z","comments":true,"path":"proxymode/","link":"","permalink":"http://tonymua.top/proxymode/","excerpt":"1.静态代理 售卖香水接口 123456/* * 定义真实对象和代理对象的公共接口 */public interface SellPerfume &#123; void sellPerfume(double price);&#125; 定义香水提供商，实现接口 123456public class ChanelFactory implements SellPerfume &#123; @Override public void sellPerfume(double price) &#123; System.out.println(\"成功购买香奈儿品牌的香水，价格是：\" + price + \"元！\"); &#125;&#125;","text":"1.静态代理 售卖香水接口 123456/* * 定义真实对象和代理对象的公共接口 */public interface SellPerfume &#123; void sellPerfume(double price);&#125; 定义香水提供商，实现接口 123456public class ChanelFactory implements SellPerfume &#123; @Override public void sellPerfume(double price) &#123; System.out.println(\"成功购买香奈儿品牌的香水，价格是：\" + price + \"元！\"); &#125;&#125; 定义代理类 123456789101112131415161718192021222324public class XiaoHongSellProxy implements SellPerfume &#123; /* * 代理对象内部保存对真实目标对象的引用，控制其它对象对目标对象的访问。 */ private ChanelFactory chanelFactory; public XiaoHongSellProxy(ChanelFactory chanelFactory) &#123; this.chanelFactory = chanelFactory; &#125; @Override public void sellPerfume(double price) &#123; doSomethingBeforeSell(); chanelFactory.sellPerfume(price); doSomethingAfterSell(); &#125; private void doSomethingBeforeSell() &#123; System.out.println(\"小红代理购买香水前的额外操作...\"); &#125; private void doSomethingAfterSell() &#123; System.out.println(\"小红代理购买香水后的额外操作...\"); &#125;&#125; 购买香水 123456789101112131415161718/* * 访问者仅能通过代理对象访问真实目标对象，不可直接访问目标对象 */public class XiaoMing &#123; public static void main(String[] args) &#123; ChanelFactory chanelFactory = new ChanelFactory(); XiaoHongSellProxy xiaoHongSellProxy = new XiaoHongSellProxy(chanelFactory); /* * 代理对象并不是真正提供服务的对象，它只是替访问者访问目标对象的一个中间人， * 真正提供服务的还是目标对象，而代理对象的作用就是在目标对象提供服务之前或之后能够执行额外的逻辑 */ xiaoHongSellProxy.sellPerfume(100); &#125;&#125;小红代理购买香水前的额外操作...成功购买香奈儿品牌的香水，价格是：100.0元！小红代理购买香水后的额外操作... 代理模式的定义：给目标对象提供一个代理对象，代理对象包含该目标对象，并控制对该目标对象的访问。 代理模式的目的：通过代理对象的隔离，可以在对目标对象的访问前后增加额外的业务逻辑，实现功能增强；通过代理对象访问目标对象，可以防止系统大量的直接对目标对象进行不正确的访问。 2.静态代理与动态代理共同点：都能实现代理模式；代理对象和目标对象都需要实现一个公共接口。 不同点： 动态代理产生代理对象的时机是运行时动态生成，它没有Java源文件，直接生成字节码文件实例化代理对象，而静态代理的代理对象，在程序编译时已经写好了Java文件，直接new一个代理对象即可。 动态代理比静态代理更加稳健，对程序的可维护性和扩展性更加友好。 3.动态代理面对新的需求时，不需要修改代理对象的代码，只需要新增接口对象，在客户端调用即可完成新的代理。 3.1 JDK ProxyJDK提供的一个动态代理机制，涉及到Proxy和InvocationHandler两个核心类。 代理对象是在程序运行过程中，有代理工厂动态生成，代理对象本身不存在Java源文件。 代理工厂需要实现InvocationHanlder接口并实现invoke()方法 1234567891011121314151617181920212223242526272829public class SellProxyFactory implements InvocationHandler &#123; // 代理的真实对象 private Object object; public SellProxyFactory(Object object) &#123; this.object = object; &#125; private void doSomethingAfter() &#123; System.out.println(\"执行代理后的额外操作...\"); &#125; private void doSomethingBefore() &#123; System.out.println(\"执行代理前的额外操作...\"); &#125; /** * @param proxy 代理对象 * @param method 真正执行的方法 * @param args 调用第二个参数method时传入的参数列表值 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; doSomethingBefore(); Object invokeObject = method.invoke(object, args); doSomethingAfter(); return invokeObject; &#125;&#125; 生成代理对象需要用到Proxy类，里面的静态方法newProxyInstance可以生成任意一个代理对象 123456 /** * @param loader 加载动态代理的类的类加载器 * @param method 代理类实现的接口，可以传入多个接口 * @param args 指定代理类的调用处理程序，即调用接口中的方法时，会找到该代理工厂h，执行invoke()方法 */Proxy.newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h) 新增红酒代理功能： 创建新的红酒供应商和售卖红酒接口 123456789/* * 红酒供应商 */public class RedWineFactory implements SellWine &#123; @Override public void SellWine(double price) &#123; System.out.println(\"成功售卖一瓶红酒，价格：\" + price + \"元\"); &#125;&#125; 123456/* * 售卖红酒接口 */public interface SellWine &#123; void SellWine(double price);&#125; 在客户端实例化一个代理对象，然后向该代理对象购买红酒 1234567891011121314151617181920212223242526public class XiaoMing &#123; public static void main(String[] args) &#123; // buyChannel(); buyRedWine(); &#125; static void buyChannel() &#123; ChanelFactory chanelFactory = new ChanelFactory(); SellProxyFactory sellProxyFactory = new SellProxyFactory(chanelFactory); SellPerfume sellPerfume = (SellPerfume)Proxy.newProxyInstance(chanelFactory.getClass().getClassLoader(), chanelFactory.getClass().getInterfaces(), sellProxyFactory); sellPerfume.sellPerfume(100); &#125; static void buyRedWine() &#123; // 实例化一个红酒供应商 RedWineFactory redWineFactory = new RedWineFactory(); // 实例化代理工厂，传入红酒供应商引用控制对其的访问 SellProxyFactory sellProxyFactory = new SellProxyFactory(redWineFactory); // 实例化代理对象 SellWine sellWine = (SellWine)Proxy.newProxyInstance(redWineFactory.getClass().getClassLoader(), redWineFactory.getClass().getInterfaces(), sellProxyFactory); // 代理售卖红酒 sellWine.SellWine(100); &#125;&#125; 总结： JDK动态代理的使用方法 代理工厂需要实现InvocationHandle接口，调用代理方法会转向执行invoke()方法。 生成代理对象需要使用Proxy对象中的newProxyInsatnce()方法，返回对象可强转成传入的其中一个接口，然后调用接口方法即可实现代理。 JDK动态代理的特点 目标对象强制需要实现一个接口，否则无法使用JDK动态代理。 3.2 CGLIBCGLIB不是JDK自带的动态代理，它需要导入第三方依赖，它是一个字节码生成类库，能够在运行时动态生成代理类对Java类和Java接口扩展。CGLIB不仅能够为Java接口做代理，而且能够为普通的Java类做代理，而JDK Proxy只能为实现了接口的Java类做代理。 CGLIB可以代理没有实现接口的Java类 导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib-nodep&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; CGLIB代理中有两个核心的类：MetondInterceptor接口和Enhancer类，前者是实现一个代理工厂的根接口，后者是创建动态代理对象的类。 定义代理工厂 1234567891011121314151617181920212223242526272829303132333435363738394041public class SellProxyFactory implements MethodInterceptor &#123; // 关联真实对象，控制真实对象的访问 private Object object; // 从代理工厂获取一个代理对象实例，等价于创建小红代理 public Object getProxyInstance(Object object) &#123; this.object = object; Enhancer enhancer = new Enhancer(); // 设置需要增强类的类加载器 enhancer.setClassLoader(object.getClass().getClassLoader()); // 设置被代理类，真实对象 enhancer.setSuperclass(object.getClass()); // 设置方法拦截器，代理工厂 enhancer.setCallback(this); // 创建代理类 return enhancer.create(); &#125; private void doSomethingBefore() &#123; System.out.println(\"执行方法前额外的操作...\"); &#125; private void doSomethingAfter() &#123; System.out.println(\"执行方法后额外的操作...\"); &#125; /** * @param o 被代理对象 * @param method 被拦截的方法 * @param objects 被拦截方法的所有入参值 * @param methodProxy 方法代理，用于调用原始的方法 */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; doSomethingBefore(); Object invokeSuperObject = methodProxy.invokeSuper(o, objects); doSomethingAfter(); return invokeSuperObject; &#125;&#125; 12345678public class XiaoMing &#123; public static void main(String[] args) &#123; SellProxyFactory sellProxyFactory = new SellProxyFactory(); //获取一个代理实例 ChanelFactory chanelFactoryInstance = (ChanelFactory) sellProxyFactory.getProxyInstance(new ChanelFactory()); chanelFactoryInstance.sellPerfume(100); &#125;&#125; 总结： CGLIB的使用方法 代理工厂需要实现MethodInterceptor接口，并重写方法，内部关联真实对象，控制第三者对真实对象的访问；代理工厂内部暴露getInstance(Object object)方法，用于从代理工厂中获取一个代理对象实例。 Enhancer类用于从代理工厂中实例化一个代理对象，给调用者提供代理服务。 JDK Proxy和CGLIB的对比 JDK Proxy CGLIB 代理工厂实现接口 InvocationHandler MethodInterceptor 构造代理对象给Client服务 Proxy Enhancer 不同点： CGLIB可以代理大部分类；而JDK Proxy仅能够代理实现了接口的类 CGLIB采用动态创建被代理类的子类实现方法拦截的方法，所以CGLIB不能代理被final关键字修饰的类和方法。 4.动态代理的实际运用AOP允许我们将重复的代码逻辑抽取出来形成一个单独的覆盖层，在执行代码时可以将覆盖层嵌入到原代码逻辑里面去。 如下图，method1和method2都需要在方法执行前后记录日志，AOP可以将大量重复的Log.info代码包装到额外的一层，监听方法的执行，当方法被调用时，通用的日志记录层会拦截掉该方法，在该方法调用前后记录日志，这样可以让方法专注于自己的业务逻辑而无需关注其它不必要的信息。 Spring AOP有许多功能：提供缓存、提供日志环绕、事务处理…… 事务 @Transactional 每个有关数据库的操作都有保证一个事务内的所有操作，要么全部执行成功，要么全部执行失败，传统的事务失败回滚和成功提交是使用try…catch代码块完成的 1234567891011121314SqlSession session = null;try&#123; session = getSqlSessionFactory().openSession(false); session.update(\"...\", new Object()); // 事务提交 session.commit();&#125;catch(Exception e)&#123; // 事务回滚 session.rollback(); throw e;&#125;finally&#123; // 关闭事务 session.close();&#125; 如果多个方法都需要写这一段逻辑非常冗余，所以Spring封装了一个注解@Transactional，使用它后，调用方法时会监视方法，如果方法上含有该注解，就会自动把数据库相关操作的代码包裹起来，类似上面一段代码。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/categories/Spring/"}],"tags":[{"name":"代理模式","slug":"代理模式","permalink":"http://tonymua.top/tags/代理模式/"}]},{"title":"通用Mapper入门","slug":"通用Mapper入门","date":"2021-05-08T13:19:59.251Z","updated":"2020-04-29T02:44:38.016Z","comments":true,"path":"2400/","link":"","permalink":"http://tonymua.top/2400/","excerpt":"1.为什么使用通用mapper​ 通用 Mapper4 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及Example 相关的单表操作。通用 Mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。 2.快速入门","text":"1.为什么使用通用mapper​ 通用 Mapper4 是一个可以实现任意 MyBatis 通用方法的框架，项目提供了常规的增删改查操作以及Example 相关的单表操作。通用 Mapper 是为了解决 MyBatis 使用中 90% 的基本操作，使用它可以很方便的进行开发，可以节省开发人员大量的时间。 2.快速入门 2.1 添加依赖12345&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt; 2.2 创建实体类12345678910@Data@Table(name = \"employee\")public class Employee implements Serializable &#123; @Id @KeySql(useGeneratedKeys = true) private Integer id; private String name; private String gender; private String email;&#125; 2.3 创建相关数据表123456789101112131415DROP TABLE IF EXISTS `employee`;CREATE TABLE `employee` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '姓名', `gender` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '性别', `email` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '邮箱', PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 4 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of employee-- ----------------------------INSERT INTO `employee` VALUES (1, '许威威', '男', 'xuweiwei@qq.com');INSERT INTO `employee` VALUES (2, '孙夏萍', '女', 'sunxiaping@qq,com');INSERT INTO `employee` VALUES (3, '杜国庆', '男', 'duguoqing@qq.com'); 2.4 创建Mapper接口12public interface EmployeeMapper extends Mapper&lt;Employee&gt; &#123;&#125; 拓展:自定义通用Mapper 123@RegisterMapperpublic interface BaseMapper&lt;T&gt; extends Mapper&lt;T&gt;, IdListMapper&lt;T,Long&gt;, InsertListMapper&lt;T&gt; &#123;&#125; 2.5 配置通用Mapper为了让上述方法可以直接使用，还需要配置通用 Mapper，让项目在启动的时候，把上述方法都自动生成好，这样在运行时就可以使用上面所有的方法。 根据不同的开发环境，需要不同的配置方式，完整的内容可以 集成通用 Mapper，我们这里以最常见的 Spring 和 MyBatis 集成为例。 在集成 Spring 的环境中使用 MyBatis 接口方式时，需要配置 MapperScannerConfigurer，在这种情况下使用通用 Mapper，只需要修改配置如下： 1234&lt;bean class=\"tk.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"扫描包名\"/&gt; &lt;!-- 其他配置 --&gt;&lt;/bean&gt; 2.6 简单使用12345678910111213141516@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath*:applicationContext.xml\")public class MapperTest &#123; @Autowired private DataSource dataSource; @Autowired private EmployeeMapper emloyeeMapper; @Test public void testDemo()&#123; List&lt;Employee&gt; employees = emloyeeMapper.selectAll(); for (Employee employee : employees) &#123; System.out.println(employee); &#125; &#125;&#125; 3.相关方法123456789101112131415161718192021222324252627282930313233343536//根据实体类不为null的字段进行查询,条件全部使用=号and条件List&lt;T&gt; select(T record); //根据实体类不为null的字段查询总数,条件全部使用=号and条件int selectCount(T record); //根据主键进行查询,必须保证结果唯一//单个字段做主键时,可以直接写主键的值//联合主键时,key可以是实体类,也可以是MapT selectByPrimaryKey(Object key); //插入一条数据//支持Oracle序列,UUID,类似Mysql的INDENTITY自动增长(自动回写)//优先使用传入的参数值,参数值空时,才会使用序列、UUID,自动增长int insert(T record); //插入一条数据,只插入不为null的字段,不会影响有默认值的字段//支持Oracle序列,UUID,类似Mysql的INDENTITY自动增长(自动回写)//优先使用传入的参数值,参数值空时,才会使用序列、UUID,自动增长int insertSelective(T record); //根据实体类中字段不为null的条件进行删除,条件全部使用=号and条件int delete(T key); //通过主键进行删除,这里最多只会删除一条数据//单个字段做主键时,可以直接写主键的值//联合主键时,key可以是实体类,也可以是Mapint deleteByPrimaryKey(Object key); //根据主键进行更新,这里最多只会更新一条数据//参数为实体类int updateByPrimaryKey(T record); //根据主键进行更新//只会更新不是null的数据int updateByPrimaryKeySelective(T record); Example方法 方法：List&lt;T&gt; selectByExample(Object example)说明：根据Example条件进行查询重点：这个查询支持通过Example类指定查询列，通过selectProperties方法指定查询列 方法：int selectCountByExample(Object example)说明：根据Example条件进行查询总数 方法：int updateByExample(T record,Object example)说明：根据Example条件更新实体record包含的全部属性，null值会被更新 方法：int updateByExampleSelective(T record, Object example)说明：根据Example条件更新实体record包含的不是null的属性值 方法：int deleteByExample(Object example)说明：根据Example条件删除数据 Demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath*:applicationContext.xml\")public class MapperTest &#123; @Autowired private DataSource dataSource; @Autowired private EmployeeMapper emloyeeMapper; @Test public void testDemo()&#123; List&lt;Employee&gt; employees = emloyeeMapper.selectAll(); for (Employee employee : employees) &#123; System.out.println(employee); &#125; &#125; @Test public void testSelect()&#123; /*Employee employee=new Employee(); employee.setId(2); List&lt;Employee&gt; select = emloyeeMapper.select(employee);*/ Employee employee=new Employee(); employee.setGender(\"男\"); int count = emloyeeMapper.selectCount(employee); Employee select = emloyeeMapper.selectByPrimaryKey(2); System.out.println(count); System.out.println(select); &#125; @Test public void testInsert()&#123; Employee employee=new Employee(); employee.setGender(\"男\"); employee.setName(\"小王\"); employee.setEmail(\"111@qq.com\"); int count = emloyeeMapper.insert(employee); System.out.println(count); &#125; @Test public void testDelete()&#123; /*Employee employee=new Employee(); employee.setGender(\"男\"); int count = emloyeeMapper.delete(employee);*/ int count = emloyeeMapper.deleteByPrimaryKey(2); System.out.println(count); &#125; @Test public void testUpdate()&#123; Employee employee=new Employee(); employee.setId(6); employee.setEmail(\"333.@qq.com\"); employee.setGender(\"女\"); int count = emloyeeMapper.updateByPrimaryKeySelective(employee); System.out.println(count); &#125;","categories":[],"tags":[{"name":"javaee","slug":"javaee","permalink":"http://tonymua.top/tags/javaee/"}]},{"title":"计算机网络与网络编程","slug":"计算机网络与网络编程","date":"2021-05-08T13:19:59.249Z","updated":"2020-04-29T02:44:38.098Z","comments":true,"path":"65346/","link":"","permalink":"http://tonymua.top/65346/","excerpt":"1.软件结构1.1 C/S结构全称为Client/Server结构，是指客户端和服务器结构。常见程序有ＱＱ、迅雷等软件。 1.2 B/S结构全称为Browser/Server结构，是指浏览器和服务器结构。常见浏览器有谷歌、火狐等。","text":"1.软件结构1.1 C/S结构全称为Client/Server结构，是指客户端和服务器结构。常见程序有ＱＱ、迅雷等软件。 1.2 B/S结构全称为Browser/Server结构，是指浏览器和服务器结构。常见浏览器有谷歌、火狐等。 两种架构各有优势，但是无论哪种架构，都离不开网络的支持。网络编程，就是在一定的协议下，实现两台计算机的通信的程序。 2.网络通信协议 网络通信协议：通过计算机网络可以使多台计算机实现连接，位于同一个网络中的计算机在进行连接和通信时需要遵守一定的规则，这就好比在道路中行驶的汽车一定要遵守交通规则一样。在计算机网络中，这些连接和通信的规则被称为网络通信协议，它对数据的传输格式、传输速率、传输步骤等做了统一规定，通信双方必须同时遵守才能完成数据交换。 TCP/IP协议： 传输控制协议/因特网互联协议( Transmission Control Protocol/Internet Protocol)，是Internet最基本、最广泛的协议。它定义了计算机如何连入因特网，以及数据如何在它们之间传输的标准。它的内部包含一系列的用于处理数据通信的协议，并采用了4层的分层模型，每一层都呼叫它的下一层所提供的协议来完成自己的需求。上图中，TCP/IP协议中的四层分别是应用层、传输层、网络层和链路层，每层分别负责不同的通信功能。链路层：链路层是用于定义物理传输通道，通常是对某些网络连接设备的驱动协议，例如针对光纤、网线提供的驱动。网络层：网络层是整个TCP/IP协议的核心，它主要用于将传输的数据进行分组，将分组数据发送到目标计算机或者网络。运输层：主要使网络程序进行通信，在进行网络通信时，可以采用TCP协议，也可以采用UDP协议。应用层：主要负责应用程序的协议，例如HTTP协议、FTP协议等。 OSI七层模型: 应用层 负责对软件提供接口时程序能使用网络服务 表示层 应用程序和网络之间的翻译官 会话层 负责在网络中的两节点之间建立和维持通信 传输层 建立端到端之间的连接，数据的分段和重组 网络层 将网络地址翻译成对应的mac地址，指导数据包的转发 数据链路层 将网络层接收到的数据包封装为特定的数据帧，使其在不可靠的物理链路上进行可靠的数据传递 物理层 建立、维护、断开物理连接。（由底层网络定义协议） 3.UDP与TCP协议3.1 UDP协议​ UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。由于使用UDP协议消耗资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输例如视频会议都使用UDP协议，因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。但是在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议。UDP的交换过程如下图所示。 3.2 TCP协议​ TCP协议是面向连接的通信协议，即在传输数据前先在发送端和接收端建立逻辑连接，然后再传输数据，它提供了两台计算机之间可靠无差错的数据传输。每次连接的创建都需要经过“三次握手”。 第一次握手，客户端向服务器端发出连接请求，等待服务器确认 第二次握手，服务器端向客户端回送一个响应，通知客户端收到了连接请求 第三次握手，客户端再次向服务器端发送确认信息，确认连接。整个交互过程如下图所示由于TCP协议的面向连接特性，它可以保证传输数据的安全性，所以是一个被广泛采用的协议，例如在下载文件时，如果数据接收不完整，将会导致文件数据丢失而不能被打开，因此，下载文件时必须采用TCP协议。 4.相关面试题 TCP断开连接的四次挥手第一次挥手：客户端发送一个FIN包（seq=x），进入FIN_WAIT（结束等待）状态第二次挥手：服务器收到FIN包，发回一个ACK包(ack=x+1)，进入CLOSE_WAIT（关闭等待）状态第三次挥手：服务器关闭客户端的连接，并发送一个FIN包(seq=y)，进入LAST_ACK（最后确认）状态第四次挥手：客户端发回ACK(ack=y+1)包确认，发送完毕后，连接断开 需要三次握手的原因为了防止失效的连接请求报文突然又传送到服务器产生错误。假如不三次握手，客户端发送连接确认给服务端就立即建立连接，如果有个连接请求阻塞了很久才到服务端，而此时本来已经关闭了连接的又重新建立了连接，然而等了很久都没有数据发送，这就会白白浪费资源 Http协议与Https协议 Http协议即超文本传输协议，是一种基于TCP的应用层协议，还是一种无状态协议。用于服务器和客户端的数据传输，客户端和服务器使用URL来建立连接和传输数据。客户端发送Http请求给服务器，服务器根据请求返回Html、文本或多媒体文件给客户端 Https协议是一种安全的Http协议。Http协议是一种明文传输的协议，存在被窃听，信息篡改等安全隐患，在Http协议的基础上加入了SSL或TLS协议，实现了数据的加密传输。因为加上了加密的协议，所以Https的响应速度会比Http慢很多。并不是所有情况下都需要使用Https协议，对于隐私的，重要的信息最好用Https协议，不重要的或者可以公开的信息就没有必要用Https协议 Http请求报文和响应报文 请求报文包括请求行，请求头，空行和请求体（GET请求没有请求体） 响应报文包括状态行，响应头，空行和响应体 Http请求常见状态码 200 OK，请求成功 404 Not Found，对应的URL上不存在资源 405 Method Not Allowed，请求不被允许，即请求方式错误 500 Internal Server Error，服务器内部错误，发现严重BUG，要及时修复 GET请求与POST请求的区别 GET请求一般用于获取服务器上的资源，是幂等的。POST请求一般用于对服务器上资源进行更新，非幂等的（幂等即每次请求返回结果一样） GET请求没有请求体，请求参数跟是在URL后面的，所以使用GET请求时请求参数用户是可以直接看到的。POST请求有请求体，请求参数放在请求体，对用户是不可见的。相对来说POST请求比GET请求更安全 GET请求的参数长度有限制，这是因为URL长度有限导致的。POST请求的参数长度可以认为是无限制的 TCP 和 UDP的区别 TCP是一种面向连接的可靠传输协议，UDP是面向无连接的不可靠传输协议 TCP支持报文传输，还支持字节流的传输。而UDP协议只支持传输报文 TCP数据报格式比较复杂，传输过程数据不容易丢失和出错，而UDP数据报格式较为简单，容易丢失 TCP传输在接收端会进行重排，所以是有序的，UDP则不保证有序 TCP速度慢，UDP速度快 TCP有流量控制和拥塞控制，而UDP没有 应用层协议有哪些 DNS协议，域名解析系统。基于TCP和UDP的协议，通过DNS可以将域名转换成IP地址 SMTP协议，电子邮件协议。基于TCP的协议，通过SMTP协议可以发送电子邮件，SMTP通信的过程建立连接、邮件传送、连接释放 Telnet协议，远程终端协议。基于TCP的协议，通过Telnet协议可以对远程的终端进行控制 Http协议，超文本传输协议。基于TCP的协议，通过Http协议实现客户端和服务端的数据传输 FTP协议，文件传输协议。基于TCP的协议，通过FTP协议达到相互传输文件的效果 OSI参考模型与TCP/IP参考模型(1) OSI参考模型由7层组成：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层(2) TCP/IP参考模型由4层组成：主机-网络层、网际层、传输层、应用层(3) 对应关系中，OSI参考模型的物理层、数据链路层对应TCP/IP的主机-网络层，网络层对应网际层，传输层对应传输层，会话层、表示层、应用层对应应用层 cookie 和 session的区别(1) cookie由于把信息保存在客户端中。session把信息保存在服务器中(2) cookie性能更高一点，速度较快，用户的信息存在各自的浏览器中，可以分担服务器的一部分存储工作。session速度较慢，所有用户的信息都存在服务器中，在高并发时必然影响服务器性能(3) cookie有限制大小，在4K以内。session没有限制(4) cookie对用户是透明的，安全性低，不重要的或者可以公开的信息保存在cookie。session对用户是不可见的，安全性高，重要信息应该保存在session forward 和 redirect的区别(1) forward为转发，进行forward操作后，请求URL不发生变化，并且会把请求的数据携带到下一个请求中。redirect是重定向，进行redirect操作后，请求URL是发生变化的(2) forward是服务器内部请求转发，不可以请求到其它站点，redirect是服务器通知客户端重新请求，可以请求到其它站点(3) forward速度快，redirect速度慢 DNS劫持和DNS污染(1) DNS劫持：指用户访问一个域名时，DNS服务器故意将此地址指向一个错误的IP地址的行为。比如进入一个网站显示的却是另外一个网站的内容(2) DNS污染：指用户访问一个域名时，国内的服务器(非DNS)监控到用户访问的已经被标记地址时，服务器伪装成DNS服务器向用户发回错误的地址的行为。比如国内不能访问Google、YouTube等 5.TCP通信程序5.1 简单的TCP网络程序TCP通信分析图解 【服务端】启动,创建ServerSocket对象，等待连接。 【客户端】启动,创建Socket对象，请求连接。 【服务端】接收连接,调用accept方法，并返回一个Socket对象。 【客户端】Socket对象，获取OutputStream，向服务端写出数据。 【服务端】Scoket对象，获取InputStream，读取客户端发送的数据。 到此，客户端向服务端发送数据成功。自此，服务端向客户端回写数据。 【服务端】Socket对象，获取OutputStream，向客户端回写数据。 【客户端】Scoket对象，获取InputStream，解析回写数据。 【客户端】释放资源，断开连接。 服务端实现： 12345678910111213141516171819202122232425262728public class ServerTCP &#123; public static void main(String[] args) throws IOException &#123; System.out.println(\"服务端启动 , 等待连接 .... \"); // 1.创建 ServerSocket对象，绑定端口，开始等待连接 ServerSocket ss = new ServerSocket(6666); // 2.接收连接 accept 方法, 返回 socket 对象. Socket server = ss.accept(); // 3.通过socket 获取输入流 InputStream is = server.getInputStream(); // 4.一次性读取数据 // 4.1 创建字节数组 byte[] b = new byte[1024]; // 4.2 据读取到字节数组中. int len = is.read(b)； // 4.3 解析数组,打印字符串信息 String msg = new String(b, 0, len); System.out.println(msg); // =================回写数据======================= // 5. 通过 socket 获取输出流 OutputStream out = server.getOutputStream(); // 6. 回写数据 out.write(\"我很好,谢谢你\".getBytes()); // 7.关闭资源. out.close(); is.close(); server.close(); &#125;&#125; 客户端实现： 12345678910111213141516171819202122public class ClientTCP &#123; public static void main(String[] args) throws Exception &#123; System.out.println(\"客户端 发送数据\"); // 1.创建 Socket ( ip , port ) , 确定连接到哪里. Socket client = new Socket(\"localhost\", 6666); // 2.通过Scoket,获取输出流对象 OutputStream os = client.getOutputStream(); // 3.写出数据. os.write(\"你好么? tcp ,我来了\".getBytes()); // ==============解析回写========================= // 4. 通过Scoket,获取 输入流对象 InputStream in = client.getInputStream(); // 5. 读取数据数据 byte[] b = new byte[100]; int len = in.read(b); System.out.println(new String(b, 0, len)); // 6. 关闭资源 . in.close(); os.close(); client.close(); &#125;&#125; 5.2 文件上传文件上传分析图解 【客户端】输入流，从硬盘读取文件数据到程序中。 【客户端】输出流，写出文件数据到服务端。 【服务端】输入流，读取文件数据到服务端程序。 【服务端】输出流，写出文件数据到服务器硬盘中。 【服务端】获取输出流，回写数据。 【客户端】获取输入流，解析回写数据。 服务端实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class FileUpload_Server &#123; public static void main(String[] args) throws IOException &#123; System.out.println(\"服务器 启动..... \"); // 1. 创建服务端ServerSocket ServerSocket serverSocket = new ServerSocket(6666); // 2. 循环接收,建立连接 while (true) &#123; Socket accept = serverSocket.accept(); /* 3. socket对象交给子线程处理,进行读写操作 Runnable接口中,只有一个run方法,使用lambda表达式简化格式 */ new Thread(() -&gt; &#123; try ( //3.1 获取输入流对象 BufferedInputStream bis = new BufferedInputStream(accept.getInputStream()); //3.2 创建输出流对象, 保存到本地 . FileOutputStream fis = new FileOutputStream(System.currentTimeMillis() + \".jpg\"); BufferedOutputStream bos = new BufferedOutputStream(fis); ) &#123; // 3.3 读写数据 byte[] b = new byte[1024 * 8]; int len; while ((len = bis.read(b)) != -1) &#123; bos.write(b, 0, len); &#125; // 4.=======信息回写=========================== System.out.println(\"back ........\"); OutputStream out = accept.getOutputStream(); out.write(\"上传成功\".getBytes()); out.close(); //================================ //5. 关闭 资源 bos.close(); bis.close(); accept.close(); System.out.println(\"文件上传已保存\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125;&#125; 客户端实现： 12345678910111213141516171819202122232425262728293031public class FileUpload_Client &#123; public static void main(String[] args) throws IOException &#123; // 1.创建流对象 // 1.1 创建输入流,读取本地文件 BufferedInputStream bis = new BufferedInputStream(new FileInputStream(\"test.jpg\")); // 1.2 创建输出流,写到服务端 Socket socket = new Socket(\"localhost\", 6666); BufferedOutputStream bos = new BufferedOutputStream(socket.getOutputStream()); //2.写出数据. byte[] b = new byte[1024 * 8 ]; int len ; while (( len = bis.read(b))!=-1) &#123; bos.write(b, 0, len); &#125; // 关闭输出流,通知服务端,写出数据完毕 socket.shutdownOutput(); System.out.println(\"文件发送完毕\"); // 3. =====解析回写============ InputStream in = socket.getInputStream(); byte[] back = new byte[20]; in.read(back); System.out.println(new String(back)); in.close(); // ============================ // 4.释放资源 socket.close(); bis.close(); &#125;&#125;","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"}]},{"title":"网上商城项目总结(四.后台)","slug":"网上商城项目总结(四.后台)","date":"2021-05-08T13:19:59.248Z","updated":"2020-04-29T02:44:38.097Z","comments":true,"path":"36372/","link":"","permalink":"http://tonymua.top/36372/","excerpt":"1.权限过滤器 项目运行过程,希望某些资源不能被未登录用户直接访问到,只有登录后才可以访问.例如:购物车页面,订单详情等资源. 12345678910111213141516171819202122232425262728public class PriviledgeFilter implements Filter &#123; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest myRequest = (HttpServletRequest) request; // 判断当前session中是否存在已经登录的用户 User user = (User) myRequest.getSession().getAttribute(\"loginUser\"); if (null != user) &#123; // 如果存在,放行 chain.doFilter(request, response); &#125; else &#123; // 如果不存在,进入提示页面 myRequest.setAttribute(\"msg\", \"请先登录\"); // 转入到提示页面 myRequest.getRequestDispatcher(\"/jsp/info.jsp\").forward(request, response); &#125; &#125; public void init(FilterConfig fConfig) throws ServletException &#123; &#125;&#125;","text":"1.权限过滤器 项目运行过程,希望某些资源不能被未登录用户直接访问到,只有登录后才可以访问.例如:购物车页面,订单详情等资源. 12345678910111213141516171819202122232425262728public class PriviledgeFilter implements Filter &#123; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest myRequest = (HttpServletRequest) request; // 判断当前session中是否存在已经登录的用户 User user = (User) myRequest.getSession().getAttribute(\"loginUser\"); if (null != user) &#123; // 如果存在,放行 chain.doFilter(request, response); &#125; else &#123; // 如果不存在,进入提示页面 myRequest.setAttribute(\"msg\", \"请先登录\"); // 转入到提示页面 myRequest.getRequestDispatcher(\"/jsp/info.jsp\").forward(request, response); &#125; &#125; public void init(FilterConfig fConfig) throws ServletException &#123; &#125;&#125; PS:一个过滤器可以配置多个不同的路径 2.后台查看所有分类步骤实现:1.准备工作 创建AdminCategoryServlet 修改链接 left.jsp 1d.add('010201','0102','分类管理', '$&#123;pageContext.request.contextPath&#125;/AdminCategoryServlet?method=findAllCats','','mainFrame'); 2.AdminCategoryServlet___&gt;findAllCats 获取全部分类信息 全部分类信息放入request 转发到/admin/category/list.jsp 3.service_dao 4.在/admin/category/list.jsp获取分类信息,完成响应 AdminCategoryServlet:12345678public String findAllCats(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 获取全部分类信息 CategoryServsice categoryServsice = new CategoryServiceImpl(); List&lt;Category&gt; list = categoryServsice.getAllCats(); // 全部分类信息放入request request.setAttribute(\"allCats\", list); return \"/admin/category/list.jsp\"; &#125; CategoryServiceImpl:12345@Override public List&lt;Category&gt; getAllCats() throws SQLException &#123; return categoryDao.getAllCats(); &#125; CategoryDaoImpl:1234567@Override public List&lt;Category&gt; getAllCats() throws SQLException &#123; String sql=\"select * from category\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanListHandler&lt;Category&gt;(Category.class)); &#125; 3.后台添加分类信息:步骤实现:1./admin/category/add.jsp 设置form __&gt;method ,action 设置form表单下各种input标签的name属性 2.AdminCategoryServlet__&gt;addCategory 获取分类名称 创建分类ID 调用业务层添加分类功能 重定向到查询全部分类信息 3.CategoryService___&gt;CategoryDaoImp PS:要在CategoryService及时更新redis中缓存的信息 总结: 虽然使用redis可以提升项目性能,但是带来开发量. 开发中,如果对redis缓存中的数据发生了更新操作,及时更新redis缓存信息,否则会造成数据不统一问题. AdminCategoryServlet:123456789101112131415public String addCategory(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //获取分类名称 String cname = request.getParameter(\"cname\"); //创建分类ID String cid = UUIDUtils.getCode(); Category category=new Category(); category.setCname(cname); category.setCid(cid); //调用业务层添加分类功能 CategoryServsice categoryServsice=new CategoryServiceImpl(); categoryServsice.addCategory(category); //重定向到查询分类信息 response.sendRedirect(\"/store_v5/AdminCategoryServlet?method=findAllCats\"); return null; &#125; CategoryServiceImpl:123456789@Override public void addCategory(Category category) throws Exception &#123; //本质是向MySQL插入一条数据 categoryDao.addCategory(category); //更新redis缓存 Jedis jedis=JedisUtils.getJedis(); jedis.del(\"allCats\"); JedisUtils.closeJedis(jedis); &#125; CategoryDaoImpl:123456@Override public void addCategory(Category category) throws Exception &#123; String sql=\"insert into category values(?,?)\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); queryRunner.update(sql,category.getCid(),category.getCname()); &#125; 4.后台分页查看所有商品步骤实现:1.修改连接 left.jsp 12d.add('010401','0104','商品管理','/store_v5/AdminProductServletmethod=findAllProductsWithPage&amp;num=1','提示信息','mainFrame'); 2AdminProductServlet___&gt;findAllProductsWithPage 获取当前页 调用业务层查全部商品信息返回PageModel 将PageModel放入request 转发到/admin/product/list.jsp 3.ProductService 创建PageModel对象 关联集合 关联URL 4./admin/product/list.jsp获取商品信息和分页数据 AdminProductServlet:1234567891011public String findAllProductsWithPage(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 获取当前页 int curNum = Integer.parseInt(request.getParameter(\"num\")); // 调用业务层查询全部商品信息返回PageModel ProductService productService = new ProductServiceImpl(); PageModel pm = productService.findAllProductsWithPage(curNum); // 将PageModel放入Request request.setAttribute(\"page\", pm); // 转发 return \"/admin/product/list.jsp\"; &#125; ProductServiceImpl:123456789101112@Override public PageModel findAllProductsWithPage(int curNum) throws Exception &#123; //1.创建对象 int totalRecords=productDao.findTotalRecords(); PageModel pm=new PageModel(curNum, totalRecords, 5); //2.关联集合 List&lt;Product&gt; list=productDao.findAllProductsWithPage(pm.getStartIndex(),pm.getPageSize()); pm.setList(list); //3.关联url pm.setUrl(\"AdminProductServlet?method=findAllProductsWithPage\"); return pm; &#125; ProductDaoImpl:1234567891011121314@Override public int findTotalRecords() throws Exception &#123; String sql = \"select count(*) from product\"; QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); Long num = (Long) qr.query(sql, new ScalarHandler()); return num.intValue(); &#125;@Override public List&lt;Product&gt; findAllProductsWithPage(int startIndex, int pageSize) throws Exception &#123; String sql = \"select * from product order by pdate desc limit ? , ?\"; QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); return qr.query(sql, new BeanListHandler&lt;Product&gt;(Product.class), startIndex, pageSize); &#125; JSP:12345678910111213141516171819202122232425262728293031323334353637&lt;c:forEach items=\"$&#123;page.list&#125;\" var=\"p\" varStatus=\"status\"&gt; &lt;tr onmouseover=\"this.style.backgroundColor = 'white'\" onmouseout=\"this.style.backgroundColor = '#F5FAFE';\"&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"18%\"&gt; $&#123; status.count &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"17%\"&gt; &lt;img width=\"40\" height=\"45\" src=\"$&#123; pageContext.request.contextPath &#125;/$&#123;p.pimage&#125;\"&gt; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"17%\"&gt; $&#123; p.pname &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"17%\"&gt; $&#123; p.shop_price &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"17%\"&gt; 是(1)/否(0) &lt;/td&gt; &lt;td align=\"center\" style=\"HEIGHT: 22px\"&gt; &lt;a href=\"\"&gt; &lt;img src=\"$&#123;pageContext.request.contextPath&#125;/img/admin/i_edit.gif\" border=\"0\" style=\"CURSOR: hand\"&gt; &lt;/a&gt; &lt;/td&gt; &lt;td align=\"center\" style=\"HEIGHT: 22px\"&gt; &lt;%--下架 pushdown --%&gt; &lt;a href=\"$&#123;pageContext.request.contextPath&#125;/\"&gt; &lt;img src=\"$&#123;pageContext.request.contextPath&#125;/img/admin/i_del.gif\" width=\"16\" height=\"16\" border=\"0\" style=\"CURSOR: hand\"&gt; &lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; 5.后台添加商品步骤实现:1.准备工作 12345Form method=”post” &lt;input type=\"file\"/&gt;Form enctype=”multiprt/form-data” /admin/product/list.jsp ,修改了 addProduct() 函数中的链接 1window.location.href = \"$&#123;pageContext.request.contextPath&#125;/AdminProductServlet?method=addProductUI\"; 2.导入commons-fileupload-1.2.1.rar之后 3.执行很简单的3行语句 4.获取到一个集合(对象) 将每对分割线中间的内容封装在FileItem对象上. 5.遍历集合 6.如果当前的FileItem对象是普通项 将普通项上name属性的值作为键,将获取到的内容作为值,放入MAP中 7.如果当前的FileItem对象是上传项 通过FileItem获取到输入流对象,通过输入流可以获取到图片二进制数据 在服务端创建一个空文件(后缀必须和上传到服务端的文件名后缀一致) 建立和空文件对应的输出流 将输入流中的数据刷到输出流中 释放资源 向map中存入一个键值对的数据 8.利用BeanUtils将MAP中的数据填充到user对象上 9.调用servcie_dao将user上携带的数据存入数据仓库,重定向到查询全部商品信息路径 PS:1.如果文件重名发生覆盖问题 UUID ​ 2.同目录下文件/目录过多,性能问题 在images下最多创建16个目录,任意一个目录进入之后最多创建16个目录, 最多创建8层目录. AdminProductServlet:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public String addProduct(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 存储表单中数据 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); //携带表单中的数据向servcie,dao Product product=new Product(); try &#123; // 利用request.getInputStream();获取到请求体中全部数据,进行拆分和封装 DiskFileItemFactory fac = new DiskFileItemFactory(); ServletFileUpload upload = new ServletFileUpload(fac); List&lt;FileItem&gt; list = upload.parseRequest(request); // 遍历集合 for (FileItem item : list) &#123; if (item.isFormField()) &#123; // 如果当前的FileItem对象是普通项 // 将普通项上name属性的值作为键,将获取到的内容作为值,放入MAP中 // &#123;username&lt;==&gt;tom,password&lt;==&gt;1234&#125; map.put(item.getFieldName(), item.getString(\"utf-8\")); &#125; else &#123; // 如果当前的FileItem对象是上传项 // 获取到原始的文件名称 String oldFileName = item.getName(); //获取到要保存文件的名称 String newFileName = UploadUtils.getUUIDName(oldFileName); //通过FileItem获取到输入流对象,通过输入流可以获取到图片二进制数据 InputStream is = item.getInputStream(); //获取到当前项目下products/3下的真实路径 String realPath = getServletContext().getRealPath(\"/products/3/\"); String dir = UploadUtils.getDir(newFileName); String path=realPath+dir; //内存中声明一个目录 File newDir=new File(path); if (!newDir.exists()) &#123; newDir.mkdirs(); &#125; //在服务端创建一个空文件(后缀必须和上传到服务端的文件名后缀一致) File finalFile=new File(newDir,newFileName); if (!finalFile.exists()) &#123; finalFile.createNewFile(); &#125; //建立和空文件对应的输出流 OutputStream os=new FileOutputStream(finalFile); //将输入流中的数据刷到输出流中 IOUtils.copy(is, os); //释放资源 IOUtils.closeQuietly(is); IOUtils.closeQuietly(os); //向map中存入一个键值对的数据 userhead&lt;===&gt; /image/11.bmp map.put(\"pimage\",\"/products/3/\"+dir+\"/\" +newFileName); &#125; &#125; //利用BeanUtils将MAP中的数据填充到Product对象上 BeanUtils.populate(product, map); product.setPid(UUIDUtils.getId()); product.setPdate(new Date()); product.setPflag(0); //调用servcie_dao将user上携带的数据存入数据仓库,重定向到查询全部商品信息路径 ProductService productService=new ProductServiceImpl(); productService.saveProduct(product); response.sendRedirect(\"/store_v5/AdminProductServlet?method=findAllProductsWithPage&amp;num=1\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; ProductServiceImpl:12345@Override public void saveProduct(Product product) throws Exception &#123; productDao.saveProduct(product); &#125; ProductDaoImpl:1234567@Override public void saveProduct(Product product) throws Exception &#123; String sql=\"INSERT INTO product VALUES(?,?,?,?,?,?,?,?,?,?)\"; QueryRunner qr=new QueryRunner(JDBCUtils.getDataSource()); Object[] params=&#123;product.getPid(),product.getPname(),product.getMarket_price(),product.getShop_price(),product.getPimage(),product.getPdate(),product.getIs_hot(),product.getPdesc(),product.getPflag(),product.getCid()&#125;; qr.update(sql, params); &#125; 6.工厂模式解耦​ 我们当前的开发末实现,service层对DAO层有依赖,例如在UserServcieImp中出现了 UserDao userDao=new UserDaoImp(); 这条语句. ​ 假如我们做了一个产品OA,但是我们没有办法确定客户采用什么样的数据库,此时我们需要为当前项目开发不同的数据库的版本,例如为oracle,sqlserver,mysql分别开发不同的DAO的实现,但是在项目具体的运行时,我们由无法确定到底执行那种版本. 此时我们可以通过配置文件来配置dao层的各个具体的实现. application.xml:123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans&gt; &lt;bean id=\"CategoryDao\" class=\"dao.daoimpl.CategoryDaoImpl\"/&gt; &lt;bean id=\"UserDao\" class=\"dao.daoimpl.UserDaoImpl\"/&gt; &lt;bean id=\"ProductDao\" class=\"dao.daoimpl.ProductDaoImpl\"/&gt;&lt;/beans&gt; BeanFactory:12345678910111213141516171819202122232425262728293031323334public class BeanFactory &#123; public static Object creatObject(String name) &#123; try &#123; // 通过传递来的name获取application.xml中name对应的class // 获取到Document对象 SAXReader reader = new SAXReader(); // 获取application.xml文件的输入流 (application.xml必须位于src下) InputStream is = BeanFactory.class.getClassLoader().getResourceAsStream(\"application.xml\"); Document document = reader.read(is); // 通过Document对象获取根节点beans Element rootElement = document.getRootElement(); // 通过根节点获取到根节点下所有的子节点 bean,返回集合 List&lt;Element&gt; list = rootElement.elements(); // 遍历集合,判断每个元素上的id的值是否和当前的name一致 for (Element ele : list) &#123; // ele相当于beans节点下的每个bean // 获取到当前节点的id属性值 // 如果一致,获取到当前元素上class属性值 String id = ele.attributeValue(\"id\"); if (id.equals(name)) &#123; String str = ele.attributeValue(\"class\"); // 通过反射创建对象并且返回 Class clazz = Class.forName(str); // 利用class值通过反射创建对象返回 return clazz.newInstance(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 运用:1CategoryDao categoryDao = (CategoryDao) BeanFactory.creatObject(\"CategoryDao\"); 7.后台分页查看所有商品准备工作:12345d.add('010501','0105','订单管理','$&#123;pageContext.request.contextPath&#125;/AdminOrderServlet?method=findOrdersWithPage&amp;num=1','','mainFrame'); d.add('010502','0105','未付款的订单','$&#123;pageContext.request.contextPath&#125;/AdminOrderServlet?method=findOrdersWithPage&amp;num=1&amp;state=1','','mainFrame'); d.add('010503','0105','已付款订单','$&#123;pageContext.request.contextPath&#125;/AdminOrderServlet?method=findOrdersWithPage&amp;num=1&amp;state=2','','mainFrame'); d.add('010504','0105','已发货的订单','$&#123;pageContext.request.contextPath&#125;/AdminOrderServlet?method=findOrdersWithPage&amp;num=1&amp;state=3','','mainFrame'); d.add('010505','0105','已完成的订单','$&#123;pageContext.request.contextPath&#125;/AdminOrderServlet?method=findOrdersWithPage&amp;num=1&amp;state=4','','mainFrame'); AdminOrderServlet:12345678910111213141516171819public String findOrdersWithPage(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 接收状态 String str = request.getParameter(\"state\"); // 获取当前页 int curNum = Integer.parseInt(request.getParameter(\"num\")); // 调用业务层查询全部订单信息返回PageModel OrderService orderService = new OrderServiceImpl(); if (null == str || \"\".equals(str)) &#123; PageModel pm = orderService.findOrdersWithPage(curNum); // 将PageModel放入request request.setAttribute(\"page\", pm); &#125; else &#123; PageModel pm = orderService.findOrdersWithPage(curNum, str); // 将PageModel放入request request.setAttribute(\"page\", pm); &#125; return \"/admin/order/list.jsp\"; &#125; OrderServiceImpl:12345678910111213141516171819202122232425@Override public PageModel findOrdersWithPage(int curNum) throws Exception &#123; // 1.创建对象 int totalRecords = orderDao.findTotalRecords(); PageModel pm = new PageModel(curNum, totalRecords, 5); // 2.关联集合 List&lt;Order&gt; list = orderDao.findOrdersWithPage(pm.getStartIndex(), pm.getPageSize()); pm.setList(list); // 3.关联url pm.setUrl(\"AdminOrderServlet?method=findOrdersWithPage\"); return pm; &#125; @Override public PageModel findOrdersWithPage(int curNum, String str) throws Exception &#123; // 1.创建对象 int totalRecords = orderDao.findTotalRecords(); PageModel pm = new PageModel(curNum, totalRecords, 5); // 2.关联集合 List&lt;Order&gt; list = orderDao.findOrdersWithPage(pm.getStartIndex(), pm.getPageSize(), str); pm.setList(list); // 3.关联url pm.setUrl(\"AdminOrderServlet?method=findOrdersWithPage\" + \"&amp;state=\" + str); return pm; &#125; OrderDaoImpl:123456789101112131415@Override public List&lt;Order&gt; findOrdersWithPage(int startIndex, int pageSize) throws Exception &#123; String sql=\"select * from orders order by ordertime desc limit ?,?\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanListHandler&lt;Order&gt;(Order.class),startIndex,pageSize); &#125; @Override public List&lt;Order&gt; findOrdersWithPage(int startIndex, int pageSize, String str) throws Exception &#123; String sql=\"select * from orders where state=? order by ordertime desc limit ?,? \"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanListHandler&lt;Order&gt;(Order.class),str,startIndex,pageSize); &#125;&#125; JSP:12345678910111213141516171819202122232425262728293031323334&lt;c:forEach items=\"$&#123;page.list &#125;\" var=\"o\" varStatus=\"status\"&gt; &lt;tr onmouseover=\"this.style.backgroundColor = 'white'\" onmouseout=\"this.style.backgroundColor = '#F5FAFE';\"&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"18%\"&gt; $&#123;status.count &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"20%\"&gt; $&#123;o.oid &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"5%\"&gt; $&#123;o.total &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"5%\"&gt; $&#123;o.name &#125; &lt;/td&gt; &lt;td style=\"CURSOR: hand; HEIGHT: 22px\" align=\"center\" width=\"5%\"&gt; &lt;c:if test=\"$&#123;o.state==1 &#125;\"&gt;未付款&lt;/c:if&gt; &lt;c:if test=\"$&#123;o.state==2 &#125;\"&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/AdminOrderServlet?method=updateOrderByOid&amp;oid=$&#123;o.oid&#125;\"&gt;去发货&lt;/a&gt;&lt;/c:if&gt; &lt;c:if test=\"$&#123;o.state==3&#125;\"&gt;已发货&lt;/c:if&gt; &lt;c:if test=\"$&#123;o.state==4 &#125;\"&gt;订单完成&lt;/c:if&gt; &lt;/td&gt; &lt;td align=\"center\" style=\"HEIGHT: 22px\" width=\"60%\"&gt; &lt;input type=\"button\" value=\"订单详情\" class=\"myClass\" id=\"$&#123;o.oid &#125;\"/&gt; &lt;table border=\"1\" width=\"100%\"&gt; &lt;/table&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; 8.异步显示订单详情步骤实现:1.将当前功能要实现最终效果先实现(静态效果) 2.用户点击订单详情按钮,向服务端发起ajax请求,向服务端传递订单id 3.服务端获取到订单ID,查询这个订单下所有的订单项以及订单项对应的商品信息,返回集合 4.将返回的集合转换为JSON格式字符串,响应到客户端 5.调试,排除2端错误 6.在客户端获取到服务端想回会的JSON格式的数据,将这些数据绑定在页面上 AdminOrderServlet:12345678910111213public String findOrderByOidWithAjax(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //服务端获取到订单ID String oid = request.getParameter(\"id\"); //查询这个订单下所有的订单项以及订单项对应的商品信息,返回集合 OrderService orderService=new OrderServiceImpl(); Order order = orderService.findOrderByOid(oid); //将返回的集合转换为JSON格式字符串,响应到客户端 String jsonStr=JSONArray.fromObject(order.getList()).toString(); //响应到客户端 response.setContentType(\"application/json;charset=utf-8\"); response.getWriter().println(jsonStr); return null; &#125; Javascript:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;script type=\"text/javascript\"&gt; $(function()&#123; //页面加载完毕之后,获取样式名称为myClass一批元素,为期绑定点击事件 $(\".myClass\").click(function()&#123; //获取当前订单id var id=this.id; //获取当前按钮文字 var txt=this.value; //PS:获取到当前元素的下一个对象table var $tb=$(this).next(); if(txt==\"订单详情\")&#123; //向服务端发送Ajax请求,将当前的订单id传递到服务端 var url=\"/store_v5/AdminOrderServlet\"; var obj=&#123;\"method\":\"findOrderByOidWithAjax\",\"id\":id&#125;; $.post(url,obj,function(data)&#123; //var $tb=$(this).next(); //此处坑爹,错误的写法 //alert(data); //清除内容 $tb.html(\"\"); var th=\"&lt;tr&gt;&lt;th&gt;商品&lt;/th&gt;&lt;th&gt;名称&lt;/th&gt;&lt;th&gt;单价&lt;/th&gt;&lt;th&gt;数量&lt;/th&gt;&lt;/tr&gt;\"; $tb.append(th); //利用JQUERY遍历响应到客户端的数据 $.each(data,function(i,obj)&#123; var td=\"&lt;tr&gt;&lt;td&gt;&lt;img src='/store_v5/\"+obj.product.pimage+\"' width='50px'/&gt;&lt;/td&gt;&lt;td&gt;\"+obj.product.pname+\"&lt;/td&gt;&lt;td&gt;\"+obj.product.shop_price+\"&lt;/td&gt;&lt;td&gt;\"+obj.quantity+\"&lt;/td&gt;&lt;/tr&gt;\"; $tb.append(td); &#125;) &#125;,\"json\"); this.value=\"关闭\"; //$(this).val(\"关闭\"); &#125;else&#123; this.value=\"订单详情\"; //清空表格内容 $tb.html(\"\"); &#125; &#125;); &#125;); &lt;/script&gt; 9.更新订单状态步骤实现:1.准备工作 admin/order/list.jsp 1&lt;a href=\"/store_v5/AdminOrderServlet?method=updateOrderByOid&amp;oid=$&#123;o.oid&#125;\"&gt;发货&lt;/a&gt; 2.AdminOrderServlet___&gt;updateOrderByOid 获取订单ID 根据订单ID查询订单 设置订单状态 修改订单信息 重新定向到查询已发货订单 3.service__&gt;dao AdminOrderServlet:1234567891011121314public String updateOrderByOid(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //获取订单id String oid = request.getParameter(\"oid\"); //根据订单id查询订单 OrderService orderService=new OrderServiceImpl(); Order order = orderService.findOrderByOid(oid); //设置订单状态 order.setState(3); //修改订单信息 orderService.updateOrder(order); //重新定向到查询已发货订单 response.sendRedirect(\"/store_v5/AdminOrderServlet?method=findOrdersWithPage&amp;num=1&amp;state=3\"); return null; &#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"网上商城项目总结(二.商品分类和详情)","slug":"网上商城项目总结(二.商品分类和详情)","date":"2021-05-08T13:19:59.246Z","updated":"2020-04-29T02:44:38.065Z","comments":true,"path":"48295/","link":"","permalink":"http://tonymua.top/48295/","excerpt":"1.获取首页分类信息步骤实现:1.导入jar包 2.导入JedisUtils工具类(修改参数127.0.0.1) 3.启动windows版本的redis 4.实现CategoryServlet__&gt;findAllCats 在redis中获取全部分类信息 如果无法获取分类信息, 查询DB中的分类,转换为JSON格式字符串, 将JSON格式字符串向redis缓存一份,之后将JSON格式数据响应到客户端 如果可以获取到分类信息 直接响应即可 CategoryServlet:1234567891011121314151617181920212223242526272829303132333435public class CategoryServlet extends BaseServlet &#123; //findAllCats public String findAllCats(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; //在redis中获取全部分类信息 Jedis jedis=JedisUtils.getJedis(); String jsonStr=jedis.get(\"allCats\"); if(null==jsonStr||\"\".equals(jsonStr))&#123; //调用业务层获取全部分类 CategoryService categoryService=new CategoryServiceImp(); List&lt;Category&gt; list = categoryService.getAllCats(); //将全部分类转换为JSON格式的数据 jsonStr=JSONArray.fromObject(list).toString(); System.out.println(jsonStr); //将获取到的JSON格式的数据存入redis jedis.set(\"allCats\", jsonStr); System.out.println(\"redis缓存中没有数据\"); //将全部分类信息响应到客户端 //告诉浏览器本次响应的数据是JSON格式的字符串 resp.setContentType(\"application/json;charset=utf-8\"); resp.getWriter().print(jsonStr); &#125;else&#123; System.out.println(\"redis缓存中有数据\"); //将全部分类信息响应到客户端 //告诉浏览器本次响应的数据是JSON格式的字符串 resp.setContentType(\"application/json;charset=utf-8\"); resp.getWriter().print(jsonStr); &#125; JedisUtils.closeJedis(jedis); return null; &#125;&#125;","text":"1.获取首页分类信息步骤实现:1.导入jar包 2.导入JedisUtils工具类(修改参数127.0.0.1) 3.启动windows版本的redis 4.实现CategoryServlet__&gt;findAllCats 在redis中获取全部分类信息 如果无法获取分类信息, 查询DB中的分类,转换为JSON格式字符串, 将JSON格式字符串向redis缓存一份,之后将JSON格式数据响应到客户端 如果可以获取到分类信息 直接响应即可 CategoryServlet:1234567891011121314151617181920212223242526272829303132333435public class CategoryServlet extends BaseServlet &#123; //findAllCats public String findAllCats(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; //在redis中获取全部分类信息 Jedis jedis=JedisUtils.getJedis(); String jsonStr=jedis.get(\"allCats\"); if(null==jsonStr||\"\".equals(jsonStr))&#123; //调用业务层获取全部分类 CategoryService categoryService=new CategoryServiceImp(); List&lt;Category&gt; list = categoryService.getAllCats(); //将全部分类转换为JSON格式的数据 jsonStr=JSONArray.fromObject(list).toString(); System.out.println(jsonStr); //将获取到的JSON格式的数据存入redis jedis.set(\"allCats\", jsonStr); System.out.println(\"redis缓存中没有数据\"); //将全部分类信息响应到客户端 //告诉浏览器本次响应的数据是JSON格式的字符串 resp.setContentType(\"application/json;charset=utf-8\"); resp.getWriter().print(jsonStr); &#125;else&#123; System.out.println(\"redis缓存中有数据\"); //将全部分类信息响应到客户端 //告诉浏览器本次响应的数据是JSON格式的字符串 resp.setContentType(\"application/json;charset=utf-8\"); resp.getWriter().print(jsonStr); &#125; JedisUtils.closeJedis(jedis); return null; &#125;&#125; CategoryServiceImpl:123456@Override public List&lt;Category&gt; getAllCats() throws SQLException &#123; CategoryDao categoryDao=new CategoryDaoImpl(); return categoryDao.getAllCats(); &#125; CategoryDaoImpl:1234567@Override public List&lt;Category&gt; getAllCats() throws SQLException &#123; String sql=\"select * from category\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanListHandler&lt;Category&gt;(Category.class)); &#125; JedisUtils:12345678910111213141516171819202122232425public class JedisUtils &#123; //创建连接池 private static JedisPoolConfig config; private static JedisPool pool; static&#123; config=new JedisPoolConfig(); config.setMaxTotal(30); config.setMaxIdle(2); pool=new JedisPool(config, \"127.0.0.1\", 6379); &#125; //获取连接的方法 public static Jedis getJedis()&#123; return pool.getResource(); &#125; //释放连接 public static void closeJedis(Jedis j)&#123; j.close(); &#125;&#125; javascript:12345678910111213141516&lt;script type=\"text/javascript\"&gt;$(function () &#123; //向服务端CategoryServlet_getAllCats发起ajax请求,服务端经过处理 //将所有分类信息以JSON格式的数据返回,获取到返回的所有分类绑定在页面的显示分类区域 var url=\"/store_v5/CategoryServlet\"; var obj=&#123;\"method\":\"findAllCats\"&#125;; $.post(url,obj,function(data)&#123; //alert(data); //获取到服务端响应回的数据 遍历data中的JSON数组,动态的显示分类区域 $.each(data,function(i,obj)&#123; var li=\"&lt;li&gt;&lt;a href='/store_v5/ProductServlet?method=findProductsByCidWithPage&amp;num=1&amp;cid=\"+obj.cid+\"'&gt;\"+obj.cname+\"&lt;/a&gt;&lt;/li&gt;\"; $(\"#myUL\").append(li); &#125;) &#125;,\"json\")&#125;)&lt;/script&gt; 2.首页热门商品和最新商品显示SQL语句:#查询商品表中最新的9件商品信息 SELECT * FROM product WHERE pflag=0 ORDER BY pdate DESC LIMIT 0 ,9 #查询商品表中最热,最新的9件商品信息 SELECT * FROM product WHERE pflag=0 AND is_hot=1 ORDER BY pdate DESC LIMIT 0 ,9 步骤分析:1.IndexServlet___&gt;execute //调用业务层查询最新商品,查询最热商品,返回2个集合 //将2个集合放入到request //转发到真实的首页 2.建立商品模块相关程序 ProductServlet ProductService ProductServiceImp ProductDao ProductDaoImp Product 3.调用service,dao 4./jsp/index.jsp 获取最新/最热9件商品信息 IndexServlet:1234567891011121314public class IndexServlet extends BaseServlet &#123; @Override public String execute(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 调用业务层查询最新商品,最热商品 ProductService productService = new ProductServiceImpl(); List&lt;Product&gt; list01 = productService.findHots(); List&lt;Product&gt; list02 = productService.findNews(); // 将2个集合放入到request request.setAttribute(\"hots\", list01); request.setAttribute(\"news\", list02); // 转发到真实的首页 return \"/jsp/index.jsp\"; &#125;&#125; ProductServiceImpl:123456789@Override public List&lt;Product&gt; findHots() throws Exception &#123; return productDao.findHots(); &#125; @Override public List&lt;Product&gt; findNews() throws Exception &#123; return productDao.findNews(); &#125; ProductDaoImpl:12345678910111213@Override public List&lt;Product&gt; findHots() throws Exception &#123; String sql = \"select * from product where pflag=0 and is_hot=1 ORDER BY pdate DESC LIMIT 0,9\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanListHandler&lt;Product&gt;(Product.class)); &#125; @Override public List&lt;Product&gt; findNews() throws Exception &#123; String sql = \"select * from product where pflag=0 ORDER BY pdate DESC LIMIT 0,9\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanListHandler&lt;Product&gt;(Product.class)); &#125; JSP:123456789&lt;c:forEach items=\"$&#123;hots &#125;\" var=\"p\"&gt; &lt;div class=\"col-md-2\" style=\"text-align:center;height:200px;padding:10px 0px;\"&gt; &lt;a href=\"$&#123;pageContext.request.contextPath&#125;/ProductServlet?method=findProductByPid&amp;pid=$&#123;p.pid&#125;\"&gt; &lt;img src=\"$&#123;pageContext.request.contextPath&#125;/$&#123;p.pimage&#125;\" width=\"130\" height=\"130\" style=\"display: inline-block;\"&gt; &lt;/a&gt; &lt;p&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/ProductServlet?method=findProductByPid&amp;pid=$&#123;p.pid&#125;\" style='color:#666'&gt;$&#123;p.pname&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;font color=\"#E4393C\" style=\"font-size:16px\"&gt;&amp;yen;$&#123;p.shop_price&#125;&lt;/font&gt;&lt;/p&gt; &lt;/div&gt; &lt;/c:forEach&gt; 3.商品详情显示步骤实现:1.准备工作 /jsp/index.jsp修改连接 123&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/ProductServlet?method=findProductByPid&amp;pid=$&#123;p.pid&#125;\"&gt; &lt;img src=\"$&#123;pageContext.request.contextPath&#125;/$&#123;p.pimage&#125;\" width=\"130\" height=\"130\" style=\"display: inline-block;\"&gt; &lt;/a&gt; 2.ProductServlet___&gt;findProductByPid 获取商品pid 根据商品pid查询商品信息 将获取到的商品放入request 转发到/jsp/product_info.jsp 3.ProductServiceImpl___&gt;ProductDaoImpl 4./jsp/product_info.jsp ProductServlet:1234567891011public String findProductByPid(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 获取商品pid String pid = request.getParameter(\"pid\"); // 根据商品pid查询商品信息 ProductService productService = new ProductServiceImpl(); Product product = productService.findProductByPid(pid); // 将获取到的商品放入request request.setAttribute(\"product\", product); // 转发到/jsp/product_info.jsp return \"/jsp/product_info.jsp\"; &#125; ProductServiceImpl:1234@Override public Product findProductByPid(String pid) throws Exception &#123; return productDao.findProductByPid(pid); &#125; ProductDaoImpl:123456@Override public Product findProductByPid(String pid) throws Exception &#123; String sql = \"select * from product where pid=?\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanHandler&lt;Product&gt;(Product.class), pid); &#125; 4.分页查看下分类下的商品信息SQL语句:#查看类别cid为1的商品的信息带有分页 SELECT * FROM product WHERE cid = 1 LIMIT ? ,? #统计类别为1的商品的数量 SELECT COUNT(*) FROM product WHERE cid = 1 步骤实现:1.准备工作 /jsp/header.jsp 123&lt;a href='/store_v5/ProductServlet?method=findProductsByCidWithPage&amp;num=1&amp;cid=\"+obj.cid+\"'&gt;\"+obj.cname+\"&lt;/a&gt;&lt;/li&gt;\"; 2.ProductServlet_____&gt;findProductsByCidWithPage 获取cid,num 调用业务层功能:以分页形式查询当前类别下商品信息 返回PageModel对象(1.当前页商品信息2.分页3.url)将PageModel对象放入request 转发到/jsp/product_list.jsp 3.ProductService 创建PageModel对象 目的:计算分页参数 关联集合 关联url 4.ProductDao 1.统计当前类别下商品个数 2.统计当前类别的当前页中的商品信息 5./jsp/product_list.jsp 获取了当前类别下的当前页中的分类数据和分页参数 约定: 1.当前页: num 2.向request放入PageModel属性名称page ProductServlet:123456789101112131415161718192021222324public String findProductsByCidWithPage(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 获取cid,num String cid = request.getParameter(\"cid\"); int curNum = Integer.parseInt(request.getParameter(\"num\")); // 调用业务层功能:以分页形式查询当前类别下商品信息 // 返回PageModel对象(1_当前页商品信息2_分页3_url) ProductService productService = new ProductServiceImpl(); PageModel pm = productService.findProductsByCidWithPage(cid, curNum); // 将PageModel对象放入request request.setAttribute(\"page\", pm); // 转发到/jsp/product_list.jsp return \"/jsp/product_list.jsp\";&#125; ProductServiceImpl:12345678910111213@Override public PageModel findProductsByCidWithPage(String cid, int curNum) throws Exception &#123; // 1_创建PageModel对象 目的:计算分页参数 // 统计当前分类下商品个数 select count(*) from product where cid=? int totalRecords = productDao.findTotalRecords(cid); PageModel pm = new PageModel(curNum, totalRecords, 12); // 2_关联集合 select * from product where cid =? limit ? ,? List list = productDao.findProductsByCidWithPage(cid, pm.getStartIndex(), pm.getPageSize()); pm.setList(list); // 3_关联url pm.setUrl(\"ProductServlet?method=findProductsByCidWithPage&amp;cid=\" + cid); return pm; &#125; ProductDaoImpl:123456@Override public List findProductsByCidWithPage(String cid, int startIndex, int pageSize) throws Exception &#123; String sql = \"select * from product where cid=? limit ? , ?\"; QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); return qr.query(sql, new BeanListHandler&lt;Product&gt;(Product.class), cid, startIndex, pageSize); &#125; 1234567@Override public int findTotalRecords(String cid) throws Exception &#123; String sql = \"select count(*) from product where cid =?\"; QueryRunner qr = new QueryRunner(JDBCUtils.getDataSource()); Long num = (Long) qr.query(sql, new ScalarHandler(), cid); return num.intValue(); &#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"网上商城项目总结(三.购物车与订单)","slug":"网上商城项目总结(三.购物车与订单)","date":"2021-05-08T13:19:59.245Z","updated":"2020-04-29T02:44:38.096Z","comments":true,"path":"21309/","link":"","permalink":"http://tonymua.top/21309/","excerpt":"1.购物车1.1抽取购物车模型步骤实现:购物项:(图片路径,商品名称,商品价格,这类商品购买的数量,这类商品总价小计) 1234567891011121314151617181920212223242526272829303132333435363738394041public class CartItem &#123; private Product product; private int num; private double subTotal; public CartItem() &#123; &#125; public CartItem(Product product, int num, double subTotal) &#123; super(); this.product = product; this.num = num; this.subTotal = subTotal; &#125; public Product getProduct() &#123; return product; &#125; public void setProduct(Product product) &#123; this.product = product; &#125; public int getNum() &#123; return num; &#125; public void setNum(int num) &#123; this.num = num; &#125; public double getSubTotal() &#123; return product.getShop_price() * num; &#125; public void setSubTotal(double subTotal) &#123; this.subTotal = subTotal; &#125;&#125;","text":"1.购物车1.1抽取购物车模型步骤实现:购物项:(图片路径,商品名称,商品价格,这类商品购买的数量,这类商品总价小计) 1234567891011121314151617181920212223242526272829303132333435363738394041public class CartItem &#123; private Product product; private int num; private double subTotal; public CartItem() &#123; &#125; public CartItem(Product product, int num, double subTotal) &#123; super(); this.product = product; this.num = num; this.subTotal = subTotal; &#125; public Product getProduct() &#123; return product; &#125; public void setProduct(Product product) &#123; this.product = product; &#125; public int getNum() &#123; return num; &#125; public void setNum(int num) &#123; this.num = num; &#125; public double getSubTotal() &#123; return product.getShop_price() * num; &#125; public void setSubTotal(double subTotal) &#123; this.subTotal = subTotal; &#125;&#125; 购物车(个数不确定的购物项) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Cart &#123; // 总计/积分 private double total = 0; // 个数不确定的购物项 商品pid&lt;===&gt;CartItem Map&lt;String, CartItem&gt; map = new HashMap&lt;&gt;(); // 添加购物项到购物车 // 当用户点击加入购物车按钮,可以将当前要购买的商品id,商品数量发送到服务端,服务端根据商品id查询到商品信息 // 有了商品信息Product对象,有了要购买商品数量,当前的购物项也就可以获取到了 public void addCartItemToCart(CartItem cartItem) &#123; // 获取到正在想购物车中添加的商品pid String pid = cartItem.getProduct().getPid(); // 将当前的购物项加入购物车之前,判断之前是否买过这类商品 // 如果没有买过 list.add(cartItem); // 如果买过: 获取到原先的数量,获取到本次的数量,相加之后设置到原先购物项上 if (map.containsKey(pid)) &#123; // 获取到原先的购物项 CartItem oldItem = map.get(pid); oldItem.setNum(oldItem.getNum() + cartItem.getNum()); &#125; else &#123; map.put(pid, cartItem); &#125; &#125; public Collection&lt;CartItem&gt; getCartItems() &#123; return map.values(); &#125; // 移除购物项 public void removeCartItem(String pid) &#123; map.remove(pid); &#125; // 清空购物车 public void clearCart() &#123; map.clear(); &#125; // 总计是可以经过计算获取到 public double getTotal() &#123; // 总计是可以经过计算获取到 total = 0; // 获取到Map中所有的购物项 Collection&lt;CartItem&gt; values = map.values(); // 遍历所有的购物项,将购物项上的小计相加 for (CartItem cartItem : values) &#123; total += cartItem.getSubTotal(); &#125; return total; &#125; public void setTotal(double total) &#123; this.total = total; &#125; public Map&lt;String, CartItem&gt; getMap() &#123; return map; &#125; public void setMap(Map&lt;String, CartItem&gt; map) &#123; this.map = map; &#125;&#125; 1.2添加商品到购物车步骤实现:1_准备工作 /jsp/product_list.jsp 修改连接 1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/ProductServlet?method=findProductByPid&amp;pid=$&#123;p.pid&#125;\"&gt; /jsp/product_info.jsp 自己设置form表单,设置form method,action 设置隐藏域向服务端传递商品pid PS:如果一个表单中有多个按钮,点击不同的按钮提交到不同路径 var form= document.getElementById(“formId”); form.submit(); 2.CartServlet____&gt;addCartgItemToCart 从session获取购物车: 如果获取不到,创建购物车对象,放在session中 如果获取到,使用即可 获取到商品id,数量 通过商品id查询都商品对象 获取到待购买的购物项 调用购物车上的方法 重定向到/jsp/cart.jsp 3_./jsp/cart.jsp 获取购物车上商品信息 CartServlet:1234567891011121314151617181920212223public String addCartItemToCart(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 从session获取购物车 Cart cart = (Cart) request.getSession().getAttribute(\"cart\"); if (null == cart) &#123; cart = new Cart(); request.getSession().setAttribute(\"cart\", cart); &#125; // 如果获取到,使用即可 // 获取到商品id,数量 String pid = request.getParameter(\"pid\"); int num = Integer.parseInt(request.getParameter(\"quantity\")); // 通过商品id查询都商品对象 ProductService productService = new ProductServiceImpl(); Product product = productService.findProductByPid(pid); // 获取到待购买的购物项 CartItem cartItem = new CartItem(); cartItem.setNum(num); cartItem.setProduct(product); // 调用购物车上的方法 cart.addCartItemToCart(cartItem); response.sendRedirect(\"/store_v5/jsp/cart.jsp\"); return null;&#125; ProductServiceImpl:1234@Override public Product findProductByPid(String pid) throws Exception &#123; return productDao.findProductByPid(pid); &#125; ProductDaoImpl:123456@Override public Product findProductByPid(String pid) throws Exception &#123; String sql = \"select * from product where pid=?\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanHandler&lt;Product&gt;(Product.class), pid); &#125; JSP:1234567891011&lt;c:forEach items=\"$&#123;cart.cartItems&#125;\" var=\"item\"&gt; &lt;tr class=\"active\"&gt; &lt;td width=\"60\" width=\"40%\"&gt;&lt;input type=\"hidden\" name=\"id\" value=\"22\"&gt; &lt;img src=\"$&#123;pageContext.request.contextPath&#125;/$&#123;item.product.pimage&#125;\" width=\"70\" height=\"60\"&gt;&lt;/td&gt; &lt;td width=\"30%\"&gt;&lt;a target=\"_blank\"&gt;$&#123;item.product.pname&#125;&lt;/a&gt;&lt;/td&gt; &lt;td width=\"20%\"&gt;￥$&#123;item.product.shop_price&#125;&lt;/td&gt; &lt;td width=\"10%\"&gt;&lt;input type=\"text\" name=\"quantity\" value=\"$&#123;item.num&#125;\" maxlength=\"4\" size=\"10\"&gt;&lt;/td&gt; &lt;td width=\"15%\"&gt;&lt;span class=\"subtotal\"&gt;￥$&#123;item.subTotal&#125;&lt;/span&gt;&lt;/td&gt; &lt;td&gt;&lt;a href=\"javascript:;\" id=\"$&#123;item.product.pid&#125;\" class=\"delete\"&gt;删除&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; 1.3移除购物项步骤实现:1.准备工作 为购物车上的删除链接绑定了点击事件 12345678910111213141516171819$(function()&#123; //页面加载完毕之后获取到class的值为delete元素,为其绑定点击事件 $(\".delete\").click(function()&#123; if(confirm(\"确认删除?\"))&#123; //获取到被删除商品pid var pid=this.id; window.loaction.href=\"/store_v5/CartServlet?method=removeCartItem&amp;id=\"+pid; &#125; &#125;);&#125;); 2.CartServlet___&gt;removeCartItem 获取待删除商品pid 获取到购物车 调用购物车删除购物项方法 重定向到/jsp/cart.jsp CartServlet:1234567891011public String removeCartItem(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; //获取待删除商品pid String pid=req.getParameter(\"id\"); //获取到购物车 Cart cart=(Cart)req.getSession().getAttribute(\"cart\"); //调用购物车删除购物项方法 cart.removeCartItem(pid); //重定向到/jsp/cart.jsp resp.sendRedirect(\"/store_v5/jsp/cart.jsp\"); return null; &#125; 1.4清空购物车步骤实现:1.准备工作 /jsp/cart.jsp 修改连接 12&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/CartServlet?method=clearCart\"id=\"clear\" class=\"clear\"&gt;清空购物车&lt;/a&gt; 2.CartServlet___&gt;clearCart 获取购物车 调用购物车的清空方法 重定向到/jsp/cart.jsp页面 CartServlet:123456789public String clearCart(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; //获取购物车 Cart cart=(Cart)req.getSession().getAttribute(\"cart\"); //调用购物车上的清空购物车方法 cart.clearCart(); //重新定向到/jsp/cart.jsp resp.sendRedirect(\"/store_v5/jsp/cart.jsp\"); return null; &#125; 2.订单2.1订单模型抽取OrderItem: 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class OrderItem &#123; private String itemid; //id private int quantity; //数量 private double total; //小计 //1.对象对应对象 //2.product,order携带更多的数据 private Product product; private Order order; public String getItemid() &#123; return itemid; &#125; public void setItemid(String itemid) &#123; this.itemid = itemid; &#125; public int getQuantity() &#123; return quantity; &#125; public void setQuantity(int quantity) &#123; this.quantity = quantity; &#125; public double getTotal() &#123; return total; &#125; public void setTotal(double total) &#123; this.total = total; &#125; public Product getProduct() &#123; return product; &#125; public void setProduct(Product product) &#123; this.product = product; &#125; public Order getOrder() &#123; return order; &#125; public void setOrder(Order order) &#123; this.order = order; &#125;&#125; Order: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public class Order &#123; private String oid; //订单编号 private Date ordertime; //下单时间 private double total; //总计 private int state; //状态 private String address; //收货人地址 private String name; //收货人姓名 private String telephone; //收货人电话 // private String uid; // 1.程序对象和对象发生关系,而不是对象和对象的属性发生关系 // 2.设计Order目的:让order携带订单上的数据向service,dao传递,user对象是可以携带更多的数据 private User user; // 程序中体现订单对象和订单项之间关系,我们再项目中的部分功能中有类似的需求:查询订单的同时还需要获取订单下所有的订单项 private List&lt;OrderItem&gt; list = new ArrayList&lt;OrderItem&gt;(); public String getOid() &#123; return oid; &#125; public void setOid(String oid) &#123; this.oid = oid; &#125; public Date getOrdertime() &#123; return ordertime; &#125; public void setOrdertime(Date ordertime) &#123; this.ordertime = ordertime; &#125; public double getTotal() &#123; return total; &#125; public void setTotal(double total) &#123; this.total = total; &#125; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getTelephone() &#123; return telephone; &#125; public void setTelephone(String telephone) &#123; this.telephone = telephone; &#125; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public List&lt;OrderItem&gt; getList() &#123; return list; &#125; public void setList(List&lt;OrderItem&gt; list) &#123; this.list = list; &#125;&#125; 2.2提交订单原理分析:保存订单: 为订单表中插入一行数据,描述本次交易,这行数据部分数据是通过程序赋予,部分数据来自购物车的,部分数据来自session中的用户 oid:UUIDUtils orderTime:new Date(); total: 从购物车获取 state:1 address: null name:null telephone:null uid:从session中的用户获取 保存订单项: 向订单项表中插入数据,描述当前订单的详细的购买信息,部分数据来自于购物车,部分数据需要通过程序赋予 itemid: UUIDUtils quantity:来自于购物车中的购物项 total:来自于购物车中的购物项 pid:来自于购物车上的购物项下商品对象pid oid:来自于当前订单id 提交订单时,订单以及订单项必须同时成功(事务) 步骤实现:1.准备工作 12 &lt;ahref=\"$&#123;pageContext.request.contextPath&#125;/OrderServlet?method=saveOrder\"&gt;&lt;/a&gt; 2.OrderServlet__&gt;saveOrder //确认用户登录状态 //创建订单对象,为订单对象赋值 //遍历购物项的同时,创建订单项 //调用业务层功能:保存订单 //清空购物车 //将订单放入request //转发/jsp/order_info.jsp return “/jsp/order_info.jsp”; 3.OrderService 利用事务保存订单,订单项 4.OrderDao 5./jsp/order_info.jsp 获取到订单信息 OrderServlet:12345678910111213141516171819202122232425262728293031323334353637383940// saveOrder 将购物车中的信息以订单的形式保存 public String saveOrder(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; //确认用户登录状态 User user=(User)req.getSession().getAttribute(\"loginUser\"); if(null==user)&#123; req.setAttribute(\"msg\", \"请登录之后在下单\"); return \"/jsp/info.jsp\"; &#125; //获取购物车 Cart cart=(Cart)req.getSession().getAttribute(\"cart\"); //创建订单对象,为订单对象赋值 Order order=new Order(); order.setOid(UUIDUtils.getCode()); order.setOrdertime(new Date()); order.setTotal(cart.getTotal()); order.setState(1); order.setUser(user); //遍历购物项的同时,创建订单项,为订单项赋值 for (CartItem item : cart.getCartItems()) &#123; OrderItem orderItem=new OrderItem(); orderItem.setItemid(UUIDUtils.getCode()); orderItem.setQuantity(item.getNum()); orderItem.setTotal(item.getSubTotal()); orderItem.setProduct(item.getProduct()); //设置当前的订单项属于哪个订单:程序的角度体检订单项和订单对应关系 orderItem.setOrder(order); order.getList().add(orderItem); &#125; //调用业务层功能:保存订单 OrderService orderService=new OrderServiceImp(); //将订单数据,用户的数据,订单下所有的订单项都传递到了service层 orderService.saveOrder(order); //清空购物车 cart.clearCart(); //将订单放入request req.setAttribute(\"order\", order); //转发/jsp/order_info.jsp return \"/jsp/order_info.jsp\"; &#125; OrderServiceImpl:123456789101112131415161718192021222324252627@Override public void saveOrder(Order order) throws SQLException &#123; /* * try &#123; JDBCUtils.startTransaction(); OrderDao orderDao = new OrderDaoImpl(); * orderDao.saveOrder(order); for (OrderItem item : order.getList()) &#123; * orderDao.saveOrderItem(item); &#125; JDBCUtils.commitAndClose(); &#125; catch * (Exception e) &#123; JDBCUtils.rollbackAndClose(); &#125; */ Connection connection = null; try &#123; // 获取连接 connection = JDBCUtils.getConnection(); // 开启事务 connection.setAutoCommit(false); // 保存订单 orderDao.saveOrder(connection, order); // 保存订单项 for (OrderItem item : order.getList()) &#123; orderDao.saveOrderItem(connection, item); &#125; // 提交 connection.commit(); &#125; catch (Exception e) &#123; connection.rollback(); &#125; &#125; OrderDaoImpl:12345678@Override public void saveOrder(Connection connection, Order order) throws Exception &#123; String sql = \"insert into orders values(?,?,?,?,?,?,?,?)\"; QueryRunner queryRunner = new QueryRunner(); Object[] params = &#123; order.getOid(), order.getOrdertime(), order.getTotal(), order.getState(), order.getAddress(), order.getName(), order.getTelephone(), order.getUser().getUid() &#125;; queryRunner.update(connection, sql, params); &#125; 12345678@Override public void saveOrderItem(Connection connection, OrderItem item) throws Exception &#123; String sql = \"insert into orderitem values(?,?,?,?,?)\"; QueryRunner queryRunner = new QueryRunner(); Object[] params = &#123; item.getItemid(), item.getQuantity(), item.getTotal(), item.getProduct().getPid(), item.getOrder().getOid() &#125;; queryRunner.update(connection, sql, params); &#125; 2.3我的订单步骤实现:1.准备工作 1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/OrderServlet?method=findMyOrdersWithPage&amp;num=1\"&gt;我的订单&lt;/a&gt; 2.OrderServlet__&gt;findMyOrdersWithPage 获取用户信息 获取当前页 调用业务层功能:查询当前用户订单信息,返回PageModel 将PageModel放入request 转发到/jsp/order_list.jsp 3.OrderServiceImpl //1.创建PageModel对象,目的:计算并且携带分页参数 //2.关联集合 //3.关联url 4.OrderDaoImpl 利用MapListHandler封装多表查询结果 多表查询语句 BeanUtils自动填充数据 5.实现/jsp/order_list.jsp 获取订单信息,完成响应 PS: 遍历数据时,2个循环,大循环遍历订单,小循环遍历的是订单上的订单项 OrderServlet:123456789101112131415public String findMyOrdersWithPage(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 获取用户信息 User user = (User) request.getSession().getAttribute(\"loginUser\"); // 获取当前页 int curNum = Integer.parseInt(request.getParameter(\"num\")); // 调用业务层功能:查询当前用户订单信息,返回PageModel OrderService orderService = new OrderServiceImpl(); // select * from orders where uid=? limit ?,? // PageModel:1.分页参数 2.url 3.当前用户的当前页的订单(集合),每笔订单上对应的订单项,以及订单项对应的商品信息 PageModel pm = orderService.findMyOrdersWithPage(user, curNum); // 将PageMpdel放入request request.setAttribute(\"page\", pm); // 转发 return \"jsp/order_list.jsp\"; &#125; OrderServiceImpl:12345678910111213@Override public PageModel findMyOrdersWithPage(User user, int curNum) throws Exception &#123; // 创建PageModel对象 目的:计算并携带分页参数 //select count(*) from orders where uid=? int totalRecords=orderDao.getTotalRecords(user); PageModel pm = new PageModel(curNum, totalRecords, 3); // 关联集合 select* from orders where uid=? limit ?,? List list=orderDao.findMyOrdersWithPage(user,pm.getStartIndex(),pm.getPageSize()); pm.setList(list); // 关联url pm.setUrl(\"OrderServlet?method=findMyOrdersWithPage\"); return pm; &#125; OrderDaoImpl:1234567891011121314151617181920212223242526272829303132333435@Override public List findMyOrdersWithPage(User user, int startIndex, int pageSize) throws Exception &#123; String sql = \"select * from orders where uid=? limit ?,?\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); List&lt;Order&gt; list = queryRunner.query(sql, new BeanListHandler&lt;Order&gt;(Order.class), user.getUid(), startIndex, pageSize); // 遍历所有订单 for (Order order : list) &#123; // 获取每笔订单oid String oid = order.getOid(); sql = \"select * from orderitem o,product p where o.pid=p.pid and oid=?\"; List&lt;Map&lt;String, Object&gt;&gt; list2 = queryRunner.query(sql, new MapListHandler(), oid); // 遍历list for (Map&lt;String, Object&gt; map : list2) &#123; OrderItem orderItem = new OrderItem(); Product product = new Product(); // 由于BeanUtils将字符串\"1922-2-2\"向user对象的setBirthday();方法传递参数有问题,手动向BeanUtils注册一个时间 // 创建时间类型转换器 DateConverter dt = new DateConverter(); // 设置转换格式 dt.setPattern(\"yyyy-MM-dd\"); // 注册转换器 ConvertUtils.register(dt, Date.class); // 将map中属于oderItem的数据自动填充到orderItem对象上 BeanUtils.populate(orderItem, map); // 将map中属于product的数据自动填充到product对象上 BeanUtils.populate(product, map); // 每个订单项和商品发生关联关系 orderItem.setProduct(product); // 每个订单项存入订单下的集合中 order.getList().add(orderItem); &#125; &#125; return list; &#125; 1234567@Override public int getTotalRecords(User user) throws Exception &#123; String sql = \"select count(*) from orders where uid=?\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); Long num = (Long) queryRunner.query(sql, new ScalarHandler(), user.getUid()); return num.intValue(); &#125; JSP:12345678910111213141516171819202122232425262728293031&lt;c:forEach items=\"$&#123;page.list &#125;\" var=\"order\"&gt; &lt;tbody&gt; &lt;tr class=\"success\"&gt; &lt;th colspan=\"5\"&gt; 订单编号:$&#123;order.oid &#125; 订单总金额:$&#123;order.total &#125; &lt;c:if test=\"$&#123;order.state==1 &#125;\"&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/OrderServlet?method=findOrderByOid&amp;oid=$&#123;order.oid&#125;\"&gt;付款&lt;/a&gt;&lt;/c:if&gt; &lt;c:if test=\"$&#123;order.state==2 &#125;\"&gt;等待发货&lt;/c:if&gt; &lt;c:if test=\"$&#123;order.state==3 &#125;\"&gt;&lt;a href=\"#\"&gt;确认收货&lt;/a&gt;&lt;/c:if&gt; &lt;c:if test=\"$&#123;order.state==4 &#125;\"&gt;&lt;a href=\"#\"&gt;评价&lt;/a&gt;&lt;/c:if&gt; &lt;/th&gt; &lt;/tr&gt; &lt;tr class=\"warning\"&gt; &lt;th&gt;图片&lt;/th&gt; &lt;th&gt;商品&lt;/th&gt; &lt;th&gt;价格&lt;/th&gt; &lt;th&gt;数量&lt;/th&gt; &lt;th&gt;小计&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach items=\"$&#123;order.list &#125;\" var=\"item\"&gt; &lt;tr class=\"active\"&gt; &lt;td width=\"60\" width=\"40%\"&gt;&lt;input type=\"hidden\" name=\"id\" value=\"22\"&gt; &lt;img src=\"$&#123;pageContext.request.contextPath&#125;/$&#123;item.product.pimage&#125;\" width=\"70\" height=\"60\"&gt;&lt;/td&gt; &lt;td width=\"30%\"&gt;&lt;a target=\"_blank\"&gt;$&#123;item.product.pname&#125;&lt;/a&gt;&lt;/td&gt; &lt;td width=\"20%\"&gt;￥$&#123;item.product.shop_price&#125;&lt;/td&gt; &lt;td width=\"10%\"&gt;$&#123;item.quantity &#125;&lt;/td&gt; &lt;td width=\"15%\"&gt;&lt;span class=\"subtotal\"&gt;￥$&#123;item.total &#125;&lt;/span&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/tbody&gt; &lt;/c:forEach&gt; 2.4订单详情1.准备工作 order_list.jsp 修改连接 1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/OrderServlet?method=findOrderByOid&amp;oid=$&#123;o.oid&#125;\"&gt;付款&lt;/a&gt; 2.OrderServlet___&gt;findOrderByOid 获取到订单oid 调用业务层功能:根据订单编号查询订单信息 将订单放入request 转发到/jsp/order_info.jsp 3.OrderService 4.OrderDaoImpl 根据订单oid查询当前订单 根据订单oid查询订单下所有的订单项以及订单项关联的商品 5./jsp/order_info.jsp 开发中:多个功能对应同一个JSP页面,为了提高代码复用率,所有的功能在向同一个 JSP页面转发的时候,向request存入相同的数据(属性名一致) request.setAttribute(name,obj); OrderServlet:12345678910public String findOrderByOid(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // 获取订单编号oid String oid = request.getParameter(\"oid\"); // 调用业务层功能:根据订单编号查询订单信息 OrderService orderService = new OrderServiceImpl(); Order order = orderService.findOrderByOid(oid); // 将订单放入request request.setAttribute(\"order\", order); return \"/jsp/order_info.jsp\"; &#125; OrderServiceImpl:1234@Override public Order findOrderByOid(String oid) throws Exception &#123; return orderDao.findOrderByOid(oid); &#125; OrderDaoImpl:12345678910111213141516171819202122232425262728@Override public Order findOrderByOid(String oid) throws Exception &#123; String sql = \"select * from orders where oid=?\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); Order order = queryRunner.query(sql, new BeanHandler&lt;Order&gt;(Order.class), oid); sql=\"select * from orderitem o,product p where o.pid=p.pid and oid=?\"; List&lt;Map&lt;String, Object&gt;&gt; list2 = queryRunner.query(sql, new MapListHandler(), oid); for (Map&lt;String, Object&gt; map : list2) &#123; OrderItem orderItem = new OrderItem(); Product product = new Product(); // 由于BeanUtils将字符串\"1922-2-2\"向user对象的setBirthday();方法传递参数有问题,手动向BeanUtils注册一个时间 // 创建时间类型转换器 DateConverter dt = new DateConverter(); // 设置转换格式 dt.setPattern(\"yyyy-MM-dd\"); // 注册转换器 ConvertUtils.register(dt, Date.class); // 将map中属于oderItem的数据自动填充到orderItem对象上 BeanUtils.populate(orderItem, map); // 将map中属于product的数据自动填充到product对象上 BeanUtils.populate(product, map); // 每个订单项和商品发生关联关系 orderItem.setProduct(product); // 每个订单项存入订单下的集合中 order.getList().add(orderItem); &#125; return order; &#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"网上商城项目总结(一.用户模块)","slug":"网上商城项目总结(一.用户模块)","date":"2021-05-08T13:19:59.244Z","updated":"2020-04-29T02:44:38.064Z","comments":true,"path":"38014/","link":"","permalink":"http://tonymua.top/38014/","excerpt":"1.注册1.1用户注册(通用servlet)1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/UserServlet?method=userRegister\"&gt;注册&lt;/a&gt; 通用servlet:原理: 从客户端向服务端发起请求,每次都要传递额外的键值对的数据method=””, 服务端获取到method对应的内容之后,通过判断不同的内容调用不同的功能. 从客户端向服务端发起请求,调用功能方式:1.通过表单向服务端发起请求 2.通过链接向服务端发起请 3.Ajax向服务端发起请求 步骤实现:1.准备工作 /jsp/regist.jsp 设置表单各种属性 action method 2.UserServlet__&gt;userRegist 接收表单参数 调用业务层注册功能 注册成功,向用户邮箱发送信息,跳转到提示页面 注册失败,跳转到提示页面","text":"1.注册1.1用户注册(通用servlet)1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/UserServlet?method=userRegister\"&gt;注册&lt;/a&gt; 通用servlet:原理: 从客户端向服务端发起请求,每次都要传递额外的键值对的数据method=””, 服务端获取到method对应的内容之后,通过判断不同的内容调用不同的功能. 从客户端向服务端发起请求,调用功能方式:1.通过表单向服务端发起请求 2.通过链接向服务端发起请 3.Ajax向服务端发起请求 步骤实现:1.准备工作 /jsp/regist.jsp 设置表单各种属性 action method 2.UserServlet__&gt;userRegist 接收表单参数 调用业务层注册功能 注册成功,向用户邮箱发送信息,跳转到提示页面 注册失败,跳转到提示页面 3.依次实现service,dao 4./jsp/info.jsp获取提示信息 UserServlet:123456789101112131415161718192021222324252627282930313233343536public String userRegister(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; User user = new User(); MyBeanUtils.populate(user, request.getParameterMap()); user.setUid(UUIDUtils.getId()); user.setState(0); user.setCode(UUIDUtils.getCode()); UserService userService = new UserServiceImpl(); try &#123; userService.userRegister(user); MailUtils.sendMail(user.getEmail(), user.getCode()); request.setAttribute(\"msg\", \"注册成功,请激活!\"); return \"/jsp/info.jsp\"; &#125; catch (Exception e) &#123; request.setAttribute(\"msg\", \"注册失败!\"); &#125; return \"/jsp/info.jsp\"; &#125; UserDaoImpl:12345678@Override public void userRegister(User user) throws SQLException &#123; String sql = \"insert into user values(?,?,?,?,?,?,?,?,?,?)\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); Object[] params = &#123; user.getUid(), user.getUsername(), user.getPassword(), user.getName(), user.getEmail(), user.getTelephone(), user.getBirthday(), user.getSex(), user.getState(), user.getCode() &#125;; queryRunner.update(sql, params); &#125; UserServicempl:12345@Override public void userRegister(User user) throws SQLException &#123; UserDao userDao = new UserDaoImpl(); userDao.userRegister(user); &#125; 1.2注册校验用户户名是否存在步骤实现:1.用户注册时通过用户离开用户名输入框事件调用功能onblur=”checkUserName()” 1&lt;input type=\"text\" name=\"username\" class=\"form-control\" id=\"username\" placeholder=\"请输入用户名\" onblur=\"checkUserName()\"&gt;&lt;span id=\"span01\"&gt;&lt;/span&gt; 2.UserServlet&gt;checkUser 调用UserServletimpl&gt;checkUserName校验用户名是否存在 UserServlet:12345678910111213141516public void checkUser(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; try &#123; String username = request.getParameter(\"username\"); UserService userService = new UserServiceImpl(); boolean flag = userService.checkUserName(username); if (flag == true) &#123; response.getWriter().println(1); &#125; else &#123; response.getWriter().println(2); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; UserDaoImpl:1234567@Override public User checkUserName(String username) throws SQLException &#123; String sql=\"select * from user where username=?\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanHandler&lt;User&gt;(User.class),username); &#125; UserServicempl:12345678910@Override public boolean checkUserName(String username) throws SQLException &#123; UserDao userDao = new UserDaoImpl(); User user = userDao.checkUserName(username); if (null!=user) &#123; return true; &#125;else &#123; return false; &#125; &#125; 1.3注册后邮箱激活步骤实现:1.用户点击激活链接 UserServlet__&gt;active 调用业务层用户激活功能 调用dao层Active方法 2.UserServletimpl__&gt;UserActive 用户激活,如果激活成功,激活码置空,更改用户状态(state=1) 3.UserServlet__&gt;active UserServletimpl返回true的话代表用户激活成功 /jsp/info.jsp获取提示信息激活成功 反之,提示激活失败 UserServlet:123456789101112131415161718public String active(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //获取激活码 String code=request.getParameter(\"code\"); //调用业务层激活功能 UserService userService=new UserServiceImp(); boolean flag=userService.userActive(code); //进行激活信息提示 if(flag==true)&#123; //用户激活成功,向request放入提示信息,转发到登录页面 request.setAttribute(\"msg\", \"用户激活成功,请登录!\"); return \"/jsp/login.jsp\"; &#125;else&#123; //用户激活失败,向request放入提示信息,转发到提示页面 request.setAttribute(\"msg\", \"用户激活失败,请重新激活!\"); return \"/jsp/info.jsp\"; &#125; &#125; UserDaompl:123456789101112131415@Override public User Active(String code) throws SQLException &#123; String sql = \"select * from user where code=?\"; QueryRunner queryRunner = new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanHandler&lt;User&gt;(User.class),code); &#125; @Override public void updateUser(User user) throws SQLException &#123; String sql=\"update user set username=? , password=? ,name =? ,email=?, telephone =? ,birthday =? ,sex=? ,state=? ,code= ? where uid=?\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); Object[] params=&#123;user.getUsername(),user.getPassword(),user.getName(),user.getEmail(),user.getTelephone(),user.getBirthday(),user.getSex(),user.getState(),user.getCode(),user.getUid()&#125;; queryRunner.update(sql,params); &#125; UserServicempl:12345678910111213@Override public boolean userActive(String code) throws SQLException &#123; UserDao userDao = new UserDaoImpl(); User user = userDao.Active(code); if (null != user) &#123; user.setState(1); user.setCode(null); userDao.updateUser(user); return true; &#125; else &#123; return false; &#125; &#125; 2.登录2.1自动登录与记住用户名步骤实现:1.准备工作 /jsp/login.jsp 设置form标签action,method 设置表单下input标签的name属性 设置用户自动登录复选框name=”auto_login” 记住用户名复选框name=”remember” 2.UserServlet_userLogin 获取数据 调用业务层功能 成功,判断auto_login remember是否on 添加cookie:auto_login remember (1).自动登录:调用过滤器AutoLoginFilter (2)记住用户名:login.jsp页面 用户名输入框设置value=”${ cookie.remember.value }” session存放用户信息,重定向到首页失败request放入失败信息,转发到登录页面3.service_daoservice:自定义异常向servlet传递2种数据(密码不存在,用户未激活) 4./jsp/index.jsp 获取到了用户信息 UserServlet:12345678910111213141516171819202122232425262728293031public String userLogin(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; try &#123; User user = new User(); MyBeanUtils.populate(user, request.getParameterMap()); String auto_login = request.getParameter(\"auto_login\"); String remember = request.getParameter(\"remember\"); UserService userService = new UserServiceImpl(); User loginUser = userService.userLogin(user); if (loginUser != null) &#123; if (\"on\".equals(auto_login)) &#123; Cookie cookie = new Cookie(\"auto_login\", loginUser.getUsername() + \"#\" + loginUser.getPassword()); cookie.setMaxAge(60 * 60 * 24 * 3); cookie.setPath(\"/\"); response.addCookie(cookie); &#125; if (\"on\".equals(remember)) &#123; CookieUtil.addCookie(response, \"remember\", loginUser.getUsername(), 60 * 60 * 24 * 3); &#125;else&#123; CookieUtil.removeCookie(response, \"remember\"); &#125; request.getSession().setAttribute(\"loginUser\", loginUser); response.sendRedirect(\"/store_v5/index.jsp\"); &#125; return null; &#125; catch (Exception e) &#123; String msg = e.getMessage(); request.setAttribute(\"msg\", msg); return \"/jsp/login.jsp\"; &#125; &#125; UserDaompl:123456@Override public User userLogin(User user) throws SQLException &#123; String sql=\"select * from user where username=? and password=?\"; QueryRunner queryRunner=new QueryRunner(JDBCUtils.getDataSource()); return queryRunner.query(sql, new BeanHandler&lt;User&gt;(User.class),user.getUsername(),user.getPassword()); &#125; UserServicempl:12345678910111213@Override public User userLogin(User user) throws SQLException &#123; UserDao userDao = new UserDaoImpl(); User uu = userDao.userLogin(user); if (null == uu) &#123; throw new RuntimeException(\"密码错误\"); &#125; else if (uu.getState() == 0) &#123; throw new RuntimeException(\"用户未激活\"); &#125; else &#123; return uu; &#125; &#125; CookieUtil:12345678910111213141516171819202122232425262728293031323334public class CookieUtil &#123; public static Cookie findCookie(Cookie[] cookies, String name) &#123; if (cookies != null) &#123; for (Cookie cookie : cookies) &#123; if (name.equals(cookie.getName())) &#123; return cookie; &#125; &#125; &#125; return null; &#125; public static void addCookie(HttpServletResponse response, String name, String value) &#123; Cookie cookie = new Cookie(name, value); cookie.setPath(\"/\"); response.addCookie(cookie); &#125; public static void addCookie(HttpServletResponse response, String name, String value, int maxAge) &#123; Cookie cookie = new Cookie(name, value); cookie.setPath(\"/\"); if (maxAge &gt; 0) &#123; cookie.setMaxAge(maxAge); &#125; response.addCookie(cookie); &#125; public static void removeCookie(HttpServletResponse response, String name) &#123; Cookie uid = new Cookie(name, null); uid.setPath(\"/\"); uid.setMaxAge(0); response.addCookie(uid); &#125;&#125; AutoLoginFilter:1234567891011121314151617181920212223242526272829303132333435363738394041424344public class AutoLoginFilter implements Filter &#123; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; try &#123; HttpServletRequest request2 = (HttpServletRequest) request; User loginUser = (User) request2.getSession().getAttribute(\"loginUser\"); if (loginUser != null) &#123; chain.doFilter(request2, response); &#125; else &#123; Cookie[] cookies = request2.getCookies(); Cookie cookie = CookieUtil.findCookie(cookies, \"auto_login\"); if (cookie == null) &#123; chain.doFilter(request2, response); &#125; else &#123; String value = cookie.getValue(); String username = value.split(\"#\")[0]; String password = value.split(\"#\")[1]; User user = new User(); user.setUsername(username); user.setPassword(password); UserService userService = new UserServiceImpl(); loginUser = userService.userLogin(user); request2.getSession().setAttribute(\"loginUser\", loginUser); chain.doFilter(request2, response); &#125; &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); chain.doFilter(request, response); &#125; &#125; public void init(FilterConfig fConfig) throws ServletException &#123; &#125;&#125; 3.退出3.1用户退出步骤实现:1.准备工作 /jsp/index.jsp 修改连接 1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/UserServlet?method=logOut\"&gt;退出&lt;/a&gt; 2.UserServlet___&gt;logOut 清除session 重新定向到首页 return null; UserServlet:12345678910111213public String logOut(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; request.getSession().invalidate(); /* * Cookie cookie = new Cookie(\"auto_login\", \"\"); * cookie.setMaxAge(0); * cookie.setPath(\"/\"); * response.addCookie(cookie); */ CookieUtil.removeCookie(response, \"auto_login\"); response.sendRedirect(\"/store_v5/index.jsp\"); return null; &#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"线程池","slug":"线程池","date":"2021-05-08T13:19:59.242Z","updated":"2020-11-03T12:25:05.495Z","comments":true,"path":"ThreadPool/","link":"","permalink":"http://tonymua.top/ThreadPool/","excerpt":"线程池1.概述","text":"线程池1.概述 原理：当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为 corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果阻塞队列满了，那就创建新的线程执行当前任务；直到线程池中的线程数达到 maxPoolSize，这时再有任务来，只能执行 reject() 处理该任务。优点： 降低资源消耗； 提高响应速度； 提高线程的可管理性。 缺点：TODO 1.1 四种常用ExecutorService特性 类型 核心线程数 最大线程数 KeepAlive时间(存活时间) 任务队列 拒绝策略 newCachedThreadPool(可缓存线程池) 0 Integer.MAX_VALUE 60s SynchronousQueue 线程池无限大，当执行第二个任务已经完成，会复用执行第一个任务的线程。 newFixedThreadPool(定长线程池) 指定大小 指定大小(与核心线程数相同) 0 LinkedBlockingQueue 线程池大小固定，没有可用的线程的时候，任务会放在队列等待，队列的长度无限制。 newSingleThreadExexutor 1 1 0 LinkedBlockingQueue 单线程化的线程池，适用于业务逻辑上只允许1个线程进行处理的场景，保证所有任务按照指定顺序FIFO(先进先出)，LIFO(后进先出)，优先级执行。 newScheduledThreadPool 指定大小 Integer.MAX_VALUE 0 DelayedWordQueue 定长线程池，支持定时及周期性任务执行。 1.2 ThreadPoolExecutor《阿里巴巴 Java 开发手册》中规定线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。而且线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式。这样的处理方式能够更加明确线程池的运行规则，规避资源耗尽的风险。 1234567ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数：corePoolSize：核心线程数，指定了线程池中的线程池数量，它的数量决定了添加的任务是开辟新的线程去执行，还是放到workQueue任务队列中； maximumPoolSize：指定了线程池中的最大线程数量，这个参数会根据使用的workQueue任务队列的类型，决定线程池会开辟的最大线程数量。 核心和最大线程数大小仅在构建时设置，但也可以使用 setCorePoolSize() 和 setMaximumPoolSize() 进行动态更改。keepAliveTime：当线程池中的空闲线程数量超过corePoolSize时，多余的线程会在多长时间内被销毁。如果线程池在以后会变得更加活跃，则应构建线程或者使用setKeepAliveTime(long, TimeUnit)方法。 unit：keepAliveTime的单位 workQueue：阻塞队列(用来保存等待被执行的任务) ArrayBlockingQueue：基于数组结构的有界任务队列，按照FIFO排序任务。若有新的任务需要执行时，线程会创建新的线程，直到创建的线程数量达到corePoolSize时，则会将新的任务加入到等待队列中。若等待队列已满，即超过ArrayBlockingQueue初始化的容量，则继续创建线程数量达到maximumPoolSize，则执行拒绝策略。这种情况下，线程数量的上限与有界任务队列的状态有直接关系，如果有界任务队列的初始容量比较大或者没有达到超负荷状态，线程数将会一直维持在corePoolSize以下，反之，则会以maximumPoolSize为最大线程数上限。 没有预定义容量的LinkedBlockingQueue：基于链表结构的无界任务队列，按照FIFO排序任务。使用无界任务队列，线程池的任务队列可以无限制的添加新的任务，当线程数达到corePoolSize后就不会再增加了。使用无界任务队列将导致新任务在队列中等待，从而导致maximumPoolSize的值没有任何作用。当使用这种任务队列模式时，一定要注意任务提交与处理之间的协调与控制，不然会出现队列中的任务由于无法及时处理导致一直增长，直到最后资源耗尽的问题。这种队列方式可以用于平滑瞬时大量请求。 SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于ArrayBlockingQueue。直接握手队列：它将任务交给线程而不需要保留，如果没有线程立即可用来运行它，那么排队任务的尝试将失败，因此构建新的线程，如果达到maximumPoolSize设置的最大值，则根据设置的handler执行拒绝策略。在这种情况下，需要对程序的并发量有个准确的评估，才能设置合适的maximumPoolSize数量避免执行拒绝策略。应注意，当任务持续以平均提交速度大于平均处理速度时，会导致线程数量会无限增长问题。 PriorityBlockingQueue：具有优先级的无界任务队列。优先任务队列：特殊的无界任务队列，无论添加了多少个任务，线程数量都不会超过corePoolSize。其它队列一般是按照FIFO(先进先出)的规则处理任务，而PriorityBlockingQueue队列可以自定义规则根据任务的优先级顺序先后执行。 threadFactory：线程工程，用于创建线程。如果未另行指定，则使用Executors.defaultThreadFactory默认工厂，使其全部位于同一个ThreadGroup中，并具有相同的NORM_PRIORITY优先级和非守护进程状态。通过不同的ThreadFactory可以更改线程的名称，线程组，优先级，守护进程状态等。privilegedThreadFactory：继承自defaultThreadFactory，主要添加了访问权限校验。 handler：拒绝策略，创建线程池时，为防止资源被耗尽，任务队列都会选择创建有界任务队列，但如果出现任务队列已满且线程池创建的线程数达到maximumPoolSize时，这时就需要指定ThreadPoolExecutor的RejectedExecutionHandler参数即合理的拒绝策略，来处理线程池”超载”的情况。ThreadPoolExecutor自带的拒绝策略如下： AbortPolicy：默认策略，丢掉任务直接抛出RejectedExecutionException异常，阻止系统正常工作。 CallerRunsPolicy：如果线程池的线程池的线程数量达到上限，该策略会把拒绝的任务放在调用者线程当中运行，如果执行程序已关闭，则会丢弃该任务。 DiscardPolicy：该策略会默默丢弃无法处理的任务，不会抛出任何异常，使用此策略，业务场景中需允许任务的丢失。 DiscardOldestPolicy：该策略会丢弃任务队列中最老的一个任务，也就是当前任务队列中最先被添加进去的。即每次移除队头元素后再尝试入队。 2.使用12345678910111213141516171819public class TestThreadPool &#123; private static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(8, 16, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(100), new ThreadPoolExecutor.AbortPolicy()); private static class testTask implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125; public static void main(String[] args) &#123; testTask testTask = new testTask(); for (int i = 0; i &lt; 50; i++) &#123; threadPoolExecutor.submit(testTask); &#125; threadPoolExecutor.shutdown(); &#125;&#125;","categories":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/tags/多线程/"},{"name":"并发编程","slug":"并发编程","permalink":"http://tonymua.top/tags/并发编程/"}]},{"title":"微服务项目总结(四.Spring Data Elasticsearch)","slug":"微服务项目总结(四.Spring-Data-Elasticsearch)","date":"2021-05-08T13:19:59.240Z","updated":"2020-04-29T02:44:38.093Z","comments":true,"path":"20904/","link":"","permalink":"http://tonymua.top/20904/","excerpt":"Spring Data ElasticsearchElasticsearch提供的Java客户端有一些不太方便的地方： 很多地方需要拼接Json字符串，在java中拼接字符串有多恐怖你应该懂的 需要自己把对象序列化为json存储 查询到结果也需要自己反序列化为对象 Spring提供的套件：Spring Data Elasticsearch。 1 简介Spring Data Elasticsearch是Spring Data项目下的一个子模块。 查看 Spring Data的官网：http://projects.spring.io/spring-data/","text":"Spring Data ElasticsearchElasticsearch提供的Java客户端有一些不太方便的地方： 很多地方需要拼接Json字符串，在java中拼接字符串有多恐怖你应该懂的 需要自己把对象序列化为json存储 查询到结果也需要自己反序列化为对象 Spring提供的套件：Spring Data Elasticsearch。 1 简介Spring Data Elasticsearch是Spring Data项目下的一个子模块。 查看 Spring Data的官网：http://projects.spring.io/spring-data/ Spring Data 的使命是给各种数据访问提供统一的编程接口，不管是关系型数据库（如MySQL），还是非关系数据库（如Redis），或者类似Elasticsearch这样的索引数据库。从而简化开发人员的代码，提高开发效率。 特征： 支持Spring的基于@Configuration的java配置方式，或者XML配置方式 提供了用于操作ES的便捷工具类ElasticsearchTemplate。包括实现文档到POJO之间的自动智能映射。 利用Spring的数据转换服务实现的功能丰富的对象映射 基于注解的元数据映射方式，而且可扩展以支持更多不同的数据格式 根据持久层接口自动生成对应实现方法，无需人工编写基本操作代码（类似mybatis，根据接口自动得到实现）。当然，也支持人工定制查询 2 创建Demo工程pom依赖： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;lwy.demo&lt;/groupId&gt; &lt;artifactId&gt;es_demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;elasticsearch&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.yml文件配置： 12345spring: data: elasticsearch: cluster-name: elasticsearch cluster-nodes: 127.0.0.1:9300 启动类: 123456@SpringBootApplicationpublic class EsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EsApplication.class); &#125;&#125; 3 实体类及注解123456789101112131415161718192021222324@AllArgsConstructor@NoArgsConstructor@Document(indexName = \"heima3\", type = \"item\", shards = 1)@Datapublic class Item &#123; @Field(type = FieldType.Long) @Id private Long id; @Field(type = FieldType.Text, analyzer = \"ik_smart\") private String title; //标题 @Field(type = FieldType.Keyword) private String category;// 分类 @Field(type = FieldType.Keyword) private String brand; // 品牌 @Field(type = FieldType.Double) private Double price; // 价格 @Field(type = FieldType.Keyword, index = false) private String images; // 图片地址&#125; 映射 Spring Data通过注解来声明字段的映射属性，有下面的三个注解： @Document 作用在类，标记实体类为文档对象，一般有两个属性 indexName：对应索引库名称 type：对应在索引库中的类型 shards：分片数量，默认5 replicas：副本数量，默认1 @Id 作用在成员变量，标记一个字段作为id主键 @Field 作用在成员变量，标记为文档的字段，并指定字段映射属性： type：字段类型，取值是枚举：FieldType index：是否索引，布尔类型，默认是true store：是否存储，布尔类型，默认是false analyzer：分词器名称 4 Template索引操作4.1 创建索引和映射 创建索引 1234567891011121314151617@RunWith(SpringRunner.class)@SpringBootTest(classes = EsApplication.class)public class EsTest &#123; @Autowired ElasticsearchTemplate template; @Autowired private ItemRepository repository; @Test public void testCreate() &#123; //创建索引库，会根据Item类的@Document注解信息来创建 template.createIndex(Item.class); //配置映射，会根据Item类中的id、Field等字段来自动完成映射 template.putMapping(Item.class); &#125;&#125; 4.2 删除索引删除索引的API： 可以根据类名或索引名删除。 示例： 1234@Testpublic void deleteIndex() &#123; esTemplate.deleteIndex(\"heima\");&#125; 5 Repository文档操作Spring Data 的强大之处，就在于你不用写任何DAO处理，自动根据方法名或类的信息进行CRUD操作。只要你定义一个接口，然后继承Repository提供的一些子接口，就能具备各种基本的CRUD功能。 我们只需要定义接口，然后继承它就OK了。 5.1 批量新增代码： 12345678@Testpublic void indexList() &#123; List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(2L, \"坚果手机R1\", \" 手机\", \"锤子\", 3699.00, \"http://image.leyou.com/123.jpg\")); list.add(new Item(3L, \"华为META10\", \" 手机\", \"华为\", 4499.00, \"http://image.leyou.com/3.jpg\")); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);&#125; 5.2 修改文档修改和新增是同一个接口，区分的依据就是id，这一点跟我们在页面发起PUT请求是类似的。 5.3 基本查询ElasticsearchRepository提供了一些基本的查询方法： 查询所有： 123456@Testpublic void testFind()&#123; // 查询全部，并安装价格降序排序 Iterable&lt;Item&gt; items = this.itemRepository.findAll(Sort.by(Sort.Direction.DESC, \"price\")); items.forEach(item-&gt; System.out.println(item));&#125; 5.4 自定义方法Spring Data 的另一个强大功能，是根据方法名称自动实现功能。 比如：你的方法名叫做：findByTitle，那么它就知道你是根据title查询，然后自动帮你完成，无需写实现类。 当然，方法名称要符合一定的约定： Keyword Sample Elasticsearch Query String And findByNameAndPrice {&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Or findByNameOrPrice {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}} Is findByName {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Not findByNameNot {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}} Between findByPriceBetween {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} LessThanEqual findByPriceLessThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} GreaterThanEqual findByPriceGreaterThan {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Before findByPriceBefore {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} After findByPriceAfter {&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}} Like findByNameLike {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} StartingWith findByNameStartingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}} EndingWith findByNameEndingWith {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}} Contains/Containing findByNameContaining {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}} In findByNameIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}} NotIn findByNameNotIn(Collection&lt;String&gt;names) {&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}} Near findByStoreNear Not Supported Yet ! True findByAvailableTrue {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} False findByAvailableFalse {&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}} OrderBy findByAvailableTrueOrderByNameDesc {&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}} 例如，我们来按照价格区间查询，定义这样的一个方法： 123public interface ItemRepository extends ElasticsearchRepository&lt;Item,Long&gt; &#123; List&lt;Item&gt; findByPriceBetween(Double begin,Double end);&#125; 然后添加一些测试数据： 1234567891011@Testpublic void indexList() &#123; List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(1L, \"小米手机7\", \"手机\", \"小米\", 3299.00, \"http://image.leyou.com/13123.jpg\")); list.add(new Item(2L, \"坚果手机R1\", \"手机\", \"锤子\", 3699.00, \"http://image.leyou.com/13123.jpg\")); list.add(new Item(3L, \"华为META10\", \"手机\", \"华为\", 4499.00, \"http://image.leyou.com/13123.jpg\")); list.add(new Item(4L, \"小米Mix2S\", \"手机\", \"小米\", 4299.00, \"http://image.leyou.com/13123.jpg\")); list.add(new Item(5L, \"荣耀V10\", \"手机\", \"华为\", 2799.00, \"http://image.leyou.com/13123.jpg\")); // 接收对象集合，实现批量新增 itemRepository.saveAll(list);&#125; 不需要写实现类，然后我们直接去运行： 1234567@Testpublic void queryByPriceBetween()&#123; List&lt;Item&gt; list = this.itemRepository.findByPriceBetween(2000.00, 3500.00); for (Item item : list) &#123; System.out.println(\"item = \" + item); &#125;&#125; 6 高级查询6.1 自定义查询先来看最基本的match query： 1234567891011121314@Testpublic void testNativeQuery()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.matchQuery(\"title\", \"小米\")); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); // 打印总页数 System.out.println(items.getTotalPages()); items.forEach(System.out::println);&#125; NativeSearchQueryBuilder：Spring提供的一个查询条件构建器，帮助构建json格式的请求体 Page&lt;item&gt;：默认是分页查询，因此返回的是一个分页的结果对象，包含属性： totalElements：总条数 totalPages：总页数 Iterator：迭代器，本身实现了Iterator接口，因此可直接迭代得到当前页的数据 6.2 分页查询利用NativeSearchQueryBuilder可以方便的实现分页： 12345678910111213141516171819202122232425@Testpublic void testQuery()&#123; //创建查询构建器 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); //结果过滤 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;\"id\",\"title\",\"price\"&#125;,null)); //添加查询条件 queryBuilder.withQuery(QueryBuilders.matchQuery(\"title\",\"小米\")); //过滤 queryBuilder.withSort(SortBuilders.fieldSort(\"price\").order(SortOrder.DESC)); //分页 queryBuilder.withPageable(PageRequest.of(0,2)); Page&lt;Item&gt; items = repository.search(queryBuilder.build()); for (Item item : items) &#123; System.out.println(item); &#125; // 打印总条数 System.out.println(items.getTotalElements()); // 打印总页数 System.out.println(items.getTotalPages()); // 每页大小 System.out.println(items.getSize()); // 当前页 System.out.println(items.getNumber());&#125; 6.3 排序排序也通用通过NativeSearchQueryBuilder完成： 12345678910111213141516@Testpublic void testSort()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.termQuery(\"category\", \"手机\")); // 排序 queryBuilder.withSort(SortBuilders.fieldSort(\"price\").order(SortOrder.DESC)); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); items.forEach(System.out::println);&#125; 7 聚合7.1 聚合为桶桶就是分组，比如这里我们按照品牌brand进行分组： 12345678910111213141516171819@Testpublic void testAgg()&#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); String aggName=\"popularBrand\"; //聚合 queryBuilder.addAggregation(AggregationBuilders.terms(aggName).field(\"brand\")); //查询并返回 AggregatedPage&lt;Item&gt; items = template.queryForPage(queryBuilder.build(), Item.class); //解析聚合 Aggregations aggs = items.getAggregations(); //获取指定名称的聚合 StringTerms terms = aggs.get(aggName); //获取桶 List&lt;StringTerms.Bucket&gt; buckets = terms.getBuckets(); for (StringTerms.Bucket bucket : buckets) &#123; System.out.println(bucket.getKeyAsString()+bucket.getDocCount()); &#125;&#125; 关键API： AggregationBuilders：聚合的构建工厂类。所有聚合都由这个类来构建 AggregatedPage：聚合查询的结果类。它是Page&lt;T&gt;的子接口： AggregatedPage在Page功能的基础上，拓展了与聚合相关的功能，它其实就是对聚合结果的一种封装，而返回的结果都是Aggregation类型对象，不过根据字段类型不同，又有不同的子类表示 7.2 嵌套聚合，求平均值代码： 1234567891011121314151617181920212223242526272829@Testpublic void testSubAgg()&#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;\"\"&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms(\"brands\").field(\"brand\") .subAggregation(AggregationBuilders.avg(\"priceAvg\").field(\"price\")) // 在品牌聚合桶内进行嵌套聚合，求平均值 ); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemRepository.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation(\"brands\"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即品牌名称 3.5、获取桶中的文档数量 System.out.println(bucket.getKeyAsString() + \"，共\" + bucket.getDocCount() + \"台\"); // 3.6.获取子聚合结果： InternalAvg avg = (InternalAvg) bucket.getAggregations().asMap().get(\"priceAvg\"); System.out.println(\"平均售价：\" + avg.getValue()); &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(十一.购物车)","slug":"微服务项目总结(十一.购物车)","date":"2021-05-08T13:19:59.239Z","updated":"2020-04-29T02:44:38.095Z","comments":true,"path":"15426/","link":"","permalink":"http://tonymua.top/15426/","excerpt":"1.搭建购物车服务1.1 创建module1.2 pom依赖","text":"1.搭建购物车服务1.1 创建module1.2 pom依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;leyou&lt;/artifactId&gt; &lt;groupId&gt;com.leyou&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-cart&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.auth&lt;/groupId&gt; &lt;artifactId&gt;ly-auth-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.common&lt;/groupId&gt; &lt;artifactId&gt;ly-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1.3 配置文件123456789101112131415161718server: port: 8088spring: application: name: cart-service redis: host: 127.0.0.1eureka: client: service-url: defaultZone: http://127.0.0.1:8090/eureka instance: prefer-ip-address: true ip-address: 127.0.0.1leyou: jwt: pubKeyPath: E:\\\\tmp\\\\rsa\\\\rsa.pub # 公钥地址 cookieName: LY_TOKEN 2.购物车功能分析2.1 需求需求描述： 用户可以在登录状态下将商品添加到购物车 放入数据库 mongodb 放入redis（采用） 用户可以在未登录状态下将商品添加到购物车 放入localstorage cookie webSQL 用户可以使用购物车一起结算下单 用户可以查询自己的购物车 用户可以在购物车中修改购买商品的数量。 用户可以在购物车中删除商品。 在购物车中展示商品优惠信息 提示购物车商品价格变化 2.2 流程图 这幅图主要描述了两个功能：新增商品到购物车、查询购物车。 新增商品： 判断是否登录 是：则添加商品到后台Redis中 否：则添加商品到本地的Localstorage 无论哪种新增，完成后都需要查询购物车列表： 判断是否登录 否：直接查询localstorage中数据并展示 是：已登录，则需要先看本地是否有数据， 有：需要提交到后台添加到redis，合并数据，而后查询 否：直接去后台查询redis，而后返回 3.未登录购物车3.1 准备3.1.1 购物车的数据结构首先分析一下未登录购物车的数据结构。 每一个购物车信息，都是一个对象，包含： 12345678&#123; skuId:2131241, title:\"小米6\", image:\"\", price:190000, num:1, ownSpec:\"&#123;\"机身颜色\":\"陶瓷黑尊享版\",\"内存\":\"6GB\",\"机身存储\":\"128GB\"&#125;\"&#125; 另外，购物车中不止一条数据，因此最终会是对象的数组。即： 123[ &#123;...&#125;,&#123;...&#125;,&#123;...&#125;] 3.1.2 web本地存储知道了数据结构，下一个问题，就是如何保存购物车数据。前面我们分析过，可以使用Localstorage来实现。Localstorage是web本地存储的一种，那么，什么是web本地存储呢？ 什么是web本地存储？ web本地存储主要有两种方式： LocalStorage：localStorage 方法存储的数据没有时间限制。第二天、第二周或下一年之后，数据依然可用。 SessionStorage：sessionStorage 方法针对一个 session 进行数据存储。当用户关闭浏览器窗口后，数据会被删除。 LocalStorage的用法 语法非常简单： 123localStorage.setItem(\"key\",\"value\"); // 存储数据localStorage.getItem(\"key\"); // 获取数据localStorage.removeItem(\"key\"); // 删除数据 注意：localStorage和SessionStorage都只能保存字符串。 不过，在我们的common.js中，已经对localStorage进行了简单的封装： 示例： 3.2 添加购物车3.2.1 点击事件现在点击加入购物车会跳转到购物车成功页面。 不过我们不这么做，我们绑定点击事件，然后实现添加购物车功能。 addCart方法中判断用户的登录状态： 1234567addCart()&#123; ly.http.get(\"/auth/verify\").then(res=&gt;&#123; // 已登录发送信息到后台，保存到redis中 &#125;).catch(()=&gt;&#123; // 未登录保存在浏览器本地的localStorage中 &#125;)&#125; 3.2.2 获取数量，添加购物车12345678910111213141516171819202122232425262728293031addCart()&#123; ly.verifyUser().then(res=&gt;&#123; // 已登录发送信息到后台，保存到redis中 &#125;).catch(()=&gt;&#123; // 未登录保存在浏览器本地的localStorage中 // 1、查询本地购物车 let carts = ly.store.get(\"carts\") || []; let cart = carts.find(c=&gt;c.skuId===this.sku.id); // 2、判断是否存在 if (cart) &#123; // 3、存在更新数量 cart.num += this.num; &#125; else &#123; // 4、不存在，新增 cart = &#123; skuId: this.sku.id, title: this.sku.title, price: this.sku.price, image: this.sku.images, num: this.num, ownSpec: this.ownSpec &#125; carts.push(cart); &#125; // 把carts写回localstorage ly.store.set(\"carts\", carts); // 跳转 window.location.href = \"http://www.leyou.com/cart.html\"; &#125;);&#125; 3.3 查询购物车页面加载时，就应该去查询购物车。 1234567891011121314151617181920212223242526var cartVm = new Vue(&#123; el: \"#cartApp\", data: &#123; ly, carts: [],// 购物车数据 &#125;, created() &#123; this.loadCarts(); &#125;, methods: &#123; loadCarts() &#123; // 先判断登录状态 ly.verifyUser().then(() =&gt; &#123; // 已登录 &#125;).catch(() =&gt; &#123; // 未登录 this.carts = ly.store.get(\"carts\") || []; this.selected = this.carts; &#125;) &#125; &#125; components: &#123; shortcut: () =&gt; import(\"/js/pages/shortcut.js\") &#125;&#125;) 3.4 修改数量我们给页面的 + 和 -绑定点击事件，修改num 的值： 两个事件： 123456789101112131415161718192021increment(c) &#123; c.num++; ly.verifyUser().then(() =&gt; &#123; // TODO 已登录，向后台发起请求 &#125;).catch(() =&gt; &#123; // 未登录，直接操作本地数据 ly.store.set(\"carts\", this.carts); &#125;)&#125;,decrement(c) &#123; if (c.num &lt;= 1) &#123; return; &#125; c.num--; ly.verifyUser().then(() =&gt; &#123; // TODO 已登录，向后台发起请求 &#125;).catch(() =&gt; &#123; // 未登录，直接操作本地数据 ly.store.set(\"carts\", this.carts); &#125;)&#125; 3.5 删除商品给删除按钮绑定事件： 点击事件中删除商品： 123456789deleteCart(i)&#123; ly.verifyUser().then(res=&gt;&#123; // TODO，已登录购物车 &#125;).catch(()=&gt;&#123; // 未登录购物车 this.carts.splice(i, 1); ly.store.set(\"carts\", this.carts); &#125;)&#125; 3.6 总价格然后编写一个计算属性，计算出选中商品总价格： 12345computed: &#123; totalPrice() &#123; return ly.formatPrice(this.selected.reduce((c1, c2) =&gt; c1 + c2.num * c2.price, 0)); &#125;&#125; 4.已登录购物车接下来，我们完成已登录购物车。 在刚才的未登录购物车编写时，我们已经预留好了编写代码的位置，逻辑也基本一致。 4.1 添加登录校验购物车系统只负责登录状态的购物车处理，因此需要添加登录校验，我们通过JWT鉴权即可实现。 4.1.1 引入JWT相关依赖我们引入之前写的鉴权工具：ly-auth-common 12345&lt;dependency&gt; &lt;groupId&gt;com.leyou.auth&lt;/groupId&gt; &lt;artifactId&gt;ly-auth-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 4.1.2 配置公钥1234leyou: jwt: pubKeyPath: C:/tmp/rsa/rsa.pub # 公钥地址 cookieName: LY_TOKEN # cookie的名称 4.1.3 加载公钥JwtProperties 12345678910111213141516171819@Data@ConfigurationProperties(prefix = \"leyou.jwt\")public class JwtProperties &#123; private String pubKeyPath;// 公钥 private String cookieName; private PublicKey publicKey; /** * @PostContruct：在构造方法执行之后执行该方法 */ @PostConstruct public void init() throws Exception &#123; //获取公钥私钥 publicKey = RsaUtils.getPublicKey(pubKeyPath); &#125;&#125; 4.1.4 编写拦截器因为很多接口都需要进行登录，我们直接编写SpringMVC拦截器，进行统一登录校验。同时，我们还要把解析得到的用户信息保存起来，以便后续的接口可以使用。 UserInterceptor 12345678910111213141516171819202122232425262728293031323334353637@Slf4jpublic class UserInterceptor implements HandlerInterceptor &#123; private JwtProperties prop; private static final ThreadLocal&lt;UserInfo&gt; THREAD_LOCAL=new ThreadLocal&lt;&gt;(); public UserInterceptor(JwtProperties prop) &#123; this.prop=prop; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; //获取cookie中的token String token = CookieUtils.getCookieValue(request, prop.getCookieName()); try &#123; //解析token UserInfo user = JwtUtils.getInfoFromToken(token, prop.getPublicKey()); //传递user THREAD_LOCAL.set(user); //放行 return true; &#125; catch (Exception e) &#123; log.error(\"[购物车服务] 解析用户身份失败\",e); return false; &#125; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; //用完数据,一定要清空 THREAD_LOCAL.remove(); &#125; public static UserInfo getUser()&#123; return THREAD_LOCAL.get(); &#125;&#125; 注意： 这里我们使用了ThreadLocal来存储查询到的用户信息，线程内共享，因此请求到达Controller后可以共享User 并且对外提供了静态的方法：getLoginUser()来获取User信息 4.1.5 配置拦截器配置SpringMVC，使过滤器生效： MVCConfig 12345678910@Configuration@EnableConfigurationProperties(JwtProperties.class)public class MVCConfig implements WebMvcConfigurer &#123; @Autowired private JwtProperties prop; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new UserInterceptor(prop)).addPathPatterns(\"/**\"); &#125;&#125; 4.2 后台购物车设计当用户登录时，我们需要把购物车数据保存到后台，可以选择保存在数据库。但是购物车是一个读写频率很高的数据。因此我们这里选择读写效率比较高的Redis作为购物车存储。 Redis有5种不同数据结构，这里选择哪一种比较合适呢？Map&lt;String, List&gt; 首先不同用户应该有独立的购物车，因此购物车应该以用户的作为key来存储，Value是用户的所有购物车信息。这样看来基本的k-v结构就可以了。 但是，我们对购物车中的商品进行增、删、改操作，基本都需要根据商品id进行判断，为了方便后期处理，我们的购物车也应该是k-v结构，key是商品id，value才是这个商品的购物车信息。 综上所述，我们的购物车结构是一个双层Map：Map&lt;String,Map&lt;String,String&gt;&gt; 第一层Map，Key是用户id 第二层Map，Key是购物车中商品id，值是购物车数据 实体类： 12345678910@Datapublic class Cart &#123; private Long userId;// 用户id private Long skuId;// 商品id private String title;// 标题 private String image;// 图片 private Long price;// 加入购物车时的价格 private Integer num;// 购买数量 private String ownSpec;// 商品规格参数&#125; 4.3 添加商品到购物车4.3.1 页面发起请求已登录情况下，向后台添加购物车： 123ly.http.post(\"/cart\", &#123;skuId: this.sku.id, num: this.num&#125;).then(res=&gt;&#123; window.location = \"http://www.leyou.com/cart.html\";&#125;) 这里发起的是Json请求。那么我们后台也要以json接收。 4.3.2 编写controller先分析一下： 请求方式：新增，肯定是Post 请求路径：/cart ，这个其实是Zuul路由的路径，我们可以不管 请求参数：Json对象，包含skuId和num属性 返回结果：无 1234567891011@RestControllerpublic class CartController &#123; @Autowired private CartService cartService; @PostMapping public ResponseEntity&lt;Void&gt; addCart(@RequestBody Cart cart)&#123; cartService.addCart(cart); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125;&#125; 在ly-gateway中添加路由配置： 1cart-service: /cart/** 4.3.3 CartService这里我们不访问数据库，而是直接操作Redis。基本思路： 先查询之前的购物车数据 判断要添加的商品是否存在 存在：则直接修改数量后写回Redis 不存在：新建一条数据，然后写入Redis 1234567891011121314151617181920212223242526272829@Servicepublic class CartService &#123; @Autowired private StringRedisTemplate redisTemplate; private static final String KEY_PREFIX=\"cart:user:id:\"; public void addCart(Cart cart) &#123; //获取登录的用户 UserInfo user = UserInterceptor.getUser(); //key String key=KEY_PREFIX+user.getId(); BoundHashOperations&lt;String, Object, Object&gt; operations = redisTemplate.boundHashOps(key); //hashKey String hashKey = cart.getSkuId().toString(); //判断当前购物车商品,是否存在 if (operations.hasKey(hashKey)) &#123; //是,修改数量 String json = operations.get(hashKey).toString(); Cart cacheCart = JsonUtils.toBean(json, Cart.class); cacheCart.setNum(cacheCart.getNum()+cart.getNum()); //写回redis operations.put(hashKey,JsonUtils.toString(cacheCart)); &#125;else &#123; //否,新增 operations.put(hashKey,JsonUtils.toString(cart)); &#125; &#125;&#125; 4.4 查询购物车CartController 1234@GetMapping(\"list\")public ResponseEntity&lt;List&lt;Cart&gt;&gt; queryCartList()&#123; return ResponseEntity.ok(cartService.queryCartList());&#125; CartService 1234567891011121314public List&lt;Cart&gt; queryCartList() &#123; //获取登录用户 UserInfo user = UserInterceptor.getUser(); //key String key=KEY_PREFIX+user.getId(); if (!redisTemplate.hasKey(key))&#123; //key不存在 throw new LyException(ExceptionEnum.CART_NOT_FOUND); &#125; //获取登录用户的所有的购物车 BoundHashOperations&lt;String, Object, Object&gt; operations = redisTemplate.boundHashOps(key); List&lt;Cart&gt; carts = operations.values().stream().map(o -&gt; JsonUtils.toBean(o.toString(), Cart.class)).collect(Collectors.toList()); return carts; &#125; 4.5 修改商品数量CartController 12345@PutMappingpublic ResponseEntity&lt;Void&gt; updateCart(@RequestParam(\"id\")Long skuId,@RequestParam(\"num\")Integer num)&#123; cartService.updateCart(skuId,num); return ResponseEntity.status(HttpStatus.NO_CONTENT).build();&#125; CartService 12345678910111213141516171819public void updateCart(Long skuId, Integer num) &#123; //获取登录的用户 UserInfo user = UserInterceptor.getUser(); //key String key=KEY_PREFIX+user.getId(); //hashKey String hashKey = skuId.toString(); //获取操作 BoundHashOperations&lt;String, Object, Object&gt; operations = redisTemplate.boundHashOps(key); //判断是否存在 if (!operations.hasKey(hashKey))&#123; throw new LyException(ExceptionEnum.CART_NOT_FOUND); &#125; //查询购物车 Cart cart = JsonUtils.toBean(operations.get(hashKey).toString(), Cart.class); cart.setNum(num); //写回redis operations.put(hashKey,JsonUtils.toString(cart));&#125; 4.6 删除购物车商品CartController 12345@DeleteMapping(\"&#123;skuId&#125;\")public ResponseEntity&lt;Void&gt; deleteCart(@PathVariable(\"skuId\")Long skuId)&#123; cartService.deleteCart(skuId); return ResponseEntity.status(HttpStatus.NO_CONTENT).build();&#125; CartService 123456public void deleteCart(Long skuId) &#123; UserInfo user = UserInterceptor.getUser(); String key=KEY_PREFIX+user.getId(); //删除 redisTemplate.opsForHash().delete(key,skuId.toString());&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(十.授权中心)","slug":"微服务项目总结(十.授权中心)","date":"2021-05-08T13:19:59.238Z","updated":"2020-04-29T02:44:38.121Z","comments":true,"path":"39109/","link":"","permalink":"http://tonymua.top/39109/","excerpt":"1.无状态登录原理1.1 什么是有状态？有状态服务，即服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，典型的设计如tomcat中的session。 例如登录：用户登录后，我们把登录者的信息保存在服务端session中，并且给用户一个cookie值，记录对应的session。然后下次请求，用户携带cookie值来，我们就能识别到对应session，从而找到用户的信息。 缺点是什么？ 服务端保存大量数据，增加服务端压力 服务端保存用户状态，无法进行水平扩展 客户端请求依赖服务端，多次请求必须访问同一台服务器","text":"1.无状态登录原理1.1 什么是有状态？有状态服务，即服务端需要记录每次会话的客户端信息，从而识别客户端身份，根据用户身份进行请求的处理，典型的设计如tomcat中的session。 例如登录：用户登录后，我们把登录者的信息保存在服务端session中，并且给用户一个cookie值，记录对应的session。然后下次请求，用户携带cookie值来，我们就能识别到对应session，从而找到用户的信息。 缺点是什么？ 服务端保存大量数据，增加服务端压力 服务端保存用户状态，无法进行水平扩展 客户端请求依赖服务端，多次请求必须访问同一台服务器 1.2 什么是无状态微服务集群中的每个服务，对外提供的都是Rest风格的接口。而Rest风格的一个最重要的规范就是：服务的无状态性，即： 服务端不保存任何客户端请求者信息 客户端的每次请求必须具备自描述信息，通过这些信息识别客户端身份 带来的好处是什么呢？ 客户端请求不依赖服务端的信息，任何多次请求不需要必须访问到同一台服务 服务端的集群和状态对客户端透明 服务端可以任意的迁移和伸缩 减小服务端存储压力 1.3 如何实现无状态无状态登录的流程： 当客户端第一次请求服务时，服务端对用户进行信息认证（登录） 认证通过，将用户信息进行加密形成token，返回给客户端，作为登录凭证 以后每次请求，客户端都携带认证的token 服务的对token进行解密，判断是否有效。 整个登录过程中，最关键的点是什么？ token的安全性 token是识别客户端身份的唯一标示，如果加密不够严密，被人伪造那就完蛋了。 采用何种方式加密才是安全可靠的呢？ 我们将采用JWT + RSA非对称加密 1.4 JWT1.4.1 简介​ JWT，全称是Json Web Token， 是JSON风格轻量级的授权和身份认证规范，可实现无状态、分布式的Web应用授权；官网：https://jwt.io 1.4.2 数据格式JWT包含三部分数据： Header：头部，通常头部有两部分信息： 声明类型，这里是JWT 我们会对头部进行base64编码，得到第一部分数据 Payload：载荷，就是有效数据，一般包含下面信息： 用户身份信息（注意，这里因为采用base64编码，可解码，因此不要存放敏感信息） 注册声明：如token的签发时间，过期时间，签发人等 这部分也会采用base64编码，得到第二部分数据 Signature：签名，是整个数据的认证信息。一般根据前两步的数据，再加上服务的的密钥（secret）（不要泄漏，最好周期性更换），通过加密算法生成。用于验证整个数据完整和可靠性 生成的数据格式：token==个人证件 jwt=个人身份证 1.4.3 JWT交互流程流程图： 步骤翻译： 1、用户登录 2、服务的认证，通过后根据secret生成token 3、将生成的token返回给浏览器 4、用户每次请求携带token 5、服务端利用公钥解读jwt签名，判断签名有效后，从Payload中获取用户信息 6、处理请求，返回响应结果 因为JWT签发的token中已经包含了用户的身份信息，并且每次请求都会携带，这样服务的就无需保存用户信息，甚至无需去数据库查询，完全符合了Rest的无状态规范。 1.4.4 非对称加密加密技术是对信息进行编码和解码的技术，编码是把原来可读信息（又称明文）译成代码形式（又称密文），其逆过程就是解码（解密），加密技术的要点是加密算法，加密算法可以分为三类： 对称加密，如AES 基本原理：将明文分成N个组，然后使用密钥对各个组进行加密，形成各自的密文，最后把所有的分组密文进行合并，形成最终的密文。 优势：算法公开、计算量小、加密速度快、加密效率高 缺陷：双方都使用同样密钥，安全性得不到保证 非对称加密，如RSA 基本原理：同时生成两把密钥：私钥和公钥，私钥隐秘保存，公钥可以下发给信任客户端 私钥加密，持有私钥或公钥才可以解密 公钥加密，持有私钥才可解密 优点：安全，难以破解 缺点：算法比较耗时 不可逆加密，如MD5，SHA 基本原理：加密过程中不需要使用密钥，输入明文后由系统直接经过加密算法处理成密文，这种加密后的数据是无法被解密的，无法根据密文推算出明文。 1.5 结合Zuul的鉴权流程我们逐步演进系统架构设计。需要注意的是：secret是签名的关键，因此一定要保密，我们放到鉴权中心保存，其它任何服务中都不能获取secret。 结合RSA的鉴权 我们首先利用RSA生成公钥和私钥。私钥保存在授权中心，公钥保存在Zuul和各个信任的微服务 用户请求登录 授权中心校验，通过后用私钥对JWT进行签名加密 返回jwt给用户 用户携带JWT访问 Zuul直接通过公钥解密JWT，进行验证，验证通过则放行 请求到达微服务，微服务直接用公钥解析JWT，获取用户信息，无需访问授权中心 2.授权中心2.1 创建授权中心授权中心的主要职责： 用户鉴权： 接收用户的登录请求，通过用户中心的接口进行校验，通过后生成JWT 使用私钥生成JWT并返回 服务鉴权：微服务间的调用不经过Zuul，会有风险，需要鉴权中心进行认证 原理与用户鉴权类似，但逻辑稍微复杂一些（此处我们不做实现） 因为生成jwt，解析jwt这样的行为以后在其它微服务中也会用到，因此我们会抽取成工具。我们把鉴权中心进行聚合，一个工具module，一个提供服务的module 2.1.1 创建父module我们先创建父module，名称为：ly-auth 将pom打包方式改为pom 2.1.2 通用module然后是授权服务的通用模块：ly-auth-common 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.1.3 授权服务12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.auth&lt;/groupId&gt; &lt;artifactId&gt;ly-auth-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.common&lt;/groupId&gt; &lt;artifactId&gt;ly-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 启动类 12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class LyAuthApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LyAuthApplication.class); &#125;&#125; application.yaml 1234567891011121314151617server: port: 8087spring: application: name: auth-serviceeureka: client: service-url: defaultZone: http://127.0.0.1:8080/eurekaleyou: jwt: secret: leyou@Login(Auth&#125;*^31)&amp;heiMa% # 登录校验的密钥 pubKeyPath: E:\\\\tmp\\\\rsa\\\\rsa.pub # 公钥地址 priKeyPath: E:\\\\tmp\\\\rsa\\\\rsa.pri # 私钥地址 expire: 30 # 过期时间,单位分钟 cookieName: LY_TOKEN cookieMaxAge: 30 在ly-gateway工程的application.yaml中，修改路由： 123456789101112zuul: prefix: /api # 添加路由前缀 retryable: true routes: item-service: /item/** search-service: /search/** upload-service: path: /upload/** serviceId: upload-service strip-prefix: false user-service: /user/** auth-service: /auth/** # 授权中心微服务 2.2 JWT工具类我们在ly-auth-common中导入工具类： UserInfo 1234567@Data@NoArgsConstructor@AllArgsConstructorpublic class UserInfo &#123; private Long id; private String username;&#125; 在ly-auth-common中编写测试类： 1234567891011121314151617181920212223242526272829303132333435363738public class JwtTest &#123; private static final String pubKeyPath = \"E:\\\\tmp\\\\rsa\\\\rsa.pub\"; private static final String priKeyPath = \"E:\\\\tmp\\\\rsa\\\\rsa.pri\"; private PublicKey publicKey; private PrivateKey privateKey; @Test public void testRsa() throws Exception &#123; RsaUtils.generateKey(pubKeyPath, priKeyPath, \"234\"); &#125; @Before public void testGetRsa() throws Exception &#123; this.publicKey = RsaUtils.getPublicKey(pubKeyPath); this.privateKey = RsaUtils.getPrivateKey(priKeyPath); &#125; @Test public void testGenerateToken() throws Exception &#123; // 生成token String token = JwtUtils.generateToken(new UserInfo(20L, \"jack\"), privateKey, 5); System.out.println(\"token = \" + token); &#125; @Test public void testParseToken() throws Exception &#123; String token = \"eyJhbGciOiJSUzI1NiJ9.eyJpZCI6MjAsInVzZXJuYW1lIjoiamFjayIsImV4cCI6MTU2ODc4ODI5MX0.e5A7Ntxn-jhJ0UTdVQPIpJSniB8I8NhK88INwKiEpbXog9aSUpdV5Y3SubUf6FbaSp1wRDVqomrodqhNHb3k9mYBE43EZ3JzB5pod9QRklHMCXpMqV8jtlrhjzopTHEpIwiLsO2d3omjQOQZcamUUohKbWeIFeWUAz1C7DOtibU\"; // 解析token UserInfo user = JwtUtils.getInfoFromToken(token, publicKey); System.out.println(\"id: \" + user.getId()); System.out.println(\"userName: \" + user.getUsername()); &#125;&#125; 测试生成公钥和私钥，我们运行这段代码：**注意需要把@Before方法注释掉 运行之后，查看目标目录：公钥和私钥已经生成了！ 测试生成token，把@Before的注释去掉 测试解析token： 2.3 编写登录授权接口接下来，我们需要在leyou-auth-servcice编写一个接口，对外提供登录授权服务。基本流程如下： 客户端携带用户名和密码请求登录 授权中心调用用户中心接口，根据用户名和密码查询用户信息 如果用户名密码正确，能获取用户，否则为空，则登录失败 如果校验成功，则生成JWT并返回 2.3.1 生成公钥和私钥我们需要在授权中心生成真正的公钥和私钥。我们必须有一个生成公钥和私钥的secret，这个可以配置到application.yml中： 123456leyou: jwt: secret: leyou@Login(Auth&#125;*^31)&amp;heiMa% # 登录校验的密钥 pubKeyPath: E:\\\\tmp\\\\rsa\\\\rsa.pub # 公钥地址 priKeyPath: E:\\\\tmp\\\\rsa\\\\rsa.pri # 私钥地址 expire: 30 # 过期时间,单位分钟 然后编写属性类，加载这些数据： 123456789101112131415161718192021222324252627282930313233343536373839404142@Data@ConfigurationProperties(prefix = \"leyou.jwt\")public class JwtProperties &#123; private String secret; // 密钥 private String pubKeyPath;// 公钥 private String priKeyPath;// 私钥 private int expire;// token过期时间 private PublicKey publicKey; // 公钥 private PrivateKey privateKey; // 私钥 private String cookieName; private Integer cookieMaxAge; private static final Logger LOGGER = LoggerFactory.getLogger(JwtProperties.class); /** * @PostContruct：在构造方法执行之后执行该方法 */ @PostConstruct public void init() &#123; try &#123; File pubKey = new File(pubKeyPath); File priKey = new File(priKeyPath); if (!pubKey.exists() || !priKey.exists()) &#123; //生成公钥和私钥 RsaUtils.generateKey(pubKeyPath, priKeyPath, secret); &#125; //获取公钥私钥 publicKey = RsaUtils.getPublicKey(pubKeyPath); privateKey = RsaUtils.getPrivateKey(priKeyPath); &#125; catch (Exception e) &#123; LOGGER.error(\"初始化公钥和私钥失败！\", e); throw new RuntimeException(); &#125; &#125;&#125; 2.3.2 Controller编写授权接口，我们接收用户名和密码，校验成功后，写入cookie中。 请求方式：post 请求路径：/accredit 请求参数：username和password 返回结果：无 1234567891011121314151617181920212223242526@RestController@EnableConfigurationProperties(JwtProperties.class)public class AuthController &#123; @Autowired private AuthService authService; @Autowired private JwtProperties prop; @PostMapping(\"accredit\") public ResponseEntity&lt;Void&gt; authentication( @RequestParam(\"username\") String username, @RequestParam(\"password\") String password, HttpServletRequest request, HttpServletResponse response ) &#123; //登录校验 String token = authService.authentication(username, password); if (StringUtils.isBlank(token)) &#123; return ResponseEntity.status(HttpStatus.UNAUTHORIZED).build(); &#125; //将token写入cookie,并指定httpOnly为true,防止通过JS获取和修改 CookieUtils.setCookie(request, response, prop.getCookieName(), token, prop.getCookieMaxAge(), null, true); return ResponseEntity.ok().build(); &#125;&#125; 2.3.3 UserClient接下来我们肯定要对用户密码进行校验，所以我们需要通过FeignClient去访问 user-service微服务： 在ly-auth中引入user-service-interface依赖 在ly-auth-service中编写FeignClient： 123@FeignClient(\"user-service\")public interface UserClient extends UserApi &#123;&#125; 在ly-user-interface工程中添加api接口： 1234567public interface UserApi &#123; @GetMapping(\"query\") User queryUser( @RequestParam(\"username\")String username, @RequestParam(\"password\")String password );&#125; 2.3.4 AuthService1234567891011121314151617181920212223@Servicepublic class AuthService &#123; @Autowired private UserClient userClient; @Autowired private JwtProperties properties; public String authentication(String username, String password) &#123; try &#123; //调用微服务, 执行查询 User user = userClient.queryUser(username, password); if (user == null) &#123; return null; &#125; // 如果有查询结果，则生成token String token = JwtUtils.generateToken(new UserInfo(user.getId(), user.getUsername()), properties.getPrivateKey(), properties.getExpire()); return token; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 2.5 解决cookie写入问题2.5.1 问题分析我们在之前测试时，清晰的看到了响应头中，有Set-Cookie属性，为什么在这里却什么都没有？ 我们之前在讲cors跨域时，讲到过跨域请求cookie生效的条件： 服务的响应头中需要携带Access-Control-Allow-Credentials并且为true。 响应头中的Access-Control-Allow-Origin一定不能为*，必须是指定的域名 浏览器发起ajax需要指定withCredentials 为true 2.5.2 解决host地址的变化那么问题来了：为什么我们这里的请求serverName变成了：127.0.0.1:8087呢？ 这里的server name其实就是请求的时的主机名：Host，之所以改变，有两个原因： 我们使用了nginx反向代理，当监听到api.leyou.com的时候，会自动将请求转发至127.0.0.1:8090，即Zuul。 而后请求到达我们的网关Zuul，Zuul就会根据路径匹配，我们的请求是/api/auth，根据规则被转发到了 127.0.0.1:8087 ，即我们的授权中心。 我们首先去更改nginx配置，让它不要修改我们的host：proxy_set_header Host $host; 这样就解决了nginx这里的问题。但是Zuul还会有一次转发，所以要去修改网关的配置（ly-gateway工程）： 2.5.3 Zuul的敏感头过滤Zuul内部有默认的过滤器，会对请求和响应头信息进行重组，过滤掉敏感的头信息： 会发现，这里会通过一个属性为SensitiveHeaders的属性，来获取敏感头列表，然后添加到IgnoredHeaders中，这些头信息就会被忽略。 而这个SensitiveHeaders的默认值就包含了set-cookie： 解决方案有两种： 全局设置： zuul.sensitive-headers= 指定路由设置： zuul.routes.&lt;routeName&gt;.sensitive-headers= zuul.routes.&lt;routeName&gt;.custom-sensitive-headers=true 思路都是把敏感头设置为null 3.首页判断登录状态虽然cookie已经成功写入，但是我们首页的顶部，登录状态依然没能判断出用户信息： 这里需要向后台发起请求，获取根据cookie获取当前用户的信息 3.1 后台实现校验用户接口我们在leyou-auth-service中定义用户的校验接口，通过cookie获取token，然后校验通过返回用户信息。 每当用户在页面进行新的操作，都应该刷新token的过期时间，否则30分钟后用户的登录信息就无效了。而刷新其实就是重新生成一份token，然后写入cookie即可。 那么问题来了：我们怎么知道用户有操作呢？ 事实上，每当用户来查询其个人信息，就证明他正在浏览网页，此时刷新cookie是比较合适的时机。因此我们可以对刚刚的校验用户登录状态的接口进行改进，加入刷新token的逻辑。 请求方式：GET 请求路径：/verify 请求参数：无，不过我们需要从cookie中获取token信息 返回结果：UserInfo，校验成功返回用户信息；校验失败，则返回401 123456789101112131415161718 @GetMapping(\"verify\") public ResponseEntity&lt;UserInfo&gt; verify(@CookieValue(\"LY_TOKEN\") String token,HttpServletRequest request,HttpServletResponse response) &#123;/* if (StringUtils.isBlank(token))&#123; throw new LyException(ExceptionEnum.UNAUTHORIZED); &#125;*/ try &#123; //解析token UserInfo info = JwtUtils.getInfoFromToken(token, prop.getPublicKey()); //刷新token,重新生成token String newToken = JwtUtils.generateToken(info, prop.getPrivateKey(), prop.getExpire()); //写入cookie CookieUtils.setCookie(request,response,prop.getCookieName(),newToken,prop.getCookieMaxAge(),null,true); return ResponseEntity.ok(info); &#125; catch (Exception e) &#123; //token已过期,或者token被篡改 throw new LyException(ExceptionEnum.UNAUTHORIZED); &#125; &#125; 4.网关的登录拦截器接下来，我们在Zuul编写拦截器，对用户的token进行校验，如果发现未登录，则进行拦截。 4.1 引入jwt相关配置既然是登录拦截，一定是前置拦截器，我们在ly-gateway中定义 编写application.yml属性文件，添加如下内容： 1234leyou: jwt: pubKeyPath: C:\\\\tmp\\\\rsa\\\\rsa.pub # 公钥地址 cookieName: LY_TOKEN # cookie的名称 编写属性类，读取公钥： 123456789101112131415161718192021@Data@ConfigurationProperties(prefix = \"leyou.jwt\")public class JwtProperties &#123; private String pubKeyPath;// 公钥 private String cookieName; private PublicKey publicKey; private static final Logger LOGGER = LoggerFactory.getLogger(JwtProperties.class); /** * @PostContruct：在构造方法执行之后执行该方法 */ @PostConstruct public void init() throws Exception &#123; //获取公钥私钥 publicKey = RsaUtils.getPublicKey(pubKeyPath); &#125;&#125; 4.2 编写过滤器逻辑(白名单)基本逻辑： 获取cookie中的token 通过JWT对token进行校验 通过：则放行；不通过：则重定向到登录页 要注意，并不是所有的路径我们都需要拦截，例如： 登录校验接口：/auth/** 注册接口：/user/register 数据校验接口：/user/check/** 发送验证码接口：/user/code 搜索接口：/search/** 另外，跟后台管理相关的接口，因为我们没有做登录和权限，因此暂时都放行，但是生产环境中要做登录校验： 后台商品服务：/item/** 所以，我们需要在拦截时，配置一个白名单，如果在名单内，则不进行拦截。 在application.yaml中添加规则： 123456789101112leyou: jwt: pubKeyPath: E:\\\\tmp\\\\rsa\\\\rsa.pub # 公钥地址 cookieName: LY_TOKEN filter: allowPaths: - /api/auth - /api/search - /api/user/register - /api/user/check - /api/user/code - /api/item 然后读取这些属性： 12345@Data@ConfigurationProperties(prefix = \"leyou.filter\")public class FilterProperties &#123; private List&lt;String&gt; allowPaths;&#125; 在过滤器中的shouldFilter方法中添加判断逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Component@EnableConfigurationProperties(&#123;JwtProperties.class, FilterProperties.class&#125;)public class AuthFilter extends ZuulFilter &#123; @Autowired private JwtProperties prop; @Autowired private FilterProperties filterProp; @Override public String filterType() &#123; //过滤器类型:前置 return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; //过滤器顺序 return FilterConstants.PRE_DECORATION_FILTER_ORDER - 1; &#125; @Override public boolean shouldFilter() &#123; //是否过滤 //获取上下文 RequestContext ctx = RequestContext.getCurrentContext(); //获取request HttpServletRequest request = ctx.getRequest(); //获取请求的url路径 String path = request.getRequestURI();// String method = request.getMethod(); //判断是否放行,放行则返回false return !isAllowPath(path); &#125; // 遍历允许访问的路径 private boolean isAllowPath(String path) &#123; for (String allowPath : filterProp.getAllowPaths()) &#123; // 然后判断是否是符合 if (path.startsWith(allowPath))&#123; return true; &#125; &#125; return false; &#125; @Override public Object run() throws ZuulException &#123; //获取上下文 RequestContext ctx = RequestContext.getCurrentContext(); //获取request HttpServletRequest request = ctx.getRequest(); //获取token String token = CookieUtils.getCookieValue(request, prop.getCookieName()); //解析token try &#123; UserInfo user = JwtUtils.getInfoFromToken(token, prop.getPublicKey()); //登录成功,校验权限 &#125; catch (Exception e) &#123; //解析token失败,未登录,拦截 ctx.setSendZuulResponse(false); //返回状态码 ctx.setResponseStatusCode(403); &#125; //校验权限 return null; &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(六.搜索微服务(二))","slug":"微服务项目总结(六.搜索微服务(二))","date":"2021-05-08T13:19:59.236Z","updated":"2020-04-29T02:44:38.120Z","comments":true,"path":"32855/","link":"","permalink":"http://tonymua.top/32855/","excerpt":"1.过滤功能分析效果预览: 整个过滤部分有3块： 顶部的导航，已经选择的过滤条件展示： 商品分类面包屑，根据用户选择的商品分类变化 其它已选择过滤参数","text":"1.过滤功能分析效果预览: 整个过滤部分有3块： 顶部的导航，已经选择的过滤条件展示： 商品分类面包屑，根据用户选择的商品分类变化 其它已选择过滤参数 过滤条件展示，又包含3部分 商品分类展示 品牌展示 其它规格参数 展开或收起的过滤条件的按钮 顶部导航要展示的内容跟用户选择的过滤条件有关。 比如用户选择了某个商品分类，则面包屑中才会展示具体的分类 比如用户选择了某个品牌，列表中才会有品牌信息。 所以，这部分需要依赖第二部分：过滤条件的展示和选择。因此我们先不着急去做。 展开或收起的按钮是否显示，取决于过滤条件有多少，如果很少，那么就没必要展示。所以也是跟第二部分的过滤条件有关。 这样分析来看，我们必须先做第二部分：过滤条件展示。 2.生成分类和品牌过滤先来看分类和品牌。在我们的数据库中已经有所有的分类和品牌信息。在这个位置，是不是把所有的分类和品牌信息都展示出来呢？ 显然不是，用户搜索的条件会对商品进行过滤，而在搜索结果中，不一定包含所有的分类和品牌，直接展示出所有商品分类，让用户选择显然是不合适的。 无论是分类信息，还是品牌信息，都应该从搜索的结果商品中进行聚合得到。 2.1 扩展返回的结果原来，我们返回的结果是PageResult对象，里面只有total、totalPage、items3个属性。但是现在要对商品分类和品牌进行聚合，数据显然不够用，我们需要对返回的结果进行扩展，添加分类和品牌的数据。 那么问题来了：以什么格式返回呢？ 分类：页面显示了分类名称，但背后肯定要保存id信息。所以至少要有id和name 品牌：页面展示的有logo，有文字，当然肯定有id，基本上是品牌的完整数据 我们新建一个类，继承PageResult，然后扩展两个新的属性：分类集合和品牌集合： 123456789101112public class SearchResult extends PageResult&lt;Goods&gt;&#123; private List&lt;Category&gt; categories; private List&lt;Brand&gt; brands; public SearchResult(Long total, Integer totalPage, List&lt;Goods&gt; items, List&lt;Category&gt; categories, List&lt;Brand&gt; brands) &#123; super(total, totalPage, items); this.categories = categories; this.brands = brands; &#125;&#125; 2.2 聚合商品分类和品牌修改搜索的业务逻辑，对分类和品牌聚合。 因为索引库中只有id，所以我们根据id聚合，然后再根据id去查询完整数据。 所以，商品微服务需要提供一个接口：根据品牌id集合，批量查询品牌。 2.2.1 提供查询品牌接口BrandApi 1234public interface BrandApi &#123; @GetMapping(\"brand/brands\") List&lt;Brand&gt; queryBrandByIds(@RequestParam(\"ids\")List&lt;Long&gt; ids);&#125; BrandController 12345 @GetMapping(\"brands\") public ResponseEntity&lt;List&lt;Brand&gt;&gt; queryBrandByIds(@RequestParam(\"ids\")List&lt;Long&gt; ids)&#123; return ResponseEntity.ok(brandService.queryBrandByIds(ids)); &#125;&#125; BrandService 123public List&lt;Brand&gt; queryBrandByIds(List&lt;Long&gt; ids) &#123; return this.brandMapper.selectByIdList(ids);&#125; BrandMapper 继承通用mapper的 SelectByIdListMapper即可 1public interface BrandMapper extends Mapper&lt;Brand&gt;, SelectByIdListMapper&lt;Brand,Long&gt; &#123;&#125; 2.2.2 搜索功能改造添加BrandClient 123@FeignClient(\"item-service\")public interface BrandClient extends BrandApi &#123;&#125; 修改SearchService： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237@Slf4j@Servicepublic class SearchService &#123; @Autowired private CategoryClient categoryClient; @Autowired private GoodsClient goodsClient; @Autowired private BrandClient brandClient; @Autowired private SpecificationClient specificationClient; @Autowired private GoodsRepository goodsRepository; @Autowired private ElasticsearchTemplate template; public Goods buildGoods(Spu spu)&#123; //查询分类 List&lt;Category&gt; categories = categoryClient.queryCategoryByIds(Arrays.asList(spu.getCid1(), spu.getCid2(), spu.getCid3())); List&lt;String&gt; names = categories.stream().map(Category::getName).collect(Collectors.toList()); //查询品牌 Brand brand = brandClient.queryNameById(spu.getBrandId()); //搜索字段 String all=spu.getTitle()+ StringUtils.join(names,\" \")+brand.getName(); //查询sku List&lt;Sku&gt; skuList = goodsClient.querySkuBySpuId(spu.getId()); //对sku进行处理 List&lt;Map&lt;String,Object&gt;&gt; skus=new ArrayList&lt;&gt;(); //价格集合 List&lt;Long&gt; priceList=new ArrayList&lt;&gt;(); for (Sku sku : skuList) &#123; Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); map.put(\"id\",sku.getId()); map.put(\"title\",sku.getTitle()); map.put(\"price\",sku.getPrice()); //取第一张图片 map.put(\"image\", StringUtils.substringBefore(sku.getImages(),\",\")); skus.add(map); //处理价格 priceList.add(sku.getPrice()); &#125; //sku的价格合集 //List&lt;Long&gt; prices = skuList.stream().map(Sku::getPrice).collect(Collectors.toList()); //查询规格参数 List&lt;SpecParam&gt; specParams = specificationClient.queryParamList(null, spu.getCid3(), true); //查询商品详情 SpuDetail spuDetail = goodsClient.querySpuDetailById(spu.getId()); //获取通用规格参数 Map&lt;Long, String&gt; genericSpec = JsonUtils.toMap(spuDetail.getGenericSpec(), Long.class, String.class); //获取特有规格参数 Map&lt;Long, List&lt;String&gt;&gt; specialSpec = JsonUtils.nativeRead(spuDetail.getSpecialSpec(), new TypeReference&lt;Map&lt;Long, List&lt;String&gt;&gt;&gt;() &#123; &#125;); //规格参数,key是规格参数的名字,值是规格参数的值 Map&lt;String,Object&gt; specs=new HashMap&lt;&gt;(); for (SpecParam specParam : specParams) &#123; //规格参数名称 String key = specParam.getName(); //规格参数的值 Object value=\"\"; //判断是否为通用规格 if (specParam.getGeneric())&#123; value=genericSpec.get(specParam.getId()); //判断是否数值类型 if (specParam.getNumeric())&#123; //处理成段 value = chooseSegment(value.toString(), specParam); &#125; &#125;else&#123; value=specialSpec.get(specParam.getId()); &#125; //存入map specs.put(key,value); &#125; //构建goods对象 Goods goods = new Goods(); goods.setBrandId(spu.getBrandId()); goods.setCid1(spu.getCid1()); goods.setCid2(spu.getCid2()); goods.setCid3(spu.getCid3()); goods.setCreateTime(spu.getCreateTime()); goods.setId(spu.getId()); goods.setAll(all); //搜索字段,包含标题,分类.品牌,规格等 goods.setPrice(priceList); // 所有sku的价格合集 goods.setSkus(JsonUtils.toString(skus)); //所有sku集合的json格式 goods.setSpecs(specs); //所有可搜索的规格参数 goods.setSubTitle(spu.getSubTitle()); return goods; &#125; private String chooseSegment(String value, SpecParam p) &#123; double val = NumberUtils.toDouble(value); String result = \"其它\"; // 保存数值段 for (String segment : p.getSegments().split(\",\")) &#123; String[] segs = segment.split(\"-\"); // 获取数值范围 double begin = NumberUtils.toDouble(segs[0]); double end = Double.MAX_VALUE; if(segs.length == 2)&#123; end = NumberUtils.toDouble(segs[1]); &#125; // 判断是否在范围内 if(val &gt;= begin &amp;&amp; val &lt; end)&#123; if(segs.length == 1)&#123; result = segs[0] + p.getUnit() + \"以上\"; &#125;else if(begin == 0)&#123; result = segs[1] + p.getUnit() + \"以下\"; &#125;else&#123; result = segment + p.getUnit(); &#125; break; &#125; &#125; return result; &#125; public SearchResult search(SearchRequest searchRequest) &#123; int page=searchRequest.getPage()-1; int size=searchRequest.getSize(); //创建查询构建器 NativeSearchQueryBuilder queryBuilder=new NativeSearchQueryBuilder(); //结果过滤 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;\"id\",\"skus\",\"subTitle\"&#125;, null)); //分页 queryBuilder.withPageable(PageRequest.of(page,size)); //排序 String sortBy = searchRequest.getSortBy(); Boolean desc = searchRequest.getDescending(); if (StringUtils.isNotBlank(sortBy))&#123; queryBuilder.withSort(SortBuilders.fieldSort(sortBy).order(desc ? SortOrder.DESC : SortOrder.ASC)); &#125; //搜索条件 QueryBuilder basicQuery = buildBasicQuery(searchRequest); queryBuilder.withQuery(basicQuery); //聚合分类和品牌 //聚合分类 String categoryAggName=\"category_agg\"; queryBuilder.addAggregation(AggregationBuilders.terms(categoryAggName).field(\"cid3\")); //聚合品牌 String brandAggName=\"brand_agg\"; queryBuilder.addAggregation(AggregationBuilders.terms(brandAggName).field(\"brandId\")); //查询 AggregatedPage&lt;Goods&gt; result = template.queryForPage(queryBuilder.build(),Goods.class); //解析结果 //解析分页结果 long totalElements = result.getTotalElements(); Long totalPages= (totalElements + searchRequest.getSize() - 1) / searchRequest.getSize(); List&lt;Goods&gt; content = result.getContent(); //解析聚合结果 Aggregations aggs = result.getAggregations(); List&lt;Category&gt; categories=parseCategoryAgg(aggs.get(categoryAggName)); List&lt;Brand&gt; brands=parseBrandAgg(aggs.get(brandAggName)); //规格参数聚合 List&lt;Map&lt;String,Object&gt;&gt; specs=new ArrayList&lt;&gt;(); if (categories!=null&amp;&amp;categories.size()==1)&#123; specs=buildSpecificationAgg(categories.get(0).getId(),basicQuery); &#125; return new SearchResult(totalElements,totalPages,content,categories,brands,specs); &#125; private QueryBuilder buildBasicQuery(SearchRequest searchRequest) &#123; //创建布尔查询 BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery(); //查询条件 queryBuilder.must(QueryBuilders.matchQuery(\"all\",searchRequest.getKey())); //过滤条件 Map&lt;String, String&gt; map = searchRequest.getFilter(); for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; String key = entry.getKey(); //处理key if (!\"cid3\".equals(key)&amp;&amp;!\"brandId\".equals(key))&#123; key=\"specs.\"+key+\".keyword\"; &#125; String value = entry.getValue(); queryBuilder.filter(QueryBuilders.termQuery(key,value)); &#125; return queryBuilder; &#125; private List&lt;Map&lt;String, Object&gt;&gt; buildSpecificationAgg(Long cid, QueryBuilder basicQuery) &#123; List&lt;Map&lt;String,Object&gt;&gt; specs=new ArrayList&lt;&gt;(); //查询需要聚合的规格参数 List&lt;SpecParam&gt; specParams = specificationClient.queryParamList(null, cid, true); //聚合 NativeSearchQueryBuilder queryBuilder=new NativeSearchQueryBuilder(); //带上查询条件 queryBuilder.withQuery(basicQuery); //聚合 for (SpecParam specParam : specParams) &#123; String name = specParam.getName(); queryBuilder.addAggregation(AggregationBuilders.terms(name).field(\"specs.\"+name+\".keyword\")); &#125; //获取结果 AggregatedPage&lt;Goods&gt; result = template.queryForPage(queryBuilder.build(), Goods.class); //解析结果 Aggregations aggs = result.getAggregations(); for (SpecParam specParam : specParams) &#123; //规格参数名称 String name = specParam.getName(); StringTerms terms= aggs.get(name); //准备map Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); map.put(\"k\",name); map.put(\"options\",terms.getBuckets().stream().map(b -&gt; b.getKeyAsString()).collect(Collectors.toList())); specs.add(map); &#125; return specs; &#125; private List&lt;Brand&gt; parseBrandAgg(LongTerms terms) &#123; try &#123; List&lt;Long&gt; ids = terms.getBuckets().stream().map(b -&gt; b.getKeyAsNumber().longValue()).collect(Collectors.toList()); List&lt;Brand&gt; brands = brandClient.queryBrandByIds(ids); return brands; &#125; catch (Exception e) &#123; log.error(\"[搜索微服务]\",e); return null; &#125; &#125; private List&lt;Category&gt; parseCategoryAgg(LongTerms terms) &#123; try &#123; List&lt;Long&gt; ids = terms.getBuckets().stream().map(c -&gt; c.getKeyAsNumber().longValue()).collect(Collectors.toList()); List&lt;Category&gt; categories = categoryClient.queryCategoryByIds(ids); return categories; &#125; catch (Exception e) &#123; return null; &#125; &#125;&#125; 2.3 页面渲染数据3.生成规格参数过滤3.1 谋而后动有四个问题需要先思考清楚： 什么时候显示规格参数过滤？ 如何知道哪些规格需要过滤？ 要过滤的参数，其可选值是如何获取的？ 规格过滤的可选值，其数据格式怎样的？ 什么情况下显示有关规格参数的过滤？ 如果用户尚未选择商品分类，或者聚合得到的分类数大于1，那么就没必要进行规格参数的聚合。因为不同分类的商品，其规格是不同的。 因此，我们在后台需要对聚合得到的商品分类数量进行判断，如果等于1，我们才继续进行规格参数的聚合。 如何知道哪些规格需要过滤？ 我们不能把数据库中的所有规格参数都拿来过滤。因为并不是所有的规格参数都可以用来过滤，参数的值是不确定的。 值的庆幸的是，我们在设计规格参数时，已经标记了某些规格可搜索，某些不可搜索。 因此，一旦商品分类确定，我们就可以根据商品分类查询到其对应的规格，从而知道哪些规格要进行搜索。 要过滤的参数，其可选值是如何获取的？ 虽然数据库中有所有的规格参数，但是不能把一切数据都用来供用户选择。 与商品分类和品牌一样，应该是从用户搜索得到的结果中聚合，得到与结果品牌的规格参数可选值。 规格过滤的可选值，其数据格式怎样的？ 我们之前存储时已经将数据分段，恰好符合这里的需求 3.2 需求实现总结一下，应该是以下几步： 1）用户搜索得到商品，并聚合出商品分类 2）判断分类数量是否等于1，如果是则进行规格参数聚合 3）先根据分类，查找可以用来搜索的规格 4）对规格参数进行聚合 5）将规格参数聚合结果整理后返回 在java中我们用List&lt;Map&lt;String, String&gt;&gt;来表示。 123456789101112131415161718@Datapublic class SearchResult extends PageResult&lt;Goods&gt; &#123; private List&lt;Category&gt; categories;// 分类过滤条件 private List&lt;Brand&gt; brands; // 品牌过滤条件 private List&lt;Map&lt;String,Object&gt;&gt; specs; // 规格参数过滤条件 public SearchResult() &#123; &#125; public SearchResult(Long total, Long totalPage, List&lt;Goods&gt; items, List&lt;Category&gt; categories, List&lt;Brand&gt; brands, List&lt;Map&lt;String, Object&gt;&gt; specs) &#123; super(total, totalPage, items); this.categories = categories; this.brands = brands; this.specs = specs; &#125;&#125; 最终的完整代码: 同上searchService 3.3 页面渲染4.过滤条件的筛选当我们点击页面的过滤项，要做哪些事情？ 把过滤条件保存在search对象中（watch监控到search变化后就会发送到后台） 在页面顶部展示已选择的过滤项 把商品分类展示到顶部面包屑 4.1 后台添加过滤条件我们需要在请求类：SearchRequest中添加属性，接收过滤属性。过滤属性都是键值对格式，但是key不确定，所以用一个map来接收即可。 123456789private Map&lt;String,String&gt; filter;public Map&lt;String, String&gt; getFilter() &#123; return filter;&#125;public void setFilter(Map&lt;String, String&gt; filter) &#123; this.filter = filter;&#125; 4.2 改造searchService5.页面展示选择的过滤项5.1 商品分类面包屑当用户选择一个商品分类以后，我们应该在过滤模块的上方展示一个面包屑，把三级商品分类都显示出来。 用户选择的商品分类就存放在search.filter中，但是里面只有第三级分类的id：cid3 我们需要根据它查询出所有三级分类的id及名称 5.1.1 提供查询分类接口我们在商品微服务中提供一个根据三级分类id查询1~3级分类集合的方法： Controller 12345678910111213/** * 根据3级分类id，查询1~3级的分类 * @param id * @return */@GetMapping(\"all/level\")public ResponseEntity&lt;List&lt;Category&gt;&gt; queryAllByCid3(@RequestParam(\"id\") Long id)&#123; List&lt;Category&gt; list = this.categoryService.queryAllByCid3(id); if (list == null || list.size() &lt; 1) &#123; return new ResponseEntity&lt;&gt;(HttpStatus.NOT_FOUND); &#125; return ResponseEntity.ok(list);&#125; Service 123456public List&lt;Category&gt; queryAllByCid3(Long id) &#123; Category c3 = this.categoryMapper.selectByPrimaryKey(id); Category c2 = this.categoryMapper.selectByPrimaryKey(c3.getParentId()); Category c1 = this.categoryMapper.selectByPrimaryKey(c2.getParentId()); return Arrays.asList(c1,c2,c3);&#125; 5.1.2 页面展示面包屑后台提供了接口，下面的问题是，我们在哪里去查询接口？ 大家首先想到的肯定是当用户点击以后。 但是我们思考一下：用户点击以后，就会重新发起请求，页面刷新，那么你渲染的结果就没了。 因此，应该是在页面重新加载完毕后，此时因为过滤条件中加入了商品分类的条件，所以查询的结果中只有1个分类。 我们判断商品分类是否只有1个，如果是，则查询三级商品分类，添加到面包屑即可。 123456//初始化商品分类过滤参数 if (resp.data.categories.length === 1) &#123; //如果只有1个,那么就查询三级商品分类,展示到面包屑 ly.http.get(\"/item/category/all/level?id=\"+resp.data.categories[0].id) .then(resp =&gt; this.breads=resp.data); &#125; 渲染： 123456789&lt;div class=\"bread\"&gt; &lt;!--面包屑--&gt; &lt;ul class=\"fl sui-breadcrumb\"&gt; &lt;li&gt;&lt;span&gt;全部结果:&lt;/span&gt;&lt;/li&gt; &lt;li v-for=\"(c,i) in breads\" :key=\"i\"&gt; &lt;a href=\"#\" v-if=\"i&lt;2\"&gt;&#123;&#123;c.name&#125;&#125;&lt;/a&gt; &lt;span v-else&gt;&#123;&#123;c.name&#125;&#125;&lt;/span&gt; &lt;/li&gt; &lt;/ul&gt; 5.2 其它过滤项在页面展示用户已选择的过滤项 所有已选择过滤项都保存在search.filter中，因此在页面遍历并展示即可 基本有四类数据： 商品分类：这个不需要展示，分类展示在面包屑位置 品牌：这个要展示，但是其key和值不合适，我们不能显示一个id在页面。需要找到其name值 数值类型规格：这个展示的时候，需要把单位查询出来 非数值类型规格：这个直接展示其值即可 取消对应条件的过滤。 思路非常简单： 给小叉绑定点击事件 点击后把过滤项从search.filter中移除，页面会自动刷新，OK 1234567&lt;!--已选择过滤项--&gt;&lt;ul class=\"tags-choose\"&gt; &lt;li class=\"tag\" v-for=\"(v,k) in search.filter\" :key=\"k\"&gt; &#123;&#123;k==='brandId' ? '品牌':k&#125;&#125;:&lt;span style=\"color: red\" v-text=\"findValue(k,v)\"&gt;&lt;/span&gt; &lt;i class=\"sui-icon icon-tb-close\" @click=\"deleteFilter(k)\"&gt;&lt;/i&gt; &lt;/li&gt;&lt;/ul&gt; 判断如果 k === &#39;cid3&#39;说明是商品分类，直接忽略 判断k === &#39;brandId&#39;说明是品牌，页面显示品牌，其它规格则直接显示k的值 值的处理比较复杂，我们用一个方法getFilterValue(k,v)来处理，调用时把k和v都传递 方法内部： 12345678910111213findValue(k,v)&#123; if (!this.filters) &#123; return; &#125; if (k !== 'brandId') return v; return this.filters.find(f=&gt;f.k ==='brandId').options[0].name;&#125;,deleteFilter(k)&#123; const &#123;... obj&#125;=this.search.filter; delete obj[k]; //添加到search.filter中 this.search.filter=obj;&#125; 5.3 隐藏已经选择的过滤项实现了已选择过滤项的展示，但是你会发现一个问题：已经选择的过滤项，在过滤列表中依然存在： 已经选择的过滤项，应该从列表中移除。 编写一个计算属性，把filters中的 已经被选择的key过滤掉： 12345678computed:&#123; remainFilter()&#123; //获取已选择的项的key const keys=Object.keys(this.search.filter); //完成对已选择过滤项的过滤 return this.filters.filter(f=&gt;!keys.includes(f.k)&amp;&amp;f.options.length&gt;1) &#125; &#125;, 然后页面不再直接遍历filters，而是遍历remainFilter 完整的java script 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141&lt;script type=\"text/javascript\"&gt; var vm = new Vue(&#123; el: \"#searchApp\", data: &#123; search:&#123;&#125;, goodsList:[], //接收搜索得到的结果 total:0, totalPage:0, selectedSku:&#123;&#125;, ly, filters:[], //过滤项 showMore:false , //展示更多 breads:\"\" //面包屑 &#125;, created()&#123; // 判断是否有请求参数 if(!location.search)&#123; return; &#125; // 将请求参数转为对象 const search = ly.parse(location.search.substring(1)); search.page=search.page ? parseInt(search.page):1; // 对排序进行初始化,默认为\"\",代表不排序 search.sortBy=search.sortBy||\"\"; // 对排序方式初始化,转为布尔值 search.descending=search.descending===true||false; search.filter=search.filter ? search.filter:&#123;&#125;; //初始化过滤条件 // 记录在data的search对象中 this.search = search; // 发起请求，根据条件搜索 this.loadData(); &#125;, watch:&#123; search:&#123; deep: true, handler(val,oldVal)&#123; if (!oldVal || !oldVal.key) &#123; return; &#125; // this.loadData(); //把请求参数写到url中 location.search=\"?\"+ly.stringify(this.search); &#125; &#125; &#125;, methods: &#123; loadData()&#123; // ly.http.post(\"/search/page\", ly.stringify(this.search)).then(resp=&gt;&#123; ly.http.post(\"/search/page\", this.search).then(resp=&gt;&#123; //保存分页结果 this.total=resp.data.total; this.totalPage=resp.data.totalPage; //保存当前页商品 resp.data.items.forEach(goods=&gt;&#123; //转换skus:把字符串转变为对象 goods.skus=JSON.parse(goods.skus); //初始化被选中的sku goods.selectedSku=goods.skus[0]; &#125;) this.goodsList=resp.data.items; //初始化商品分类过滤参数 if (resp.data.categories.length === 1) &#123; //如果只有1个,那么就查询三级商品分类,展示到面包屑 ly.http.get(\"/item/category/all/level?id=\"+resp.data.categories[0].id) .then(resp =&gt; this.breads=resp.data); &#125; //获取聚合结果,形成过滤项 //商品分类 this.filters.push(&#123; k:\"cid3\", options: resp.data.categories &#125;); //商品品牌 this.filters.push(&#123; k:\"brandId\", options: resp.data.brands &#125;); //其他规格 resp.data.specs.forEach(spec=&gt;this.filters.push(spec)); &#125;).catch(error =&gt;&#123; &#125;); &#125;, index(i)&#123; if(this.search.page &lt;= 3 || this.totalPage &lt;= 5)&#123; // 如果当前页小于等于3或者总页数小于等于5 return i; &#125; else if(this.search.page &gt; 3) &#123; // 如果当前页大于3 return this.search.page - 3 + i; &#125; else &#123; return this.totalPage - 5 + i; &#125; &#125;, prevPage()&#123; if(this.search.page &gt; 1)&#123; this.search.page-- &#125; &#125;, nextPage()&#123; if(this.search.page &lt; this.totalPage)&#123; this.search.page++ &#125; &#125;, selectFilter(key,option)&#123; const &#123;... obj&#125;=this.search.filter; obj[key]=option //添加到search.filter中 this.search.filter=obj; &#125;, findValue(k,v)&#123; if (!this.filters) &#123; return; &#125; if (k !== 'brandId') return v; return this.filters.find(f=&gt;f.k ==='brandId').options[0].name; &#125;, deleteFilter(k)&#123; const &#123;... obj&#125;=this.search.filter; delete obj[k]; //添加到search.filter中 this.search.filter=obj; &#125; &#125;, computed:&#123; remainFilter()&#123; //获取已选择的项的key const keys=Object.keys(this.search.filter); //完成对已选择过滤项的过滤 return this.filters.filter(f=&gt;!keys.includes(f.k)&amp;&amp;f.options.length&gt;1) &#125; &#125;, components:&#123; lyTop: () =&gt; import(\"./js/pages/top.js\") &#125; &#125;);&lt;/script&gt; 6.优化搜索系统需要优化的点： 查询规格参数部分可以添加缓存 聚合计算interval变化频率极低，所以可以设计为定时任务计算（周期为天），然后缓存起来。 elasticsearch本身有查询缓存，可以不进行优化 商品图片应该采用缩略图，减少流量，提高页面加载速度 图片采用延迟加载 图片还可以采用CDN服务器 sku信息应该在页面异步加载，而不是放到索引库","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(八.RabbitMQ)","slug":"微服务项目总结(八.RabbitMQ)","date":"2021-05-08T13:19:59.235Z","updated":"2020-04-29T02:44:38.062Z","comments":true,"path":"33993/","link":"","permalink":"http://tonymua.top/33993/","excerpt":"1.RabbitMQ1.1 搜索与商品服务的问题目前我们已经完成了商品详情和搜索系统的开发。我们思考一下，是否存在问题？ 商品的原始数据保存在数据库中，增删改查都在数据库中完成。 搜索服务数据来源是索引库，如果数据库商品发生变化，索引库数据不能及时更新。 商品详情做了页面静态化，静态页面数据也不会随着数据库商品发生变化。 如果我们在后台修改了商品的价格，搜索页面和商品详情页显示的依然是旧的价格，这样显然不对。该如何解决？ 解决这个问题：消息队列 1.2 消息队列（MQ）1.2.1 什么是消息队列","text":"1.RabbitMQ1.1 搜索与商品服务的问题目前我们已经完成了商品详情和搜索系统的开发。我们思考一下，是否存在问题？ 商品的原始数据保存在数据库中，增删改查都在数据库中完成。 搜索服务数据来源是索引库，如果数据库商品发生变化，索引库数据不能及时更新。 商品详情做了页面静态化，静态页面数据也不会随着数据库商品发生变化。 如果我们在后台修改了商品的价格，搜索页面和商品详情页显示的依然是旧的价格，这样显然不对。该如何解决？ 解决这个问题：消息队列 1.2 消息队列（MQ）1.2.1 什么是消息队列 消息队列，即MQ，Message Queue。 消息队列是典型的：生产者、消费者模型。生产者不断向消息队列中生产消息，消费者不断的从队列中获取消息。因为消息的生产和消费都是异步的，而且只关心消息的发送和接收，没有业务逻辑的侵入，这样就实现了生产者和消费者的解耦。 结合前面所说的问题： 商品服务对商品增删改以后，无需去操作索引库或静态页面，只是发送一条消息，也不关心消息被谁接收。 搜索服务和静态页面服务接收消息，分别去处理索引库和静态页面。 如果以后有其它系统也依赖商品服务的数据，同样监听消息即可，商品服务无需任何代码修改。 1.2.2 AMQP和JMSMQ是消息通信的模型，并不是具体实现。现在实现MQ的有两种主流方式：AMQP、JMS。 两者间的区别和联系： JMS是定义了统一的接口，来对消息操作进行统一；AMQP是通过规定协议来统一数据交互的格式 JMS限定了必须使用Java语言；AMQP只是协议，不规定实现方式，因此是跨语言的。 JMS规定了两种消息模型；而AMQP的消息模型更加丰富 1.2.3 常见MQ产品 ActiveMQ：基于JMS RabbitMQ：基于AMQP协议，erlang语言开发，稳定性好 RocketMQ：基于JMS，阿里巴巴产品，目前交由Apache基金会 Kafka：分布式消息系统，高吞吐量 1.2.4 RabbitMQRabbitMQ是基于AMQP的一款消息管理系统 官网： http://www.rabbitmq.com/ 官方教程：http://www.rabbitmq.com/getstarted.html ​ RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而集群和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。 2.五种消息模型RabbitMQ提供了6种消息模型，但是第6种其实是RPC，并不是MQ，因此不予学习。那么也就剩下5种。 但是其实3、4、5这三种都属于订阅模型，只不过进行路由的方式不同。 2.1 订阅模型-TopicTopic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！ Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则： 123`#`：匹配一个或多个词`*`：匹配不多不少恰好1个词 举例： 123`audit.#`：能够匹配`audit.irs.corporate` 或者 `audit.irs``audit.*`：只能匹配`audit.irs` 在这个例子中，我们将发送所有描述动物的消息。消息将使用由三个字（两个点）组成的routing key发送。路由关键字中的第一个单词将描述速度，第二个颜色和第三个种类：“..”。 我们创建了三个绑定：Q1绑定了绑定键“* .orange.”，Q2绑定了“.*.rabbit”和“lazy.＃”。 Q1匹配所有的橙色动物。 Q2匹配关于兔子以及懒惰动物的消息。 2.1.1 生产者使用topic类型的Exchange，发送消息的routing key有3种： item.isnert、item.update、item.delete： 1234567891011121314151617181920public class Send &#123; private final static String EXCHANGE_NAME = \"topic_exchange_test\"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明exchange，指定类型为topic channel.exchangeDeclare(EXCHANGE_NAME, \"topic\"); // 消息内容 String message = \"新增商品 : id = 1001\"; // 发送消息，并且指定routing key 为：insert ,代表新增商品 channel.basicPublish(EXCHANGE_NAME, \"item.insert\", null, message.getBytes()); System.out.println(\" [商品服务：] Sent '\" + message + \"'\"); channel.close(); connection.close(); &#125;&#125; 2.1.2 消费者1我们此处假设消费者1只接收两种类型的消息：更新商品和删除商品 12345678910111213141516171819202122232425262728293031public class Recv &#123; private final static String QUEUE_NAME = \"topic_exchange_queue_1\"; private final static String EXCHANGE_NAME = \"topic_exchange_test\"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。需要 update、delete channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \"item.update\"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \"item.delete\"); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(\" [消费者1] received : \" + msg + \"!\"); &#125; &#125;; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 2.1.3 消费者2我们此处假设消费者2接收所有类型的消息：新增商品，更新商品和删除商品。 123456789101112131415161718192021222324252627282930313233/** * 消费者2 */public class Recv2 &#123; private final static String QUEUE_NAME = \"topic_exchange_queue_2\"; private final static String EXCHANGE_NAME = \"topic_exchange_test\"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。订阅 insert、update、delete channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \"item.*\"); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(\" [消费者2] received : \" + msg + \"!\"); &#125; &#125;; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125; 2.3 消息丢失 解决消息丢失 ack(消息确认) 持久化(交换机持久化, 队列持久化, 消息持久化) 生产者确认 发送消息前,将消息持久到数据库,并记消息状态(可靠消息服务) 3.项目改造接下来，我们就改造项目，实现搜索服务、商品静态页的数据同步。 3.1 思路分析 发送方：商品微服务 什么时候发？ 当商品服务对商品进行写操作：增、删、改的时候，需要发送一条消息，通知其它服务。 发送什么内容？ 对商品的增删改时其它服务可能需要新的商品数据，但是如果消息内容中包含全部商品信息，数据量太大，而且并不是每个服务都需要全部的信息。因此我们只发送商品id，其它服务可以根据id查询自己需要的信息。 接收方：搜索微服务、静态页微服务 接收消息后如何处理？ 搜索微服务： 增/改：添加新的数据到索引库 删：删除索引库数据 静态页微服务： 增/改：创建新的静态页 删：删除原来的静态页 3.2 商品服务发送消息我们先在商品微服务leyou-item-service中实现发送消息。 3.2.1 引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 3.2.2 配置文件我们在application.yml中添加一些有关RabbitMQ的配置： 1234567891011121314spring: rabbitmq: host: 127.0.0.1 username: leyou password: leyou virtual-host: /leyou template: retry: enabled: true initial-interval: 10000ms max-interval: 30000ms multiplier: 2 exchange: leyou.item.exchange publisher-confirms: true template：有关AmqpTemplate的配置 exchange：缺省的交换机名称，此处配置后，发送消息如果不指定交换机就会使用这个 publisher-confirms：生产者确认机制，确保消息会正确发送，如果发送失败会有错误回执，从而触发重试 3.2.3 改造GoodsService在GoodsService中封装一个发送消息到mq的方法：（需要注入AmqpTemplate模板） 12345678private void sendMessage(Long spuId, String type)&#123; // 发送消息 try &#123; this.amqpTemplate.convertAndSend(\"item.\" + type, spuId); &#125; catch (Exception e) &#123; logger.error(\"&#123;&#125;商品消息发送异常，商品id：&#123;&#125;\", type, spuId, e); &#125;&#125; 这里没有指定交换机，因此默认发送到了配置中的：leyou.item.exchange 然后在新增, 修改的时候调用： 1sendMessage(spu.getId(),\"update\") 3.3 搜索服务接收消息搜索服务接收到消息后要做的事情： 增：添加新的数据到索引库 删：删除索引库数据 改：修改索引库数据 因为索引库的新增和修改方法是合二为一的，因此我们可以将这两类消息一同处理，删除另外处理。 3.3.1 引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 3.3.2 添加配置123456spring: rabbitmq: host: 127.0.0.1 username: leyou password: leyou virtual-host: /leyou 这里只是接收消息而不发送，所以不用配置template相关内容。 3.3.3 编写监听器ItemListener 1234567891011121314151617181920212223242526272829303132@Componentpublic class ItemListener &#123; @Autowired private SearchService searchService; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"search.item.delete.queue\",durable = \"true\"), exchange = @Exchange(name = \"leyou.item.exchange\",type = ExchangeTypes.TOPIC), key = &#123;\"item.insert\",\"item.update\"&#125; )) public void listenerInsertOrUpdate(Long spuId)&#123; if (spuId==null)&#123; return; &#125; //处理消息,对索引库进行新增或者修改 searchService.createOrUpdateIndex(spuId); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"search.item.insert.queue\",durable = \"true\"), exchange = @Exchange(name = \"leyou.item.exchange\",type = ExchangeTypes.TOPIC), key = &#123;\"item.delete\"&#125; )) public void listenerDelete(Long spuId)&#123; if (spuId==null)&#123; return; &#125; //处理消息,对索引库进行新增或者修改 searchService.deleteIndex(spuId); &#125;&#125; 3.3.4 编写创建和删除索引方法这里因为要创建和删除索引，我们需要在SearchService中拓展两个方法，创建和删除索引： SearchService 123456789101112public void createOrUpdateIndex(Long spuId) &#123; //查询spu Spu spu = goodsClient.querySpuById(spuId); //构建Goods Goods goods = buildGoods(spu); //存入索引库 goodsRepository.save(goods);&#125;public void deleteIndex(Long spuId) &#123; goodsRepository.deleteById(spuId);&#125; 3.4 静态页服务接收消息商品静态页服务接收到消息后的处理： 增：创建新的静态页 删：删除原来的静态页 改：创建新的静态页并覆盖原来的 不过，我们编写的创建静态页的方法也具备覆盖以前页面的功能，因此：增和改的消息可以放在一个方法中处理，删除消息放在另一个方法处理。 3.4.1 引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 3.4.2 添加配置123456spring: rabbitmq: host: 127.0.0.1 username: leyou password: leyou virtual-host: /leyou 这里只是接收消息而不发送，所以不用配置template相关内容。 3.4.3 编写监听器123456789101112131415161718192021222324252627282930@Componentpublic class ItemListener &#123; @Autowired private PageService pageService; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"page.item.insert.queue\",durable = \"true\"), exchange = @Exchange(name = \"leyou.item.exchange\",type = ExchangeTypes.TOPIC), key = &#123;\"item.insert\",\"item.update\"&#125; )) public void listenInsertOrUpdate(Long spuId)&#123; if (spuId==null)&#123; return; &#125; //处理消息,创建静态页 pageService.createHtml(spuId); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"page.item.delete.queue\",durable = \"true\"), exchange = @Exchange(name = \"leyou.item.exchange\",type = ExchangeTypes.TOPIC), key = &#123;\"item.delete\"&#125; )) public void listenDelete(Long spuId)&#123; if (spuId==null)&#123; return; &#125; //处理消息,删除静态页 pageService.deleteHtml(spuId); &#125; 3.4.4 添加删除页面方法PageService 1234567 public void deleteHtml(Long spuId) &#123; File dest = new File(\"E:\\\\tools\\\\nginx-1.14.0\\\\html\\\\item\", spuId + \".html\"); if (dest.exists())&#123; dest.delete(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(五.搜索微服务(一))","slug":"微服务项目总结(五.搜索微服务(一))","date":"2021-05-08T13:19:59.233Z","updated":"2020-04-29T02:44:38.118Z","comments":true,"path":"54042/","link":"","permalink":"http://tonymua.top/54042/","excerpt":"1.索引库数据导入1.1 创建搜索服务Pom文件：","text":"1.索引库数据导入1.1 创建搜索服务Pom文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;leyou&lt;/artifactId&gt; &lt;groupId&gt;com.leyou&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-search&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- elasticsearch --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- eureka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- feign --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-item-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml： 123456789101112131415161718192021222324server: port: 8083spring: application: name: search-service jackson: default-property-inclusion: non_null # 配置json处理时忽略空值 data: elasticsearch: cluster-name: elasticsearch cluster-nodes: 127.0.0.1:9300 datasource: url: jdbc:mysql://localhost:3306/leyou username: root password: 547717253eureka: client: service-url: defaultZone: http://127.0.0.1:8080/eureka instance: lease-renewal-interval-in-seconds: 5 # 每隔5秒发送一次心跳 prefer-ip-address: true ip-address: 127.0.0.1# instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; 启动类： 12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class LySearchApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LySearchApplication.class,args); &#125;&#125; 1.2 索引库数据格式分析1.2.1 以结果为导向每一个搜索结果都有至少1个商品，当我们选择大图下方的小图，商品会跟着变化。因此，搜索的结果是SPU，即多个SKU的集合。既然搜索的结果是SPU，那么我们索引库中存储的应该也是SPU，但是却需要包含SKU的信息。 1.2.2 需要什么数据直观能看到的：图片、价格、标题、副标题 暗藏的数据：spu的id，sku的id 过滤条件也都需要存储到索引库中，包括： 商品分类、品牌、可用来搜索的规格参数等 综上所述，我们需要的数据格式有： spuId、SkuId、商品分类id、品牌id、图片、价格、商品的创建时间、sku信息集、可搜索的规格参 1.2.3 最终的数据结构创建一个类，封装要保存到索引库的数据，并设置映射属性： 12345678910111213141516171819@Data@Document(indexName = \"goods\", type = \"docs\", shards = 1, replicas = 0)public class Goods &#123; @Id private Long id; // spuId @Field(type = FieldType.text, analyzer = \"ik_max_word\") private String all; // 所有需要被搜索的信息，包含标题，分类，甚至品牌 @Field(type = FieldType.keyword, index = false) private String subTitle;// 卖点 private Long brandId;// 品牌id private Long cid1;// 1级分类id private Long cid2;// 2级分类id private Long cid3;// 3级分类id private Date createTime;// 创建时间 private List&lt;Long&gt; price;// 价格 @Field(type = FieldType.keyword, index = false) private String skus;// sku信息的json结构 private Map&lt;String, Object&gt; specs;// 可搜索的规格参数，key是参数名，值是参数值&#125; 一些特殊字段解释： all：用来进行全文检索的字段，里面包含标题、商品分类信息 price：价格数组，是所有sku的价格集合。方便根据价格进行筛选过滤 skus：用于页面展示的sku信息，不索引，不搜索。包含skuId、image、price、title字段 specs：所有规格参数的集合。key是参数名，值是参数值。 例如：我们在specs中存储 内存：4G,6G，颜色为红色，转为json就是： 123456&#123; \"specs\":&#123; \"内存\":[4G,6G], \"颜色\":\"红色\" &#125;&#125; 当存储到索引库时，elasticsearch会处理为两个字段： specs.内存：[4G,6G] specs.颜色：红色 另外， 对于字符串类型，还会额外存储一个字段，这个字段不会分词，用作聚合。 specs.颜色.keyword：红色 1.3 商品微服务提供接口索引库中的数据来自于数据库，我们不能直接去查询商品的数据库，因为真实开发中，每个微服务都是相互独立的，包括数据库也是一样。所以我们只能调用商品微服务提供的接口服务。 先思考我们需要的数据： SPU信息 SKU信息 SPU的详情 商品分类名称（拼接all字段） 再思考我们需要哪些服务： 第一：分批查询spu的服务，已经写过。 第二：根据spuId查询sku的服务，已经写过 第三：根据spuId查询SpuDetail的服务，已经写过 第四：根据商品分类id，查询商品分类名称，没写过 第五：根据商品品牌id，查询商品的品牌，没写过 因此我们需要额外提供一个查询商品分类名称的接口。 1.3.1 商品分类名称查询CategoryController 1234@GetMapping(\"list/ids\")public ResponseEntity&lt;List&lt;Category&gt;&gt; queryNameByIds(@RequestParam(\"ids\")List&lt;Long&gt; ids)&#123; return ResponseEntity.ok(categoryService.queryNameByIds(ids));&#125; CategoryService 12345678 public List&lt;Category&gt; queryNameByIds(List&lt;Long&gt; ids)&#123; List&lt;Category&gt; list = categoryMapper.selectByIdList(ids); if (CollectionUtils.isEmpty(list))&#123; throw new LyException(ExceptionEnum.CATEGORY_NOT_FOND); &#125; return list; &#125;&#125; 1.3.2 商品品牌名称查询BrandController 12345 @GetMapping(\"&#123;id&#125;\") public ResponseEntity&lt;Brand&gt; queryNameById(@PathVariable(\"id\")Long id)&#123; return ResponseEntity.ok(brandService.queryNameById(id)); &#125;&#125; BrandService 1234567public Brand queryNameById(Long id)&#123; Brand brand = brandMapper.selectByPrimaryKey(id); if (brand==null)&#123; throw new LyException(ExceptionEnum.BRAND_NOT_FOND); &#125; return brand; &#125; 1.3.3 编写FeignClient 我们的服务提供方不仅提供实体类，还要提供api接口声明 调用方不用字自己编写接口方法声明，直接继承提供方给的Api接口即可， 第一步：服务的提供方在leyou-item-interface中提供API接口，并编写接口声明： 商品分类服务接口： 1234public interface CategoryApi &#123; @GetMapping(\"category/list/ids\") List&lt;Category&gt; queryNameByIds(@RequestParam(\"ids\")List&lt;Long&gt; ids);&#125; 商品服务接口，返回值不再使用ResponseEntity： 123456789101112131415public interface GoodsApi &#123; @GetMapping(\"spu/detail/&#123;id&#125;\") SpuDetail querySpuDetailById(@PathVariable(\"id\") Long id); @GetMapping(\"sku/list\") List&lt;Sku&gt; querySkuBySpuId(@RequestParam(\"id\") Long id); @GetMapping(\"spu/page\") PageResult&lt;Spu&gt; querySpuByPage( @RequestParam(value = \"page\", defaultValue = \"1\") Integer page, @RequestParam(value = \"rows\", defaultValue = \"5\") Integer rows, @RequestParam(value = \"saleable\", required = false) Boolean saleable, @RequestParam(value = \"key\", required = false) String key );&#125; BrandApi: 1234public interface BrandApi &#123; @GetMapping(\"brand/&#123;id&#125;\") Brand queryNameById(@PathVariable(\"id\")Long id);&#125; SpecificationApi: 12345678public interface SpecificationApi &#123; @GetMapping(\"spec/params\") List&lt;SpecParam&gt;queryParamList( @RequestParam(value = \"gid\",required = false) Long gid, @RequestParam(value = \"cid\",required = false)Long cid, @RequestParam(value = \"searching\",required = false)Boolean searching );&#125; 第二步：在调用方leyou-search中编写FeignClient，但不要写方法声明了，直接继承leyou-item-interface提供的api接口： 商品的FeignClient： 1234@FeignClient(\"item-service\")public interface GoodsClient extends GoodsApi &#123;&#125; 商品分类的FeignClient： 123@FeignClient(\"item-service\")public interface CategoryClient extends CategoryApi &#123;&#125; BrandClient: 123@FeignClient(\"item-service\")public interface BrandClient extends BrandApi &#123;&#125; SpecificationClient: 123@FeignClient(\"item-service\")public interface SpecificationClient extends SpecificationApi &#123;&#125; 1.3.4 测试创建测试类：Navigate-Test 测试代码： 12345678910111213141516@RunWith(SpringRunner.class)@SpringBootTest(classes = LySearchApplication.class)public class CategoryClientTest &#123; @Autowired private CategoryClient categoryClient; @Test public void queryNameByIds() &#123; List&lt;Category&gt; categories = categoryClient.queryNameByIds(Arrays.asList(1L, 2L, 3L)); Assert.assertEquals(3,categories.size()); for (Category category : categories) &#123; System.out.println(category); &#125; &#125;&#125; 1.4 导入数据导入数据只做一次,以后的更新删除等操作通过消息队列来操作索引库 1.4.1 创建GoodsRepository12public interface GoodsRepository extends ElasticsearchRepository&lt;Goods,Long&gt; &#123;&#125; 1.4.2 创建索引我们新建一个测试类，在里面进行数据的操作： 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest(classes = LySearchApplication.class)public class GoodsRepositoryTest &#123; @Autowired private GoodsRepository goodsRepository; @Autowired private ElasticsearchTemplate template; @Autowired private GoodsClient goodsClient; @Autowired private SearchService searchService; @Test public void testCreateIndex() &#123; template.createIndex(Goods.class); template.putMapping(Goods.class); &#125;&#125; 1.4.3 导入数据导入数据其实就是查询数据，然后把查询到的Spu转变为Goods来保存，因此我们先编写一个SearchService，然后在里面定义一个方法， 把Spu转为Goods SearchService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118@Servicepublic class SearchService &#123; @Autowired private CategoryClient categoryClient; @Autowired private GoodsClient goodsClient; @Autowired private BrandClient brandClient; @Autowired private SpecificationClient specificationClient; @Autowired private GoodsRepository goodsRepository; public Goods buildGoods(Spu spu)&#123; //查询分类 List&lt;Category&gt; categories = categoryClient.queryNameByIds(Arrays.asList(spu.getCid1(), spu.getCid2(), spu.getCid3())); List&lt;String&gt; names = categories.stream().map(Category::getName).collect(Collectors.toList()); //查询品牌 Brand brand = brandClient.queryNameById(spu.getBrandId()); //搜索字段 String all=spu.getTitle()+ StringUtils.join(names,\" \")+brand.getName(); //查询sku List&lt;Sku&gt; skuList = goodsClient.querySkuBySpuId(spu.getId()); //对sku进行处理 List&lt;Map&lt;String,Object&gt;&gt; skus=new ArrayList&lt;&gt;(); //价格集合 List&lt;Long&gt; priceList=new ArrayList&lt;&gt;(); for (Sku sku : skuList) &#123; Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); map.put(\"id\",sku.getId()); map.put(\"title\",sku.getTitle()); map.put(\"price\",sku.getPrice()); //取第一张图片 map.put(\"image\", StringUtils.substringBefore(sku.getImages(),\",\")); skus.add(map); //处理价格 priceList.add(sku.getPrice()); &#125; //sku的价格合集 //List&lt;Long&gt; prices = skuList.stream().map(Sku::getPrice).collect(Collectors.toList()); //查询规格参数 List&lt;SpecParam&gt; specParams = specificationClient.queryParamList(null, spu.getCid3(), true); //查询商品详情 SpuDetail spuDetail = goodsClient.querySpuDetailById(spu.getId()); //获取通用规格参数 Map&lt;Long, String&gt; genericSpec = JsonUtils.toMap(spuDetail.getGenericSpec(), Long.class, String.class); //获取特有规格参数 Map&lt;Long, List&lt;String&gt;&gt; specialSpec = JsonUtils.nativeRead(spuDetail.getSpecialSpec(), new TypeReference&lt;Map&lt;Long, List&lt;String&gt;&gt;&gt;() &#123; &#125;); //规格参数,key是规格参数的名字,值是规格参数的值 Map&lt;String,Object&gt; specs=new HashMap&lt;&gt;(); for (SpecParam specParam : specParams) &#123; //规格参数名称 String key = specParam.getName(); //规格参数的值 Object value=\"\"; //判断是否为通用规格 if (specParam.getGeneric())&#123; value=genericSpec.get(specParam.getId()); //判断是否数值类型 if (specParam.getNumeric())&#123; //处理成段 value = chooseSegment(value.toString(), specParam); &#125; &#125;else&#123; value=specialSpec.get(specParam.getId()); &#125; //存入map specs.put(key,value); &#125; //构建goods对象 Goods goods = new Goods(); goods.setBrandId(spu.getBrandId()); goods.setCid1(spu.getCid1()); goods.setCid2(spu.getCid2()); goods.setCid3(spu.getCid3()); goods.setCreateTime(spu.getCreateTime()); goods.setId(spu.getId()); goods.setAll(all); //搜索字段,包含标题,分类.品牌,规格等 goods.setPrice(priceList); // 所有sku的价格合集 goods.setSkus(JsonUtils.toString(skus)); //所有sku集合的json格式 goods.setSpecs(specs); //所有可搜索的规格参数 goods.setSubTitle(spu.getSubTitle()); return goods; &#125; private String chooseSegment(String value, SpecParam p) &#123; double val = NumberUtils.toDouble(value); String result = \"其它\"; // 保存数值段 for (String segment : p.getSegments().split(\",\")) &#123; String[] segs = segment.split(\"-\"); // 获取数值范围 double begin = NumberUtils.toDouble(segs[0]); double end = Double.MAX_VALUE; if(segs.length == 2)&#123; end = NumberUtils.toDouble(segs[1]); &#125; // 判断是否在范围内 if(val &gt;= begin &amp;&amp; val &lt; end)&#123; if(segs.length == 1)&#123; result = segs[0] + p.getUnit() + \"以上\"; &#125;else if(begin == 0)&#123; result = segs[1] + p.getUnit() + \"以下\"; &#125;else&#123; result = segment + p.getUnit(); &#125; break; &#125; &#125; return result; &#125; 因为过滤参数中有一类比较特殊，就是数值区间, 所以我们在存入时要进行处理 然后编写一个测试类，循环查询Spu，然后调用IndexService中的方法，把SPU变为Goods，然后写入索引库： 123456789101112131415161718192021@Testpublic void loadData() &#123; int page = 1; int rows = 50; int size=0; do &#123; //查询spu信息 PageResult&lt;Spu&gt; pageResult = goodsClient.querySpuByPage(page, rows, true, null); List&lt;Spu&gt; spuList = pageResult.getItems(); if (CollectionUtils.isEmpty(spuList))&#123; break; &#125; //构建成goods List&lt;Goods&gt; goodsList = spuList.stream().map(searchService::buildGoods).collect(Collectors.toList()); //构入索引库 goodsRepository.saveAll(goodsList); //翻页 page++; size = spuList.size(); &#125;while (size==50);&#125; 2.实现基本搜索2.1 后台提供搜索接口首先分析几个问题： 请求方式：Post 请求路径：/search/page，不过前面的/search应该是网关的映射路径，因此真实映射路径page，代表分页查询 请求参数：json格式，目前只有一个属性：key-搜索关键字，但是搜索结果页一定是带有分页查询的，所以将来肯定会有page属性，因此我们可以用一个对象来接收请求的json数据： 1234567891011121314151617181920212223242526272829303132public class SearchRequest &#123; private String key;// 搜索条件 private Integer page;// 当前页 private static final Integer DEFAULT_SIZE = 20;// 每页大小，不从页面接收，而是固定大小 private static final Integer DEFAULT_PAGE = 1;// 默认页 public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125; public Integer getPage() &#123; if(page == null)&#123; return DEFAULT_PAGE; &#125; // 获取页码时做一些校验，不能小于1 return Math.max(DEFAULT_PAGE, page); &#125; public void setPage(Integer page) &#123; this.page = page; &#125; public Integer getSize() &#123; return DEFAULT_SIZE; &#125;&#125; 返回结果：作为分页结果，一般都两个属性：当前页数据、总条数信息，我们可以使用之前定义的PageResult类 SearchController 1234567891011@RestController@RequestMappingpublic class SearchController &#123; @Autowired private SearchService searchService; @PostMapping(\"page\") public ResponseEntity&lt;PageResult&lt;Goods&gt;&gt; search(@RequestBody SearchRequest searchRequest)&#123; return ResponseEntity.ok(searchService.search(searchRequest)); &#125;&#125; 2.1.2 serviceSearchService 12345678910111213141516171819public PageResult&lt;Goods&gt; search(SearchRequest searchRequest) &#123; int page=searchRequest.getPage()-1; int size=searchRequest.getSize(); //创建查询构建器 NativeSearchQueryBuilder queryBuilder=new NativeSearchQueryBuilder(); //结果过滤 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;\"id\",\"skus\",\"subTitle\"&#125;, null)); //分页 queryBuilder.withPageable(PageRequest.of(page,size)); //过滤 queryBuilder.withQuery(QueryBuilders.matchQuery(\"all\",searchRequest.getKey())); //查询 Page&lt;Goods&gt; result = goodsRepository.search(queryBuilder.build()); //解析结果 long totalElements = result.getTotalElements(); Long totalPages= (totalElements + searchRequest.getSize() - 1) / searchRequest.getSize(); List&lt;Goods&gt; content = result.getContent(); return new PageResult&lt;&gt;(totalElements, totalPages,content);&#125; 2.2 测试数据查到后，但是因为我们只查询部分字段，所以结果json 数据中有很多null，这很不优雅。 解决办法很简单，在leyou-search的application.yml中添加一行配置，json处理时忽略空值： 123spring: jackson: default-property-inclusion: non_null # 配置json处理时忽略空值 3.排序3.1 页面搜索排序条件点击新品，应该按照商品创建时间排序，点击价格应该按照价格排序。因为我们没有统计销量和评价，这里咱们以新品和价格为例，进行讲解，做法是想通的。 排序需要知道两个内容： 排序的字段 排序的方式 因此，我们首先在search中记录这两个信息，因为created钩子函数会对search进行覆盖，因此我们在钩子函数中对这两个信息进行初始化即可： 1234// 对排序进行初始化,默认为\"\",代表不排序search.sortBy=search.sortBy||\"\";// 对排序方式初始化,转为布尔值search.descending=search.descending===\"true\"||false; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&lt;script type=\"text/javascript\"&gt; var vm = new Vue(&#123; el: \"#searchApp\", data: &#123; search:&#123;&#125;, goodsList:[], //接收搜索得到的结果 total:0, totalPage:0, selectedSku:&#123;&#125;, ly &#125;, created()&#123; // 判断是否有请求参数 if(!location.search)&#123; return; &#125; // 将请求参数转为对象 const search = ly.parse(location.search.substring(1)); search.page=search.page ? parseInt(search.page):1; // 对排序进行初始化,默认为\"\",代表不排序 search.sortBy=search.sortBy||\"\"; // 对排序方式初始化,转为布尔值 search.descending=search.descending===\"true\"||false; // 记录在data的search对象中 this.search = search; // 发起请求，根据条件搜索 this.loadData(); &#125;, watch:&#123; search:&#123; deep: true, handler(val,oldVal)&#123; if (!oldVal || !oldVal.key) &#123; return; &#125; // this.loadData(); //把请求参数写到url中 location.search=\"?\"+ly.stringify(this.search); &#125; &#125; &#125;, methods: &#123; loadData()&#123; // ly.http.post(\"/search/page\", ly.stringify(this.search)).then(resp=&gt;&#123; ly.http.post(\"/search/page\", this.search).then(resp=&gt;&#123; //保存分页结果 this.total=resp.data.total; this.totalPage=resp.data.totalPage; //保存当前页商品 resp.data.items.forEach(goods=&gt;&#123; //转换skus:把字符串转变为对象 goods.skus=JSON.parse(goods.skus); //初始化被选中的sku goods.selectedSku=goods.skus[0]; &#125;) this.goodsList=resp.data.items; &#125;).catch(error =&gt;&#123; &#125;); &#125;, index(i)&#123; if(this.search.page &lt;= 3 || this.totalPage &lt;= 5)&#123; // 如果当前页小于等于3或者总页数小于等于5 return i; &#125; else if(this.search.page &gt; 3) &#123; // 如果当前页大于3 return this.search.page - 3 + i; &#125; else &#123; return this.totalPage - 5 + i; &#125; &#125;, prevPage()&#123; if(this.search.page &gt; 1)&#123; this.search.page-- &#125; &#125;, nextPage()&#123; if(this.search.page &lt; this.totalPage)&#123; this.search.page++ &#125; &#125; &#125;, components:&#123; lyTop: () =&gt; import(\"./js/pages/top.js\") &#125; &#125;);&lt;/script&gt; 然后，在页面上给按钮绑定点击事件，修改sortBy和descending的值： 1234567891011121314151617181920&lt;ul class=\"sui-nav\"&gt; &lt;li :class=\"&#123;active:!search.sortBy&#125;\" @click=\"search.sortBy=''\"&gt; &lt;a href=\"#\"&gt;综合&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;销量&lt;/a&gt; &lt;/li&gt; &lt;li :class=\"&#123;active:search.sortBy==='createTime'&#125;\" @click=\"search.sortBy='createTime'\"&gt; &lt;a href=\"#\"&gt;新品&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;评价&lt;/a&gt; &lt;/li&gt; &lt;li :class=\"&#123;active:search.sortBy==='price'&#125;\" @click=\"search.sortBy='price'\"&gt; &lt;a href=\"#\"&gt;价格 &lt;v-icon v-show=\"search.descending\"&gt;arrow_drop_down&lt;/v-icon&gt; &lt;v-icon v-show=\"!search.descending\"&gt;arrow_drop_up&lt;/v-icon&gt; &lt;/a&gt; &lt;/li&gt;&lt;/ul&gt; 3.2 后台添加排序逻辑后台需要接收请求参数中的排序信息，然后在搜索中加入排序的逻辑。现在，我们的请求参数对象SearchRequest中，只有page、key两个字段。需要进行扩展： 然后在搜索业务逻辑中，添加排序条件：","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(二.品牌管理, FastDFS, 商品规格管理)","slug":"微服务项目总结(二.品牌管理, FastDFS, 商品规格管理)","date":"2021-05-08T13:19:59.232Z","updated":"2020-04-29T05:55:11.397Z","comments":true,"path":"43998/","link":"","permalink":"http://tonymua.top/43998/","excerpt":"1.新增品牌分析四个内容： 请求方式：刚才看到了是POST 请求路径：/brand 请求参数：brand对象，外加商品分类的id数组cids 返回值：无","text":"1.新增品牌分析四个内容： 请求方式：刚才看到了是POST 请求路径：/brand 请求参数：brand对象，外加商品分类的id数组cids 返回值：无 BrandController 123456 @PostMapping public ResponseEntity&lt;Void&gt; saveBrand(Brand brand, @RequestParam(value = \"cids\")List&lt;Long&gt; cids)&#123; brandService.saveBrand(brand,cids); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125;&#125; BrandService 这里要注意，我们不仅要新增品牌，还要维护品牌和商品分类的中间表。 12345678910111213141516@Transactional //添加事务public void saveBrand(Brand brand, List&lt;Long&gt; cids) &#123; //新增品牌 brand.setId(null); int count = brandMapper.insert(brand); if (count!=1)&#123; throw new LyException(ExceptionEnum.BRAND_SAVE_ERROR); &#125; //新增中间表 for (Long cid : cids) &#123; count = brandMapper.insertCategoryBrand(cid, brand.getId()); if (count!=1)&#123; throw new LyException(ExceptionEnum.BRAND_SAVE_ERROR); &#125; &#125;&#125; ExceptionEnum 1234567891011@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ExceptionEnum &#123; CATEGORY_NOT_FOND(404,\"暂时没有分类信息\"), BRAND_NOT_FOND(404,\"暂时没有品牌信息\"), BRAND_SAVE_ERROR(500,\"新增品牌失败\") ; private int code; private String msg;&#125; BrandMapper 通用Mapper只能处理单表，也就是Brand的数据，因此我们手动编写一个方法及sql，实现中间表的新增： 1234public interface BrandMapper extends Mapper&lt;Brand&gt; &#123; @Insert(\"insert into tb_category_brand(category_id,brand_id) values(#&#123;cid&#125;,#&#123;pid&#125;)\") int insertCategoryBrand(@Param(\"cid\")Long cid,@Param(\"pid\")Long pid);&#125; 2.实现图片上传2.1 搭建项目文件的上传并不只是在品牌管理中有需求，以后的其它服务也可能需要，因此我们创建一个独立的微服务，专门处理各种上传。 2.1.1 创建ly-upload module2.1.2 导入依赖1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.common&lt;/groupId&gt; &lt;artifactId&gt;ly-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.1.3 编写配置12345678910111213141516171819server: port: 8082spring: application: name: upload-service servlet: multipart: max-file-size: 5MB # 限制文件上传的大小# Eurekaeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka instance: lease-renewal-interval-in-seconds: 5 # 每隔5秒发送一次心跳 lease-expiration-duration-in-seconds: 10 # 10秒不发送就过期 prefer-ip-address: true ip-address: 127.0.0.1 instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; 2.1.4 启动类 1234567@SpringBootApplication@EnableDiscoveryClientpublic class LyUploadApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LyUploadApplication.class); &#125;&#125; 2.2 编写上传功能UploadController 编写controller需要知道4个内容： 请求方式：上传肯定是POST 请求路径：/upload/image 请求参数：文件，参数名是file，SpringMVC会封装为一个接口：MultipleFile 返回结果：上传成功后得到的文件的url路径 123456789101112@RestController@RequestMapping(\"upload\")public class UploadController &#123; @Autowired private UploadService uploadService; @PostMapping(\"image\") public ResponseEntity&lt;String&gt; uploadImage(@RequestParam(\"file\")MultipartFile file)&#123; return ResponseEntity.ok(uploadService.UploadImage(file)); &#125;&#125; ExceptionEnum 12345678910@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ExceptionEnum &#123; UPLOAD_ERROR(500,\"文件上传失败\"), INVALID_FILE_TYPE(500,\"无效的文件类型\") ; private int code; private String msg;&#125; gateway.application.yaml 123456789zuul: prefix: /api # 添加路由前缀 retryable: true routes: item-service: /item/** upload-service: path: /upload/** serviceId: upload-service strip-prefix: false 3.FastDFS3.1 什么是分布式文件系统分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点相连。 通俗来讲： 传统文件系统管理的文件就存储在本机。 分布式文件系统管理的文件存储在很多机器，这些机器通过网络连接，要被统一管理。无论是上传或者访问文件，都需要通过管理中心来访问 3.2 什么是FastDFSFastDFS是由淘宝的余庆先生所开发的一个轻量级、高性能的开源分布式文件系统。用纯C语言开发，功能丰富： 文件存储 文件同步 文件访问（上传、下载） 存取负载均衡 在线扩容 适合有大容量存储需求的应用或系统。同类的分布式文件系统有谷歌的GFS、HDFS（Hadoop）、TFS（淘宝）等。 3.3 FastDFS的架构3.3.1 架构图先上图： FastDFS两个主要的角色：Tracker Server 和 Storage Server 。 Tracker Server：跟踪服务器，主要负责调度storage节点与client通信，在访问上起负载均衡的作用，和记录storage节点的运行状态，是连接client和storage节点的枢纽。 Storage Server：存储服务器，保存文件和文件的meta data（元数据），每个storage server会启动一个单独的线程主动向Tracker cluster中每个tracker server报告其状态信息，包括磁盘使用情况，文件同步情况及文件上传下载次数统计等信息 Group：文件组，多台Storage Server的集群。上传一个文件到同组内的一台机器上后，FastDFS会将该文件即时同步到同组内的其它所有机器上，起到备份的作用。不同组的服务器，保存的数据不同，而且相互独立，不进行通信。 Tracker Cluster：跟踪服务器的集群，有一组Tracker Server（跟踪服务器）组成。 Storage Cluster ：存储集群，有多个Group组成。 3.3.2 上传和下载流程 上传 Client通过Tracker server查找可用的Storage server。 Tracker server向Client返回一台可用的Storage server的IP地址和端口号。 Client直接通过Tracker server返回的IP地址和端口与其中一台Storage server建立连接并进行文件上传。 上传完成，Storage server返回Client一个文件ID，文件上传结束。 下载 Client通过Tracker server查找要下载文件所在的的Storage server。 Tracker server向Client返回包含指定文件的某个Storage server的IP地址和端口号。 Client直接通过Tracker server返回的IP地址和端口与其中一台Storage server建立连接并指定要下载文件。 下载文件成功。 3.4 实现3.4.1 引入依赖在父工程中，我们已经管理了依赖，版本为： 1&lt;fastDFS.client.version&gt;1.26.2&lt;/fastDFS.client.version&gt; 因此，这里我们直接引入坐标即可： 1234&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt;&lt;/dependency&gt; 3.4.2 引入配置类123456@Configuration@Import(FdfsClientConfig.class)// 解决jmx重复注册bean的问题@EnableMBeanExport(registration = RegistrationPolicy.IGNORE_EXISTING)public class FastClientImporter &#123;&#125; 3.4.3 编写FastDFS属性application.yaml 123456789101112131415fdfs: so-timeout: 2500 connect-timeout: 600 thumb-image: # 缩略图 width: 60 height: 60 tracker-list: # tracker地址 - 192.168.179.128:22122ly: upload: baseUrl: http://image.leyou.com/upload/ allowTypes: -image/bmp -image/png -image/jpeg 3.4.4 改造上传逻辑UploadProperties 123456@Data@ConfigurationProperties(prefix = \"ly.upload\")public class UploadProperties &#123; private String baseUrl; private List&lt;String&gt; allowTypes;&#125; UploadService 123456789101112131415161718192021222324252627282930313233343536373839@Service@Slf4j@EnableConfigurationProperties(UploadProperties.class)public class UploadService &#123; @Autowired private FastFileStorageClient storageClient; @Autowired private UploadProperties uploadProperties;// public static final List&lt;String&gt; ALLOW_TYPES = Arrays.asList(\"image/jpeg\", \"image/png\", \"image/bmp\"); public String UploadImage(MultipartFile file) &#123; try &#123; //校验文件类型 String contentType = file.getContentType(); if (!uploadProperties.getAllowTypes().contains(contentType)) &#123; throw new LyException(ExceptionEnum.INVALID_FILE_TYPE); &#125; //校验文件内容 BufferedImage image = ImageIO.read(file.getInputStream()); if (image == null) &#123; throw new LyException(ExceptionEnum.INVALID_FILE_TYPE); &#125; /*//准备目标路径 File dest = new File(\"E:\\\\uploadTest\", file.getOriginalFilename()); //保存文件到本地 file.transferTo(dest);*/ //上传到FastDFS// String extension=file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf(\".\")+1); String extension = StringUtils.substringAfterLast(file.getOriginalFilename(), \".\"); StorePath storePath = storageClient.uploadFile(file.getInputStream(), file.getSize(), extension, null); //返回路径 return uploadProperties.getBaseUrl() + storePath.getFullPath(); &#125; catch (IOException e) &#123; //上传失败 log.error(\"上传文件失败!\", e); throw new LyException(ExceptionEnum.UPLOAD_ERROR); &#125; &#125;&#125; 4.修改品牌BrandController 12345@PutMappingpublic ResponseEntity&lt;Void&gt; editBrand(Brand brand,@RequestParam(value = \"cids\")List&lt;Long&gt; cids)&#123; brandService.editBrand(brand,cids); return ResponseEntity.status(HttpStatus.CREATED).build();&#125; BrandService 1234567891011121314 @Transactional public void editBrand(Brand brand,List&lt;Long&gt; cids) &#123; int count=brandMapper.updateByPrimaryKey(brand); if (count!=1)&#123; throw new LyException(ExceptionEnum.EDIT_ERROR); &#125; for (Long cid :cids)&#123; count = brandMapper.editCategoryBrand(cid, brand.getId()); if (count!=1)&#123; throw new LyException(ExceptionEnum.EDIT_ERROR); &#125; &#125; &#125;&#125; BrandMapper 1234public interface BrandMapper extends Mapper&lt;Brand&gt; &#123; @Update(\"update tb_category_brand set category_id=#&#123;cid&#125; where brand_id=#&#123;bid&#125;\") int editCategoryBrand(@Param(\"cid\")Long cid,@Param(\"bid\")Long bid);&#125; 5.商品规格管理@RequestBody可以接收json数组 5.1 商品规格组管理实体类 12345678910@Data@Table(name = \"tb_spec_group\")public class SpecGroup &#123; @Id @KeySql(useGeneratedKeys = true) private Long id; private Long cid; private String name;&#125; SpecGroupMapper 12public interface SpecGroupMapper extends Mapper&lt;SpecGroup&gt; &#123;&#125; SpecificationController 12345678910111213141516171819202122232425262728293031@RestController@RequestMapping(\"spec\")public class SpecificationController &#123; @Autowired private SpecificationService specificationService; //根据分类id查询规格组 @GetMapping(\"groups/&#123;cid&#125;\") public ResponseEntity&lt;List&lt;SpecGroup&gt;&gt; queryGroupByCid(@PathVariable(\"cid\") Long cid) &#123; return ResponseEntity.ok(specificationService.queryGroupByCid(cid)); &#125; @PostMapping(\"group\") public ResponseEntity&lt;Void&gt; saveSpecGroup(@RequestBody SpecGroup specGroup) &#123; specificationService.saveSpecGroup(specGroup); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125; @PutMapping(\"group\") public ResponseEntity&lt;Void&gt; editSpecGroup(@RequestBody SpecGroup specGroup) &#123; specificationService.editGroup(specGroup); System.out.println(specGroup); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125; @DeleteMapping(\"group/&#123;id&#125;\") public ResponseEntity&lt;Void&gt; deleteSpecGroup(@PathVariable(\"id\") Long id) &#123; specificationService.deleteSpecGroup(id); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125;&#125; SpecificationService 1234567891011121314151617181920212223242526272829303132@Servicepublic class SpecificationService &#123; @Autowired private SpecGroupMapper specGroupMapper; public List&lt;SpecGroup&gt; queryGroupByCid(Long cid) &#123; SpecGroup specGroup=new SpecGroup(); specGroup.setCid(cid); //根据对象的非空字段查询 List&lt;SpecGroup&gt; list = specGroupMapper.select(specGroup); if (CollectionUtils.isEmpty(list))&#123; throw new LyException(ExceptionEnum.SPEC_GROUP_NOT_FOND); &#125; return list; &#125; @Transactional public void editGroup(SpecGroup specGroup) &#123; specGroupMapper.updateByPrimaryKeySelective(specGroup); &#125; @Transactional public void saveSpecGroup(SpecGroup specGroup) &#123; specGroupMapper.insert(specGroup); &#125; @Transactional public void deleteSpecGroup(Long id) &#123; specGroupMapper.deleteByPrimaryKey(id); &#125;&#125; 5.2商品规格参数管理实体类 12345678910111213141516@Data@Table(name = \"tb_spec_param\")public class SpecParam &#123; @Id @KeySql(useGeneratedKeys = true) private Long id; private Long cid; private Long groupId; private String name; @Column(name = \"`numeric`\") //numeric在数据库中是关键字@Column(name = \"`numeric`\")用于区分 private Boolean numeric; private String unit; private Boolean generic; private Boolean searching; private String segments;&#125; SpecParamMapper 12public interface SpecParamMapper extends Mapper&lt;SpecParam&gt; &#123;&#125; SpecificationController 12345678910111213141516171819202122232425262728@RestController@RequestMapping(\"spec\")public class SpecificationController &#123; @Autowired private SpecificationService specificationService; @GetMapping(\"params\") public ResponseEntity&lt;List&lt;SpecParam&gt;&gt; queryParamByGid(@RequestParam(\"gid\") Long gid) &#123; return ResponseEntity.ok(specificationService.queryParamByGid(gid)); &#125; @PostMapping(\"param\") public ResponseEntity&lt;Void&gt; saveSpecParam(@RequestBody SpecParam specParam) &#123; specificationService.saveSpecParam(specParam); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125; @PutMapping(\"param\") public ResponseEntity&lt;Void&gt; editSpecParam(@RequestBody SpecParam specParam)&#123; specificationService.editSpecParam(specParam); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125; @DeleteMapping(\"param/&#123;id&#125;\") public ResponseEntity&lt;Void&gt; deleteSpecParam(@PathVariable(\"id\") Long id) &#123; specificationService.deleteSpecParam(id); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125;&#125; SpecificationService 123456789101112131415161718192021222324252627282930@Servicepublic class SpecificationService &#123; @Autowired private SpecParamMapper specParamMapper; public List&lt;SpecParam&gt; queryParamByGid(Long gid) &#123; SpecParam specParam=new SpecParam(); specParam.setGroupId(gid); List&lt;SpecParam&gt; list = specParamMapper.select(specParam); if (CollectionUtils.isEmpty(list))&#123; throw new LyException(ExceptionEnum.SPEC_PARAM_NOT_FOND); &#125; return list; &#125; @Transactional public void saveSpecParam(SpecParam specParam) &#123; specParamMapper.insert(specParam); &#125; @Transactional public void editSpecParam(SpecParam specParam) &#123; specParamMapper.updateByPrimaryKeySelective(specParam); &#125; @Transactional public void deleteSpecParam(Long id) &#123; specParamMapper.deleteByPrimaryKey(id); &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(九.用户注册)","slug":"微服务项目总结(九.用户注册)","date":"2021-05-08T13:19:59.230Z","updated":"2020-04-29T02:44:38.116Z","comments":true,"path":"16677/","link":"","permalink":"http://tonymua.top/16677/","excerpt":"1.阿里云短信服务1.1 创建短信微服务因为系统中不止注册一个地方需要短信发送，因此我们将短信发送抽取为微服务：leyou-sms-service，凡是需要的地方都可以使用。 另外，因为短信发送API调用时长的不确定性，为了提高程序的响应速度，短信发送我们都将采用异步发送方式，即： 短信服务监听MQ消息，收到消息后发送短信。 其它服务要发送短信时，通过MQ通知短信微服务 1.1.1 创建module","text":"1.阿里云短信服务1.1 创建短信微服务因为系统中不止注册一个地方需要短信发送，因此我们将短信发送抽取为微服务：leyou-sms-service，凡是需要的地方都可以使用。 另外，因为短信发送API调用时长的不确定性，为了提高程序的响应速度，短信发送我们都将采用异步发送方式，即： 短信服务监听MQ消息，收到消息后发送短信。 其它服务要发送短信时，通过MQ通知短信微服务 1.1.1 创建module 1.1.2 pom123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;leyou&lt;/artifactId&gt; &lt;groupId&gt;com.leyou&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-sms&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-dysmsapi&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.common&lt;/groupId&gt; &lt;artifactId&gt;ly-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1.1.3 编写启动类123456@SpringBootApplicationpublic class LySmsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LySmsApplication.class); &#125;&#125; 1.1.4 编写application.yml123456789101112131415161718server: port: 8086spring: application: name: sms-service redis: host: 127.0.0.1 rabbitmq: host: 127.0.0.1 username: leyou password: leyou virtual-host: /leyouleyou: sms: accessKeyId: LTAI4XXXXXXXXXXXX # 你自己的accessKeyId accessKeySecret: 1jaqiXXXXXXXXXXXXX # 你自己的AccessKeySecret signName: 乐优商城 # 签名名称 verifyCodeTemplate: SMS_173945834 # 模板名称 1.2 编写短信工具类1.2.1 属性抽取常量抽取到application.yml中, 然后注入到属性类中： 1234567891011@Data@ConfigurationProperties(prefix = \"ly.sms\")public class SmsProperties &#123; String accessKeyId; String accessKeySecret; String signName; String verifyCodeTemplate;&#125; 1.2.2 工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Slf4j@Component@EnableConfigurationProperties(SmsProperties.class)public class SmsUtil &#123; @Autowired private SmsProperties prop; @Autowired private StringRedisTemplate redisTemplate; static final String KEY_PREFIX=\"sms:phone:\"; static final long SMS_MIN_INTERVAL_IN_MILLIS=60000; //产品名称:云通信短信API产品,开发者无需替换 static final String product = \"Dysmsapi\"; //产品域名,开发者无需替换 static final String domain = \"dysmsapi.aliyuncs.com\"; // TODO 此处需要替换成开发者自己的AK(在阿里云访问控制台寻找) static final String accessKeyId = \"LTAXXXXXXXXX\"; static final String accessKeySecret = \"1jaqiYZ6XXXXXXXXX\"; public SendSmsResponse sendSms(String phoneNumber, String signName, String templateCode, String templateParam) &#123; String key=KEY_PREFIX+phoneNumber; //限流 //读取时间 String lastTime = redisTemplate.opsForValue().get(key); if (StringUtils.isNotBlank(lastTime))&#123; Long last = Long.valueOf(lastTime); if (System.currentTimeMillis()-last&lt;SMS_MIN_INTERVAL_IN_MILLIS)&#123; log.info(\"[短信服务] 发送短信频率过高,被拦截, phoneNumber:&#123;&#125;\",phoneNumber); return null; &#125; &#125; try &#123; //可自助调整超时时间 System.setProperty(\"sun.net.client.defaultConnectTimeout\", \"10000\"); System.setProperty(\"sun.net.client.defaultReadTimeout\", \"10000\"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile(\"cn-hangzhou\", prop.getAccessKeyId(), prop.getAccessKeySecret()); DefaultProfile.addEndpoint(\"cn-hangzhou\", \"cn-hangzhou\", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象-具体描述见控制台-文档部分内容 SendSmsRequest request = new SendSmsRequest(); request.setMethod(MethodType.POST); //必填:待发送手机号 request.setPhoneNumbers(phoneNumber); //必填:短信签名-可在短信控制台中找到 request.setSignName(signName); //必填:短信模板-可在短信控制台中找到 request.setTemplateCode(templateCode); //可选:模板中的变量替换JSON串,如模板内容为\"亲爱的$&#123;name&#125;,您的验证码为$&#123;code&#125;\"时,此处的值为 request.setTemplateParam(templateParam); //hint 此处可能会抛出异常，注意catch SendSmsResponse sendSmsResponse = acsClient.getAcsResponse(request); if (!\"OK\".equals(sendSmsResponse.getCode())) &#123; log.info(\"[短信服务] 发送短信失败, phoneNumber:&#123;&#125;, 原因:&#123;&#125;\", phoneNumber, sendSmsResponse.getMessage()); &#125; //发送短信日志 log.info(\"[短信服务], 发送短信验证码,phoneNumber:&#123;&#125;\",phoneNumber); //发送短信成功后, 写入redis,指定生存时间 redisTemplate.opsForValue().set(key,String.valueOf(System.currentTimeMillis()),1, TimeUnit.MINUTES); return sendSmsResponse; &#125; catch (Exception e) &#123; log.error(\"[短信服务] 发送短信异常, phoneNumber:&#123;&#125;,\",phoneNumber,e); return null; &#125; &#125;&#125; 1.3 编写消息监听器编写消息监听器，当接收到消息后，我们发送短信。 123456789101112131415161718192021222324@Componentpublic class SmsListener &#123; @Autowired private SmsUtil smsUtil; @Autowired private SmsProperties prop; @RabbitListener(bindings = @QueueBinding( value = @Queue(name = \"sms.verify.code.queue\", durable = \"true\"), exchange = @Exchange(name = \"ly.sms.exchange\", type = ExchangeTypes.TOPIC), key = \"sms.verify.code\" )) public void listenSms(Map&lt;String, String&gt; msg) throws Exception &#123; if (CollectionUtils.isEmpty(msg)) &#123; // 放弃处理 return; &#125; String phone = msg.remove(\"phone\"); if (StringUtils.isBlank(phone))&#123; return; &#125; smsUtil.sendSms(phone,prop.getSignName(),prop.getVerifyCodeTemplate(), JsonUtils.toString(msg)); &#125;&#125; 2.创建用户中心用户搜索到自己心仪的商品，接下来就要去购买，但是购买必须先登录。所以接下来我们编写用户中心，实现用户的登录和注册功能。 用户中心的提供的服务： 用户的注册 用户登录 用户个人信息管理 用户地址管理 用户收藏管理 我的订单 优惠券管理 这里我们暂时先实现基本的：注册和登录功能，其它功能大家可以自行补充完整。 因为用户中心的服务其它微服务也会调用，因此这里我们做聚合。 leyou-user：父工程，包含2个子工程： leyou-user-interface：实体及接口 leyou-user-service：业务和服务 2.1 创建父module2.2 创建leyou-user-interface在leyou-user下，创建module： pom： 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;ly-user&lt;/artifactId&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-user-interface&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-core&lt;/artifactId&gt; &lt;version&gt;1.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.10.0.pr1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-sms&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3 创建leyou-user-servicepom： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;leyou&lt;/artifactId&gt; &lt;groupId&gt;com.leyou&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-user&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;ly-user-interface&lt;/module&gt; &lt;module&gt;ly-user-service&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 启动类 12345678@SpringBootApplication@EnableDiscoveryClient@MapperScan(\"lwy.mapper\")public class LyUserApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LyUserApplication.class); &#125;&#125; 配置 1234567891011121314151617181920212223242526server: port: 8085spring: application: name: user-service datasource: url: jdbc:mysql://127.0.0.1:3306/leyou username: root password: 547717253 driver-class-name: com.mysql.jdbc.Driver rabbitmq: host: 127.0.0.1 username: leyou password: leyou virtual-host: /leyou redis: host: 127.0.0.1eureka: client: service-url: defaultZone: http://127.0.0.1:8080/eureka instance: prefer-ip-address: true ip-address: 127.0.0.1mybatis: type-aliases-package: lwy.pojo 2.4 添加网关路由我们修改leyou-gateway，添加路由规则，对leyou-user-service进行路由: 3.数据验证功能3.1 基本代码3.1.1 实体类12345678910111213141516171819@Table(name = \"tb_user\")@Datapublic class User &#123; @Id @KeySql(useGeneratedKeys = true) private Long id; private String username;// 用户名 @JsonIgnore private String password;// 密码 private String phone;// 电话 private Date created;// 创建时间 @JsonIgnore private String salt;// 密码的盐值&#125; 注意：为了安全考虑。这里对password和salt添加了注解@JsonIgnore，这样在json序列化时，就不会把password和salt返回。 3.1.2 mapper12public interface UserMapper extends BaseMapper&lt;User&gt; &#123;&#125; 3.1.3 Service123456@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper;&#125; 3.1.4 controller1234567@Controllerpublic class UserController &#123; @Autowired private UserService userService; &#125; 3.2 接口说明实现用户数据的校验，主要包括对：手机号、用户名的唯一性校验。 接口路径： 1GET /check/&#123;data&#125;/&#123;type&#125; 参数说明： 参数 说明 是否必须 数据类型 默认值 data 要校验的数据 是 String 无 type 要校验的数据类型：1，用户名；2，手机； 否 Integer 1 返回结果： 返回布尔类型结果： true：可用 false：不可用 状态码： 200：校验成功 400：参数有误 500：服务器内部异常 controller 因为有了接口，我们可以不关心页面，所有需要的东西都一清二楚： 请求方式：GET 请求路径：/check/{param}/{type} 请求参数：param,type 返回结果：true或false 1234@GetMapping(\"/check/&#123;data&#125;/&#123;type&#125;\")public ResponseEntity&lt;Boolean&gt; checkData(@PathVariable(\"data\")String data,@PathVariable(\"type\")Integer type)&#123; return ResponseEntity.ok(userService.checkData(data,type));&#125; service 123456789101112131415161718192021222324@Servicepublic class UserService &#123; @Autowired private UserMapper userMapper; private static final String KEY_PREFIX=\"user:verify:phone:\"; public Boolean checkData(String data, Integer type) &#123; User record = new User(); //判断数据类型 switch (type) &#123; case 1: record.setUsername(data); break; case 2: record.setPhone(data); break; default: throw new LyException(ExceptionEnum.INVALID_USER_DATA_TYPE); &#125; int count = userMapper.selectCount(record); return count == 0; &#125;&#125; 4.发送短信功能4.1 接口说明功能说明 根据用户输入的手机号，生成随机验证码，长度为6位，纯数字。并且调用短信服务，发送验证码到用户手机。 接口路径 1POST /code 参数说明： 参数 说明 是否必须 数据类型 默认值 phone 用户的手机号码 是 String 无 返回结果： 无 状态码： 204：请求已接收 400：参数有误 500：服务器内部异常 4.2 Redis4.2.1 Spring Data Redis​ Spring Data Redis，是Spring Data 家族的一部分。 对Jedis客户端进行了封装，与spring进行了整合。可以非常方便的来实现redis的配置和操作。 4.2.2 RedisTemplate基本操作Spring Data Redis 提供了一个工具类：RedisTemplate。里面封装了对于Redis的五种数据结构的各种操作，包括： redisTemplate.opsForValue() ：操作字符串 redisTemplate.opsForHash() ：操作hash redisTemplate.opsForList()：操作list redisTemplate.opsForSet()：操作set redisTemplate.opsForZSet()：操作zset 其它一些通用命令，如expire，可以通过redisTemplate.xx()来直接调用 5种结构： String：等同于java中的，Map&lt;String,String&gt; list：等同于java中的Map&lt;String,List&lt;String&gt;&gt; set：等同于java中的Map&lt;String,Set&lt;String&gt;&gt; sort_set：可排序的set hash：等同于java中的：Map&lt;String,Map&lt;String,String&gt;&gt; 4.2.3 StringRedisTemplateRedisTemplate在创建时，可以指定其泛型类型： K：代表key 的数据类型 V: 代表value的数据类型 注意：这里的类型不是Redis中存储的数据类型，而是Java中的数据类型，RedisTemplate会自动将Java类型转为Redis支持的数据类型：字符串、字节、二进制等等。 ​ 不过RedisTemplate默认会采用JDK自带的序列化（Serialize）来对对象进行转换。生成的数据十分庞大，因此一般我们都会指定key和value为String类型，这样就由我们自己把对象序列化为json字符串来存储即可。因为大部分情况下，我们都会使用key和value都为String的RedisTemplate:StringRedisTemplate 4.3 controller1234567891011@RestControllerpublic class UserController &#123; @Autowired private UserService userService; @GetMapping(\"code\") public ResponseEntity&lt;Void&gt; sendCode(@RequestParam(\"phoneNumber\")String phoneNumber)&#123; userService.sendCode(phoneNumber); return ResponseEntity.status(HttpStatus.NO_CONTENT).build(); &#125;&#125; 4.4 service这里的逻辑会稍微复杂： 生成随机验证码 将验证码保存到Redis中，用来在注册的时候验证 发送验证码到leyou-sms-service服务，发送短信 生成随机码的工具： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class NumberUtils &#123; public static boolean isInt(Double num) &#123; return num.intValue() == num; &#125; /** * 判断字符串是否是数值格式 * @param str * @return */ public static boolean isDigit(String str)&#123; if(str == null || str.trim().equals(\"\"))&#123; return false; &#125; return str.matches(\"^\\\\d+\\\\.?\\\\d+$\"); &#125; public static double toDouble(String s)&#123; if(s == null)&#123; return 0; &#125; if(!isDigit(s))&#123; return 0; &#125; return Double.valueOf(s); &#125; /** * 将一个小数精确到指定位数 * @param num * @param scale * @return */ public static double scale(double num, int scale) &#123; BigDecimal bd = new BigDecimal(num); return bd.setScale(scale, RoundingMode.HALF_UP).doubleValue(); &#125; // 从字符串中根据正则表达式寻找，返回找到的数字数组 public static Double[] searchNumber(String value, String regex)&#123; List&lt;Double&gt; doubles = new ArrayList&lt;&gt;(); Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(value); if(matcher.find()) &#123; MatchResult result = matcher.toMatchResult(); for (int i = 1; i &lt;= result.groupCount(); i++) &#123; doubles.add(Double.valueOf(result.group(i))); &#125; &#125; return doubles.toArray(new Double[doubles.size()]); &#125; /** * 生成指定位数的随机数字 * @param len * @return */ public static String generateCode(int len)&#123; len = Math.min(len, 8); int min = Double.valueOf(Math.pow(10, len - 1)).intValue(); int num = new Random().nextInt(Double.valueOf(Math.pow(10, len + 1)).intValue() - 1) + min; return String.valueOf(num).substring(0,len); &#125;&#125; UserService 1234567891011121314151617181920212223@Servicepublic class UserService &#123; @Autowired private AmqpTemplate amqpTemplate; @Autowired private RedisTemplate redisTemplate; private static final String KEY_PREFIX=\"user:verify:phone:\"; public void sendCode(String phoneNumber) &#123; //生成验证码 String code= NumberUtils.generateCode(6); //生成key String key=KEY_PREFIX+phoneNumber; Map&lt;String,String&gt; msg=new HashMap&lt;&gt;(); msg.put(\"phone\",phoneNumber); msg.put(\"code\",code); //发送验证码 amqpTemplate.convertAndSend(\"ly.sms.exchange\",\"sms.verify.code\",msg); //保存验证码 redisTemplate.opsForValue().set(key,code,5, TimeUnit.MINUTES); &#125;&#125; 5.注册功能5.1 接口说明功能说明 实现用户注册功能，需要对用户密码进行加密存储，使用MD5加密，加密过程中使用随机码作为salt加盐。另外还需要对用户输入的短信验证码进行校验。 接口路径 1POST /register 参数说明： form表单格式 参数 说明 是否必须 数据类型 默认值 username 用户名，格式为4~30位字母、数字、下划线 是 String 无 password 用户密码，格式为4~30位字母、数字、下划线 是 String 无 phone 手机号码 是 String 无 code 短信验证码 是 String 无 返回结果： 无返回值。 状态码： 201：注册成功 400：参数有误，注册失败 500：服务器内部异常，注册失败 5.2 controller12345@GetMapping(\"register\")public ResponseEntity&lt;Void&gt; register(@Valid User user, @RequestParam(\"code\") String code)&#123; userService.register(user,code); return ResponseEntity.status(HttpStatus.CREATED).build();&#125; 5.3 service基本逻辑： 1）校验短信验证码 2）生成盐 3）对密码加密 4）写入数据库 5）删除Redis中的验证码 CodecUtils 123456789101112131415161718192021222324import org.apache.commons.codec.digest.DigestUtils;import org.apache.commons.lang3.StringUtils;import java.util.UUID;public class CodecUtils &#123; public static String md5Hex(String data, String salt) &#123; if (StringUtils.isBlank(salt)) &#123; salt = data.hashCode() + \"\"; &#125; return DigestUtils.md5Hex(salt + DigestUtils.md5Hex(data)); &#125; public static String shaHex(String data, String salt) &#123; if (StringUtils.isBlank(salt)) &#123; salt = data.hashCode() + \"\"; &#125; return DigestUtils.sha512Hex(salt + DigestUtils.sha512Hex(data)); &#125; public static String generateSalt() &#123; return StringUtils.replace(UUID.randomUUID().toString(), \"-\", \"\"); &#125;&#125; service 123456789101112131415161718192021222324252627public Boolean register(User user, String code) &#123; String key=KEY_PREFIX+user.getPhone(); //从redis中取出验证码 String codeCache= (String) redisTemplate.opsForValue().get(key); //校验验证码是否正确 if (!code.equals(codeCache))&#123; return false; &#125; user.setId(null); user.setCreated(new Date()); //生成盐 String salt = CodecUtils.generateSalt(); user.setSalt(salt); //对密码进行加密 user.setPassword(CodecUtils.md5Hex(user.getPassword(),salt)); //写入数据库 boolean b = userMapper.insertSelective(user) == 1; //如果注册成功, 删除redis中的code if(b)&#123; try &#123; redisTemplate.delete(key); &#125; catch (Exception e) &#123; log.info(\"删除缓存验证码失败，code：&#123;&#125;\", code, e); &#125; &#125; return b;&#125; 5.4 服务端数据校验刚才虽然实现了注册，但是服务端并没有进行数据校验，而前端的校验是很容易被有心人绕过的。所以我们必须在后台添加数据校验功能： 我们这里会使用Hibernate-Validator框架完成数据校验： 而SpringBoot的web启动器中已经集成了相关依赖 5.4.1 什么是Hibernate ValidatorHibernate Validator是Hibernate提供的一个开源框架，使用注解方式非常方便的实现服务端的数据校验。 官网：http://hibernate.org/validator/ hibernate Validator 是 Bean Validation 的参考实现 。 Hibernate Validator 提供了 JSR 303 规范中所有内置 constraint（约束） 的实现，除此之外还有一些附加的 constraint。 在日常开发中，Hibernate Validator经常用来验证bean的字段，基于注解，方便快捷高效。 5.4.2 Bean校验的注解常用注解如下： Constraint 详细信息 @Valid 被注释的元素是一个对象，需要检查此对象的所有字段值 @Null 被注释的元素必须为 null @NotNull 被注释的元素必须不为 null @AssertTrue 被注释的元素必须为 true @AssertFalse 被注释的元素必须为 false @Min(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @Max(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 @Size(max, min) 被注释的元素的大小必须在指定的范围内 @Digits (integer, fraction) 被注释的元素必须是一个数字，其值必须在可接受的范围内 @Past 被注释的元素必须是一个过去的日期 @Future 被注释的元素必须是一个将来的日期 @Pattern(value) 被注释的元素必须符合指定的正则表达式 @Email 被注释的元素必须是电子邮箱地址 @Length 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range 被注释的元素必须在合适的范围内 @NotBlank 被注释的字符串的必须非空 @URL(protocol=,host=, port=,regexp=, flags=) 被注释的字符串必须是一个有效的url @CreditCardNumber 被注释的字符串必须通过Luhn校验算法，银行卡，信用卡等号码一般都用Luhn计算合法性 5.4.3 给User添加校验我们在ly-user-interface中添加Hibernate-Validator依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;&lt;/dependency&gt; 我们在User对象的部分属性上添加注解： 12345678910111213141516171819202122@Table(name = \"tb_user\")@Datapublic class User &#123; @Id @KeySql(useGeneratedKeys = true) private Long id; @Length(min = 4, max = 30, message = \"用户名只能在4~30位之间\") private String username;// 用户名 @JsonIgnore @Length(min = 4, max = 30, message = \"密码只能在4~30位之间\") private String password;// 密码 @Pattern(regexp = \"^1[35678]\\\\d&#123;9&#125;$\", message = \"手机号格式不正确\") private String phone;// 电话 private Date created;// 创建时间 @JsonIgnore private String salt;// 密码的盐值&#125; 5.4.4 在controller上进行控制在controller中只需要给User添加 @Valid注解即可 12345@GetMapping(\"register\")public ResponseEntity&lt;Void&gt; register(@Valid User user, @RequestParam(\"code\") String code)&#123; userService.register(user,code); return ResponseEntity.status(HttpStatus.CREATED).build();&#125; 6.根据用户名和密码查询用户6.1 接口说明功能说明 查询功能，根据参数中的用户名和密码查询指定用户 接口路径 1GET /query 参数说明： form表单格式 参数 说明 是否必须 数据类型 默认值 username 用户名，格式为4~30位字母、数字、下划线 是 String 无 password 用户密码，格式为4~30位字母、数字、下划线 是 String 无 返回结果： 用户的json格式数据 123456&#123; \"id\": 6572312, \"username\":\"test\", \"phone\":\"13688886666\", \"created\": 1342432424&#125; 状态码： 200：注册成功 400：用户名或密码错误 500：服务器内部异常，注册失败 6.2 controller1234567@GetMapping(\"query\")public ResponseEntity&lt;User&gt; queryUser( @RequestParam(\"username\")String username, @RequestParam(\"password\")String password)&#123; return ResponseEntity.ok(userService.queryUser(username,password));&#125; 6.3 service要注意，查询时也要对密码进行加密后判断是否一致 123456789101112131415public User queryUser(String username, String password) &#123; //查询 User record=new User(); record.setUsername(username); User user = userMapper.selectOne(record); //校验用户名 if (user==null)&#123; return null; &#125; //校验密码 if (!user.getPassword().equals(CodecUtils.md5Hex(password,user.getSalt())))&#123; return null; &#125; return user;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(三.商品管理, Elasticsearch入门)","slug":"微服务项目总结(三.商品管理, Elasticsearch入门)","date":"2021-05-08T13:19:59.229Z","updated":"2020-04-29T05:55:00.563Z","comments":true,"path":"51642/","link":"","permalink":"http://tonymua.top/51642/","excerpt":"1.商品管理1.1 商品查询实体类 123456789101112131415161718192021222324@Data@Table(name = \"tb_spu\")public class Spu &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private Long brandId; private Long cid1;// 1级类目 private Long cid2;// 2级类目 private Long cid3;// 3级类目 private String title;// 标题 private String subTitle;// 子标题 private Boolean saleable;// 是否上架 @JsonIgnore private Boolean valid;// 是否有效，逻辑删除用 private Date createTime;// 创建时间 @JsonIgnore //返回时忽略该字段 private Date lastUpdateTime;// 最后修改时间 @Transient private String cname;// 商品分类名称 @Transient private String bname;// 品牌名称&#125;","text":"1.商品管理1.1 商品查询实体类 123456789101112131415161718192021222324@Data@Table(name = \"tb_spu\")public class Spu &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private Long brandId; private Long cid1;// 1级类目 private Long cid2;// 2级类目 private Long cid3;// 3级类目 private String title;// 标题 private String subTitle;// 子标题 private Boolean saleable;// 是否上架 @JsonIgnore private Boolean valid;// 是否有效，逻辑删除用 private Date createTime;// 创建时间 @JsonIgnore //返回时忽略该字段 private Date lastUpdateTime;// 最后修改时间 @Transient private String cname;// 商品分类名称 @Transient private String bname;// 品牌名称&#125; @JsonIgnore 注解需要导入以下依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.10.0.pr1&lt;/version&gt;&lt;/dependency&gt; SpuMapper 12public interface SpuMapper extends Mapper&lt;Spu&gt; &#123;&#125; GoodsController 12345678910111213141516@RestController@RequestMappingpublic class GoodsController &#123; @Autowired private GoodsService goodsService; @GetMapping(\"spu/page\") public ResponseEntity&lt;PageResult&lt;Spu&gt;&gt; querySpuByPage( @RequestParam(value = \"page\",defaultValue = \"1\")Integer page, @RequestParam(value = \"rows\",defaultValue = \"5\")Integer rows, @RequestParam(value = \"saleable\",required= false)Boolean saleable, @RequestParam(value = \"key\",required = false)String key )&#123; return ResponseEntity.ok(goodsService.querySpuByPage(page,rows,saleable,key)); &#125;&#125; GoodsService 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Servicepublic class GoodsService &#123; @Autowired private SpuMapper spuMapper; @Autowired private CategoryService categoryService; @Autowired private BrandService brandService; public PageResult&lt;Spu&gt; querySpuByPage(Integer page, Integer rows, Boolean saleable, String key) &#123; //分页 PageHelper.startPage(page,rows); //过滤 Example example = new Example(Spu.class); Example.Criteria criteria = example.createCriteria(); //搜索key过滤 if (StringUtils.isNotBlank(key))&#123; criteria.andLike(\"title\",\"%\"+key+\"%\"); &#125; //上下架过滤 if (saleable!=null)&#123; criteria.andEqualTo(\"saleable\",saleable); &#125; //默认排序 example.setOrderByClause(\"last_update_time DESC\"); //查询 List&lt;Spu&gt; spus = spuMapper.selectByExample(example); if (CollectionUtils.isEmpty(spus))&#123; throw new LyException(ExceptionEnum.GOODS_NOT_FOND); &#125; //解析分类和品牌的名称 loadCategoryAndBrandName(spus); //解析分页结果 PageInfo&lt;Spu&gt; info = new PageInfo&lt;&gt;(spus); return new PageResult&lt;&gt;(info.getTotal(),spus); &#125; private void loadCategoryAndBrandName(List&lt;Spu&gt; spus) &#123; for (Spu spu : spus) &#123; //处理分类名称 List&lt;String&gt; names = categoryService.queryNameByIds(Arrays.asList(spu.getCid1(), spu.getCid2(), spu.getCid3())).stream().map(Category::getName).collect(Collectors.toList()); spu.setCname(StringUtils.join(names,\"/\")); //处理品牌名称 spu.setBname(brandService.queryNameById(spu.getBrandId()).getName()); &#125; &#125;&#125; Category中拓展查询名称的功能 页面需要商品的分类名称需要在这里查询，因此要额外提供查询分类名称的功能， 在CategoryService中添加功能： 1234567public List&lt;Category&gt; queryNameByIds(List&lt;Long&gt; ids)&#123; List&lt;Category&gt; list = categoryMapper.selectByIdList(ids); if (CollectionUtils.isEmpty(list))&#123; throw new LyException(ExceptionEnum.CATEGORY_NOT_FOND); &#125; return list;&#125; mapper的selectByIdList方法是来自于通用mapper。不过需要我们在mapper上继承一个通用mapper接口： 12public interface CategoryMapper extends Mapper&lt;Category&gt;, IdListMapper&lt;Category,Long&gt; &#123;&#125; Brand中拓展查询名称的功能 在BrandService中添加功能： 1234 public Brand queryNameById(Long id)&#123; return brandMapper.selectByPrimaryKey(id); &#125;&#125; 1.2 商品修改1.2.1 查询SpuDetail 分析 请求方式：GET 请求路径：/spu/detail/{id} 请求参数：id，应该是spu的id 返回结果：SpuDetail对象 GoodsController 1234@GetMapping(\"spu/detail/&#123;id&#125;\")public ResponseEntity&lt;SpuDetail&gt; querySpuDetailById(@PathVariable(\"id\")Long id)&#123; return ResponseEntity.ok(goodsService.querySpuDetailById(id));&#125; GoodsService 1234567public SpuDetail querySpuDetailById(Long id) &#123; SpuDetail spuDetail = spuDetailMapper.selectByPrimaryKey(id); if (spuDetail == null) &#123; throw new LyException(ExceptionEnum.GOODS_NOT_FOND); &#125; return spuDetail;&#125; 1.2.2 查询sku 分析 请求方式：Get 请求路径：/sku/list 请求参数：id，应该是spu的id 返回结果：sku的集合 GoodsController 1234@GetMapping(\"sku/list\")public ResponseEntity&lt;List&lt;Sku&gt;&gt; querySkuBySpuId(@RequestParam(\"id\")Long id)&#123; return ResponseEntity.ok(goodsService.querySkuBySpuId(id));&#125; GoodsService 12345678910111213141516171819202122232425public List&lt;Sku&gt; querySkuBySpuId(Long id) &#123; Sku sku = new Sku(); sku.setSpuId(id); List&lt;Sku&gt; skuList = skuMapper.select(sku); if (CollectionUtils.isEmpty(skuList)) &#123; throw new LyException(ExceptionEnum.GOODS_NOT_FOND); &#125; /*for (Sku s : skuList) &#123; Stock stock = stockMapper.selectByPrimaryKey(s.getId()); if (stock==null)&#123; throw new LyException(ExceptionEnum.STOCK_NOT_FOND); &#125; s.setStock(stock.getStock()); &#125;*/ //查询库存 List&lt;Long&gt; ids = skuList.stream().map(Sku::getId).collect(Collectors.toList()); List&lt;Stock&gt; stockList = stockMapper.selectByIdList(ids); if (CollectionUtils.isEmpty(stockList)) &#123; throw new LyException(ExceptionEnum.STOCK_NOT_FOND); &#125; //把stock变成一个map,其key是sku的id,值是库存 Map&lt;Long, Integer&gt; stockMap = stockList.stream().collect(Collectors.toMap(Stock::getSkuId, Stock::getStock)); skuList.forEach(s -&gt; s.setStock(stockMap.get(s.getId()))); return skuList;&#125; 1.2.3 商品修改 分析 请求方式：PUT 请求路径：/ 请求参数：Spu对象 返回结果：无 GoodsController 123456 @PutMapping(\"goods\") public ResponseEntity&lt;Void&gt; editGoods(@RequestBody Spu spu)&#123; goodsService.editGoods(spu); return ResponseEntity.status(HttpStatus.NO_CONTENT).build(); &#125;&#125; GoodsService spu数据可以修改，但是SKU数据无法修改，因为有可能之前存在的SKU现在已经不存在了，或者以前的sku属性都不存在了。比如以前内存有4G，现在没了。 因此这里直接删除以前的SKU，然后新增即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Transactionalpublic void editGoods(Spu spu) &#123; if (spu.getId()==null)&#123; throw new LyException(ExceptionEnum.GOODS_ID_CANNOT_BE_NULL); &#125; // 查询以前sku Sku sku = new Sku(); sku.setSpuId(spu.getId()); List&lt;Sku&gt; skus = skuMapper.select(sku); // 如果以前存在，则删除 if(!CollectionUtils.isEmpty(skus)) &#123; List&lt;Long&gt; ids = skus.stream().map(s -&gt; s.getId()).collect(Collectors.toList()); // 删除以前库存 Example example = new Example(Stock.class); example.createCriteria().andIn(\"skuId\", ids); this.stockMapper.deleteByExample(example); // 删除以前的sku skuMapper.delete(sku); &#125; // 新增sku和库存 saveSkuAndStock(spu); // 更新spu spu.setLastUpdateTime(new Date()); spu.setCreateTime(null); spu.setValid(null); spu.setSaleable(null); spuMapper.updateByPrimaryKeySelective(spu); // 更新spu详情 spuDetailMapper.updateByPrimaryKeySelective(spu.getSpuDetail());&#125;private void saveSkuAndStock(Spu spu) &#123; //定义库存集合 List&lt;Stock&gt; stockList = new ArrayList&lt;Stock&gt;(); //保存sku List&lt;Sku&gt; skus = spu.getSkus(); for (Sku sku : skus) &#123; sku.setCreateTime(new Date()); sku.setLastUpdateTime(sku.getCreateTime()); sku.setSpuId(spu.getId()); skuMapper.insert(sku); //保存stock Stock stock = new Stock(); stock.setSkuId(sku.getId()); stock.setStock(sku.getStock()); stockList.add(stock); &#125; //批量新增stock stockMapper.insertList(stockList); spuDetailMapper.updateByPrimaryKeySelective(spu.getSpuDetail());&#125; 2.Elasticsearch入门之操作索引2.1 基本概念Elasticsearch也是基于Lucene的全文检索库，本质也是存储数据，很多概念与MySQL类似的。 对比关系： ​ 索引（indices）——————————– Databases 数据库 ​ 类型（type）——————————– Table 数据表 ​ 文档（Document）——————————– Row 行 ​ 字段（Field）——————————– Columns 列 详细说明： 概念 说明 索引库（indices) indices是index的复数，代表许多的索引， 类型（type） 类型是模拟mysql中的table概念，一个索引库下可以有不同类型的索引，比如商品索引，订单索引，其数据格式不同。不过这会导致索引库混乱，因此未来版本中会移除这个概念 文档（document） 存入索引库原始的数据。比如每一条商品信息，就是一个文档 字段（field） 文档中的属性 映射配置（mappings） 字段的数据类型、属性、是否索引、是否存储等特性 是不是与Lucene和solr中的概念类似。 另外，在SolrCloud中，有一些集群相关的概念，在Elasticsearch也有类似的： 索引集（Indices，index的复数）：逻辑上的完整索引 分片（shard）：数据拆分后的各个部分 副本（replica）：每个分片的复制 要注意的是：Elasticsearch本身就是分布式的，因此即便你只有一个节点，Elasticsearch默认也会对你的数据进行分片和副本操作，当你向集群添加新数据时，数据也会在新加入的节点中进行平衡。 2.2 创建索引2.2.1 语法Elasticsearch采用Rest风格API，因此其API就是一次http请求，你可以用任何工具发起http请求 创建索引的请求格式： 请求方式：PUT 请求路径：/索引库名 请求参数：json格式： 1234567PUT heima&#123; \"settings\": &#123; \"number_of_shards\": 3, \"number_of_replicas\": 2 &#125;&#125; settings：索引库的设置 number_of_shards：分片数量 number_of_replicas：副本数量 2.3 查看索引设置 语法 Get请求可以帮我们查看索引信息，格式： 1GET /索引库名 或者，我们可以使用*来查询所有索引库配置： 1GET * 2.4 删除索引删除索引使用DELETE请求 语法 1DELETE 索引库名 当然，我们也可以用HEAD请求，查看索引是否存在： 1HEAD 索引库名 2.5 映射配置索引有了，接下来肯定是添加数据。但是，在添加数据之前必须定义映射。 什么是映射？ ​ 映射是定义文档的过程，文档包含哪些字段，这些字段是否保存，是否索引，是否分词等 只有配置清楚，Elasticsearch才会帮我们进行索引库的创建（不一定） 2.5.1 创建映射字段 语法 请求方式依然是PUT 1234567891011PUT /索引库名/_mapping/类型名称&#123; \"properties\": &#123; \"字段名\": &#123; \"type\": \"类型\", \"index\": true， \"store\": true， \"analyzer\": \"分词器\" &#125; &#125;&#125; 类型名称：就是前面将的type的概念，类似于数据库中的不同表字段名：任意填写 ，可以指定许多属性，例如： type：类型，可以是text、long、short、date、integer、object等 index：是否索引，默认为true store：是否存储，默认为false analyzer：分词器，这里的ik_max_word即使用ik分词器 示例 发起请求： 12345678910111213141516PUT heima/_mapping/&#123; \"properties\": &#123; \"title\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\" &#125;, \"images\": &#123; \"type\": \"keyword\", \"index\": \"false\" &#125;, \"price\": &#123; \"type\": \"float\" &#125; &#125;&#125; 2.5.2 查看映射关系 语法： 1GET /索引库名/_mapping 示例： 1GET /heima/_mapping 2.5.3 字段属性详解2.5.3.1 typeElasticsearch中支持的数据类型非常丰富： 几个关键的： String类型，又分两种： text：可分词，不可参与聚合 keyword：不可分词，数据会作为完整字段进行匹配，可以参与聚合 Numerical：数值类型，分两类 基本数据类型：long、interger、short、byte、double、float、half_float 浮点数的高精度类型：scaled_float 需要指定一个精度因子，比如10或100。elasticsearch会把真实值乘以这个因子后存储，取出时再还原。 Date：日期类型 elasticsearch可以对日期格式化为字符串存储，但是建议我们存储为毫秒值，存储为long，节省空间。 2.5.3.2 indexindex影响字段的索引情况。 true：字段会被索引，则可以用来进行搜索。默认值就是true false：字段不会被索引，不能用来搜索 index的默认值就是true，也就是说你不进行任何配置，所有字段都会被索引。 但是有些字段是我们不希望被索引的，比如商品的图片信息，就需要手动设置index为false。 2.5.3.3 store是否将数据进行额外存储。 在学习lucene和solr时，我们知道如果一个字段的store设置为false，那么在文档列表中就不会有这个字段的值，用户的搜索结果中不会显示出来。 但是在Elasticsearch中，即便store设置为false，也可以搜索到结果。 原因是Elasticsearch在创建文档索引时，会将文档中的原始数据备份，保存到一个叫做_source的属性中。而且我们可以通过过滤_source来选择哪些要显示，哪些不显示。 而如果设置store为true，就会在_source以外额外存储一份数据，多余，因此一般我们都会将store设置为false，事实上，store的默认值就是false。 2.6 新增数据2.6.1 随机生成id通过POST请求，可以向一个已经存在的索引库中添加数据。 语法： 1234POST /索引库名/类型名&#123; \"key\":\"value\"&#125; 示例： 12345678POST /heima/_doc/&#123; \"title\":\"大米手机\", \"images\":\"http://image.leyou.com/12479122.jpg\", \"price\":2899.00, \"stock\": 200, \"saleable\":true&#125; 通过kibana查看数据： 1GET /heima/_search 2.6.2 自定义id如果我们想要自己新增的时候指定id，可以这么做： 1234POST /索引库名/类型/id值&#123; ...&#125; 示例： 12345678POST /heima/_doc/2&#123; \"title\":\"大米手机\", \"images\":\"http://image.leyou.com/12479122.jpg\", \"price\":2899.00, \"stock\": 200, \"saleable\":true&#125; 1GET heima/_doc/2 2.7 修改数据把刚才新增的请求方式改为PUT，就是修改了。不过修改必须指定id， id对应文档存在，则修改 id对应文档不存在，则新增 12345678PUT /heima/_doc/2&#123; \"title\":\"超大米手机\", \"images\":\"http://image.leyou.com/12479122.jpg\", \"price\":3899.00, \"stock\": 100, \"saleable\":true&#125; 2.8 删除数据删除使用DELETE请求，同样，需要根据id进行删除： 语法 1DELETE /索引库名/类型名/id值 示例： 1DELETE /heima/_doc/2 3.查询3.1 基本查询 基本语法 12345678GET /索引库名/_search&#123; \"query\":&#123; \"查询类型\":&#123; \"查询条件\":\"查询条件值\" &#125; &#125;&#125; 这里的query代表一个查询对象，里面可以有不同的查询属性 查询类型： 例如：match_all， match，term ， range 等等 查询条件：查询条件会根据类型的不同，写法也有差异，后面详细讲解 3.1.1 查询所有（match_all) 示例： 123456GET /heima/_search&#123; \"query\":&#123; \"match_all\": &#123;&#125; &#125;&#125; query：代表查询对象 match_all：代表查询所有 took：查询花费时间，单位是毫秒 time_out：是否超时 _shards：分片信息 hits：搜索结果总览对象 total：搜索到的总条数 max_score：所有结果中文档得分的最高分 hits：搜索结果的文档对象数组，每个元素是一条搜索到的文档信息 _index：索引库 _type：文档类型 _id：文档id _score：文档得分 _source：文档的源数据 3.1.2 匹配查询（match） or关系 match类型查询，会把查询条件进行分词，然后进行查询,多个词条之间是or的关系 and关系 某些情况下，我们需要更精确查找，我们希望这个关系变成and，可以这样做： 1234567891011GET /heima/_search&#123; \"query\": &#123; \"match\": &#123; \"title\": &#123; \"query\": \"大米手机\", \"operator\": \"and\" &#125; &#125; &#125;&#125; or和and之间？ 在 or 与 and 间二选一有点过于非黑即白。 如果用户给定的条件分词后有 5 个查询词项，想查找只包含其中 4 个词的文档，该如何处理？将 operator 操作符参数设置成 and 只会将此文档排除。 有时候这正是我们期望的，但在全文搜索的大多数应用场景下，我们既想包含那些可能相关的文档，同时又排除那些不太相关的。换句话说，我们想要处于中间某种结果。 match 查询支持 minimum_should_match 最小匹配参数， 这让我们可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字，更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量： 1234567891011GET /heima/_search&#123; \"query\":&#123; \"match\":&#123; \"title\":&#123; \"query\":\"小米曲面电视\", \"minimum_should_match\": \"75%\" &#125; &#125; &#125;&#125; 本例中，搜索语句可以分为3个词，如果使用and关系，需要同时满足3个词才会被搜索到。这里我们采用最小品牌数：75%，那么也就是说只要匹配到总词条数量的75%即可，这里3*75% 约等于2。所以只要包含2个词条就算满足条件了。 3.1.3 多字段查询（multi_match）multi_match与match类似，不同的是它可以在多个字段中查询 123456789GET /heima/_search&#123; \"_source\": [\"title\", \"price\"], \"query\": &#123; \"match\": &#123; \"title\": \"大米手机\" &#125; &#125;&#125; 本例中，我们会在title字段和price字段中查询大米手机这个词 3.1.4 词条匹配(term)term 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些未分词的字符串 12345678GET /heima/_search&#123; \"query\": &#123; \"term\": &#123; \"price\": \"2899\" &#125; &#125;&#125; 3.1.5 多词条精确匹配(terms)terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件： 12345678GET /heima/_search&#123; \"query\":&#123; \"terms\":&#123; \"price\":[2699.00,2899.00,3899.00] &#125; &#125;&#125; 3.2 结果过滤默认情况下，elasticsearch在搜索的结果中，会把文档中保存在_source的所有字段都返回。 如果我们只想获取其中的部分字段，我们可以添加_source的过滤 3.2.1直接指定字段示例： 123456789GET /heima/_search&#123; \"_source\": [\"title\", \"price\"], \"query\": &#123; \"match\": &#123; \"title\": \"大米手机\" &#125; &#125;&#125; 3.2.2 指定includes和excludes我们也可以通过： includes：来指定想要显示的字段 excludes：来指定不想要显示的字段 二者都是可选的。 示例： 1234567891011GET /heima/_search&#123; \"_source\": &#123; \"excludes\": \"images\" &#125;, \"query\": &#123; \"match\": &#123; \"title\": \"大米手机\" &#125; &#125;&#125; 3.3 高级查询3.3.1 布尔组合（bool)bool把各种其它查询通过must（与）、must_not（非）、should（或）的方式进行组合 12345678910GET /heima/_search&#123; \"query\":&#123; \"bool\":&#123; \"must\": &#123; \"match\": &#123; \"title\": \"大米\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"title\": \"电视\" &#125;&#125;, \"should\": &#123; \"match\": &#123; \"title\": \"手机\" &#125;&#125; &#125; &#125;&#125; 结果： 3.3.2 范围查询(range)range 查询找出那些落在指定区间内的数字或者时间 1234567891011GET /heima/_search&#123; \"query\": &#123; \"range\": &#123; \"price\": &#123; \"gte\": 2000, \"lte\": 2800 &#125; &#125; &#125;&#125; range查询允许以下字符： 操作符 说明 gt 大于 gte 大于等于 lt 小于 lte 小于等于 3.3.3 模糊查询(fuzzy)fuzzy 查询是 term 查询的模糊等价。它允许用户搜索词条与实际词条的拼写出现偏差，但是偏差的编辑距离不得超过2： 12345678GET /heima/_search&#123; \"query\": &#123; \"fuzzy\": &#123; \"title\": \"appla\" &#125; &#125;&#125; 上面的查询，也能查询到apple手机 我们可以通过fuzziness来指定允许的编辑距离： 1234567891011GET /heima/_search&#123; \"query\": &#123; \"fuzzy\": &#123; \"title\": &#123; \"value\":\"appla\", \"fuzziness\":1 &#125; &#125; &#125;&#125; 3.4 过滤(filter) 条件查询中进行过滤 所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter方式： 1234567891011GET /heima/_search&#123; \"query\":&#123; \"bool\":&#123; \"must\":&#123; \"match\": &#123; \"title\": \"大米手机\" &#125;&#125;, \"filter\":&#123; \"range\":&#123;\"price\":&#123;\"gt\":2000.00,\"lt\":3800.00&#125;&#125; &#125; &#125; &#125;&#125; 注意：filter中还可以再次进行bool组合条件过滤。 无查询条件，直接过滤 如果一次查询只有过滤，没有查询条件，不希望进行评分，我们可以使用constant_score取代只有 filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。 123456789GET /heima/_search&#123; \"query\":&#123; \"constant_score\": &#123; \"filter\": &#123; \"range\":&#123;\"price\":&#123;\"gt\":2000.00,\"lt\":3000.00&#125;&#125; &#125; &#125;&#125; 3.5 排序3.4.1 单字段排序sort 可以让我们按照不同的字段进行排序，并且通过order指定排序的方式 123456789101112131415GET /heima/_search&#123; \"query\": &#123; \"match\": &#123; \"title\": \"大米手机\" &#125; &#125;, \"sort\": [ &#123; \"price\": &#123; \"order\": \"desc\" &#125; &#125; ]&#125; 3.4.2 多字段排序假定我们想要结合使用 price和 _score（得分） 进行查询，并且匹配的结果首先按照价格排序，然后按照相关性得分排序： 123456789101112131415GET /goods/_search&#123; \"query\":&#123; \"bool\":&#123; \"must\":&#123; \"match\": &#123; \"title\": \"小米手机\" &#125;&#125;, \"filter\":&#123; \"range\":&#123;\"price\":&#123;\"gt\":200000,\"lt\":300000&#125;&#125; &#125; &#125; &#125;, \"sort\": [ &#123; \"price\": &#123; \"order\": \"desc\" &#125;&#125;, &#123; \"_score\": &#123; \"order\": \"desc\" &#125;&#125; ]&#125; 4. 聚合aggregations聚合可以让我们极其方便的实现对数据的统计、分析。例如： 什么品牌的手机最受欢迎？ 这些手机的平均价格、最高价格、最低价格？ 这些手机每月的销售情况如何？ 实现这些统计功能的比数据库的sql要方便的多，而且查询速度非常快，可以实现实时搜索效果。 4.1 基本概念Elasticsearch中的聚合，包含多种类型，最常用的两种，一个叫桶，一个叫度量： 桶（bucket） 桶的作用，是按照某种方式对数据进行分组，每一组数据在ES中称为一个桶，例如我们根据国籍对人划分，可以得到中国桶、英国桶，日本桶……或者我们按照年龄段对人进行划分：010,1020,2030,3040等。 Elasticsearch中提供的划分桶的方式有很多： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 …… 综上所述，我们发现bucket aggregations 只负责对数据进行分组，并不进行计算，因此往往bucket中往往会嵌套另一种聚合：metrics aggregations即度量 度量（metrics） 分组完成以后，我们一般会对组中的数据进行聚合运算，例如求平均值、最大、最小、求和等，这些在ES中称为度量 比较常用的一些度量聚合方式： Avg Aggregation：求平均值 Max Aggregation：求最大值 Min Aggregation：求最小值 Percentiles Aggregation：求百分比 Stats Aggregation：同时返回avg、max、min、sum、count等 Sum Aggregation：求和 Top hits Aggregation：求前几 Value Count Aggregation：求总数 …… 为了测试聚合，我们先批量导入一些数据 1234567891011121314151617PUT /cars&#123; \"settings\": &#123; \"number_of_shards\": 1, \"number_of_replicas\": 0 &#125;, \"mappings\": &#123; \"properties\": &#123; \"color\": &#123; \"type\": \"keyword\" &#125;, \"make\": &#123; \"type\": \"keyword\" &#125; &#125; &#125;&#125; 注意：在ES中，需要进行聚合、排序、过滤的字段其处理方式比较特殊，因此不能被分词。这里我们将color和make这两个文字类型的字段设置为keyword类型，这个类型不会被分词，将来就可以参与聚合 1234567891011121314151617POST /cars/_bulk&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 10000, \"color\" : \"red\", \"make\" : \"honda\", \"sold\" : \"2014-10-28\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 20000, \"color\" : \"red\", \"make\" : \"honda\", \"sold\" : \"2014-11-05\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 30000, \"color\" : \"green\", \"make\" : \"ford\", \"sold\" : \"2014-05-18\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 15000, \"color\" : \"blue\", \"make\" : \"toyota\", \"sold\" : \"2014-07-02\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 12000, \"color\" : \"green\", \"make\" : \"toyota\", \"sold\" : \"2014-08-19\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 20000, \"color\" : \"red\", \"make\" : \"honda\", \"sold\" : \"2014-11-05\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 80000, \"color\" : \"red\", \"make\" : \"bmw\", \"sold\" : \"2014-01-01\" &#125;&#123; \"index\": &#123;&#125;&#125;&#123; \"price\" : 25000, \"color\" : \"blue\", \"make\" : \"ford\", \"sold\" : \"2014-02-12\" &#125; 4.2 聚合为桶首先，我们按照 汽车的颜色make来划分桶 1234567891011GET /cars/_search&#123; \"size\" : 0, \"aggs\" : &#123; \"popular_brand\" : &#123; \"terms\" : &#123; \"field\" : \"make\" &#125; &#125; &#125;&#125; size： 查询条数，这里设置为0，因为我们不关心搜索到的数据，只关心聚合结果，提高效率 aggs：声明这是一个聚合查询，是aggregations的缩写 popular_brand：给这次聚合起一个名字，任意。 terms：划分桶的方式，这里是根据词条划分 field：划分桶的字段 4.3 桶内度量前面的例子告诉我们每个桶里面的文档数量，这很有用。 但通常，我们的应用需要提供更复杂的文档度量。 例如，每种颜色汽车的平均价格是多少？ 因此，我们需要告诉Elasticsearch使用哪个字段，使用何种度量方式进行运算，这些信息要嵌套在桶内，度量的运算会基于桶内的文档进行 现在，我们为刚刚的聚合结果添加 求价格平均值的度量： 123456789101112131415161718GET /cars/_search&#123; \"size\": 0, \"aggs\": &#123; \"popular_brand\": &#123; \"terms\": &#123; \"field\": \"make\" &#125;, \"aggs\": &#123; \"price_avg\": &#123; \"avg\": &#123; \"field\": \"price\" &#125; &#125; &#125; &#125; &#125;&#125; 结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&#123; \"took\" : 0, \"timed_out\" : false, \"_shards\" : &#123; \"total\" : 1, \"successful\" : 1, \"skipped\" : 0, \"failed\" : 0 &#125;, \"hits\" : &#123; \"total\" : &#123; \"value\" : 8, \"relation\" : \"eq\" &#125;, \"max_score\" : null, \"hits\" : [ ] &#125;, \"aggregations\" : &#123; \"popular_brand\" : &#123; \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ &#123; \"key\" : \"honda\", \"doc_count\" : 3, \"price_avg\" : &#123; \"value\" : 16666.666666666668 &#125; &#125;, &#123; \"key\" : \"ford\", \"doc_count\" : 2, \"price_avg\" : &#123; \"value\" : 27500.0 &#125; &#125;, &#123; \"key\" : \"toyota\", \"doc_count\" : 2, \"price_avg\" : &#123; \"value\" : 13500.0 &#125; &#125;, &#123; \"key\" : \"bmw\", \"doc_count\" : 1, \"price_avg\" : &#123; \"value\" : 80000.0 &#125; &#125; ] &#125; &#125;&#125; hits：查询结果为空，因为我们设置了size为0 aggregations：聚合的结果 popular_colors：我们定义的聚合名称 buckets：查找到的桶，每个不同的color字段值都会形成一个桶 key：这个桶对应的color字段的值 doc_count：这个桶中的文档数量 aggs：我们在上一个aggs(popular_colors)中添加新的aggs。可见度量也是一个聚合,度量是在桶内的聚合 avg_price：聚合的名称 avg：度量的类型，这里是求平均值 field：度量运算的字段 4.4 划分桶的其它方式前面讲了，划分桶的方式有很多，例如： Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组 Histogram Aggregation：根据数值阶梯分组，与日期类似 Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组 Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组 刚刚的案例中，我们采用的是Terms Aggregation，即根据词条划分桶。 接下来，我们再学习几个比较实用的： 4.4.1 阶梯分桶Histogram 原理： histogram是把数值类型的字段，按照一定的阶梯大小进行分组。你需要指定一个阶梯值（interval）来划分阶梯大小。 举例： 比如你有价格字段，如果你设定interval的值为200，那么阶梯就会是这样的： 0，200，400，600，… 上面列出的是每个阶梯的key，也是区间的启点。 如果一件商品的价格是450，会落入哪个阶梯区间呢？计算公式如下： 1bucket_key = Math.floor((value - offset) / interval) * interval + offset value：就是当前数据的值，本例中是450 offset：起始偏移量，默认为0 interval：阶梯间隔，比如200 因此你得到的key = Math.floor((450 - 0) / 200) * 200 + 0 = 400 操作一下： 比如，我们对汽车的价格进行分组，指定间隔interval为5000： 12345678910111213GET /cars/_search&#123; \"size\":0, \"aggs\":&#123; \"price\":&#123; \"histogram\": &#123; \"field\": \"price\", \"interval\": 5000, \"min_doc_count\": 1 &#125; &#125; &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(七.商品详情及静态化(Thymeleaf))","slug":"微服务项目总结(七.商品详情及静态化(Thymeleaf))","date":"2021-05-08T13:19:59.227Z","updated":"2020-04-29T02:44:38.061Z","comments":true,"path":"11565/","link":"","permalink":"http://tonymua.top/11565/","excerpt":"1.商品详情当用户搜索到商品，肯定会点击查看，就会进入商品详情页，接下来我们完成商品详情页的展示， 1.1商品详情页服务商品详情浏览量比较大，并发高，我们会独立开启一个微服务，用来展示商品详情。 1.1.1 创建module商品的详情页服务，命名为：leyou-page 1.1.2 pom依赖","text":"1.商品详情当用户搜索到商品，肯定会点击查看，就会进入商品详情页，接下来我们完成商品详情页的展示， 1.1商品详情页服务商品详情浏览量比较大，并发高，我们会独立开启一个微服务，用来展示商品详情。 1.1.1 创建module商品的详情页服务，命名为：leyou-page 1.1.2 pom依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;leyou&lt;/artifactId&gt; &lt;groupId&gt;com.leyou&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-page&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.leyou.service&lt;/groupId&gt; &lt;artifactId&gt;ly-item-interface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1.1.3 编写启动类12345678@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class LyGoodsWebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LyGoodsWebApplication.class); &#125;&#125; 1.1.4 application.yml文件1234567891011server: port: 8084spring: application: name: page-service thymeleaf: cache: falseeureka: client: service-url: defaultZone: http://127.0.0.1:8080/eureka 1.2 页面跳转1.2.1 修改页面跳转路径我们应该跳转到对应的商品的详情页才对。 那么问题来了：商品详情页是一个SKU？还是多个SKU的集合？ 通过详情页的预览，我们知道它是多个SKU的集合，即SPU。 所以，页面跳转时，我们应该携带SPU的id信息。 例如：http://www.leyou.com/item/2314123.html 这里就采用了路径占位符的方式来传递spu的id，我们打开search.html，修改其中的商品路径： 1.2.2 nginx反向代理12345location /item &#123; proxy_pass http://127.0.0.1:8084; proxy_connect_timeout 600; proxy_read_timeout 600; &#125; 把以/item开头的请求，代理到我们的8084端口 1.3 封装模型数据我们已知的条件是传递来的spu的id，我们需要根据spu的id查询到下面的数据： spu信息 spu的详情 spu下的所有sku 品牌 商品三级分类 商品规格参数、规格参数组 1.3.1 商品微服务提供接口1.3.1.1 查询spu以上所需数据中，根据id查询spu的接口目前还没有，我们需要在商品微服务中提供这个接口： GoodsApi 12@GetMapping(\"spu/&#123;id&#125;\")Spu querySpuById(@PathVariable(\"id\") Long id); GoodsController 1234@GetMapping(\"spu/&#123;id&#125;\")public ResponseEntity&lt;Spu&gt; querySpuById(@PathVariable(\"id\")Long id)&#123; return ResponseEntity.ok(goodsService.querySpuById(id));&#125; GoodsService 1234567public Spu querySpuById(Long id) &#123; Spu spu = spuMapper.selectByPrimaryKey(id); //查询sku spu.setSkus(querySkuBySpuId(id)); spu.setSpuDetail(querySpuDetailById(id)); return spu;&#125; 1.3.1.2 查询规格参数组我们在页面展示规格时，需要按组展示： 组内有多个参数，为了方便展示。我们在leyou-item-service中提供一个接口，查询规格组，同时在规格组内的所有参数。 拓展SpecGroup类： 我们在SpecGroup中添加一个SpecParam的集合，保存该组下所有规格参数 123456789101112@Data@Table(name = \"tb_spec_group\")public class SpecGroup &#123; @Id @KeySql(useGeneratedKeys = true) private Long id; private Long cid; private String name; @Transient private List&lt;SpecParam&gt; params;&#125; 然后提供查询接口： SpecificationAPI 12@GetMapping(\"spec/group\") List&lt;SpecGroup&gt; queryListByCid(@RequestParam(\"cid\")Long cid); SpecificationController 1234@GetMapping(\"group\")public ResponseEntity&lt;List&lt;SpecGroup&gt;&gt; queryListByCid(@RequestParam(\"cid\")Long cid)&#123; return ResponseEntity.ok(specificationService.queryListByCid(cid));&#125; SpecificationService 1234567891011121314151617181920public List&lt;SpecGroup&gt; queryListByCid(Long cid) &#123; //查询规格组 List&lt;SpecGroup&gt; specGroups = queryGroupByCid(cid); //查询组内参数 List&lt;SpecParam&gt; specParams = queryParamList(null, cid, null); //先把规格参数变成map,map的key是规格组id,map的值是组下的所有参数 Map&lt;Long,List&lt;SpecParam&gt;&gt; map=new HashMap&lt;&gt;(); for (SpecParam specParam : specParams) &#123; if (!map.containsKey(specParam.getId()))&#123; //这个组id在map中已经存在,新增一个list map.put(specParam.getGroupId(),new ArrayList&lt;&gt;()); &#125; map.get(specParam.getGroupId()).add(specParam); &#125; //填充param到group for (SpecGroup specGroup : specGroups) &#123; specGroup.setParams(map.get(specGroup.getId())); &#125; return specGroups;&#125; 1.3.2 创建FeignClient拷贝ly-search下的client包 1.3.3 封装数据模型我们创建一个GoodsService，在里面来封装数据模型。 这里要查询的数据： SPU SpuDetail SKU集合 商品分类 这里值需要分类的id和name就够了，因此我们查询到以后自己需要封装数据 品牌对象 规格组 查询规格组的时候，把规格组下所有的参数也一并查出，上面提供的接口中已经实现该功能，我们直接调 sku的特有规格参数 在页面渲染时，需要知道参数的名称，我们就需要把id和name一一对应起来，因此需要额外查询sku的特有规格参数，然后变成一个id:name的键值对格式。也就是一个Map，方便将来根据id查找！ PageService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4j@Servicepublic class PageService &#123; @Autowired private GoodsClient goodsClient; @Autowired private BrandClient brandClient; @Autowired private CategoryClient categoryClient; @Autowired private SpecificationClient specificationClient; @Autowired private TemplateEngine templateEngine; public Map&lt;String, Object&gt; loadModel(Long spuId) &#123; Map&lt;String, Object&gt; model = new HashMap&lt;&gt;(); // 查询spu Spu spu = goodsClient.querySpuById(spuId); // 查询spu详情 SpuDetail spuDetail = spu.getSpuDetail(); // 查询sku List&lt;Sku&gt; skus = spu.getSkus(); // 查询品牌 Brand brand = brandClient.queryNameById(spu.getBrandId()); // 查询分类 List&lt;Category&gt; categories = categoryClient.queryCategoryByIds(Arrays.asList(spu.getCid1(),spu.getCid2(),spu.getCid3())); // 查询规格参数 List&lt;SpecGroup&gt; groups = specificationClient.queryListByCid(spu.getCid3()); // 查询所有特有规格参数 // 查询所有特有规格参数 List&lt;SpecParam&gt; specParams = this.specificationClient.queryParamList(null, spu.getCid3(), null); // 处理规格参数 Map&lt;Long, String&gt; paramMap = new HashMap&lt;&gt;(); specParams.forEach(param-&gt;&#123; paramMap.put(param.getId(), param.getName()); &#125;); model.put(\"spu\", spu); model.put(\"spuDetail\", spuDetail); model.put(\"skus\", skus); model.put(\"brand\", brand); model.put(\"categories\", categories); model.put(\"groups\", groups); model.put(\"params\", paramMap); return model; &#125;&#125; 然后在controller中把数据放入model： PageController 12345678910111213141516@Controllerpublic class PageController &#123; @Autowired private PageService pageService; @GetMapping(\"item/&#123;id&#125;.html\") public String toItemPage(@PathVariable(\"id\")Long spuId, Model model)&#123; //查询模型数据 Map&lt;String,Object&gt; attributes=pageService.loadModel(spuId); //准备模型数据 model.addAllAttributes(attributes); //返回视图 return \"item\"; &#125;&#125; 2.页面静态化2.1 简介2.1.1 问题分析现在，我们的页面是通过Thymeleaf模板引擎渲染后返回到客户端。在后台需要大量的数据查询，而后渲染得到HTML页面。会对数据库造成压力，并且请求的响应时间过长，并发能力不高。 大家能想到什么办法来解决这个问题？ 首先我们能想到的就是缓存技术，比如之前学习过的Redis。不过Redis适合数据规模比较小的情况。假如数据量比较大，例如我们的商品详情页。每个页面如果10kb，100万商品，就是10GB空间，对内存占用比较大。此时就给缓存系统带来极大压力，如果缓存崩溃，接下来倒霉的就是数据库了。 所以缓存并不是万能的，某些场景需要其它技术来解决，比如静态化。 2.1.2 什么是静态化静态化是指把动态生成的HTML页面变为静态内容保存，以后用户的请求到来，直接访问静态页面，不再经过服务的渲染。 而静态的HTML页面可以部署在nginx中，从而大大提高并发能力，减小tomcat压力。 2.1.3 如何实现静态化目前，静态化页面都是通过模板引擎来生成，而后保存到nginx服务器来部署。常用的模板引擎比如： Freemarker Velocity Thymeleaf 我们之前就使用的Thymeleaf，来渲染html返回给用户。Thymeleaf除了可以把渲染结果写入Response，也可以写到本地文件，从而实现静态化。 2.2 Thymeleaf实现静态化2.2.1 概念先说下Thymeleaf中的几个概念： Context：运行上下文 TemplateResolver：模板解析器 TemplateEngine：模板引擎 Context 上下文： 用来保存模型数据，当模板引擎渲染时，可以从Context上下文中获取数据用于渲染。 当与SpringBoot结合使用时，我们放入Model的数据就会被处理到Context，作为模板渲染的数据使用。 TemplateResolver 模板解析器：用来读取模板相关的配置，例如：模板存放的位置信息，模板文件名称，模板文件的类型等等。 当与SpringBoot结合时，TemplateResolver已经由其创建完成，并且各种配置也都有默认值，比如模板存放位置，其默认值就是：templates。比如模板文件类型，其默认值就是html。 TemplateEngine 模板引擎：用来解析模板的引擎，需要使用到上下文、模板解析器。分别从两者中获取模板中需要的数据，模板文件。然后利用内置的语法规则解析，从而输出解析后的文件。来看下模板引擎进行处理的函数： 1templateEngine.process(\"模板名\", context, writer); 三个参数： 模板名称 上下文：里面包含模型数据 writer：输出目的地的流 在输出时，我们可以指定输出的目的地，如果目的地是Response的流，那就是网络响应。如果目的地是本地文件，那就实现静态化了。 而在SpringBoot中已经自动配置了模板引擎，因此我们不需要关心这个。现在我们做静态化，就是把输出的目的地改成本地文件即可！ 2.2.2 具体实现PageService 12345678910111213141516171819202122232425public void createHtml(Long spuId)&#123; //上下文 Context context=new Context(); context.setVariables(loadModel(spuId)); //输出流 File dest = new File(\"E:\\\\tools\\\\nginx-1.14.0\\\\html\\\\item\", spuId + \".html\"); if (dest.exists())&#123; dest.delete(); &#125; try (PrintWriter writer = new PrintWriter(dest, \"UTF-8\")) &#123; //生成html templateEngine.process(\"item\",context,writer); &#125;catch (Exception e)&#123; log.error(\"[静态页面] 生成静态页面异常:\",e); &#125;&#125;public void asyncExcute(Long spuId) &#123; ThreadUtils.execute(()-&gt;createHtml(spuId)); /*ThreadUtils.execute(new Runnable() &#123; @Override public void run() &#123; createHtml(spuId); &#125; &#125;);*/&#125; 线程工具类： 12345678public class ThreadUtils &#123; private static final ExecutorService es = Executors.newFixedThreadPool(10); public static void execute(Runnable runnable) &#123; es.submit(runnable); &#125;&#125; 2.2.3 什么时候创建静态文件我们编写好了创建静态文件的service，那么问题来了：什么时候去调用它呢 我们编写好了创建静态文件的service，那么问题来了：什么时候去调用它呢 想想这样的场景： 假如大部分的商品都有了静态页面。那么用户的请求都会被nginx拦截下来，根本不会到达我们的leyou-goods-web服务。只有那些还没有页面的请求，才可能会到达这里。 因此，如果请求到达了这里，我们除了返回页面视图外，还应该创建一个静态页面，那么下次就不会再来麻烦我们了。 所以，我们在GoodsController中添加逻辑，去生成静态html文件： 123456789101112131415161718@Controllerpublic class PageController &#123; @Autowired private PageService pageService; @GetMapping(\"item/&#123;id&#125;.html\") public String toItemPage(@PathVariable(\"id\")Long spuId, Model model)&#123; //查询模型数据 Map&lt;String,Object&gt; attributes=pageService.loadModel(spuId); //准备模型数据 model.addAllAttributes(attributes); // 页面静态化 pageService.asyncExcute(spuId); //返回视图 return \"item\"; &#125;&#125; 注意：生成html 的代码不能对用户请求产生影响，所以这里我们使用额外的线程进行异步创建。 2.3 nginx代理静态页面接下来，我们修改nginx，让它对商品请求进行监听，指向本地静态页面，如果本地没找到，才进行反向代理： 1234567891011121314151617181920212223server &#123; listen 80; server_name www.leyou.com; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location /item &#123; # 先找本地 root html; if (!-f $request_filename) &#123; #请求的文件不存在，就反向代理 proxy_pass http://127.0.0.1:8084; break; &#125; &#125; location / &#123; proxy_pass http://127.0.0.1:9002; proxy_connect_timeout 600; proxy_read_timeout 600; &#125;&#125; 重启测试：发现请求速度得到了极大提升","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微服务项目总结(一.通用异常处理, 分类查询, 品牌查询)","slug":"微服务项目总结(一.通用异常处理, 分类查询, 品牌查询)","date":"2021-05-08T13:19:59.226Z","updated":"2020-04-29T05:54:48.581Z","comments":true,"path":"55497/","link":"","permalink":"http://tonymua.top/55497/","excerpt":"1.通用异常处理场景模拟 加入我们做新增商品，需要接收下面的参数： 123price：价格name：名称12 然后对数据做简单校验： 价格不能为空 新增时，自动生成 ID ，然后随商品对象一起返回","text":"1.通用异常处理场景模拟 加入我们做新增商品，需要接收下面的参数： 123price：价格name：名称12 然后对数据做简单校验： 价格不能为空 新增时，自动生成 ID ，然后随商品对象一起返回 实体类： 12345678910package com.leyou.item.pojo;import lombok.Data;@Datapublic class Item &#123; private Integer id; private String name; private Long price;&#125; service: 123456789101112131415161718package com.leyou.item.service;import com.leyou.item.pojo.Item;import org.springframework.stereotype.Service;import java.util.Random;@Servicepublic class ItemService &#123; public Item saveItem(Item item)&#123; // 商品新增 int id = new Random().nextInt(100); item.setId(id); return item; &#125;&#125; ExceptionEnum: 异常 枚举 123456789@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ExceptionEnum &#123; PRICE_CANNOT_BE_NULL(400,\"价格不能为空\"), ; private int code; private String msg;&#125; LyException：自定义异常 123456@NoArgsConstructor@AllArgsConstructor@Getterpublic class LyException extends RuntimeException &#123; private ExceptionEnum exceptionEnum;&#125; ExceptionResult：异常结果 123456789101112@Datapublic class ExceptionResult &#123; private int status; private String message; private Long timetamp; public ExceptionResult(ExceptionEnum em) &#123; this.status = em.getCode(); this.message =em.getMsg(); this.timetamp = System.currentTimeMillis(); &#125;&#125; CommonExceptionHandler: 通用的异常处理 添加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;&lt;/dependency&gt; 1234567@ControllerAdvicepublic class CommonExceptionHandler &#123; @ExceptionHandler(LyException.class) public ResponseEntity&lt;ExceptionResult&gt; handleException(LyException e)&#123; return ResponseEntity.status(e.getExceptionEnum().getCode()).body(new ExceptionResult(e.getExceptionEnum())); &#125;&#125; ItemController: 123456789101112131415161718@Controller@RequestMapping(\"item\")public class ItemController &#123; @Autowired private ItemService itemService; @PostMapping @ResponseBody public ResponseEntity&lt;Item&gt; saveItem(Item item)&#123; //校验价格是否为空 if (item.getPrice()==null)&#123;// return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(null); throw new LyException(ExceptionEnum.PRICE_CANNOT_BE_NULL); &#125; return ResponseEntity.status(HttpStatus.CREATED).body(itemService.saveItem(item)); &#125;&#125; 2.商品分类查询2.1 需求实现导入通用mapper依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-core&lt;/artifactId&gt; &lt;version&gt;1.1.5&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在ly-item-interface中添加category实体类： Category 1234567891011@Table(name=\"tb_category\")@Datapublic class Category &#123; @Id @KeySql(useGeneratedKeys=true) private Long id; private String name; private Long parentId; private Boolean isParent; // 注意isParent生成的getter和setter方法需要手动加上Is private Integer sort;&#125; 我们使用通用mapper来简化开发： 12public interface CategoryMapper extends Mapper&lt;Category&gt; &#123;&#125; 要注意，我们并没有在mapper接口上声明@Mapper注解，那么mybatis如何才能找到接口呢？ 我们在启动类上添加一个扫描包功能： 12345678@SpringBootApplication@EnableDiscoveryClient@MapperScan(\"lwy.mapper\")public class LyItemApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(LyItemApplication.class); &#125;&#125; CategoryService 123456789101112131415@Servicepublic class CategoryService &#123; @Autowired private CategoryMapper categoryMapper; public List&lt;Category&gt; queryCategoryListByPid(Long pid) &#123; Category category=new Category(); category.setParentId(pid); List&lt;Category&gt; list = categoryMapper.select(category); if (CollectionUtils.isEmpty(list))&#123; throw new LyException(ExceptionEnum.CATEGORY_NOT_FOND); &#125; return list; &#125;&#125; 在ExceptionEnum中定义CATEGORY_NOT_FOND异常 123456789@Getter@NoArgsConstructor@AllArgsConstructorpublic enum ExceptionEnum &#123; CATEGORY_NOT_FOND(404,\"暂时没有分类信息\") ; private int code; private String msg;&#125; CategoryController 1234567891011@RestController@RequestMapping(\"category\")public class CategoryController &#123; @Autowired private CategoryService categoryService; @GetMapping(\"list\") public ResponseEntity&lt;List&lt;Category&gt;&gt; queryCategoryListByPid(@RequestParam(value = \"pid\",defaultValue = \"0\")Long pid)&#123; return ResponseEntity.ok(categoryService.queryCategoryListByPid(pid)); &#125;&#125; 浏览器直接访问http://localhost:8081/category/list成功，但是通过http://manage.leyou.com/#/item/category访问却报错，什么原因？ 3.跨域问题跨域：浏览器对于javascript的同源策略的限制 。 以下情况都属于跨域： 跨域原因说明 示例 域名不同 www.jd.com 与 www.taobao.com 域名相同，端口不同 www.jd.com:8080 与 www.jd.com:8081 二级域名不同 item.jd.com 与 miaosha.jd.com 如果域名和端口都相同，但是请求路径不同，不属于跨域，如： www.jd.com/item www.jd.com/goods 而我们刚才是从manage.leyou.com去访问api.leyou.com，这属于二级域名不同，跨域了。 3.1 为什么有跨域问题？跨域不一定会有跨域问题。 因为跨域问题是浏览器对于ajax请求的一种安全限制：一个页面发起的ajax请求，只能是与当前页域名相同的路径，这能有效的阻止跨站攻击。 因此：跨域问题 是针对ajax的一种限制。 但是这却给我们的开发带来了不便，而且在实际生产环境中，肯定会有很多台服务器之间交互，地址和端口都可能不同，怎么办？ 3.2 解决跨域问题的方案目前比较常用的跨域解决方案有3种： Jsonp 最早的解决方案，利用script标签可以跨域的原理实现。 限制： 需要服务的支持 只能发起GET请求 nginx反向代理 思路是：利用nginx把跨域反向代理为不跨域，支持各种请求方式 缺点：需要在nginx进行额外配置，语义不清晰 CORS 规范化的跨域请求解决方案，安全可靠。 优势： 在服务端进行控制是否允许跨域，可自定义规则 支持各种请求方式 缺点： 会产生额外的请求 3.3 采用cors的跨域方案 Access-Control-Request-Method：接下来会用到的请求方式，比如PUT Access-Control-Request-Headers：会额外用到的头信息 预检请求的响应 服务的收到预检请求，如果许可跨域，会发出响应： 除了Access-Control-Allow-Origin和Access-Control-Allow-Credentials以外，这里又额外多出3个头： Access-Control-Allow-Methods：允许访问的方式 Access-Control-Allow-Headers：允许携带的头 Access-Control-Max-Age：本次许可的有效时长，单位是秒，过期之前的ajax请求就无需再次进行预检了 3.4 解决跨域问题在leyou-gateway中编写一个配置类，并且注册CorsFilter： GlobalCorsConfig 12345678910111213141516171819202122232425262728293031323334353637import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;@Configurationpublic class GlobalCorsConfig &#123; @Bean public CorsFilter corsFilter() &#123; //1.添加CORS配置信息 CorsConfiguration config = new CorsConfiguration(); //1) 允许的域,不要写*，否则cookie就无法使用了 config.addAllowedOrigin(\"http://manage.leyou.com\"); //2) 是否发送Cookie信息 config.setAllowCredentials(true); //3) 允许的请求方式 config.addAllowedMethod(\"OPTIONS\"); config.addAllowedMethod(\"HEAD\"); config.addAllowedMethod(\"GET\"); config.addAllowedMethod(\"PUT\"); config.addAllowedMethod(\"POST\"); config.addAllowedMethod(\"DELETE\"); config.addAllowedMethod(\"PATCH\"); // 4）允许的头信息 config.addAllowedHeader(\"*\"); // 5) 设置有效时长 config.setMaxAge(3600L); //2.添加映射路径，我们拦截一切请求 UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration(\"/**\", config); //3.返回新的CorsFilter. return new CorsFilter(configSource); &#125;&#125; 如果增加zuul前缀后会导致header中出现Access-Control-Allow-Credentials等属性重复的异常，需要在zuul中设置header忽略。参数配置如下 123zuul: sensitiveHeaders: Authorization ignored-headers: Access-Control-Allow-Credentials,Access-Control-Allow-Origin,Vary,X-Frame-Options 4.品牌查询Brand 12345678910@Data@Table(name = \"tb_brand\")public class Brand &#123; @Id @KeySql(useGeneratedKeys = true) private Long id; private String name; private String image; private Character letter;&#125; BrandMapper 12public interface BrandMapper extends Mapper&lt;Brand&gt; &#123;&#125; 编写controller先思考四个问题，这次没有前端代码，需要我们自己来设定 请求方式：查询，肯定是Get 请求路径：分页查询，/brand/page 请求参数：根据我们刚才编写的页面，有分页功能，有排序功能，有搜索过滤功能，因此至少要有5个参数： page：当前页，int rows：每页大小，int sortBy：排序字段，String desc：是否为降序，boolean key：搜索关键词，String 响应结果：分页结果一般至少需要两个数据 total：总条数 items：当前页数据 totalPage：有些还需要总页数 这里我们封装一个类，来表示分页结果, 这个PageResult以后可能在其它项目中也有需求，因此我们将其抽取到leyou-common中，提高复用性： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class PageResult&lt;T&gt; &#123; private Long total;// 总条数 private Long totalPage;// 总页数 private List&lt;T&gt; items;// 当前页数据 public PageResult() &#123; &#125; public PageResult(Long total, List&lt;T&gt; items) &#123; this.total = total; this.items = items; &#125; public PageResult(Long total, Long totalPage, List&lt;T&gt; items) &#123; this.total = total; this.totalPage = totalPage; this.items = items; &#125; public Long getTotal() &#123; return total; &#125; public void setTotal(Long total) &#123; this.total = total; &#125; public List&lt;T&gt; getItems() &#123; return items; &#125; public void setItems(List&lt;T&gt; items) &#123; this.items = items; &#125; public Long getTotalPage() &#123; return totalPage; &#125; public void setTotalPage(Long totalPage) &#123; this.totalPage = totalPage; &#125;&#125; 接下来，我们编写Controller BrandController 1234567891011121314151617@RestController@RequestMapping(\"brand\")public class BrandController &#123; @Autowired private BrandService brandService; @GetMapping(\"page\") public ResponseEntity&lt;PageResult&lt;Brand&gt;&gt; queryBrandByPage( @RequestParam(value = \"page\",defaultValue = \"1\")Integer page, @RequestParam(value = \"rows\",defaultValue = \"5\")Integer rows, @RequestParam(value = \"sortBy\",required = false)String sortBy, @RequestParam(value = \"desc\",defaultValue = \"false\")Boolean desc, @RequestParam(value = \"key\",required = false)String key )&#123; return ResponseEntity.ok(brandService.queryBrandByPageAndSort(page, rows, sortBy, desc, key)); &#125;&#125; BrandService 1234567891011121314151617181920212223242526272829@Servicepublic class BrandService &#123; @Autowired private BrandMapper brandMapper; public PageResult&lt;Brand&gt; queryBrandByPageAndSort(Integer page,Integer rows,String sortBy, Boolean desc, String key)&#123; //开始分页 PageHelper.startPage(page,rows); //过滤 Example example=new Example(Brand.class); if (StringUtils.isNoneBlank(key))&#123; //过滤条件 example.createCriteria().orLike(\"name\",\"%\"+key+\"%\") .orEqualTo(\"letter\",key.toUpperCase()); &#125; //排序 if (StringUtils.isNotBlank(sortBy))&#123; String orderByClause=sortBy+(desc ? \" DESC\":\" ASC\"); //DESC ASC前要加空格 example.setOrderByClause(orderByClause); &#125; //查询 List&lt;Brand&gt; list=brandMapper.selectByExample(example); if (CollectionUtils.isEmpty(list))&#123; throw new LyException(ExceptionEnum.BRAND_NOT_FOND); &#125; //解析分页结果 PageInfo&lt;Brand&gt; pageInfo=new PageInfo&lt;&gt;(list); return new PageResult&lt;&gt;(pageInfo.getTotal(),list); &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"微信公众号开发(四)处理语音消息","slug":"微信公众号开发(四)处理语音消息","date":"2021-05-08T13:19:59.224Z","updated":"2020-04-29T02:44:38.015Z","comments":true,"path":"35386/","link":"","permalink":"http://tonymua.top/35386/","excerpt":"1.语音识别接口为了实现微信公众号与用户的多样化交互, 本章进行处理用户语音消息的开发. 开发者进入微信公众平台 https://mp.weixin.qq.com/ —接口权限—对话服务—接受消息—打开接收语音识别结果接口权限","text":"1.语音识别接口为了实现微信公众号与用户的多样化交互, 本章进行处理用户语音消息的开发. 开发者进入微信公众平台 https://mp.weixin.qq.com/ —接口权限—对话服务—接受消息—打开接收语音识别结果接口权限 2.获取语音识别结果请注意，开通语音识别后，用户每次发送语音给公众号时，微信会在推送的语音消息XML数据包中，增加一个Recognition字段（注：由于客户端缓存，开发者开启或者关闭语音识别功能，对新关注者立刻生效，对已关注用户需要24小时生效。开发者可以重新关注此帐号进行测试）。 开启语音识别后的语音XML数据包如下： 12345678910&lt;xml&gt; &lt;ToUserName&gt;&lt; ![CDATA[toUser] ]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt; ![CDATA[fromUser] ]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1357290913&lt;/CreateTime&gt; &lt;MsgType&gt;&lt; ![CDATA[voice] ]&gt;&lt;/MsgType&gt; &lt;MediaId&gt;&lt; ![CDATA[media_id] ]&gt;&lt;/MediaId&gt; &lt;Format&gt;&lt; ![CDATA[Format] ]&gt;&lt;/Format&gt; &lt;Recognition&gt;&lt; ![CDATA[腾讯微信团队] ]&gt;&lt;/Recognition&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 语音消息参数说明 开通语音识别功能以后，用户每次发送语音给微信公众号，微信会在推送语音消息XML数据包中添加一个Recongnition字段，该字段为语音识别出的文本内容. 3.功能实现实体类VoiceMessage 1234@Datapublic class VoiceMessage extends BaseMessage&#123; private String Recognition;&#125; MessageUtil 1234public static String voiceMessageToXml(VoiceMessage voiceMessage) &#123; xstream.alias(\"xml\", voiceMessage.getClass()); return xstream.toXML(voiceMessage);&#125; MsgService 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Servicepublic class MsgService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(MsgService.class); public String processRequest(HttpServletRequest request) &#123; String respMessage = null; System.out.println(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); try &#123; // xml请求解析 Map&lt;String, String&gt; requestMap = MessageUtil.xmlToMap(request); // 发送方帐号（open_id） String fromUserName = requestMap.get(\"FromUserName\"); // 公众帐号 String toUserName = requestMap.get(\"ToUserName\"); // 消息类型 String msgType = requestMap.get(\"MsgType\"); // 消息内容 String content = requestMap.get(\"Content\"); String recognition = requestMap.get(\"Recognition\"); LOGGER.info(\"FromUserName is:\" + fromUserName + \", ToUserName is:\" + toUserName + \", MsgType is:\" + msgType); if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_VOICE))&#123; System.out.println(recognition); if(recognition.indexOf(\"环境信息\")!=-1)&#123; Map map = IoTPopApiUtil.IoTpop(); Map ioTpop = JSON.parseObject(JSONObject.toJSONString(map), Map.class); Object data = ioTpop.get(\"data\"); String str = data.toString(); int index=str.indexOf(\"[\"); String result=str.substring(index); String jsonStr = result.substring(0, result.length() - 1); JSONArray array = JSONArray.parseArray(jsonStr); List&lt;Pi&gt; pi = JSONObject.parseArray(array.toJSONString(),Pi.class); String returnText=\"当前温度:\"+pi.get(3).getValue()+\"°C\"+\"\\n\" +\"当前湿度:\"+pi.get(2).getValue()+\"%\"+\"\\n\" +\"当前光照强度:\"+pi.get(4).getValue()+\"Lux\"+\"\\n\" +\"当前气压:\"+pi.get(1).getValue()+\"hPa\"+\"\\n\" +\"当前海拔:\"+pi.get(0).getValue()+\"m\"+\"\\n\" +\"降雨情况:\"+(pi.get(5).getValue()==1?\"降雨\":\"未降雨\"); //文本消息 TextMessage text = new TextMessage(); text.setContent(returnText); text.setToUserName(fromUserName); text.setFromUserName(toUserName); text.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); text.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_TEXT); respMessage = MessageUtil.textMessageToXml(text); &#125; if(recognition.indexOf(\"天气\")!=-1)&#123; //自动回复 NewsMessage newmsg = new NewsMessage(); newmsg.setToUserName(fromUserName); newmsg.setFromUserName(toUserName); newmsg.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); newmsg.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_NEWS); newmsg.setFuncFlag(0); List&lt;Article&gt; articleList = new ArrayList&lt;&gt;(); Article article = new Article(); article.setTitle(\"天气预报\"); article.setDescription(\"点击了解未来天气详情...\"); article.setPicUrl(\"https://xxxx.oss-cn-beijing.aliyuncs.com/ep.png\"); article.setUrl(\"https://widget-page.heweather.net/h5/index.html?bg=1&amp;md=0123456&amp;lc=accu&amp;key=4bdfe35a67bb4b53bee844f6ce7a4b5c\"); articleList.add(article); // 设置图文消息个数 newmsg.setArticleCount(articleList.size()); // 设置图文消息包含的图文集合 newmsg.setArticles(articleList); // 将图文消息对象转换成xml字符串 respMessage = MessageUtil.newsMessageToXml(newmsg); &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.error(\"error......\"); &#125; return respMessage; &#125;&#125; 4.测试","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"微信公众号开发(五)部署项目到阿里云服务器","slug":"微信公众号开发(五)部署项目到阿里云服务器","date":"2021-05-08T13:19:59.223Z","updated":"2020-05-28T02:18:40.540Z","comments":true,"path":"deployment/","link":"","permalink":"http://tonymua.top/deployment/","excerpt":"1.准备工作 可以正常运行提供服务的项目 一台云服务器 2.项目打包首先将我们在IDEA下的项目进行打包，这边基于的是maven项目的打包。点击菜单栏 File → Project Structure → Artifacts 添加一个jar","text":"1.准备工作 可以正常运行提供服务的项目 一台云服务器 2.项目打包首先将我们在IDEA下的项目进行打包，这边基于的是maven项目的打包。点击菜单栏 File → Project Structure → Artifacts 添加一个jar 之后，对添加的jar进行配置 点击右侧竖排菜单栏的maven project 然后点开Lifecycle，先clean再package，注意在打包之前，要将项目的启动端口号改为80，8080端口是本机端口，不适用于服务器。 当下方控制器显示BUILD SUCCESS时说明打包成功 这时候我们可以在项目的文件目录下看到多了个target目录，点开目录移动到最下方我们可以看到项目jar包,我们可以从电脑磁盘中将放置该项目的文件夹打开并找到该项目文件。 3.导入服务器使用FTP工具负责构建完成的项目jar包到云服务器 4.运行项目4.1 配置Java运行环境 查看yum库中的Java安装包 1yum -y list java* 以yum库中java-1.8.0为例, “*”表示将java-1.8.0的所有相关Java程序都安装上 1yum -y install java-1.8.0-openjdk* 检查是否安装成功输入 java -version javac 4.2 启动项目查询一下80端口是否已开放，开放了80端口后我们就可以启动我们的项目了，通过输入指令：Java -jar [jar包的完整文件名(.jar别忘了加)] 如下图所示。这样我们的项目就开始启动了 1java -jar WeChat-1.0-SNAPSHOT.jar","categories":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/categories/项目/"}],"tags":[{"name":"项目部署","slug":"项目部署","permalink":"http://tonymua.top/tags/项目部署/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://tonymua.top/tags/Spring-Boot/"},{"name":"微信公众号","slug":"微信公众号","permalink":"http://tonymua.top/tags/微信公众号/"}]},{"title":"微信公众号开发(二)自动回复功能实现简单的天气查询","slug":"微信公众号开发(二)自动回复功能实现简单的天气查询","date":"2021-05-08T13:19:59.221Z","updated":"2020-04-29T02:44:38.058Z","comments":true,"path":"39972/","link":"","permalink":"http://tonymua.top/39972/","excerpt":"1.前言微信公众平台服务器配置通过后，就能进行下面的开发啦 首先可以查看官方的说明文档：https://developers.weixin.qq.com/doc/offiaccount/Getting_Started/Overview.html 普通消息的类型分为7种：","text":"1.前言微信公众平台服务器配置通过后，就能进行下面的开发啦 首先可以查看官方的说明文档：https://developers.weixin.qq.com/doc/offiaccount/Getting_Started/Overview.html 普通消息的类型分为7种： 文本消息 图片消息 语音消息 视频消息 小视频消息 地理位置消息 链接消息 本文使用的是文本消息与图片消息 2.图文消息的自动回复2.1 文本消息文本消息的XML结构是： 12345678&lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[this is a test]]&gt;&lt;/Content&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 参数包含： 定义一个BaseMessage，消息基类，封装通用属性： 123456789101112131415161718192021/** * 消息基类（普通用户 -&gt; 公众帐号） * */@Datapublic class BaseMessage &#123; // 开发者微信号 private String ToUserName; // 发送方帐号（一个OpenID） private String FromUserName; // 消息创建时间 （整型） private String CreateTime; // 消息类型（text/image/location/link） private String MsgType; // 消息id，64位整型 private long MsgId; /** * 位0x0001被标志时，星标刚收到的消息 */ private int FuncFlag;&#125; 接下来定义文本消息属性TextMessage： 12345678/** * 文本消息 */@Datapublic class TextMessage extends BaseMessage&#123; // 消息内容 private String Content;&#125; 2.2 图片消息图片消息的XML结构是： 123456789&lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[image]]&gt;&lt;/MsgType&gt; &lt;PicUrl&gt;&lt;![CDATA[this is a url]]&gt;&lt;/PicUrl&gt; &lt;MediaId&gt;&lt;![CDATA[media_id]]&gt;&lt;/MediaId&gt; &lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; 参数包含： 123@Datapublic class ImageMessage extends BaseMessage&#123;&#125; 2.3 图文消息1234567891011121314151617181920@Datapublic class Article &#123; /** * 图文消息描述 */ private String Description; /** * 图片链接，支持JPG、PNG格式，&lt;br&gt; * 较好的效果为大图640*320，小图80*80 */ private String PicUrl; /** * 图文消息名称 */ private String Title; /** * 点击图文消息跳转链接 */ private String Url;&#125; 123456789101112131415/** * &lt;p&gt; 图文消息 &lt;/p&gt; */@Setter@Getterpublic class NewsMessage extends BaseMessage&#123; /** * 图文消息个数，限制为10条以内 */ private Integer ArticleCount; /** * 多条图文消息信息，默认第一个item为大图 */ private List&lt;Article&gt; Articles;&#125; 3.功能实现3.1 工具类MessageUtil 解析微信发来的请求（xml） 将响应消息的Java对象转换成xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180public class MessageUtil &#123; /** * 返回消息类型：文本 */ public static final String RESP_MESSAGE_TYPE_TEXT = \"text\"; /** * 返回消息类型：音乐 */ public static final String RESP_MESSAGE_TYPE_MUSIC = \"music\"; /** * 返回消息类型：图文 */ public static final String RESP_MESSAGE_TYPE_NEWS = \"news\"; /** * 请求消息类型：文本 */ public static final String REQ_MESSAGE_TYPE_TEXT = \"text\"; /** * 请求消息类型：图片 */ public static final String REQ_MESSAGE_TYPE_IMAGE = \"image\"; /** * 请求消息类型：链接 */ public static final String REQ_MESSAGE_TYPE_LINK = \"link\"; /** * 请求消息类型：地理位置 */ public static final String REQ_MESSAGE_TYPE_LOCATION = \"location\"; /** * 请求消息类型：音频 */ public static final String REQ_MESSAGE_TYPE_VOICE = \"voice\"; /** * 请求消息类型：推送 */ public static final String REQ_MESSAGE_TYPE_EVENT = \"event\"; /** * 事件类型：subscribe(订阅) */ public static final String EVENT_TYPE_SUBSCRIBE = \"subscribe\"; /** * 事件类型：unsubscribe(取消订阅) */ public static final String EVENT_TYPE_UNSUBSCRIBE = \"unsubscribe\"; /** * 事件类型：CLICK(自定义菜单点击事件) */ public static final String EVENT_TYPE_CLICK = \"CLICK\"; /** * xml转换为map * @param request * @return * @throws IOException */ public static Map&lt;String, String&gt; xmlToMap(HttpServletRequest request) throws IOException &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); SAXReader reader = new SAXReader(); InputStream ins = null; try &#123; ins = request.getInputStream(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; Document doc = null; try &#123; doc = reader.read(ins); Element root = doc.getRootElement(); List&lt;Element&gt; list = root.elements(); for (Element e : list) &#123; map.put(e.getName(), e.getText()); &#125; return map; &#125; catch (DocumentException e1) &#123; e1.printStackTrace(); &#125;finally&#123; ins.close(); &#125; return null; &#125; /** * @Description: 解析微信发来的请求（XML） * @param @param request * @param @return * @param @throws Exception * @author dapengniao * @date 2016年3月7日 上午10:04:02 */ public static Map&lt;String, String&gt; parseXml(HttpServletRequest request) throws Exception &#123; // 将解析结果存储在HashMap中 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 从request中取得输入流 InputStream inputStream = request.getInputStream(); // 读取输入流 SAXReader reader = new SAXReader(); Document document = reader.read(inputStream); // 得到xml根元素 Element root = document.getRootElement(); // 得到根元素的所有子节点 List&lt;Element&gt; elementList = root.elements(); // 遍历所有子节点 for (Element e : elementList) &#123; map.put(e.getName(), e.getText()); &#125; // 释放资源 inputStream.close(); inputStream = null; return map; &#125;// public static XStream xstream = new XStream(); /** * 文本消息对象转换成xml * * @param textMessage 文本消息对象 * @return xml */ public static String textMessageToXml(TextMessage textMessage)&#123;// XStream xstream = new XStream(); xstream.alias(\"xml\", textMessage.getClass()); return xstream.toXML(textMessage); &#125; /** * @Description: 图文消息对象转换成xml * @param @param newsMessage * @param @return * @author dapengniao * @date 2016年3月8日 下午4:14:09 */ public static String newsMessageToXml(NewsMessage newsMessage) &#123; xstream.alias(\"xml\", newsMessage.getClass()); xstream.alias(\"item\", new Article().getClass()); return xstream.toXML(newsMessage); &#125; /** * @Description: 图片消息对象转换成xml * @param @param imageMessage * @param @return * @author dapengniao * @date 2016年3月9日 上午9:25:51 */ public static String imageMessageToXml(ImageMessage imageMessage) &#123; xstream.alias(\"xml\", imageMessage.getClass()); return xstream.toXML(imageMessage); &#125; /** * 对象到xml的处理 */ private static XStream xstream = new XStream(new XppDriver() &#123; public HierarchicalStreamWriter createWriter(Writer out) &#123; return new PrettyPrintWriter(out) &#123; // 对所有xml节点的转换都增加CDATA标记 boolean cdata = true; @SuppressWarnings(\"rawtypes\") public void startNode(String name, Class clazz) &#123; super.startNode(name, clazz); &#125; protected void writeText(QuickWriter writer, String text) &#123; if (cdata) &#123; writer.write(\"&lt;![CDATA[\"); writer.write(text); writer.write(\"]]&gt;\"); &#125; else &#123; writer.write(text); &#125; &#125; &#125;; &#125; &#125;);&#125; 3.2 实现当用户发送消息给公众号时（或某些特定的用户操作引发的事件推送时），会产生一个POST请求，开发者可以在响应包（Get）中返回特定XML结构，来对该消息进行响应（现支持回复文本、图片、图文、语音、视频、音乐）。 上一篇文章，已经创建了IndexController ，里面的GET方法用来验证token，下面直接加一个POST方法，用于进行消息管理。消息接收POST和微信认证GET是同一个接口（开发者填写的URL） Controller 12345678910111213141516171819202122@PostMappingpublic void msgProcess(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; try &#123; request.setCharacterEncoding(\"UTF-8\"); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; response.setCharacterEncoding(\"UTF-8\"); // 调用核心业务类接收消息、处理消息 String respMessage = msgService.processRequest(request); // 响应消息 PrintWriter out = null; try &#123; out = response.getWriter(); out.print(respMessage); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; out.close(); out = null; &#125;&#125; Service 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Servicepublic class MsgService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(MsgService.class); public String processRequest(HttpServletRequest request) &#123; String respMessage = null; System.out.println(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); try &#123; // xml请求解析 Map&lt;String, String&gt; requestMap = MessageUtil.xmlToMap(request); // 发送方帐号（open_id） String fromUserName = requestMap.get(\"FromUserName\"); // 公众帐号 String toUserName = requestMap.get(\"ToUserName\"); // 消息类型 String msgType = requestMap.get(\"MsgType\"); // 消息内容 String content = requestMap.get(\"Content\"); LOGGER.info(\"FromUserName is:\" + fromUserName + \", ToUserName is:\" + toUserName + \", MsgType is:\" + msgType); // 文本消息 if (msgType.equals(MessageUtil.REQ_MESSAGE_TYPE_TEXT)) &#123; //这里根据关键字执行相应的逻辑，只有你想不到的，没有做不到的 if (content.indexOf(\"天气\")!=-1) &#123; //自动回复 NewsMessage newmsg = new NewsMessage(); newmsg.setToUserName(fromUserName); newmsg.setFromUserName(toUserName); newmsg.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); newmsg.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_NEWS); newmsg.setFuncFlag(0); List&lt;Article&gt; articleList = new ArrayList&lt;&gt;(); Article article = new Article(); article.setTitle(\"天气预报\"); article.setDescription(\"点击了解未来天气详情...\"); article.setPicUrl(\"https://lwy-image.oss-cn-beijing.aliyuncs.com/ep.png\"); article.setUrl(\"https://widget-page.heweather.net/h5/index.html?bg=1&amp;md=0123456&amp;lc=auto&amp;key=f1688db9422246fc969a6ba559075097\"); articleList.add(article); // 设置图文消息个数 newmsg.setArticleCount(articleList.size()); // 设置图文消息包含的图文集合 newmsg.setArticles(articleList); // 将图文消息对象转换成xml字符串 respMessage = MessageUtil.newsMessageToXml(newmsg); &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.error(\"error......\"); &#125; return respMessage; &#125;&#125; 测试 源码参考 https://github.com/zhouminpz/wechatPublicAccount-","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"微信公众号开发(三)快递信息查询","slug":"微信公众号开发(三)快递信息查询","date":"2021-05-08T13:19:59.220Z","updated":"2020-04-29T02:44:38.057Z","comments":true,"path":"12221/","link":"","permalink":"http://tonymua.top/12221/","excerpt":"1.快递查询API这里使用的是阿里云全国快递物流查询-快递查询接口:https://market.aliyun.com/products/56928004/cmapi021863.html 该接口支持只通过快递运单号查询物流信息, 不需要在额外设置参数. 该种方式95%能自动识别, 填写查询速度会更快, 已经满足一般开发的需求, 并能极大方便开发者的使用.","text":"1.快递查询API这里使用的是阿里云全国快递物流查询-快递查询接口:https://market.aliyun.com/products/56928004/cmapi021863.html 该接口支持只通过快递运单号查询物流信息, 不需要在额外设置参数. 该种方式95%能自动识别, 填写查询速度会更快, 已经满足一般开发的需求, 并能极大方便开发者的使用. 请求参数说明 返回结果说明 官方提供的示例代码: 1234567891011121314151617181920212223242526272829303132333435public static void main(String[] args) &#123; String host = \"https://wuliu.market.alicloudapi.com\"; String path = \"/kdi\"; String method = \"GET\"; System.out.println(\"请先替换成自己的AppCode\"); String appcode = \"833509fd73fe1124838xxxxxxxx\"; // !!!替换填写自己的AppCode 在买家中心查看 Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(); headers.put(\"Authorization\", \"APPCODE \" + appcode); //格式为:Authorization:APPCODE 83359fd73fe11248385f570e3c139xxx Map&lt;String, String&gt; querys = new HashMap&lt;String, String&gt;(); querys.put(\"no\", \"462587770684\");// !!! 请求参数 querys.put(\"type\", \"zto\");// !!! 请求参数 //JDK 1.8示例代码请在这里下载： http://code.fegine.com/Tools.zip try &#123; /** * 重要提示如下: * HttpUtils请从 * https://github.com/aliyun/api-gateway-demo-sign-java/blob/master/src/main/java/com/aliyun/api/gateway/demo/util/HttpUtils.java * 或者直接下载： * http://code.fegine.com/HttpUtils.zip * 下载 * * 相应的依赖请参照 * https://github.com/aliyun/api-gateway-demo-sign-java/blob/master/pom.xml * 相关jar包（非pom）直接下载： * http://code.fegine.com/aliyun-jar.zip */ HttpResponse response = HttpUtils.doGet(host, path, method, headers, querys); //System.out.println(response.toString());如不输出json, 请打开这行代码，打印调试头部状态码。 //状态码: 200 正常；400 URL无效；401 appCode错误； 403 次数用完； 500 API网管错误 //获取response的body System.out.println(EntityUtils.toString(response.getEntity())); //输出json &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 正常返回示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123; \"status\": \"0\",/* status 0:正常查询 201:快递单号错误 203:快递公司不存在 204:快递公司识别失败 205:没有信息 207:该单号被限制，错误单号 */ \"msg\": \"ok\", \"result\": &#123; \"number\": \"780098068058\", \"type\": \"zto\", \"list\": [&#123; \"time\": \"2018-03-09 11:59:26\", \"status\": \"【石家庄市】快件已在【长安三部】 签收,签收人: 本人,感谢使用中通快递,期待再次为您服务!\" &#125;, &#123; \"time\": \"2018-03-09 09:03:10\", \"status\": \"【石家庄市】 快件已到达 【长安三部】（0311-85344265）,业务员 容晓光（13081105270） 正在第1次派件, 请保持电话畅通,并耐心等待\" &#125;, &#123; \"time\": \"2018-03-08 23:43:44\", \"status\": \"【石家庄市】 快件离开 【石家庄】 发往 【长安三部】\" &#125;, &#123; \"time\": \"2018-03-08 21:00:44\", \"status\": \"【石家庄市】 快件到达 【石家庄】\" &#125;, &#123; \"time\": \"2018-03-07 01:38:45\", \"status\": \"【广州市】 快件离开 【广州中心】 发往 【石家庄】\" &#125;, &#123; \"time\": \"2018-03-07 01:36:53\", \"status\": \"【广州市】 快件到达 【广州中心】\" &#125;, &#123; \"time\": \"2018-03-07 00:40:57\", \"status\": \"【广州市】 快件离开 【广州花都】 发往 【石家庄中转】\" &#125;, &#123; \"time\": \"2018-03-07 00:01:55\", \"status\": \"【广州市】 【广州花都】（020-37738523） 的 马溪 （18998345739） 已揽收\" &#125;], \"deliverystatus\": \"3\", /* 0：快递收件(揽件)1.在途中 2.正在派件 3.已签收 4.派送失败 5.疑难件 6.退件签收 */ \"issign\": \"1\", /* 1.是否签收 */ \"expName\": \"中通快递\", /* 快递公司名称 */ \"expSite\": \"www.zto.com\", /* 快递公司官网 */ \"expPhone\": \"95311\", /* 快递公司电话 */ \"courier\": \"容晓光\", /* 快递员 或 快递站(没有则为空)*/ \"courierPhone\":\"13081105270\", /* 快递员电话 (没有则为空) */ \"updateTime\":\"2019-08-27 13:56:19\", /* 快递轨迹信息最新时间 */ \"takeTime\":\"2天20小时14分\", /* 发货到收货消耗时长 (截止最新轨迹) */ \"logo\":\"http://img3.fegine.com/express/zto.jpg\" /* 快递公司LOGO */ &#125;&#125; 失败返回示例: 123456789&#123; \"status\": \"205\", /* status状态码见产品详情 */ \"msg\": \"没有信息\", \"result\": &#123; \"number\": \"1111ADECD1234\", \"type\": \"AUTO\", \"list\": [] &#125;&#125; 错误码定义: 错误码 错误信息 描述 201 快递单号错误 status：快递单号错误 203 快递公司不存在 status：快递公司不存在 204 快递公司识别失败 status：快递公司识别失败 205 没有信息 status：没有信息 207 该单号被限制，错误单号 status：该单号被限制，错误单号；一个单号对应多个快递公司，请求须指定快递公司 0 正常 status：正常查询 2.核心代码工具类: HttpUtils(官方提供) 下载地址 http://code.fegine.com/HttpUtils.zip TextUtil 用于判断输入发送的消息是否为英文字母+数字或纯数字(即符合快递运单号基本规则) 1234567public class TextUtil &#123; public static boolean DecText(String text)&#123; Pattern p=Pattern.compile(\"^[A-Za-z0-9]+$\"); //正则表达式 Matcher matcher = p.matcher(text); return matcher.matches(); &#125;&#125; ExpressUtil 调用API查询物流信息 1234567891011121314151617181920212223public class ExpressUtil &#123; public static String QueryExpress(String num) throws Exception &#123; String host = \"https://wuliu.market.alicloudapi.com\"; String path = \"/kdi\"; String method = \"GET\"; String appcode = \"06a9e928218141bxxxxxxx\"; // !!!替换填写自己的AppCode 在买家中心查看 Map&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;(); headers.put(\"Authorization\", \"APPCODE \" + appcode); //格式为:Authorization:APPCODE 83359fd73fe11248385f570e3c139xxx Map&lt;String, String&gt; querys = new HashMap&lt;String, String&gt;(); querys.put(\"no\", num);// !!! 请求参数 HttpResponse response = HttpUtils.doGet(host, path, method, headers, querys); //System.out.println(response.toString()); //获取response的body String str = EntityUtils.toString(response.getEntity());//输出json JSONObject jsonObject = JSONObject.parseObject(str); // 获取到key为result的值 String result = jsonObject.getString(\"result\"); jsonObject = JSONObject.parseObject(result); // 获取到key为list的值 String list = jsonObject.getString(\"list\"); return list; &#125;&#125; 此时返回的数据为: 12345678910111213141516171819202122[&#123; \"time\": \"2020-02-29 19:45:12\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何海桃】\"&#125;, &#123; \"time\": \"2020-02-29 19:45:12\", \"status\": \"快件在【浙江嘉善公司】进行装车，扫描员【何海桃】，车签号【】\"&#125;, &#123; \"time\": \"2020-02-29 19:42:13\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何德文】\"&#125;, &#123; \"time\": \"2020-02-29 19:42:13\", \"status\": \"快件在【浙江嘉善公司】进行装包，扫描员【何德文】，袋号【9005261902881】\"&#125;, &#123; \"time\": \"2020-02-29 19:41:07\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何德文】\"&#125;, &#123; \"time\": \"2020-02-29 19:29:40\", \"status\": \"【浙江嘉善公司】的【公司称重（)】已收件，扫描员【公司出港1】\"&#125;, &#123; \"time\": \"2020-02-29 18:32:52\", \"status\": \"快件由【浙江嘉善公司】发往【下一站浙江嘉兴转运中心】，扫描员【何德文】\"&#125;] MsgService 1234567891011121314151617181920212223if (TextUtil.DecText(content)==true)&#123; String str = ExpressUtil.QueryExpress(content); List&lt;HashMap&gt; r = JSON.parseArray(str, HashMap.class); StringBuilder stringBuilder = new StringBuilder(); for (int i = r.size() - 1; i &gt;= 0; i--) &#123; System.out.println(r.get(i).get(\"time\") + \":\" + r.get(i).get(\"status\")); String string = r.get(i).get(\"time\") + \":\" + r.get(i).get(\"status\"); if (i == 0) &#123; stringBuilder.append(string); &#125; else &#123; stringBuilder.append(string).append(\"\\n\"); &#125; &#125; System.out.println(stringBuilder); //文本消息 TextMessage text = new TextMessage(); text.setContent(stringBuilder+\"\"); text.setToUserName(fromUserName); text.setFromUserName(toUserName); text.setCreateTime(LocalDateTime.now().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"))); text.setMsgType(MessageUtil.RESP_MESSAGE_TYPE_TEXT); respMessage = MessageUtil.textMessageToXml(text); &#125; 3.功能测试","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"微信公众号开发(一)开发者接入微信公众号","slug":"微信公众号开发(一)开发者接入微信公众号","date":"2021-05-08T13:19:59.218Z","updated":"2020-04-29T02:44:38.014Z","comments":true,"path":"38103/","link":"","permalink":"http://tonymua.top/38103/","excerpt":"微信公众号开发(一)开发者接入微信公众号1.前言该文章基于JDK1.8 springboot2.1.7.RELEASE环境 实现开发者第一次接入微信公众号后台的需求 2.准备工作2.1 进入微信公众平台注册账号 https://mp.weixin.qq.com/ 个人用户建议注册订阅号","text":"微信公众号开发(一)开发者接入微信公众号1.前言该文章基于JDK1.8 springboot2.1.7.RELEASE环境 实现开发者第一次接入微信公众号后台的需求 2.准备工作2.1 进入微信公众平台注册账号 https://mp.weixin.qq.com/ 个人用户建议注册订阅号 2.2 内网穿透因为要直接用内网本机开发调试，微信网页授权在回调时要访问本机，所以直接做个内网穿透，可以直接在外网访问到本机，做法如下： 登录 https://natapp.cn/ （我用的natapp.cn，你可以用其他类似的，个人感觉这个不错） 购买隧道：购买后使用方式: 参考官方教程：https://natapp.cn/article/natapp_newbie 使用后会得到natapp分配的网址，如 xxx.natapp.cn，这个地址就可以访问到开发本机。 下载并配置config.ini, 运行natapp 3.接入认证成为开发者 可参考微信官方开发文档 https://developers.weixin.qq.com/doc/offiaccount/Basic_Information/Access_Overview.html 3.1 填写服务器配置登录微信公众号开发平台:https://mp.weixin.qq.com/ 开发—开发者工具—公众平台测试账号 Tips: 微信公众号接口必须以http://或https://开头，分别支持80端口和443端口！ 这里的url可以选择自己买的服务器地址，记得必须开放80端口去使用！ 或者使用内网映射外网工具生成一个域名地址供给你开发使用，此方法自行百度，如下就是其中一种使用~ 目前提交是无法配置成功的, 不要着急 3.2 提交验证URL有效性3.2.1 搭建SpingBoot工程项目结构 pom.xml 123456789101112131415161718192021&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.binarywang&lt;/groupId&gt; &lt;artifactId&gt;weixin-java-mp&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yaml 123456wechat: mpAppId: xxxxxxxx #公众平台测试账号---测试号信息, 目前可以不填 mpAppSecret: xxxxxx #公众平台测试账号---测试号信息, 目前可以不填 mpToken: xxxxx #与前面在公众平台测试账号---接口配置信息所填写保持一致server: port: 80 #端口号 sha1加密工具类 1234567891011121314151617181920public class SecurityUtil &#123; public static String sha1(String str) &#123; try &#123; StringBuilder sb = new StringBuilder(); MessageDigest digest = MessageDigest.getInstance(\"sha1\"); // 放入加密字符串 digest.update(str.getBytes()); // 进行加密 byte[] digestMsg = digest.digest(); // byte转换16进制 for (byte b : digestMsg) &#123; sb.append(String.format(\"%02x\", b)); &#125; return sb.toString(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; return str; &#125;&#125; 12345678@Data@Component@ConfigurationProperties(prefix = \"wechat\")public class WechatAccountConfig &#123; private String mpAppId; private String mpAppSecret; private String mpToken;&#125; Controller 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Slf4j@RestController@RequestMapping(\"/wechat/index\")public class IndexController &#123; @Autowired private WechatAccountConfig wechatAccountConfig; /** * 处理微信认证：验证服务器地址的有效性，get提交 * signature: 微信加密签名，signature结合了开发者填写的token参数和请求中的timestamp参数、nonce参数。 * timestamp 时间戳 * nonce: 随机数 * echostr: 随机字符串 */ @GetMapping public void checkSignature(HttpServletRequest request, HttpServletResponse response) throws IOException, IOException &#123; System.out.println(\"============= 处理微信认证 ===============\"); // 拿到微信的请求参数 String signature = request.getParameter(\"signature\"); String timestamp = request.getParameter(\"timestamp\"); String nonce = request.getParameter(\"nonce\"); String echostr = request.getParameter(\"echostr\"); // TODO 这里的token是微信公众平台上自己所配的！ String token = wechatAccountConfig.getMpToken(); // ① 将token、timestamp、nonce三个参数进行字典序排序 b a d c h ==&gt;a b c d h String[] strArr = &#123;token, timestamp, nonce&#125;; // 字典排序 Arrays.sort(strArr); // ② 将三个参数字符串拼接成一个字符串进行sha1加密 StringBuffer sb = new StringBuffer(); // 字符串拼接 for (String str : strArr) &#123; sb.append(str); &#125; // 加密 String sha1Str = SecurityUtil.sha1(sb.toString()); // ③ 开发者获得加密后的字符串可与signature对比，标识该请求来源于微信 if (sha1Str.equals(signature)) &#123; // 如果相等，就是来自微信请求 // 若确认此次GET请求来自微信服务器，原样返回echostr参数内容，则接入生效 response.getWriter().println(echostr); &#125; &#125;&#125; 启动类 123456@SpringBootApplicationpublic class WeChatService &#123; public static void main(String[] args) &#123; SpringApplication.run(WeChatService.class); &#125;&#125; 3.2.2 测试 启动该SpringBoot项目 回到公众平台测试账号—接口配置信息, 点击提交即可","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"常用设计模式","slug":"常用设计模式","date":"2021-05-08T13:19:59.217Z","updated":"2020-04-29T02:44:38.055Z","comments":true,"path":"14808/","link":"","permalink":"http://tonymua.top/14808/","excerpt":"Java 中一般认为有23种设计模式, 下面介绍几种常见的设计模式。总体来说设计模式分为三大类： 创建型模式, 共5五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共7种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。","text":"Java 中一般认为有23种设计模式, 下面介绍几种常见的设计模式。总体来说设计模式分为三大类： 创建型模式, 共5五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共7种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共11种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 1.单例模式所谓的单例设计指的是一个类只允许产生一个实例化对象。最好理解的一种设计模式，分为懒汉式和饿汉式。 饿汉式: 构造方法私有化，外部无法产生新的实例化对象，只能通过static方法取得实例化对象 123456789101112131415161718class Singleton &#123; /** * 在类的内部可以访问私有结构，所以可以在类的内部产生实例化对象 */ private static Singleton instance = new Singleton(); /** * private 声明构造 */ private Singleton() &#123; &#125; /** * 返回对象实例 */ public static Singleton getInstance() &#123; return instance; &#125;&#125; 懒汉式: 当第一次去使用Singleton对象的时候才会为其产生实例化对象的操作 123456789101112131415161718192021222324class Singleton &#123; /** * 声明变量 */ private static volatile Singleton singleton = null; /** * 私有构造方法 */ private Singleton() &#123; &#125; public static Singleton getInstance() &#123; // 还未实例化 if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; ​ 当多个线程并发执行 getInstance() 方法时，懒汉式会存在线程安全问题，所以用到了 synchronized 来实现线程的同步，当一个线程获得锁的时候其他线程就只能在外等待其执行完毕。而饿汉式则不存在线程安全的问题。 适用场景： 单例模式只允许创建一个对象，因此节省内存，加快对象访问速度，因此对象需要被公用的场合适合使用，如多个模块使用同一个数据源连接对象等等。如： (1) 需要频繁实例化然后销毁的对象。 (2) 创建对象时耗时过多或者耗资源过多，但又经常用到的对象。 (3) 有状态的工具类对象。 (4) 频繁访问数据库或文件的对象。以下都是单例模式的经典使用场景： (1) 资源共享的情况下，避免由于资源操作时导致的性能或损耗等。如上述中的日志文件，应用配置。 (2) 控制资源的情况下，方便资源之间的互相通信。如线程池等。 2.观察者模式一个对象(subject)被其他多个对象(observer)所依赖。则当一个对象变化时，发出通知，其它依赖该对象的对象都会收到通知，并且随着变化。 3.装饰者模式对已有的业务逻辑进一步的封装, 使其增加额外的功能, 要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例。 适用环境: ​ (1) 在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。 ​ (2) 处理那些可以撤消的职责。 ​ (3) 当不能采用生成子类的方法进行扩充时。一种情况是，可能有大量独立的扩展，为支持每一种组合将产生大量的 子类，使得子类数目呈爆炸性增长。另一种情况可能是因为类定义被隐藏，或类定义不能用于生成子类。 4.适配器模式适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 5.工厂模式5.1 简单工厂模式简单工厂模式就是把对类的创建初始化全都交给一个工厂来执行，而用户不需要去关心创建的过程是什么样的，只用告诉工厂我想要什么就行了。而这种方法的缺点也很明显，违背了设计模式的开闭原则，因为如果你要增加工厂可以初始化的类的时候，你必须对工厂进行改建 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 抽象产品类abstract class Car &#123; public void run(); public void stop();&#125; // 具体实现类class Benz implements Car &#123; public void run() &#123; System.out.println(\"Benz开始启动了。。。。。\"); &#125; public void stop() &#123; System.out.println(\"Benz停车了。。。。。\"); &#125;&#125; class Ford implements Car &#123; public void run() &#123; System.out.println(\"Ford开始启动了。。。\"); &#125; public void stop() &#123; System.out.println(\"Ford停车了。。。。\"); &#125;&#125; // 工厂类class Factory &#123; public static Car getCarInstance(String type) &#123; Car c = null; if (\"Benz\".equals(type)) &#123; c = new Benz(); &#125; if (\"Ford\".equals(type)) &#123; c = new Ford(); &#125; return c; &#125;&#125; public class Test &#123; public static void main(String[] args) &#123; Car c = Factory.getCarInstance(\"Benz\"); if (c != null) &#123; c.run(); c.stop(); &#125; else &#123; System.out.println(\"造不了这种汽车。。。\"); &#125; &#125; 5.2 工厂方法模式设计一个工厂的接口，你想要什么东西，就写个类继承于这个工厂，这样就不用修改什么，直接添加就行了。就相当于，我这个工厂是用来生汽车的，而要什么品牌的汽车具体分到了每个车间，如果新多了一种品牌的汽车，直接新增一个车间就行了。那么问题又来了，如果想要生产大炮怎么办？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 抽象产品角色public interface Moveable &#123; void run();&#125; // 具体产品角色public class Plane implements Moveable &#123; @Override public void run() &#123; System.out.println(\"plane....\"); &#125;&#125; public class Broom implements Moveable &#123; @Override public void run() &#123; System.out.println(\"broom.....\"); &#125;&#125; // 抽象工厂public abstract class VehicleFactory &#123; abstract Moveable create();&#125; // 具体工厂public class PlaneFactory extends VehicleFactory &#123; public Moveable create() &#123; return new Plane(); &#125;&#125; public class BroomFactory extends VehicleFactory &#123; public Moveable create() &#123; return new Broom(); &#125;&#125; // 测试类public class Test &#123; public static void main(String[] args) &#123; VehicleFactory factory = new BroomFactory(); Moveable m = factory.create(); m.run(); &#125;&#125; 5.3 抽象工厂模式与工厂方法模式不同的是，工厂方法模式中的工厂只生产单一的产品，而抽象工厂模式中的工厂生产多个产品 123456789101112131415161718192021222324252627282930313233//抽象工厂类public abstract class AbstractFactory &#123; public abstract Vehicle createVehicle(); public abstract Weapon createWeapon(); public abstract Food createFood();&#125;//具体工厂类，其中Food,Vehicle，Weapon是抽象类，public class DefaultFactory extends AbstractFactory&#123; @Override public Food createFood() &#123; return new Apple(); &#125; @Override public Vehicle createVehicle() &#123; return new Car(); &#125; @Override public Weapon createWeapon() &#123; return new AK47(); &#125;&#125;//测试类public class Test &#123; public static void main(String[] args) &#123; AbstractFactory f = new DefaultFactory(); Vehicle v = f.createVehicle(); v.run(); Weapon w = f.createWeapon(); w.shoot(); Food a = f.createFood(); a.printName(); &#125;&#125;","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"}]},{"title":"学成在线(四.页面静态化)","slug":"学成在线(四.页面静态化)","date":"2021-05-08T13:19:59.215Z","updated":"2020-04-29T02:44:38.089Z","comments":true,"path":"8151/","link":"","permalink":"http://tonymua.top/8151/","excerpt":"1.页面静态化需求(1) 为什么要进行页面管理？ 本项目cms系统的功能就是根据运营需要，对门户等子系统的部分页面进行管理，从而实现快速根据用户需求修改页面内容并上线的需求。 (2) 如何修改页面的内容？ 在开发中修改页面内容是需要人工编写html及JS文件，CMS系统是通过程序自动化的对页面内容进行修改，通过页面静态化技术生成html页面。","text":"1.页面静态化需求(1) 为什么要进行页面管理？ 本项目cms系统的功能就是根据运营需要，对门户等子系统的部分页面进行管理，从而实现快速根据用户需求修改页面内容并上线的需求。 (2) 如何修改页面的内容？ 在开发中修改页面内容是需要人工编写html及JS文件，CMS系统是通过程序自动化的对页面内容进行修改，通过页面静态化技术生成html页面。 (3) 如何对页面进行静态化？一个页面等于模板加数据，在添加页面的时候我们选择了页面的模板。页面静态化就是将页面模板和数据通过技术手段将二者合二为一，生成一个html网页文件。 (4) 页面静态化及页面发布流程图如下： 业务流程如下： 1、获取模型数据 2、制作模板 3、对页面进行静态化 4、将静态化生成的html页面存放文件系统中 5、将存放在文件系统的html文件发布到服务器 2.页面静态化2.1 页面静态化流程​ 通过上边对FreeMarker的研究我们得出：模板+数据模型=输出，页面静态化需要准备数据模型和模板，先知道数 据模型的结构才可以编写模板，因为在模板中要引用数据模型中的数据，本节将系统讲解CMS页面数据模型获取、 模板管理及静态化的过程。 下边讨论一个问题：如何获取页面的数据模型？ CMS管理了各种页面，CMS对页面进行静态化时需要数据模型，但是CMS并不知道每个页面的数据模型的具体内容，它只管执行静态化程序便可对页面进行静态化，所以CMS静态化程序需要通过一种通用的方法来获取数据模型。 在编辑页面信息时指定一个DataUrl，此DataUrl便是获取数据模型的Url，它基于Http方式，CMS对页面进行静态化时会从页面信息中读取DataUrl，通过Http远程调用的方法请求DataUrl获取数据模型。 管理员怎么知道DataUrl的内容呢？举例说明： 此页面是轮播图页面，它的DataUrl由开发轮播图管理的程序员提供。 此页面是精品课程推荐页面，它的DataUrl由精品课程推荐的程序员提供。 此页面是课程详情页面，它的DataUrl由课程管理的程序员提供。页面静态化流程如下图： 1、静态化程序首先读取页面获取DataUrl2、静态化程序远程请求DataUrl得到数据模型3、获取页面模板4、执行页面静态化 2.2 数据模型2.2.1 轮播图DataUrl接口2.2.1.1 需求分析CMS中有轮播图管理、精品课程推荐的功能，以轮播图管理为例说明： 轮播图管理是通过可视化的操作界面由管理员指定轮播图图片地址，最后将轮播图图片地址保存在cms_conﬁg集合中，下边是轮播图数据模型： ​ 针对首页的轮播图信息、精品推荐等信息的获取统一提供一个Url供静态化程序调用，这样我们就知道了轮播图页面、精品课程推荐页面的DataUrl，管理在页面配置中将此Url配置在页面信息中。本小节开发一个查询轮播图、精品推荐信息的接口，此接口供静态化程序调用获取数据模型。 2.2.1.2 接口定义轮播图信息、精品推荐等信息存储在MongoDB的cms_conﬁg集合中。 cms_conﬁg有固定的数据结构，如下： 12345678910@Data@ToString@Document(collection = \"cms_config\")public class CmsConfig &#123; @Id private String id; private String name; private List&lt;CmsConfigModel&gt; model;&#125; 根据配置信息Id查询配置信息，定义接口如下： 12345@Api(value=\"cms配置管理接口\",description = \"cms配置管理接口，提供数据模型的管理、查询接口\")public interface CmsConfigControllerApi &#123; @ApiOperation(\"根据id查询CMS配置信息\") public CmsConfig getModel(String id);&#125; 2.2.1.3 Dao定义CmsConﬁg的dao接口： 12public interface CmsConfigRepository extends MongoRepository&lt;CmsConfig,String&gt; &#123;&#125; 2.2.1.4 Service定义CmsConﬁgService实现根据id查询CmsConﬁg信息: 1234567891011121314@Servicepublic class CmsConfigService &#123; @Autowired CmsConfigRepository cmsConfigRepository; //根据id查询配置管理信息 public CmsConfig getCmsConfigById(String id)&#123; Optional&lt;CmsConfig&gt; optional = cmsConfigRepository.findById(id); if (optional.isPresent())&#123; CmsConfig cmsConfig = optional.get(); return cmsConfig; &#125; return null; &#125;&#125; 2.2.1.5 Controller123456789101112@RestController@RequestMapping(\"/cms/config\")public class CmsConfigController implements CmsConfigControllerApi &#123; @Autowired CmsConfigService cmsConfigService; @Override @GetMapping(\"/getmodel/&#123;id&#125;\") public CmsConfig getModel(@PathVariable(\"id\") String id) &#123; return cmsConfigService.getCmsConfigById(id); &#125;&#125; 2.2.1.6 测试使用postman测试接口 get请求：http://localhost:31001/cms/config/getmodel/5a791725dd573c3574ee333f （轮播图信息） 2.2.3 远程请求接口SpringMVC提供 RestTemplate请求http接口，RestTemplate的底层可以使用第三方的http客户端工具实现http 的请求，常用的http客户端工具有Apache HttpClient、OkHttpClient等，本项目使用OkHttpClient完成http请求， 原因也是因为它的性能比较出众。 (1) 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; (2) 配置RestTemplate在SpringBoot启动类中配置 RestTemplate 123456789101112131415@SpringBootApplication@EntityScan(\"com.xuecheng.framework.domain.cms\") //扫描实体类@ComponentScan(basePackages = &#123;\"com.xuecheng.api\"&#125;) //扫描接口@ComponentScan(basePackages = &#123;\"com.xuecheng.manage_cms\"&#125;) //扫描本项目下的所有类@ComponentScan(basePackages = &#123;\"com.xuecheng.framework\"&#125;) //扫描common工程下的类public class ManageCmsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ManageCmsApplication.class); &#125; @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(new OkHttp3ClientHttpRequestFactory()); &#125;&#125; (3) 测试RestTemplate根据url获取数据，并转为map格式 12345678910111213@SpringBootTest@RunWith(SpringRunner.class)public class RestTemplateTest &#123; @Autowired RestTemplate restTemplate; @Test public void testRestTemplate() &#123; ResponseEntity&lt;Map&gt; forEntity = restTemplate.getForEntity(\"http://localhost:31001/cms/config/getmodel/5a791725dd573c3574ee333f\", Map.class); Map body = forEntity.getBody(); System.out.println(body); &#125;&#125; 2.3 模板管理2.3.1 模板管理业务流程CMS提供模板管理功能，业务流程如下： 1、要增加新模板首先需要制作模板，模板的内容就是Freemarker ftl模板内容。2、通过模板管理模块功能新增模板、修改模板、删除模板。3、模板信息存储在MongoDB数据库，其中模板信息存储在cms_template集合中，模板文件存储在GridFS文件系 统中。 cms_template集合：下边是一个模板的例子： 12345678&#123; \"_id\" : ObjectId(\"5a925be7b00ffc4b3c1578b5\"), \"_class\" : \"com.xuecheng.framework.domain.cms.CmsTemplate\", \"siteId\" : \"5a751fab6abb5044e0d19ea1\", \"templateName\" : \"课程详情页面\", \"templateParameter\" : \"courseid\", \"templateFileId\" : \"5ad8a51f68db5240b42e5fea\"&#125; 上边模板信息中templateFileId是模板文件的ID，此ID对应GridFS文件系统中文件ID。 2.3.2 模板制作2.3.2.1 编写模板文件(1) 轮播图页面原型在门户的静态工程目录有轮播图的静态页面，路径是：/include/index_banner.html http://www.xuecheng.com/include/index_banner.html (2) 编写模板 在freemarker测试工程中新建模板index_banner.ftl。 12345678910111213141516&lt;div class=\"banner-roll\"&gt; &lt;div class=\"banner-item\"&gt; &lt;#--&lt;div class=\"item\" style=\"background-image: url(http://www.xuecheng.com/img/widget-bannerB.jpg);\"&gt;&lt;/div&gt; &lt;div class=\"item\" style=\"background-image: url(http://www.xuecheng.com/img/widget-bannerA.jpg);\"&gt;&lt;/div&gt; &lt;div class=\"item\" style=\"background-image: url(http://www.xuecheng.com/img/widget-banner3.png);\"&gt;&lt;/div&gt; &lt;div class=\"item\" style=\"background-image: url(http://www.xuecheng.com/img/widget-bannerB.jpg);\"&gt;&lt;/div&gt; &lt;div class=\"item\" style=\"background-image: url(http://www.xuecheng.com/img/widget-bannerA.jpg);\"&gt;&lt;/div&gt; &lt;div class=\"item\" style=\"background-image: url(http://www.xuecheng.com/img/widget-banner3.png);\"&gt;&lt;/div&gt;--&gt; &lt;#if model??&gt; &lt;#list model as item&gt; &lt;div class=\"item\" style=\"background-image: url($&#123;item.value&#125;);\"&gt;&lt;/div&gt; &lt;/#list&gt; &lt;/#if&gt; &lt;/div&gt; &lt;div class=\"indicators\"&gt;&lt;/div&gt;&lt;/div&gt; 2.3.2.2 模板测试在freemarker测试工程编写一个方法测试轮播图模板，代码如下： 1234567891011@AutowiredRestTemplate restTemplate;@RequestMapping(\"/banner\")public String index_banner(Map&lt;String, Object&gt; map) &#123; ResponseEntity&lt;Map&gt; forEntity = restTemplate.getForEntity(\"http://localhost:31001/cms/config/getmodel/5a791725dd573c3574ee333f\", Map.class); Map body = forEntity.getBody(); //设置模型数据 map.putAll(body); return \"index_banner\";&#125; 2.3.3 GridFS研究2.3.3.1 GridFS介绍​ GridFS是MongoDB提供的用于持久化存储文件的模块，CMS使用MongoDB存储数据，使用GridFS可以快速集成开发。 它的工作原理是： 在GridFS存储文件是将文件分块存储，文件会按照256KB的大小分割成多个块进行存储，GridFS使用两个集合 (collection)存储文件，一个集合是chunks, 用于存储文件的二进制数据；一个集合是ﬁles，用于存储文件的元数 据信息(文件名称、块大小、上传时间等信息)。从GridFS中读取文件要对文件的各各块进行组装、合并。详细参考：https://docs.mongodb.com/manual/core/gridfs/ 2.3.3.2 GridFS存取文件测试(1) 存文件 使用GridFsTemplate存储文件测试代码：向测试程序注入GridFsTemplate 12345678910@AutowiredGridFsTemplate gridFsTemplate;//存文件@Testpublic void testStore() throws FileNotFoundException &#123; FileInputStream fileInputStream=new FileInputStream(new File(\"e:/index_banner.ftl\")); ObjectId objectId = gridFsTemplate.store(fileInputStream, \"index_banner.ftl\"); System.out.println(objectId);&#125; 存储原理说明：文件存储成功得到一个文件id 此文件id是fs.ﬁles集合中的主键。可以通过文件id查询fs.chunks表中的记录，得到文件的内容。 (2) 读取文件 1）在conﬁg包中定义Mongodb的配置类，如下： GridFSBucket用于打开下载流对象 123456789101112@Configurationpublic class MongoConfig &#123; @Value(\"$&#123;spring.data.mongodb.database&#125;\") String db; @Bean public GridFSBucket getGridFSBucket(MongoClient mongoClient)&#123; MongoDatabase database = mongoClient.getDatabase(db); GridFSBucket gridFSBucket = GridFSBuckets.create(database); return gridFSBucket; &#125;&#125; 2）测试代码如下 1234567891011121314151617@AutowiredGridFsTemplate gridFsTemplate;@AutowiredGridFSBucket gridFSBucket;//读取文件@Testpublic void queryFile() throws IOException &#123; //根据id查询文件 GridFSFile gridFSFile = gridFsTemplate.findOne(Query.query(Criteria.where(\"_id\").is(\"5dd67cbc972a8fcc703498e2\"))); //打开下载流对象 GridFSDownloadStream gridFSDownloadStream = gridFSBucket.openDownloadStream(gridFSFile.getObjectId()); //创建gridFsResource，用于获取流对象 GridFsResource gridFsResource=new GridFsResource(gridFSFile,gridFSDownloadStream); //获取流中的数据 String content = IOUtils.toString(gridFsResource.getInputStream(),\"utf-8\"); System.out.println(content);&#125; (3) 删除文件 1234567 //删除文件 @Test public void delFile()&#123; //根据文件id删除fs.files和fs.chunks中的记录 gridFsTemplate.delete(Query.query(Criteria.where(\"_id\").is(\"5dd67cbc972a8fcc703498e2\"))); &#125; 2.3.4 模板存储​ 根据模板管理的流程，最终将模板信息存储到MongoDB的cms_template中，将模板文件存储到GridFS中。 模板管理功能在课堂中不再讲解，教学中手动向cms_template及GridFS中存储模板，方法如下： (1) 添加模板1）使用GridFS测试代码存储模板文件到GridFS，并得到文件id.2）向cms_template添加记录。 (2) 删除模板1）使用GridFS测试代码根据文件id删除模板文件。2）根据模板id删除cms_template中的记录。 (3) 修改模板信息可以通过Studio 3T修改模板文件，先找到模板文件，再导入进去：使用Studio 3T修改cms_template中的记录。 2.4 静态化测试上边章节完成了数据模型和模板管理的测试，下边测试整个页面静态化的流程，流程如下：1、填写页面DataUrl 在编辑cms页面信息界面填写DataUrl，将此字段保存到cms_page集合中。2、静态化程序获取页面的DataUrl3、静态化程序远程请求DataUrl获取数据模型。4、静态化程序获取页面的模板信息5、执行页面静态化 2.4.1 填写页面DataUrl修改页面管理模板代码，实现编辑页面DataUrl。注意：此地址由程序员提供给系统管理员，由系统管理员录入到系统中。下边实现页面修改界面录入DataUrl： (1) 修改页面管理前端的page_edit.vue 在表单中添加dataUrl输入框： 123&lt;el-form-item label=\"数据Url\" prop=\"dataUrl\"&gt; &lt;el-input v-model=\"pageForm.dataUrl\" auto-complete=\"off\" &gt;&lt;/el-input&gt;&lt;/el-form-item&gt; (2) 修改页面管理服务端PageService在更新cmsPage数据代码中添加： 12//更像DataUrlone.setDataUrl(cmsPage.getDataUrl()); 2.4.2 静态化程序在PageService中定义页面静态化方法，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889 //页面静态化 public String getPageHtml(String pageId) &#123; //获取数据模型 Map model = getModelByPageId(pageId); if (model == null) &#123; ExceptionCast.cast(CmsCode.CMS_GENERATEHTML_DATAISNULL); &#125; //获取页面的模板信息 String template = getTemplateByPageId(pageId); if (StringUtils.isEmpty(template)) &#123; ExceptionCast.cast(CmsCode.CMS_GENERATEHTML_TEMPLATEISNULL); &#125; //执行静态化 String html = generateHtml(template, model); if (StringUtils.isEmpty(html))&#123; ExceptionCast.cast(CmsCode.CMS_GENERATEHTML_HTMLISNULL); &#125; return html; &#125; //执行静态化 private String generateHtml(String template, Map model) &#123; try &#123; //生成配置类 Configuration configuration = new Configuration(Configuration.getVersion()); //模板加载器 StringTemplateLoader stringTemplateLoader = new StringTemplateLoader(); stringTemplateLoader.putTemplate(\"template\", template); //配置模板加载器 configuration.setTemplateLoader(stringTemplateLoader); //获取模板 Template configurationTemplate = configuration.getTemplate(\"template\"); String html = FreeMarkerTemplateUtils.processTemplateIntoString(configurationTemplate, model); return html; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; //获取页面的模板信息 private String getTemplateByPageId(String pageId) &#123; //取出页面的信息 CmsPage cmsPage = this.findById(pageId); if (cmsPage == null) &#123; ExceptionCast.cast(CmsCode.CMS_PAGE_NOTEXISTS); &#125; String templateId = cmsPage.getTemplateId(); if (StringUtils.isEmpty(templateId)) &#123; ExceptionCast.cast(CmsCode.CMS_GENERATEHTML_TEMPLATEISNULL); &#125; //查询模板信息 Optional&lt;CmsTemplate&gt; optional = cmsTemplateRepository.findById(templateId); if (optional.isPresent()) &#123; CmsTemplate cmsTemplate = optional.get(); //获取模板文件id String templateFileId = cmsTemplate.getTemplateFileId(); //取出模板文件内容 GridFSFile gridFSFile = gridFsTemplate.findOne(Query.query(Criteria.where(\"_id\").is(templateFileId))); //打开下载流对象 GridFSDownloadStream gridFSDownloadStream = gridFSBucket.openDownloadStream(gridFSFile.getObjectId()); //创建GridFsResource GridFsResource gridFsResource = new GridFsResource(gridFSFile, gridFSDownloadStream); try &#123; String content = IOUtils.toString(gridFsResource.getInputStream(), \"utf-8\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125; //获取数据模型 private Map getModelByPageId(String pageId) &#123; //取出页面的信息 CmsPage cmsPage = this.findById(pageId); if (cmsPage == null) &#123; ExceptionCast.cast(CmsCode.CMS_PAGE_NOTEXISTS); &#125; //取出页面的dataUrl String dataUrl = cmsPage.getDataUrl(); if (StringUtils.isNotEmpty(dataUrl)) &#123; ExceptionCast.cast(CmsCode.CMS_GENERATEHTML_DATAURLISNULL); &#125; ResponseEntity&lt;Map&gt; forEntity = restTemplate.getForEntity(dataUrl, Map.class); Map body = forEntity.getBody(); return body; &#125;&#125; 单元测试getPageHtml方法 1234567891011@SpringBootTest@RunWith(SpringRunner.class)public class PageServiceTest &#123; @Autowired PageService pageService; @Test public void testGetPageHtml()&#123; String pageHtml = pageService.getPageHtml(\"5dc6b56f69ffadf1002adbaa\"); System.out.println(pageHtml); &#125;&#125; 3.页面预览3.1 页面预览开发3.1.1 需求分析页面在发布前增加页面预览的步骤，方便用户检查页面内容是否正确。页面预览的流程如下： 1、用户进入cms前端，点击“页面预览”在浏览器请求cms页面预览链接2、cms根据页面id查询DataUrl并远程请求DataUrl获取数据模型3、cms根据页面id查询页面模板内容4、cms执行页面静态化5、cms将静态化内容响应给浏览器6、在浏览器展示页面内容，实现页面预览的功能 3.1.2 搭建环境在cms服务需要集成freemarker： (1) 在CMS服务中加入freemarker的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; (2) 在application.yml配置freemarker 3.1.3 Service静态化方法在静态化测试章节已经实现。 3.1.4 Controller调用service的静态化方法，将静态化内容通过response输出到浏览器显示 创建CmsPagePreviewController类，用于页面预览： 请求页面id，查询得到页面的模板信息、数据模型url，根据模板和数据生成静态化内容，并输出到浏览器。 12345678910111213141516171819@Controllerpublic class CmsPagePreviewController extends BaseController &#123; @Autowired PageService pageService; //接收到页面id @RequestMapping(value = \"/cms/preview/&#123;pageId&#125;\",method = RequestMethod.GET) public void preview(@PathVariable(\"pageId\")String pageId)&#123; String pageHtml = pageService.getPageHtml(pageId); if (StringUtils.isNotEmpty(pageHtml))&#123; try &#123; ServletOutputStream outputStream = response.getOutputStream(); outputStream.write(pageHtml.getBytes(\"utf-8\")); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 3.2 页面预览测试3.2.1 配置Nginx代理为了通过nginx请求静态资源（css、图片等），通过nginx代理进行页面预览。 在www.xuecheng.com虚拟主机配置： 1234#页面预览location /cms/preview/ &#123; proxy_pass http://cms_server_pool/cms/preview/;&#125; 配置cms_server_pool将请求转发到cms： 1234 #cms页面预览 upstream cms_server_pool&#123;server 127.0.0.1:31001 weight=10; &#125; 重新加载nginx 配置文件。 从cms_page找一个页面进行测试。注意：页面配置一定要正确，需设置正确的模板id和dataUrl。 在浏览器打开：http://www.xuecheng.com/cms/preview/5dc6b56f69ffadf1002adbaa 3.2.2 添加“页面预览”链接在页面列表添加“页面预览”链接，修改page_list.vue: 123456789101112131415 &lt;el-table-column label=\"页面预览\" width=\"80\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-button size=\"small\" type=\"primary\" plain @click=\"preview(scope.row.pageId)\"&gt;页面预览 &lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column label=\"静态化\" width=\"80\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-button size=\"small\" type=\"primary\" plain @click=\"generateHtml(scope.row.pageId)\"&gt;静态化 &lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt;... 添加preview方法： 123preview(pageId)&#123; window.open(\"http://www.xuecheng.com/cms/preview/\"+pageId)&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(十四.在线学习HLS)","slug":"学成在线(十四.在线学习HLS)","date":"2021-05-08T13:19:59.214Z","updated":"2020-06-16T13:39:03.926Z","comments":true,"path":"HLS/","link":"","permalink":"http://tonymua.top/HLS/","excerpt":"1.在线学习需求分析1.1 需求描述学成在线作为在线教育网站，提供多种学习形式，包括：录播、直播、图文、社群等，学生登录进入学习中心即可 在线学习，本章节将开发录播课程的在线学习功能，需求如下： 学生可以在windows浏览器上在线观看视频。 播放器具有快进、快退、暂停等基本功能。 学生可以方便切换章节进行学习。 什么是录播课程？录播课程就是提供录制好课程视频，供用户在线点播，反复学习。 课程视频如何管理？媒资管理系统专门来管理课程视频，用户视频文件上传到媒资系统，并对视频进行编码处理","text":"1.在线学习需求分析1.1 需求描述学成在线作为在线教育网站，提供多种学习形式，包括：录播、直播、图文、社群等，学生登录进入学习中心即可 在线学习，本章节将开发录播课程的在线学习功能，需求如下： 学生可以在windows浏览器上在线观看视频。 播放器具有快进、快退、暂停等基本功能。 学生可以方便切换章节进行学习。 什么是录播课程？录播课程就是提供录制好课程视频，供用户在线点播，反复学习。 课程视频如何管理？媒资管理系统专门来管理课程视频，用户视频文件上传到媒资系统，并对视频进行编码处理 1.2 视频点播解决方案1.2.1 流媒体 概括理解：流媒体就是将视频文件分成许多小块儿，将这些小块儿作为数据包通过网络发送出去，实现一边传输视频数据包一边观看视频。 流式传输在网络上传输音、视频信息有两个方式：下载和流式传输。 下载：就是把音、视频文件完全下载到本机后开始播放，它的特点是必须等到视频文件下载完成方可播放， 播放等待时间较长，无法去播放还未下载的部分视频。 流式传输：就是客户端通过链接视频服务器实时传输音、视频信息，实现“边下载边播放”。 流式传输包括如下两种方式：(1) 顺序流式传输即顺序下载音、视频文件，可以实现边下载边播放，不过，用户只能观看已下载的视频内容，无法快进到未下载的视频部分，顺序流式传输可以使用Http服务器来实现，比如Nginx、Apache等。(2) 实时流式传输可以解决顺序流式传输无法快进的问题，它与Http流式传输不同，它必须使用流媒体服务器并且使用流媒体协议来传输视频，它比Http流式传输复杂。常见的实时流式传输协议有RTSP、RTMP、RSVP 等。 流媒体系统的概要结构(1) 将原始的视频文件通过编码器转换为适合网络传输的流格式，编码后的视频直接输送给媒体服务器。原始的视频文件通常是事先录制好的视频，比如通过摄像机、摄像头等录像、录音设备采集到的音视频文件，体积较大，要想在网络上传输需要经过压缩处理，即通过编码器进行编码。(2) 媒体服务获取到编码好的视频文件，对外提供流媒体数据传输接口，接口协议包括：HTTP、RTSP、 RTMP等。(3) 播放器通过流媒体协议与媒体服务器通信，获取视频数据，播放视频。 1.2.2 点播方案本项目包括点播和直播两种方式，我们先调研点播的方案，如下： 播放器通过 http协议从http服务器上下载视频文件进行播放问题：必须等到视频下载完才可以播放, 不支持快进到某个时间点进行播放 播放器通过rtmp协议连接媒体服务器以实时流方式播放视频问题：使用rtmp协议需要架设媒体服务器, 造价高, 对于直播多采用此方案 播放器使用HLS协议连接http服务器（Nginx、Apache等）实现近实时流方式播放视频HLS协议规定：基于Http协议, 视频封装格式为ts, 视频的编码格式为H264, 音频编码格式为MP3、AAC或者AC3 HLS是什么？HLS的工作方式是：将视频拆分成若干ts格式的小文件，通过m3u8格式的索引文件对这些ts小文件建立索引。一般10秒一个ts文件，播放器连接m3u8文件播放，当快进时通过m3u8即可找到对应的索引文件，并去下载对应的ts文件，从而实现快进、快退以近实时的方式播放视频。采用HLS方案即可实现边下载边播放，并可不用使用rtmp等流媒体协议，不用构建专用的媒体服务器，节省成本。本项目点播方案确定为方案3。 2.视频编码2.1 视频编码格式 文件格式：是指.mp4、.avi、.rmvb等这些不同扩展名的视频文件的文件格式 ，视频文件的内容主要包括视频和音频，其文件格式是按照一定的编码格式去编码，并且按照该文件所规定的封装格式将视频、音频、字幕等信息封装在一起，播放器会根据它们的封装格式去提取出编码，然后由播放器解码，最终播放音视频。 音视频编码格式：通过音视频的压缩技术，将视频格式转换成另一种视频格式，通过视频编码实现流媒体的传输。比如：一个.avi的视频文件原来的编码是a，通过编码后编码格式变为b，音频原来为c，通过编码后变为d。 2.2 FFmpeg 的基本使用我们将视频录制完成后，使用视频编码软件对视频进行编码，本项目使用FFmpeg对视频进行编码 。下载并安装FFmpeg 简单的测试：将一个.avi文件转成mp4、mp3、gif等。比如我们将test.avi文件转成mp4，运行如下命令：转成mp4：ffmpeg -i test.avi test.mp4转成mp3：ffmpeg -i test.avi test.mp3转成gif：ffmpeg -i test.avi test.gif 2.3 生成m3u8/ts文件使用ﬀmpeg生成 m3u8的步骤如下： 先将avi视频转成mp4 1ffmpeg.exe -i lucene.avi -c:v libx264 -s 1280x720 -pix_fmt yuv420p -b:a 63k -b:v 753k -r 18 lucene.mp4 123456-c:v 视频编码为x264 ，x264编码是H264的一种开源编码格式。-s 设置分辨率 -pix_fmt yuv420p：设置像素采样方式，主流的采样方式有三种，YUV4:4:4，YUV4:2:2，YUV4:2:0， 它的作用是根据采样方式来从码流中还原每个像素点的YUV（亮度信息与色彩信息）值。 -b 设置码率，-b:a和-b:v分别表示音频的码率和视频的码率，-b表示音频加视频的总码率。码率对一个视频质量有 很大的作用。-r 帧率，表示每秒更新图像画面的次数，通常大于24肉眼就没有连贯与停顿的感觉了。 将mp4生成m3u8 1ffmpeg -i lucene.mp4 -hls_time 10 -hls_list_size 0 -hls_segment_filename ./hls/lucene_%05d.ts ./hls/lucene.m3u8 123-hls_time 设置每片的长度，单位为秒-hls_list_size n: 保存的分片的数量，设置为0表示保存所有分片 -hls_segment_ﬁlename ：段文件的名称，%05d表示5位数字 生成的效果是：将test.mp4视频文件每10秒生成一个ts文件，最后生成一个m3u8文件，m3u8文件是ts的索引文件。 2.3.1 码率的设置码率又叫比特率即每秒传输的bit数，单位为bps(Bit Per Second)，码率越大传送数据的速度越快。码率的计算公式是：文件大小（转成bit）/ 时长（秒）/1024 = kbps 即每秒传输千位数例如一个1M的视频，它的时长是10s，它的码率等于 11* 1024* 1024* 8/10/1024 = 819Kbps 3.播放器3.1 技术选型 ﬂash播放器：缺点是需要在客户机安装Adobe Flash Player播放器，优点是ﬂash播放器已经很成熟了，并且浏览器对ﬂash支持也很好。 H5播放器：基于h5自带video标签进行构建，优点是大部分浏览器支持H5，不用再安装第三方的ﬂash播放器，并且随着前端技术的发展，h5技术会越来越成熟本项目采用H5播放器，使用Video.js开源播放器。 3.2 Video.js 3.3 搭建媒体服务器​ 正常使用video.js播放视频是通过一个网页，用户通过浏览器打开网页去播放视频，网页和视频都从web服务器请 求，通常视频的url地址使用单独的域名。 cors跨域参数：​ Access-Control-Allow-Origin：允许跨域访问的外域地址​ 通常允许跨域访问的站点不是一个，所以这里用map定义了多个站点。​ 如果允许任何站点跨域访问则设置为*，通常这是不建议的。​ Access-Control-Allow-Credentials： 允许客户端携带证书访问​ Access-Control-Allow-Methods：允许客户端跨域访问的方法 4.媒资管理4.1 需求分析媒资管理系统是每个在线教育平台所必须具备的，百度百科对它的定义如下： 每个教学机构都可以在媒资系统管理自己的教学资源，包括：视频、教案等文件。 目前媒资管理的主要管理对象是课程录播视频，包括：媒资文件的查询、视频上传、视频删除、视频处理等。 媒资查询：教学机构查询自己所拥有的媒体文件。 视频上传：将用户线下录制的教学视频上传到媒资系统。 视频处理：视频上传成功，系统自动对视频进行编码处理。 视频删除：如果该视频已不再使用，可以从媒资系统删除。 下边是媒资系统与其它系统的交互情况： 1.上传媒资文件前端/客户端请求媒资系统上传文件。 文件上传成功将文件存储到媒资服务器，将文件信息存储到数据库。2.使用媒资 课程管理请求媒资系统查询媒资信息，将课程计划与媒资信息对应、存储。3.视频播放 用户进入学习中心请求学习服务学习在线播放视频。 学习服务校验用户资格通过后请求媒资系统获取视频地址。 4.2 上传文件4.2.1 断点续传解决方案​ 通常视频文件都比较大，所以对于媒资系统上传文件的需求要满足大文件的上传要求。http协议本身对上传文件大小没有限制，但是客户的网络环境质量、电脑硬件环境等参差不齐，如果一个大文件快上传完了网断了，电断了没有上传完成，需要客户重新上传，这是致命的，所以对于大文件上传的要求最基本的是断点续传。 断点续传: 断点续传指的是在下载或上传时，将下载或上传任务（一个文件或一个压缩包）人为的划分为几个部分，每一个部分采用一个线程进行上传或下载，如果碰到网络故障，可以从已经上传或下载的部分开始继续上传下载未完成的部分，而没有必要从头开始上传下载，断点续传可以提高节省操作时间，提高用户体验性。如下图： 上传流程如下： 上传前先把文件分成块 一块一块的上传，上传中断后重新上传，已上传的分块则不用再上传 各分块上传完成最后合并文件 文件下载则同理 4.2.2 文件分块与合并为了更好的理解文件分块上传的原理，下边用java代码测试文件的分块与合并。 4.2.2.1文件分块文件分块的流程如下： 获取源文件长度 根据设定的分块文件的大小计算出块数 从源文件读数据依次向每一个块文件写数据。 1234567891011121314151617181920212223242526272829303132333435363738@SpringBootTest@RunWith(SpringRunner.class)public class TestFile &#123; //测试文件分块 @Test public void testChunk() throws Exception &#123; //源文件 File sourceFile = new File(\"E:\\\\test\\\\test.avi\"); //块文件目录 String chunkFileFolder = \"E:\\\\test\\\\chunks\\\\\"; //定义块文件的大小 long chunkFileSize = 1 * 1024 * 1024; //1M //块数 long chunkFileNum = (long) Math.ceil(sourceFile.length() * 1.0 / chunkFileSize); //Math.ceil 向上转型,进1 //创建读文件的对象 RandomAccessFile raf_read = new RandomAccessFile(sourceFile, \"r\"); //缓冲区 byte[] b = new byte[1024]; //分块 for (int i = 0; i &lt; chunkFileNum; i++) &#123; //创建分块文件 File chunkFile = new File(chunkFileFolder + i); //创建写文件的对象 RandomAccessFile raf_write = new RandomAccessFile(chunkFile, \"rw\"); int len = -1; while ((len = raf_read.read(b)) != -1) &#123; //向分块文件中写数据 raf_write.write(b, 0, len); //如果块文件大小达到1M,写下一块 if (chunkFile.length() &gt;= chunkFileSize) &#123; break; &#125; &#125; raf_write.close(); &#125; raf_read.close(); &#125;&#125; 4.2.2.2文件分块文件合并流程： 找到要合并的文件并按文件合并的先后进行排序 创建合并文件 依次从合并的文件中读取数据向合并文件写入数 123456789101112131415161718192021222324252627282930313233343536373839//测试文件合并@Testpublic void testMergeFile() throws Exception &#123; //分块文件目录 String chunkFilePath = \"E:\\\\test\\\\chunks\\\\\"; //块文件目录对象 File chunkFileFolder = new File(chunkFilePath); //块文件列表 File[] files = chunkFileFolder.listFiles(); //块文件按名称升序 List&lt;File&gt; fileList = Arrays.asList(files); Collections.sort(fileList, new Comparator&lt;File&gt;() &#123; @Override public int compare(File o1, File o2) &#123; if (Integer.parseInt(o1.getName()) &gt; Integer.parseInt(o2.getName())) &#123; return 1; &#125; return -1; &#125; &#125;); //合并文件 File mergeFile = new File(\"E:\\\\test\\\\testMerge.avi\"); //创建新文件 boolean newFile = mergeFile.createNewFile(); //创建写对象 RandomAccessFile raf_write = new RandomAccessFile(mergeFile, \"rw\"); //缓冲区 byte[] b = new byte[1024]; for (File chunkFile : fileList) &#123; //创建读对象 RandomAccessFile raf_read = new RandomAccessFile(chunkFile, \"r\"); int len = -1; while ((len = raf_read.read(b)) != -1) &#123; raf_write.write(b, 0, len); &#125; raf_read.close(); &#125; raf_write.close();&#125; 4.3 Api接口使用WebUploader上传流程如下：定义文件上传的Api接口，此接收是前端WebUploader调用服务端的接口。编写此接口需要参数前端WebUploader应用代码。 xc-serve-api com.xuecheng.api.media.MediaUploadControllerApi 1234567891011121314151617181920212223242526272829@Api(value = \"媒资管理接口\")public interface MediaUploadControllerApi &#123; //文件上传前的准备工作 @ApiOperation(\"文件上传注册\") public ResponseResults register(String fileMd5, String fileName, Long fileSize, String mimetype, String fileExt ); @ApiOperation(\"校验分块文件是否存在\") public CheckChunkResult checkchunk(String fileMd5, Integer chunk, Integer fileSize); @ApiOperation(\"上传分块\") public ResponseResult uploadchunk(MultipartFile file, String fileMd5, Integer chunk); @ApiOperation(\"合并分块\") public ResponseResult mergechunks(String fileMd5, String fileName, Long fileSize, String mimetype, String fileExt);&#125; 4.4 媒资服务端实现4.4.1 业务流程服务端需要实现如下功能： 上传前检查上传环境检查文件是否上传，已上传则直接返回。检查文件上传路径是否存在，不存在则创建。 分块检查, 检查分块文件是否上传，已上传则返回true。未上传则检查上传路径是否存在，不存在则创建。 分块上传将分块文件上传到指定的路径。 合并分块将所有分块文件合并为一个文件。在数据库记录文件信息。 4.4.2 上传注册由于上传过程复杂，开发时按业务流程分别实现。 配置 application.yml配置上传文件的路径： 12xc-service-manage-media: upload-location: E:/test/ 定义Dao媒资文件管理Dao 12public interface MediaFileRepository extends MongoRepository&lt;MediaFile,String&gt; &#123;&#125; Service功能：检查上传文件是否存在 ​ 创建文件目录 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Servicepublic class MediaUploadService &#123; @Autowired MediaFileRepository mediaFileRepository; @Value(\"$&#123;xc-service-manage-media.upload-location&#125;\") String upload_location; /** * 根据文件md5得到文件路径 * 规则： * 一级目录：md5的第一个字符 * 二级目录：md5的第二个字符 * 三级目录：md5 * 文件名：md5+文件扩展名 * * @param fileMd5 文件md5值 * @param fileExt 文件扩展名 * @return 文件路径 */ //得到文件所属目录的路径 private String getFileFolderPath(String fileMd5) &#123; return upload_location + fileMd5.substring(0, 1) + \"/\" + fileMd5.substring(1, 2) + \"/\" + fileMd5 + \"/\"; &#125; //得到文件的路径 private String getFilePath(String fileMd5, String fileExt) &#123; return upload_location + fileMd5.substring(0, 1) + \"/\" + fileMd5.substring(1, 2) + \"/\" + fileMd5 + \"/\" + fileMd5 + \".\" + fileExt; &#125; //得到块文件所属目录 private String getChunkFileFolderPath(String fileMd5) &#123; return upload_location + fileMd5.substring(0, 1) + \"/\" + fileMd5.substring(1, 2) + \"/\" + fileMd5 + \"/\" + \"/chunk/\"; &#125; //文件上传前的注册,检查文件是否存在 public ResponseResult register(String fileMd5, String fileName, Long fileSize, String mimetype, String fileExt) &#123; //1.检查文件在磁盘上是否存在 //文件所属目录的路径 String fileFolderPath = this.getFileFolderPath(fileMd5); //文件路径 String filePath = this.getFilePath(fileMd5, fileExt); File file = new File(filePath); //检验是否存在 boolean exists = file.exists(); //2.检查文件信息是否在mongodb中是否存在 Optional&lt;MediaFile&gt; optional = mediaFileRepository.findById(fileMd5); if (exists &amp;&amp; optional.isPresent()) &#123; //文件存在 ExceptionCast.cast(MediaCode.UPLOAD_FILE_REGISTER_EXIST); &#125; //文件不存在,检查文件所在目录是否存在,如果不存在则创建 File fileFolder = new File(fileFolderPath); if (!fileFolder.exists()) &#123; fileFolder.mkdirs(); &#125; return new ResponseResult(CommonCode.SUCCESS); &#125;&#125; 4.4.3 分块检查1234567891011121314//分块检查 public CheckChunkResult checkchunk(String fileMd5, Integer chunk, Integer fileSize) &#123; //检查分块文件是否存在 //得到分块文件所在目录 String chunkFileFolderPath = this.getChunkFileFolderPath(fileMd5); //块文件 File chunkFile = new File(chunkFileFolderPath + chunk); if (chunkFile.exists()) &#123; return new CheckChunkResult(CommonCode.SUCCESS, true); &#125; else &#123; return new CheckChunkResult(CommonCode.SUCCESS, false); &#125; &#125; 4.4.4 上传分块12345678910111213141516171819202122232425262728293031323334//上传分块public ResponseResult uploadchunk(MultipartFile file, String fileMd5, Integer chunk) &#123; //检查分块目录,如果不存在则要自动创建 //得到分块目录 String chunkFileFolderPath = this.getChunkFileFolderPath(fileMd5); //得到分块文件路径 String chunkFilePath = chunkFileFolderPath + chunk; File chunkFileFolder = new File(chunkFileFolderPath); if (!chunkFileFolder.exists()) &#123; chunkFileFolder.mkdirs(); &#125; //得到上传文件输入流 InputStream inputStream = null; FileOutputStream outputStream = null; try &#123; inputStream = file.getInputStream(); outputStream = new FileOutputStream(new File(chunkFilePath)); IOUtils.copy(inputStream, outputStream); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return new ResponseResult(CommonCode.SUCCESS);&#125; 4.4.5 合并分块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798//合并分块文件public ResponseResult mergechunks(String fileMd5, String fileName, Long fileSize, String mimetype, String fileExt) &#123; //1.合并所有分块 //得到分块文件所属目录 String chunkFileFolderPath = this.getChunkFileFolderPath(fileMd5); File chunkFileFolder = new File(chunkFileFolderPath); //分块文件列表 File[] files = chunkFileFolder.listFiles(); List&lt;File&gt; fileList = Arrays.asList(files); //创建一个合并文件 String filePath = this.getFilePath(fileMd5, fileExt); File mergeFile = new File(filePath); //执行合并 mergeFile = this.mergeFile(fileList, mergeFile); if (mergeFile == null) &#123; //合并文件失败 ExceptionCast.cast(MediaCode.MERGE_FILE_FAIL); &#125; //2.校验文件的md5值是否和前端传入的md5一致 boolean checkFileMd5 = this.checkFileMd5(mergeFile, fileMd5); if (!checkFileMd5) &#123; ExceptionCast.cast(MediaCode.MERGE_FILE_CHECKFAIL); &#125; //3.将文件的信息写入mongodb MediaFile mediaFile = new MediaFile(); mediaFile.setFileId(fileMd5); mediaFile.setFileOriginalName(fileName); mediaFile.setFileName(fileMd5 + \".\" + fileExt); //文件路径保存相对路径 mediaFile.setFilePath(fileMd5.substring(0, 1) + \"/\" + fileMd5.substring(1, 2) + \"/\" + fileMd5 + \"/\"); mediaFile.setFileSize(fileSize); mediaFile.setUploadTime(new Date()); mediaFile.setMimeType(mimetype); mediaFile.setFileType(fileExt); //状态为上传成功 mediaFile.setFileStatus(\"301002\"); MediaFile save = mediaFileRepository.save(mediaFile); return new ResponseResult(CommonCode.SUCCESS);&#125;//校验文件private boolean checkFileMd5(File mergeFile, String md5) &#123; //创建文件输入流 try &#123; FileInputStream inputStream = new FileInputStream(mergeFile); //得到文件的md5 String md5Hex = DigestUtils.md5Hex(inputStream); //校验 if (md5.equalsIgnoreCase(md5Hex)) &#123; return true; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return false;&#125;//合并文件private File mergeFile(List&lt;File&gt; chunkFileList, File mergeFile) &#123; try &#123; if (mergeFile.exists()) &#123; mergeFile.delete(); &#125; else &#123; //创建一个新文件 mergeFile.createNewFile(); &#125; //对块文件进行排序 Collections.sort(chunkFileList, new Comparator&lt;File&gt;() &#123; @Override public int compare(File o1, File o2) &#123; if (Integer.parseInt(o1.getName()) &gt; Integer.parseInt(o2.getName())) &#123; return 1; &#125; return -1; &#125; &#125;); //创建一个写对象 RandomAccessFile raf_write = new RandomAccessFile(mergeFile, \"rw\"); //缓冲区 byte[] b = new byte[1024]; for (File chunkFile : chunkFileList) &#123; //创建一个读对象 RandomAccessFile raf_read = new RandomAccessFile(chunkFile, \"r\"); int len = -1; while ((len = raf_read.read(b)) != -1) &#123; raf_write.write(b, 0, len); &#125; raf_read.close(); &#125; raf_write.close(); return mergeFile; &#125; catch (IOException e) &#123; e.printStackTrace(); return null; &#125;&#125;","categories":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/categories/项目/"}],"tags":[{"name":"HLS","slug":"HLS","permalink":"http://tonymua.top/tags/HLS/"},{"name":"文件上传","slug":"文件上传","permalink":"http://tonymua.top/tags/文件上传/"},{"name":"文件分块","slug":"文件分块","permalink":"http://tonymua.top/tags/文件分块/"}]},{"title":"学成在线(十五.媒资管理)","slug":"学成在线(十五.媒资管理)","date":"2021-05-08T13:19:59.212Z","updated":"2020-06-25T13:51:28.242Z","comments":true,"path":"Media_Manager/","link":"","permalink":"http://tonymua.top/Media_Manager/","excerpt":"1.视频处理1.1 需求分析原始视频通常需要经过编码处理，生成m3u8和ts文件方可基于HLS协议播放视频。通常用户上传原始视频，系统自动处理成标准格式，系统对用户上传的视频自动编码、转换，最终生成m3u8文件和ts文件，处理流程如下： 用户上传视频成功 系统对上传成功的视频自动开始编码处理 用户查看视频处理结果，没有处理成功的视频用户可在管理界面再次触发处理 视频处理完成将视频地址及处理结果保存到数据库","text":"1.视频处理1.1 需求分析原始视频通常需要经过编码处理，生成m3u8和ts文件方可基于HLS协议播放视频。通常用户上传原始视频，系统自动处理成标准格式，系统对用户上传的视频自动编码、转换，最终生成m3u8文件和ts文件，处理流程如下： 用户上传视频成功 系统对上传成功的视频自动开始编码处理 用户查看视频处理结果，没有处理成功的视频用户可在管理界面再次触发处理 视频处理完成将视频地址及处理结果保存到数据库 视频处理流程如下： 视频处理进程的任务是接收视频处理消息进行视频处理，业务流程如下： 监听MQ，接收视频处理消息。 进行视频处理。 向数据库写入视频处理结果。视频处理进程属于媒资管理系统的一部分，考虑提高系统的扩展性，将视频处理单独定义视频处理工程。 1.2 视频处理开发1.2.1 RabbitMQ配置 使用rabbitMQ的routing交换机模式，视频处理程序监听视频处理队列，如下图： 12345678910111213141516171819202122232425262728293031323334353637383940@Configurationpublic class RabbitMQConfig &#123; public static final String EX_MEDIA_PROCESSTASK = \"ex_media_processor\"; //视频处理队列 @Value(\"$&#123;xc-service-manage-media.mq.queue-media-video-processor&#125;\") public String queue_media_video_processtask; //视频处理路由 @Value(\"$&#123;xc-service-manage-media.mq.routingkey-media-video&#125;\") public String routingkey_media_video; //消费者并发数量 public static final int DEFAULT_CONCURRENT = 10; /** * 交换机配置 * @return the exchange */ @Bean(EX_MEDIA_PROCESSTASK) public Exchange EX_MEDIA_VIDEOTASK() &#123; return ExchangeBuilder.directExchange(EX_MEDIA_PROCESSTASK).durable(true).build(); &#125; //声明队列 @Bean(\"queue_media_video_processtask\") public Queue QUEUE_PROCESSTASK() &#123; Queue queue = new Queue(queue_media_video_processtask,true,false,true); return queue; &#125; /** * 绑定队列到交换机. * @param queue the queue * @param exchange the exchange * @return the binding */ @Bean public Binding binding_queue_media_processtask(@Qualifier(\"queue_media_video_processtask\") Queue queue, @Qualifier(EX_MEDIA_PROCESSTASK) Exchange exchange) &#123; return BindingBuilder.bind(queue).to(exchange).with(routingkey_media_video).noargs(); &#125;&#125; 在application.yml中配置队列名称及routingkey 1234xc-service-manage-media: mq: queue-media-video-processor: queue_media_video_processor routingkey-media-video: routingkey_media_video 1.2.2 视频处理技术方案如何通过程序进行视频处理？ffmpeg是一个可行的视频处理程序，可以通过Java调用ffmpeg.exe完成视频处理。在java中可以使用Runtime类和Process Builder类两种方式来执行外部程序，工作中至少掌握一种。本项目使用Process Builder的方式来调用ffmpeg完成视频处理。关于Process Builder的测试如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@SpringBootTest@RunWith(SpringRunner.class)public class TestProcessBuilder &#123; @Test public void testProcessBuilder() throws IOException &#123; //创建ProcessBuilder对象 ProcessBuilder processBuilder =new ProcessBuilder(); //设置执行的第三方程序(命令)// processBuilder.command(\"ping\",\"127.0.0.1\"); processBuilder.command(\"ipconfig\");// processBuilder.command(\"java\",\"-jar\",\"f:/xc-service-manage-course.jar\"); //将标准输入流和错误输入流合并，通过标准输入流读取信息就可以拿到第三方程序输出的错误信息、正常信息 processBuilder.redirectErrorStream(true); //启动一个进程 Process process = processBuilder.start(); //由于前边将错误和正常信息合并在输入流，只读取输入流 InputStream inputStream = process.getInputStream(); //将字节流转成字符流 InputStreamReader reader = new InputStreamReader(inputStream,\"gbk\"); //字符缓冲区 char[] chars = new char[1024]; int len = -1; while((len = reader.read(chars))!=-1)&#123; String string = new String(chars,0,len); System.out.println(string); &#125; inputStream.close(); reader.close(); &#125; //测试使用工具类将avi转成mp4 @Test public void testProcessMp4()&#123; //String ffmpeg_path, String video_path, String mp4_name, String mp4folder_path //ffmpeg的路径 String ffmpeg_path = \"E:/software/ffmpeg/bin/ffmpeg.exe\"; //video_path视频地址 String video_path = \"E:\\\\test\\\\1.avi\"; //mp4_name mp4文件名称 String mp4_name =\"1.mp4\"; //mp4folder_path mp4文件目录路径 String mp4folder_path=\"E:\\\\test\\\\\"; Mp4VideoUtil mp4VideoUtil = new Mp4VideoUtil(ffmpeg_path,video_path,mp4_name,mp4folder_path); //开始编码,如果成功返回success，否则返回输出的日志 String result = mp4VideoUtil.generateMp4(); System.out.println(result); &#125;&#125; 上边的代码已经封装成工具类，参见：上边的工具类中： Mp4VideoUtil.java完成avi转mp4 HlsVideoUtil.java完成mp4转hls 1.2.3 视频处理实现1.2.3.1 确定消息格式MQ消息统一采用json格式，视频处理生产方会向MQ发送如下消息，视频处理消费方接收此消息后进行视频处理：{&quot;mediaId&quot;:XXXX} 1.2.3.2 处理流程 接收视频处理消息 判断媒体文件是否需要处理（本视频处理程序目前只接收avi视频的处理）, 当前只有avi文件需要处理，其它文件需要更新处理状态为“无需处理”。 处理前初始化处理状态为“未处理” 处理失败需要在数据库记录处理日志，及处理状态为“处理失败” 处理成功记录处理状态为“处理成功” 1.2.3.3 数据模型在MediaFile类中添加mediaFileProcess_m3u8属性记录ts文件列表，代码如下： 123456789@Data@ToString@Document(collection = \"media_file\")public class MediaFile &#123; ... //hls处理 private MediaFileProcess_m3u8 mediaFileProcess_m3u8; ...&#125; MediaFileProcess_m3u8 123456@Data@ToStringpublic class MediaFileProcess_m3u8 extends MediaFileProcess &#123; //ts列表 private List&lt;String&gt; tslist;&#125; 1.2.3.4 视频处理 视频处理结果需要保存到媒资数据库，创建dao如下： 12public interface MediaFileRepository extends MongoRepository&lt;MediaFile,String&gt; &#123;&#125; 在application.yml中配置ffmpeg的位置及视频目录的根目录： 1234xc-service-manage-media: mq: queue-media-video-processor: queue_media_video_processor routingkey-media-video: routingkey_media_video 处理任务类在mq包下创建MediaProcessTask类，此类负责监听视频处理队列，并进行视频处理。整个视频处理内容较多，这里分两部分实现：生成mp4和生成m3u8。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Componentpublic class MediaProcessTask &#123; @Autowired MediaFileRepository mediaFileRepository; //ffmpeg绝对路径 @Value(\"$&#123;xc-service-manage-media.ffmpeg-path&#125;\") String ffmpeg_path; //上传文件根目录 @Value(\"$&#123;xc-service-manage-media.video-location&#125;\") String serverPath; //接收视频处理消息进行视频处理 @RabbitListener(queues = \"$&#123;xc-service-manage-media.mq.queue-media-video-processor&#125;\") public void receiveMediaProcessTask(String msg) &#123; //1.解析消息内容,得到mediaId Map map = JSON.parseObject(msg, Map.class); String mediaId = (String) map.get(\"mediaId\"); //2.根据mediaId查询文件信息 Optional&lt;MediaFile&gt; optional = mediaFileRepository.findById(mediaId); if (!optional.isPresent()) &#123; return; &#125; MediaFile mediaFile = optional.get(); //文件类型 String fileType = mediaFile.getFileType(); if (!fileType.equals(\"avi\")) &#123; //目前只处理avi文件 mediaFile.setProcessStatus(\"303004\");//处理状态为无需处理 mediaFileRepository.save(mediaFile); return; &#125; else &#123; mediaFile.setProcessStatus(\"303001\"); mediaFileRepository.save(mediaFile); &#125; //3.使用工具类将avi转成mp4 //要处理的视频文件的路径 String video_path=serverPath+ mediaFile.getFilePath()+mediaFile.getFileName(); //生成的mp4的文件名称 String mp4_name=mediaFile.getFileId()+\".mp4\"; //生成mp4所在的路径 String mp4folder_path=serverPath+mediaFile.getFilePath(); //创建工具类对象 Mp4VideoUtil mp4VideoUtil=new Mp4VideoUtil(ffmpeg_path,video_path,mp4_name,mp4folder_path); //进行处理 String result = mp4VideoUtil.generateMp4(); if (result==null||!result.equals(\"success\"))&#123; //处理失败 mediaFile.setProcessStatus(\"303003\"); //定义mediaFileProcess_m3u8 MediaFileProcess_m3u8 mediaFileProcess_m3u8=new MediaFileProcess_m3u8(); mediaFileProcess_m3u8.setErrormsg(result); mediaFile.setMediaFileProcess_m3u8(mediaFileProcess_m3u8); mediaFileRepository.save(mediaFile); return; &#125; //4.将mp4生成m3u8 //mp4视频文件路径 String mp4_video_path=mp4folder_path+mp4_name; //m3u8文件名称 String m3u8_name=mediaFile.getFileId()+\".m3u8\"; //m3u8文件所在目录 String m3u8folder_path=serverPath+mediaFile.getFilePath()+\"hls/\"; HlsVideoUtil hlsVideoUtil=new HlsVideoUtil(ffmpeg_path,mp4_video_path,m3u8_name,m3u8folder_path); result = hlsVideoUtil.generateM3u8(); if (result==null||!result.equals(\"success\"))&#123; //处理失败 mediaFile.setProcessStatus(\"303003\"); //定义mediaFileProcess_m3u8 MediaFileProcess_m3u8 mediaFileProcess_m3u8=new MediaFileProcess_m3u8(); mediaFileProcess_m3u8.setErrormsg(result); mediaFile.setMediaFileProcess_m3u8(mediaFileProcess_m3u8); mediaFileRepository.save(mediaFile); return; &#125; //处理成功 mediaFile.setProcessStatus(\"303002\"); //获取m3u8列表 List&lt;String&gt; ts_list = hlsVideoUtil.get_ts_list(); MediaFileProcess_m3u8 mediaFileProcess_m3u8=new MediaFileProcess_m3u8(); mediaFileProcess_m3u8.setTslist(ts_list); mediaFile.setMediaFileProcess_m3u8(mediaFileProcess_m3u8); //m3u8 fileUrl(视频播放的相对路径) mediaFile.setFileUrl(mediaFile.getFilePath()+\"hls/\"+m3u8_name); mediaFileRepository.save(mediaFile); &#125;&#125; 1.3 发送视频处理消息当视频上传成功后向MQ 发送视频处理消息。修改媒资管理服务的文件上传代码，当文件上传成功向MQ发送视频处理消息。 1.3.1 RabbitMQ配置 将media-processor工程下的RabbitmqConfig配置类拷贝到media工程下。 在media工程下配置mq队列等信息修改application.yml 1234xc-service-manage-media: mq: queue-media-video-processor: queue_media_video_processor routingkey-media-video: routingkey_media_video 1.3.2 修改Service在文件合并方法中添加向mq发送视频处理消息的代码： 1234567891011121314151617181920212223242526 @Autowired RabbitTemplate rabbitTemplate; @Value(\"$&#123;xc-service-manage-media.mq.routingkey-media-video&#125;\") String routingkey_media_video; //发送视频处理MQ消息 public ResponseResult sendProcessVideoMsg(String mediaId)&#123; Optional&lt;MediaFile&gt; optional = mediaFileRepository.findById(mediaId); if (!optional.isPresent())&#123; ExceptionCast.cast(CommonCode.FAIL); &#125; //构造消息内容 Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(\"mediaId\",mediaId); String jsonString = JSON.toJSONString(map); //发送视频处理消息 try &#123;rabbitTemplate.convertAndSend(RabbitMQConfig.EX_MEDIA_PROCESSTASK,routingkey_media_video,jsonString); &#125; catch (AmqpException e) &#123; e.printStackTrace(); return new ResponseResult(CommonCode.FAIL); &#125; return new ResponseResult(CommonCode.SUCCESS); &#125; 在mergechunks方法最后调用sendProcessVideo方法 12345//状态为上传成功 mediaFile.setFileStatus(\"301002\"); MediaFile save = mediaFileRepository.save(mediaFile); sendProcessVideoMsg(mediaFile.getFileId()); return new ResponseResult(CommonCode.SUCCESS);","categories":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/categories/项目/"}],"tags":[{"name":"视频处理","slug":"视频处理","permalink":"http://tonymua.top/tags/视频处理/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://tonymua.top/tags/RabbitMQ/"},{"name":"m3u8","slug":"m3u8","permalink":"http://tonymua.top/tags/m3u8/"}]},{"title":"学成在线(十二.ElasticSearch(二))","slug":"学成在线(十二.ElasticSearch(二))","date":"2021-05-08T13:19:59.211Z","updated":"2020-04-29T02:44:38.129Z","comments":true,"path":"2642/","link":"","permalink":"http://tonymua.top/2642/","excerpt":"1.索引管理1.1 搭建工程1.1.1 ES客户端ES提供多种不同的客户端： TransportClient ES提供的传统客户端，官方计划8.0版本删除此客户端。 RestClient RestClient是官方推荐使用的，它包括两种：Java Low Level REST Client和 Java High Level REST Client。 ES在6.0之后提供 Java High Level REST Client， 两种客户端官方更推荐使用 Java High Level REST Client，不过当前它还处于完善中，有些功能还没有。本教程准备采用 Java High Level REST Client，如果它有不支持的功能，则使用Java Low Level REST Client。","text":"1.索引管理1.1 搭建工程1.1.1 ES客户端ES提供多种不同的客户端： TransportClient ES提供的传统客户端，官方计划8.0版本删除此客户端。 RestClient RestClient是官方推荐使用的，它包括两种：Java Low Level REST Client和 Java High Level REST Client。 ES在6.0之后提供 Java High Level REST Client， 两种客户端官方更推荐使用 Java High Level REST Client，不过当前它还处于完善中，有些功能还没有。本教程准备采用 Java High Level REST Client，如果它有不支持的功能，则使用Java Low Level REST Client。 添加依赖： 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch --&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.2.1&lt;/version&gt;&lt;/dependency&gt; 1.1.2 创建搜索工程创建搜索工程（maven工程）：xc-service-search，添加RestHighLevelClient依赖及junit依赖。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;xc-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../xc-framework-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;xc-service-search&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-service-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;6.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 配置文件 application.yml 12345678server: port: $&#123;port:40100&#125;spring: application: name: xc-search-servicexuecheng: elasticsearch: hostlist: $&#123;eshostlist:127.0.0.1:9200&#125; #多个结点中间用逗号分隔 配置类创建com.xuecheng.search.conﬁg包在其下创建配置类 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class ElasticsearchConfig &#123; @Value(\"$&#123;xuecheng.elasticsearch.hostlist&#125;\") private String hostlist; @Bean public RestHighLevelClient restHighLevelClient()&#123; //解析hostlist配置信息 String[] split = hostlist.split(\",\"); //创建HttpHost数组，其中存放es主机和端口的配置信息 HttpHost[] httpHostArray = new HttpHost[split.length]; for(int i=0;i&lt;split.length;i++)&#123; String item = split[i]; httpHostArray[i] = new HttpHost(item.split(\":\")[0], Integer.parseInt(item.split(\":\")[1]), \"http\"); &#125; //创建RestHighLevelClient客户端 return new RestHighLevelClient(RestClient.builder(httpHostArray)); &#125; //项目主要使用RestHighLevelClient，对于低级的客户端暂时不用 @Bean public RestClient restClient()&#123; //解析hostlist配置信息 String[] split = hostlist.split(\",\"); //创建HttpHost数组，其中存放es主机和端口的配置信息 HttpHost[] httpHostArray = new HttpHost[split.length]; for(int i=0;i&lt;split.length;i++)&#123; String item = split[i]; httpHostArray[i] = new HttpHost(item.split(\":\")[0], Integer.parseInt(item.split(\":\")[1]), \"http\"); &#125; return RestClient.builder(httpHostArray).build(); &#125;&#125; 启动类 12345678910@SpringBootApplication@EntityScan(\"com.xuecheng.framework.domain.search\")//扫描实体类@ComponentScan(basePackages=&#123;\"com.xuecheng.api\"&#125;)//扫描接口@ComponentScan(basePackages=&#123;\"com.xuecheng.search\"&#125;)//扫描本项目下的所有类@ComponentScan(basePackages=&#123;\"com.xuecheng.framework\"&#125;)//扫描common下的所有类public class SearchApplication &#123; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SearchApplication.class, args); &#125;&#125; 1.2 创建索引库1.2.1 API创建索引：Post http://localhost:9200/索引名称 12345678&#123; \"settings\":&#123; \"index\":&#123; \"number_of_shards\":1,#分片的数量 \"number_of_replicas\":0#副本数量 &#125; &#125; &#125; 创建映射：发送：Post http://localhost:9200/索引库名称/类型名称/_mapping创建类型为xc_course的映射 Post http://localhost:9200/xc_course/doc/mapping 12345678910111213141516171819202122232425262728&#123; \"properties\": &#123; \"description\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\" &#125;, \"name\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\" &#125;, \"pic\":&#123; \"type\":\"text\", \"index\":false &#125;, \"price\": &#123; \"type\": \"float\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125;, \"timestamp\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis\" &#125; &#125;&#125; 1.2.2 Java Client1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@SpringBootTest@RunWith(SpringRunner.class)public class testIndex &#123; @Autowired RestHighLevelClient restHighLevelClient; @Autowired RestClient restClient; //创建索引库 @Test public void testCreateIndex() throws IOException &#123; //创建索引对象 CreateIndexRequest createIndexRequest=new CreateIndexRequest(\"xc_course\"); //设置参数 createIndexRequest.settings(Settings.builder().put(\"number_of_shards\",\"1\").put(\"number_of_replicas\",\"0\")); //指定映射 createIndexRequest.mapping(\"doc\",\"&#123;\\n\" + \"\\t\\\"properties\\\": &#123;\\n\" + \"\\t\\t\\\"description\\\": &#123;\\n\" + \"\\t\\t\\t\\\"type\\\": \\\"text\\\",\\n\" + \"\\t\\t\\t\\\"analyzer\\\": \\\"ik_max_word\\\",\\n\" + \"\\t\\t\\t\\\"search_analyzer\\\": \\\"ik_smart\\\"\\n\" + \"\\t\\t&#125;,\\n\" + \"\\t\\t\\\"name\\\": &#123;\\n\" + \"\\t\\t\\t\\\"type\\\": \\\"text\\\",\\n\" + \"\\t\\t\\t\\\"analyzer\\\": \\\"ik_max_word\\\",\\n\" + \"\\t\\t\\t\\\"search_analyzer\\\": \\\"ik_smart\\\"\\n\" + \"\\t\\t&#125;,\\n\" + \"\\t\\t\\\"pic\\\":&#123;\\n\" + \"\\t\\t\\t\\\"type\\\":\\\"text\\\",\\n\" + \"\\t\\t\\t\\\"index\\\":false\\n\" + \"\\t\\t&#125;,\\n\" + \"\\t\\t\\\"price\\\": &#123;\\n\" + \"\\t\\t\\t\\\"type\\\": \\\"float\\\"\\n\" + \"\\t\\t&#125;,\\n\" + \"\\t\\t\\\"studymodel\\\": &#123;\\n\" + \"\\t\\t\\t\\\"type\\\": \\\"keyword\\\"\\n\" + \"\\t\\t&#125;,\\n\" + \"\\t\\t\\\"timestamp\\\": &#123;\\n\" + \"\\t\\t\\t\\\"type\\\": \\\"date\\\",\\n\" + \"\\t\\t\\t\\\"format\\\": \\\"yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis\\\"\\n\" + \"\\t\\t&#125;\\n\" + \"\\t&#125;\\n\" + \"&#125;\", XContentType.JSON); //操作索引的客户端 IndicesClient indices = restHighLevelClient.indices(); //执行创建索引库 CreateIndexResponse createIndexResponse = indices.create(createIndexRequest); //得到响应 boolean acknowledged = createIndexResponse.isAcknowledged(); System.out.println(acknowledged); &#125; //删除索引库 @Test public void testDeleteIndex() throws IOException &#123; //删除索引请求对象 DeleteIndexRequest deleteIndexRequest=new DeleteIndexRequest(\"xc_course\"); //删除索引 IndicesClient indices = restHighLevelClient.indices(); DeleteIndexResponse delete = indices.delete(deleteIndexRequest); //删除索引响应结果 boolean acknowledged = delete.isAcknowledged(); System.out.println(acknowledged); &#125;&#125; 1.3 添加文档1.3.1 API格式如下： PUT /{index}/{type}/{id} { “ﬁeld”: “value”, … } 如果不指定id，ES会自动生成。一个例子：Put http://localhost:9200/xc_course/doc/3 12345678&#123; \"name\": \"Bootstrap开发\", \"description\": \"Bootstrap是由Twitter推出的一个前台页面开发框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量 的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。\", \"studymodel\": \"201002\", \"price\":38.6, \"timestamp\":\"2018‐04‐25 19:11:35\", \"pic\":\"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg\"&#125; 1.3.2 Java Client123456789101112131415161718192021//添加文档@Testpublic void testAddDoc() throws IOException &#123; //准备Json数据 Map&lt;String,Object&gt; jsonMap=new HashMap&lt;&gt;(); jsonMap.put(\"name\",\"Bootstrap开发\"); jsonMap.put(\"description\",\"Bootstrap是由Twitter推出的一个前台页面开发框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量 的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精美界面效果。\"); jsonMap.put(\"studymodel\",\"201002\"); jsonMap.put(\"price\",\"38.8\"); jsonMap.put(\"timestamp\",\"2018‐04‐25 19:11:35\"); jsonMap.put(\"pic\",\"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg\"); //索引请求对象 IndexRequest indexRequest=new IndexRequest(\"xc_course\",\"doc\"); //指定索引文档内容 indexRequest.source(jsonMap); //索引响应对象 IndexResponse indexResponse = restHighLevelClient.index(indexRequest); //获取响应结果 DocWriteResponse.Result result = indexResponse.getResult(); System.out.println(result);&#125; 1.4 查询文档1.4.1 API格式如下： GET /{index}/{type}/{id} 1.4.2 Java Client12345678910//查询文档@Testpublic void testGetDoc() throws IOException &#123; //查询请求对象 GetRequest getRequest=new GetRequest(\"xc_course\",\"doc\",\"li4jcnABjL_5Yi0Ybjbc\"); GetResponse getResponse = restHighLevelClient.get(getRequest); //得到文档内容 Map&lt;String, Object&gt; sourceAsMap = getResponse.getSourceAsMap(); System.out.println(sourceAsMap);&#125; 1.5 更新文档1.5.1 ApiES更新文档的顺序是：先检索到文档、将原来的文档标记为删除、创建新文档、删除旧文档，创建新文档就会重建 索引。通过请求Url有两种方法： 完全替换 Post：http://localhost:9200/xc_test/doc/3 局部更新下边的例子是只更新price字段 Post: http://localhost:9200/xc_test/doc/3/_update 123&#123; \"doc\":&#123;\"price\":66.6&#125; &#125; 1.5.2 Java Client使用 Client Api更新文档的方法同上边第二种局部更新方法。可以指定文档的部分字段也可以指定完整的文档内容。 1234567891011//更新文档@Testpublic void updateDoc() throws IOException &#123; UpdateRequest updateRequest=new UpdateRequest(\"xc_course\",\"doc\",\"li4jcnABjL_5Yi0Ybjbc\"); Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(\"price\",\"98\"); updateRequest.doc(map); UpdateResponse updateResponse = restHighLevelClient.update(updateRequest); RestStatus status = updateResponse.status(); System.out.println(status);&#125; 1.6 删除文档1.6.1 Api根据id删除，格式如下：DELETE /{index}/{type}/{id} 搜索匹配删除，将搜索出来的记录删除，格式如下：POST /{index}/{type}/_delete_by_query下边是搜索条件例子： 1234567&#123; \"query\":&#123; \"term\":&#123; \"studymodel\":\"201001\" &#125; &#125; &#125; 上边例子的搜索匹配删除会将studymodel为201001的记录全部删除。 1.6.2 Java Client12345678910111213//删除文档@Testpublic void testDelDoc() throws IOException &#123; //删除文档id String id=\"li4jcnABjL_5Yi0Ybjbc\"; //删除索引请求对象 DeleteRequest deleteRequest=new DeleteRequest(\"xc_course\",\"doc\",id); //响应对象 DeleteResponse deleteResponse = restHighLevelClient.delete(deleteRequest); //获取响应结果 DocWriteResponse.Result result = deleteResponse.getResult(); System.out.println(result);&#125; 搜索匹配删除还没有具体的api，可以采用先搜索出文档id，根据文档id删除。 2.搜索管理2.1 简单搜索简单搜索就是通过url进行查询，以Get方式请求ES。格式：Get ../_search?q=….. q：搜索字符串。例子：?q=name:spring 搜索name中包括spring的文档。 2.2 DSL搜索DSL(Domain Speciﬁc Language)是ES提出的基于json的搜索方式，在搜索时传入特定的json格式的数据来完成不 同的搜索需求。DSL比URI搜索方式功能强大，在项目中建议使用DSL方式来完成搜索。 2.2.1 查询所有文档查询所有索引库的文档。发送：Post http://localhost:9200/_search查询指定索引库指定类型下的文档。（通过使用此方法）发送：Post http://localhost:9200/xc_course/doc/_search 123456&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\" : [\"name\",\"studymodel\"] &#125; _source：source源过滤设置，指定结果中所包括的字段有哪些。 结果说明： took：本次操作花费的时间，单位为毫秒。 timed_out：请求是否超时 _shards：说明本次操作共搜索了哪些分片 hits：搜索命中的记录 hits.total ： 符合条件的文档总数 hits.hits ：匹配度较高的前N个文档 hits.max_score：文档匹配得分，这里为高分 _score：每个文档都有一个匹配度得分，按照降序排列。 _source：显示了文档的原始内容。 JavaClient 12345678910111213141516171819202122232425262728293031323334353637@Testpublic void testSearchAll() throws Exception &#123; //搜索请求对象 SearchRequest searchRequest=new SearchRequest(\"xc_course\"); //指定类型 searchRequest.types(\"doc\"); //构建搜索源对象 SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder(); //搜索方式 //matchAllQuery搜索全部 searchSourceBuilder.query(QueryBuilders.matchAllQuery()); //设置源字段过滤,第一个参数结果集包括哪些字段,第二个参数结果集不包括哪些字段 searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); //向搜索请求对象设置搜索源 searchRequest.source(searchSourceBuilder); //执行搜索,向ES发起http请求 SearchResponse searchResponse = restHighLevelClient.search(searchRequest); //搜索结果 SearchHits hits = searchResponse.getHits(); //匹配到的总记录数 long totalHits = hits.getTotalHits(); //得到匹配度高度文档 SearchHit[] searchHits = hits.getHits(); //日期格式化对象 SimpleDateFormat dateFormat=new SimpleDateFormat(\"yyyy‐MM‐dd HH:mm:ss\"); for (SearchHit searchHit : searchHits) &#123; //文档的主键 String id = searchHit.getId(); //源文档内容 Map&lt;String, Object&gt; sourceAsMap = searchHit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); String studymodel = (String) sourceAsMap.get(\"studymodel\"); String price = (String) sourceAsMap.get(\"price\"); Date timestamp = dateFormat.parse(sourceAsMap.get(\"timestamp\").toString()); System.out.println(name+studymodel+price+timestamp); &#125;&#125; 2.2.2 分页查询ES支持分页查询，传入两个参数：from和size。form：表示起始文档的下标，从0开始。 size：查询的文档数量。发送：Post http://localhost:9200/xc_course/doc/_search 1234567&#123; \"from\" : 0, \"size\" : 1, \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\" : [\"name\",\"studymodel\"] &#125; JavaClient 1234567891011SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();//设置分页参数//页码int page=1;//每页记录数int size=1;//计算出记录的起始下标int from=(page-1)*size;searchSourceBuilder.from(from);//起始记录下标,从0开始searchSourceBuilder.size(size);//每页显示记录时0searchSourceBuilder.query(QueryBuilders.matchAllQuery()); 2.2.3 Term QueryTerm Query为精确查询，在搜索时会整体匹配关键字，不再将关键字分词。发送：Post http://localhost:9200/xc_course/doc/_search 12345678&#123; \"query\": &#123; \"term\" : &#123; \"name\": \"spring\" &#125; &#125;, \"_source\" : [\"name\",\"studymodel\"] &#125; 上边的搜索会查询name包括“spring”这个词的文档。 JavaClient 12345SearchRequest searchRequest=new SearchRequest(\"xc_course\");searchRequest.types(\"doc\");SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();//搜索方式termQuerysearchSourceBuilder.query(QueryBuilders.termQuery(\"name\",\"spring\")); 2.3.4 根据id精确匹配ES提供根据多个id值匹配的方法：测试：Post： http://127.0.0.1:9200/xc_course/doc/_search 12345678&#123; \"query\": &#123; \"ids\" : &#123; \"type\" : \"doc\", \"values\" : [\"3\", \"4\", \"100\"] &#125; &#125; &#125; JavaClient 搜索方式termsQuery 1234567SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();//搜索方式termsQuery//定义idString[] ids=new String[]&#123;\"li4jcnABjL_5Yi0Ybjbc\",\"UI0ld3ABiLWW6w-rp_8z\"&#125;;searchSourceBuilder.query(QueryBuilders.termsQuery(\"_id\",ids));searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;);searchRequest.source(searchSourceBuilder); 2.3.5 Match Query 基本使用 match Query即全文检索，它的搜索方式是先将搜索字符串分词，再使用各各词条从索引中搜索。match query与Term query区别是match query在搜索前先将搜索关键字分词，再拿各各词语去索引中搜索, 而term query,输入的查询内容是什么，就会按照什么去查询，并不会解析查询内容，对它分词。 发送：Post http://localhost:9200/xc_course/doc/_search 12345678910&#123; \"query\": &#123; \"match\" : &#123; \"description\" : &#123; \"query\" : \"spring开发\", \"operator\" : \"or\" &#125; &#125; &#125; &#125; query：搜索的关键字，对于英文关键字如果有多个单词则中间要用半角逗号分隔，而对于中文关键字中间可以用逗号分隔也可以不用。operator：or 表示只要有一个词在文档中出现则就符合条件，and表示每个词都在文档中出现则才符合条件。 上边的搜索的执行过程是：(1) 将“spring开发”分词，分为spring、开发两个词(2) 再使用spring和开发两个词去匹配索引中搜索。(3) 由于设置了operator为or，只要有一个词匹配成功则就返回该文档。 JavaClient 12345 SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder(); //搜索方式MatchQuery//匹配关键字 searchSourceBuilder.query(QueryBuilders.matchQuery(\"description\",\"spring开发框架\").operator(Operator.OR)); searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); minimum_should_match上边使用的operator = or表示只要有一个词匹配上就得分，如果实现三个词至少有两个词匹配如何实现？ 使用minimum_should_match可以指定文档匹配词的占比：比如搜索语句如下： 12345678910&#123; \"query\": &#123; \"match\" : &#123; \"description\" : &#123; \"query\" : \"spring开发框架\", \"minimum_should_match\": \"80%\" &#125; &#125; &#125; &#125; “spring开发框架”会被分为三个词：spring、开发、框架设置”minimum_should_match”: “80%”表示，三个词在文档的匹配占比为80%，即30.8=2.4，*向上取整得2，表示至少有两个词在文档中要匹配成功** JavaClient 1234SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();//搜索方式MatchQuerysearchSourceBuilder.query(QueryBuilders.matchQuery(\"name\",\"spring开发框架\").minimumShouldMatch(\"80%\"));searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); 2.3.6 MultiMatch Query上边学习的termQuery和matchQuery一次只能匹配一个Field，本节学习multiQuery，一次可以匹配多个字段. 基本使用单项匹配是在一个ﬁeld中去匹配，多项匹配是拿关键字去多个Field中匹配。例子：发送：Post http://localhost:9200/xc_course/doc/_search拿关键字 “spring css”去匹配name 和description字段。 123456789 &#123; \"query\": &#123; \"multi_match\" : &#123; \"query\" : \"spring css\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name\", \"description\" ] &#125; &#125; &#125; 提升boost 匹配多个字段时可以提升字段的boost（权重）来提高得分例子：提升boost之前，执行下边的查询： 123456789&#123; \"query\": &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name\", \"description\" ] &#125; &#125; &#125; 通过查询发现Bootstrap排在前边。 提升boost，通常关键字匹配上name的权重要比匹配上description的权重高，这里可以对name的权重提升。 12345678&#123; \"query\": &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ] &#125; &#125; &#125; “name^10” 表示权重提升10倍，执行上边的查询，发现name中包括spring关键字的文档排在前边。 JavaClient 123456 SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder(); //搜索方式MultiMatchQuerysearchSourceBuilder.query(QueryBuilders .multiMatchQuery(\"spring\",\"name\",\"description\") .minimumShouldMatch(\"80%\").field(\"name\",10)); searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;); 2.3.7 布尔查询布尔查询对应于Lucene的BooleanQuery查询，实现将多个查询组合起来。 三个参数：must：文档必须匹配must所包括的查询条件，相当于 “AND”should：文档应该匹配should所包括的查询条件其中的一个或多个，相当于 “OR”must_not：文档不能匹配must_not所包括的该查询条件，相当于“NOT” 分别使用must、should、must_not测试下边的查询：发送：POST http://localhost:9200/xc_course/doc/_search 12345678910111213141516171819202122&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\"], \"from\" : 0, \"size\" : 1, \"query\": &#123; \"bool\" : &#123; \"must\":[ &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ] &#125; &#125;, &#123; \"term\":&#123; \"studymodel\" : \"201001\" &#125; &#125; ] &#125; &#125; &#125; must：表示必须，多个查询条件必须都满足。（通常使用must）should：表示或者，多个查询条件只要有一个满足即可。must_not：表示非。 JavaClient 1234567891011SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();//布尔查询//先定义一个MultiMatchQueryMultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(\"spring\", \"name\", \"description\").minimumShouldMatch(\"80%\").field(\"name\", 10);//再定义一个TermQueryTermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"studymodel\", \"201000\");//定义一个boolQueryBoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();boolQueryBuilder.must(multiMatchQueryBuilder);boolQueryBuilder.must(termQueryBuilder);searchSourceBuilder.query(boolQueryBuilder); 2.3.8 过滤器过滤是针对搜索的结果进行过滤，过滤器主要判断的是文档是否匹配，不去计算和判断文档的匹配度得分，所以过滤器性能比查询要高，且方便缓存，推荐尽量使用过滤器去实现查询或者过滤器和查询共同使用。过滤器在布尔查询中使用，下边是在搜索结果的基础上进行过滤： 1234567891011121314151617181920&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\",\"price\"], \"query\": &#123; \"bool\" : &#123; \"must\":[ &#123; \"multi_match\" : &#123; \"query\" : \"spring框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ] &#125; &#125; ], \"filter\": [ &#123; \"term\": &#123; \"studymodel\": \"201001\" &#125;&#125;, &#123; \"range\": &#123; \"price\": &#123; \"gte\": 60 ,\"lte\" : 100&#125;&#125;&#125; ] &#125; &#125; &#125; range：范围过滤，保留大于等于60并且小于等于100的记录。term：项匹配过滤，保留studymodel等于”201001”的记录。 注意：range和term一次只能对一个Field设置范围过虑。 JavaClient 1234567891011SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();//布尔查询//先定义一个MultiMatchQueryMultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(\"spring\", \"name\", \"description\").minimumShouldMatch(\"80%\").field(\"name\", 10);//定义一个boolQueryBoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();boolQueryBuilder.must(multiMatchQueryBuilder);//再定义一个过滤器boolQueryBuilder.filter(QueryBuilders.termQuery(\"studymodel\",\"201000\"));boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(50).lte(100));searchSourceBuilder.query(boolQueryBuilder); 2.3.9 排序可以在字段上添加一个或多个排序，支持在keyword、date、ﬂoat等类型上添加，text类型的字段上不允许添加排 序。 发送 POST http://localhost:9200/xc_course/doc/_search过滤0-10元价格范围的文档，并且对结果进行排序，先按studymodel降序，再按价格升序 123456789101112131415161718&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\",\"price\"], \"query\": &#123; \"bool\" : &#123; \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"gte\": 0 ,\"lte\" : 100&#125;&#125;&#125; ] &#125; &#125;, \"sort\" : [ &#123; \"studymodel\" : \"desc\" &#125;, &#123; \"price\" : \"asc\" &#125; ] &#125; JavaClient 12345678910SearchSourceBuilder searchSourceBuilder=new SearchSourceBuilder();BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(50).lte(100));searchSourceBuilder.query(boolQueryBuilder);//添加排序searchSourceBuilder.sort(\"studymodel\", SortOrder.DESC);searchSourceBuilder.sort(\"price\",SortOrder.ASC);searchSourceBuilder.fetchSource(new String[]&#123;\"name\",\"studymodel\",\"price\",\"timestamp\"&#125;,new String[]&#123;&#125;);searchRequest.source(searchSourceBuilder);SearchResponse searchResponse = restHighLevelClient.search(searchRequest); 2.3.10 高亮显示高亮显示可以将搜索结果一个或多个字突出显示，以便向用户展示匹配关键字的位置。在搜索语句中添加highlight即可实现，如下：Post http://127.0.0.1:9200/xc_course/doc/_search 123456789101112131415161718192021222324252627282930313233&#123; \"_source\" : [ \"name\", \"studymodel\", \"description\",\"price\"], \"query\": &#123; \"bool\" : &#123; \"must\":[ &#123; \"multi_match\" : &#123; \"query\" : \"开发框架\", \"minimum_should_match\": \"50%\", \"fields\": [ \"name^10\", \"description\" ], \"type\":\"best_fields\" &#125; &#125; ], \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"gte\": 0 ,\"lte\" : 100&#125;&#125;&#125; ] &#125; &#125;, \"sort\" : [ &#123; \"price\" : \"asc\" &#125; ], \"highlight\": &#123; \"pre_tags\": [\"&lt;tag&gt;\"], \"post_tags\": [\"&lt;/tag&gt;\"], \"fields\": &#123; \"name\": &#123;&#125;, \"description\":&#123;&#125; &#125; &#125; &#125; JavaClient 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Testpublic void testHighLight() throws Exception &#123; SearchRequest searchRequest = new SearchRequest(\"xc_course\"); searchRequest.types(\"doc\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(\"开发框架\", \"name\", \"description\").minimumShouldMatch(\"80%\").field(\"name\", 10); BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); boolQueryBuilder.must(multiMatchQueryBuilder); boolQueryBuilder.filter(QueryBuilders.rangeQuery(\"price\").gte(0).lte(100)); searchSourceBuilder.query(boolQueryBuilder); //设置高亮 HighlightBuilder highlightBuilder=new HighlightBuilder(); highlightBuilder.preTags(\"&lt;tag&gt;\"); highlightBuilder.postTags(\"&lt;tag&gt;\"); highlightBuilder.fields().add(new HighlightBuilder.Field(\"name\")); searchSourceBuilder.highlighter(highlightBuilder); searchSourceBuilder.fetchSource(new String[]&#123;\"name\", \"studymodel\", \"price\", \"timestamp\"&#125;, new String[]&#123;&#125;); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = restHighLevelClient.search(searchRequest); SearchHits hits = searchResponse.getHits(); long totalHits = hits.getTotalHits(); SearchHit[] searchHits = hits.getHits(); SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy‐MM‐dd HH:mm:ss\"); for (SearchHit searchHit : searchHits) &#123; String id = searchHit.getId(); Map&lt;String, Object&gt; sourceAsMap = searchHit.getSourceAsMap(); //源文档的name字段 String name = (String) sourceAsMap.get(\"name\"); //取出name高亮字段 Map&lt;String, HighlightField&gt; highlightFields = searchHit.getHighlightFields(); if(highlightFields!=null)&#123; HighlightField highlightField = highlightFields.get(\"name\"); if (highlightField!=null)&#123; Text[] fragments = highlightField.getFragments(); StringBuffer stringBuffer=new StringBuffer(); for (Text text : fragments) &#123; stringBuffer.append(text); &#125; name=stringBuffer.toString(); &#125; &#125; String studymodel = (String) sourceAsMap.get(\"studymodel\"); String price = (String) sourceAsMap.get(\"price\"); Date timestamp = dateFormat.parse(sourceAsMap.get(\"timestamp\").toString()); System.out.println(name + studymodel + price + timestamp); &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(十三.课程搜索)","slug":"学成在线(十三.课程搜索)","date":"2021-05-08T13:19:59.209Z","updated":"2020-04-29T02:44:38.112Z","comments":true,"path":"64679/","link":"","permalink":"http://tonymua.top/64679/","excerpt":"1.课程搜索需求分析1.1 需求分析 根据分类搜索课程信息。 根据关键字搜索课程信息，搜索方式为全文检索，关键字需要匹配课程的名称、 课程内容。 根据难度等级搜索课程。 搜索结点分页显示。","text":"1.课程搜索需求分析1.1 需求分析 根据分类搜索课程信息。 根据关键字搜索课程信息，搜索方式为全文检索，关键字需要匹配课程的名称、 课程内容。 根据难度等级搜索课程。 搜索结点分页显示。 1.2 搜索流程 课程管理服务将数据写到MySQL数据库 使用Logstash将MySQL数据库中的数据写到ES的索引库。 用户在前端搜索课程信息，请求到搜索服务。 搜索服务请求ES搜索课程信息。 2.全文检索技术研究研究ElasticSearch搜索方法。 参考：学成在线(十二.ElasticSearch(一)) 学成在线(十二.ElasticSearch(二)) 3.课程索引3.1 技术方案如何维护课程索引信息？ 当课程向MySQL添加后同时将课程信息添加到索引库。 采用Logstach实现，Logstach会从MySQL中将数据采集到ES索引库。 当课程在MySQL更新信息后同时更新该课程在索引库的信息。 采用Logstach实现。 当课程在MySQL删除后同时将该课程从索引库删除。手工写程序实现，在删除课程后将索引库中该课程信息删除。3.2 准备课程索引信息课程发布成功在MySQL数据库存储课程发布信息，此信息作为课程索引信息。3.2.1 创建课程发布表课程信息分布在course_base、course_pic等不同的表中。课程发布成功后, 为了方便进行索引将这几张表的数据合并在一张表中，作为课程发布信息。 3.2.2 创建课程发布表模型在课程管理服务创建模型： 12345678910111213141516171819202122232425262728293031@Data@ToString@Entity@Table(name=\"course_pub\")@GenericGenerator(name = \"jpa-assigned\", strategy = \"assigned\")public class CoursePub implements Serializable &#123; private static final long serialVersionUID = -916357110051689487L; @Id @GeneratedValue(generator = \"jpa-assigned\") @Column(length = 32) private String id; private String name; private String users; private String mt; private String st; private String grade; private String studymodel; private String teachmode; private String description; private String pic;//图片 private Date timestamp;//时间戳 private String charge; private String valid; private String qq; private Double price; private Double price_old; private String expires; private String teachplan;//课程计划 @Column(name=\"pub_time\") private String pubTime;//课程发布时间&#125; 3.2.3 修改课程发布在课程管理服务定义dao： 创建course_pub表的dao 12public interface CoursePubRepository extends JpaRepository&lt;CoursePub,String&gt; &#123;&#125; 在CourseService中修改课程发布方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960 @Transactional public CoursePublishResult publish(String id) &#123;------ //保存课程索引信息 //创建一个coursePub对象 CoursePub coursePub = createCoursePub(id); //将coursePub对象保存到数据库 saveCoursePub(id, coursePub); ------ &#125; //创建coursePub对象 private CoursePub createCoursePub(String id)&#123; CoursePub coursePub=new CoursePub(); //根据课程id查询course_base Optional&lt;CourseBase&gt; baseOptional = courseBaseRepository.findById(id); if (baseOptional.isPresent())&#123; CourseBase courseBase = baseOptional.get(); //将courseBase属性拷贝到CoursePub中 BeanUtils.copyProperties(courseBase,coursePub); &#125; //根据课程id查询course_pic Optional&lt;CoursePic&gt; picOptional = coursePicRepository.findById(id); if (picOptional.isPresent())&#123; CoursePic coursePic = picOptional.get(); BeanUtils.copyProperties(coursePic,coursePub); &#125; //课程营销信息 Optional&lt;CourseMarket&gt; marketOptional = courseMarketRepository.findById(id); if (marketOptional.isPresent())&#123; CourseMarket courseMarket = marketOptional.get(); BeanUtils.copyProperties(courseMarket,coursePub); &#125; //课程计划信息 TeachplanNode teachplanNode = teachplanMapper.selectList(id); String jsonString = JSON.toJSONString(teachplanNode); //将课程计划信息Json串保存到coursePub中 coursePub.setTeachplan(jsonString); return coursePub; &#125; //将coursePub对象保存到数据库 private CoursePub saveCoursePub(String id,CoursePub coursePub)&#123; CoursePub coursePubNEW=new CoursePub(); //根据课程id查询coursePub Optional&lt;CoursePub&gt; pubOptional = coursePubRepository.findById(id); if (pubOptional.isPresent())&#123; coursePubNEW=pubOptional.get(); &#125;else &#123; coursePubNEW=new CoursePub(); &#125; BeanUtils.copyProperties(coursePub,coursePubNEW); coursePubNEW.setId(id); //时间戳 coursePubNEW.setTimestamp(new Date()); //发布时间 SimpleDateFormat simpleDateFormat=new SimpleDateFormat(\"YYYY-MM-dd HH:mm:ss\"); String date=simpleDateFormat.format(new Date()); coursePubNEW.setPubTime(date); coursePubRepository.save(coursePubNEW); return coursePubNEW; &#125; 3.3 搭建ES环境3.3.1 ES启动 启动elasticsearch.bat, 运行elasticsearch 进入elasticsearch-head-master文件夹, 运行命令行npm run stat启动elasticsearch-head-master 访问 http://localhost:9100/3.3.2 创建索引库创建索引库创建xc_course索引库，一个分片，0个副本。 3.3.3 创建映射Post http://localhost:9200/xc_course/doc/_mapping1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&#123; \"properties\": &#123; \"description\": &#123; \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\", \"type\": \"text\" &#125;, \"grade\": &#123; \"type\": \"keyword\" &#125;, \"id\": &#123; \"type\": \"keyword\" &#125;, \"mt\": &#123; \"type\": \"keyword\" &#125;, \"name\": &#123; \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\", \"type\": \"text\" &#125;, \"users\": &#123; \"index\": false, \"type\": \"text\" &#125;, \"charge\": &#123; \"type\": \"keyword\" &#125;, \"valid\": &#123; \"type\": \"keyword\" &#125;, \"pic\": &#123; \"index\": false, \"type\": \"keyword\" &#125;, \"qq\": &#123; \"index\": false, \"type\": \"keyword\" &#125;, \"price\": &#123; \"type\": \"float\" &#125;, \"price_old\": &#123; \"type\": \"float\" &#125;, \"st\": &#123; \"type\": \"keyword\" &#125;, \"status\": &#123; \"type\": \"keyword\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125;, \"teachmode\": &#123; \"type\": \"keyword\" &#125;, \"teachplan\": &#123; \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\", \"type\": \"text\" &#125;, \"expires\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐ddHH:mm:ss\" &#125;, \"pub_time\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐ddHH:mm:ss\" &#125;, \"start_time\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐ddHH:mm:ss\" &#125;, \"end_time\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐ddHH:mm:ss\" &#125; &#125;&#125; 3.4 Logstash创建索引Logstash是ES下的一款开源软件，它能够同时从多个来源采集数据、转换数据，然后将数据发送到Eleasticsearch 中创建索引。本项目使用Logstash将MySQL中的数据采用到ES索引中。 3.4.1 创建模板文件Logstash的工作是从MySQL中读取数据，向ES中创建索引，这里需要提前创建mapping的模板文件以便logstash 使用。在logstach的conﬁg目录创建xc_course_template.json，内容如下：本教程的xc_course_template.json目录是：D:/ElasticSearch/logstash-6.2.1/conﬁg/xc_course_template.json 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&#123; \"mappings\" : &#123; \"doc\" : &#123; \"properties\" : &#123; \"charge\" : &#123; \"type\" : \"keyword\" &#125;, \"description\" : &#123; \"analyzer\" : \"ik_max_word\", \"search_analyzer\" : \"ik_smart\", \"type\" : \"text\" &#125;, \"end_time\" : &#123; \"format\" : \"yyyy-MM-dd HH:mm:ss\", \"type\" : \"date\" &#125;, \"expires\" : &#123; \"format\" : \"yyyy-MM-dd HH:mm:ss\", \"type\" : \"date\" &#125;, \"grade\" : &#123; \"type\" : \"keyword\" &#125;, \"id\" : &#123; \"type\" : \"keyword\" &#125;, \"mt\" : &#123; \"type\" : \"keyword\" &#125;, \"name\" : &#123; \"analyzer\" : \"ik_max_word\", \"search_analyzer\" : \"ik_smart\", \"type\" : \"text\" &#125;, \"pic\" : &#123; \"index\" : false, \"type\" : \"keyword\" &#125;, \"price\" : &#123; \"type\" : \"float\" &#125;, \"price_old\" : &#123; \"type\" : \"float\" &#125;, \"pub_time\" : &#123; \"format\" : \"yyyy-MM-dd HH:mm:ss\", \"type\" : \"date\" &#125;, \"qq\" : &#123; \"index\" : false, \"type\" : \"keyword\" &#125;, \"st\" : &#123; \"type\" : \"keyword\" &#125;, \"start_time\" : &#123; \"format\" : \"yyyy-MM-dd HH:mm:ss\", \"type\" : \"date\" &#125;, \"status\" : &#123; \"type\" : \"keyword\" &#125;, \"studymodel\" : &#123; \"type\" : \"keyword\" &#125;, \"teachmode\" : &#123; \"type\" : \"keyword\" &#125;, \"teachplan\" : &#123; \"analyzer\" : \"ik_max_word\", \"search_analyzer\" : \"ik_smart\", \"type\" : \"text\" &#125;, \"users\" : &#123; \"index\" : false, \"type\" : \"text\" &#125;, \"valid\" : &#123; \"type\" : \"keyword\" &#125; &#125; &#125; &#125;, \"template\" : \"xc_course\"&#125; 3.4.2 配置mysql.conf在logstash的conﬁg目录下配置mysql.conf文件供logstash使用，logstash会根据mysql.conf文件的配置的地址从 MySQL中读取数据向ES中写入索引。 参考 https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html 配置输入数据源和输出数据源。说明： 123456789101112131415161718192021222324252627282930313233343536373839404142input &#123; stdin &#123; &#125; jdbc &#123; jdbc_connection_string =&gt; \"jdbc:mysql://localhost:3306/xc_course?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=true&amp;serverTimezone=UTC\" # the user we wish to excute our statement as jdbc_user =&gt; \"root\" jdbc_password =&gt; \"xxxxxxx\" # the path to our downloaded jdbc driver jdbc_driver_library =&gt; \"E:/tools/maven/maven_repository/mysql/mysql-connector-java/5.1.6/mysql-connector-java-5.1.6.jar\" # the name of the driver class for mysql jdbc_driver_class =&gt; \"com.mysql.jdbc.Driver\" jdbc_paging_enabled =&gt; \"true\" jdbc_page_size =&gt; \"50000\" #要执行的sql文件 #statement_filepath =&gt; \"/conf/course.sql\" statement =&gt; \"select * from course_pub\" #定时配置 schedule =&gt; \"* * * * *\" record_last_run =&gt; true last_run_metadata_path =&gt; \"E:/tools/elasticsearch/logstash-6.5.4/config/logstash_metadata\" &#125;&#125;output &#123; elasticsearch &#123; #ES的ip地址和端口 hosts =&gt; \"localhost:9200\" #hosts =&gt; [\"localhost:9200\",\"localhost:9202\",\"localhost:9203\"] #ES索引库名称 index =&gt; \"xc_course\" document_id =&gt; \"%&#123;id&#125;\" document_type =&gt; \"doc\" template =&gt;\"E:/tools/elasticsearch/logstash-6.5.4/config/xc_course_template.json\" template_name =&gt;\"xc_course\" template_overwrite =&gt;\"true\" &#125; stdout &#123; #日志输出 codec =&gt; json_lines &#125;&#125; ES采用UTC时区问题 ES采用UTC 时区，比北京时间早8小时，所以ES读取数据时让最后更新时间加8小时 where timestamp &gt; date_add(:sql_last_value,INTERVAL 8 HOUR) logstash每个执行完成会在指定目录文件中记录执行时间下次以此时间为基准进行增量同步数据到索引库。3.4.3 测试启动logstash.bat：.\\logstash.bat -f ..\\config\\mysql.conf4 课程搜索4.1 需求分析 根据分类搜索课程信息。 根据关键字搜索课程信息，搜索方式为全文检索，关键字需要匹配课程的名称、 课程内容。 根据难度等级搜索课程。 搜索结点分页显示。 技术分析： 根据关键字搜索，采用MultiMatchQuery，搜索name、description、teachplan 根据分类、课程等级搜索采用过滤器实现。 分页查询。 高亮显示。 4.2 创建搜索服务工程 创建xc-service-search工程 配置 配置appliction.yml 1234567891011server: port: $&#123;port:40100&#125;spring: application: name: xc-search-servicexuecheng: elasticsearch: hostlist: $&#123;eshostlist:127.0.0.1:9200&#125; #多个结点中间用逗号分隔 course: index: xc_course type: doc 配置RestHighLevelClient和RestClient (ElasticsearchConfig) 1234567891011121314151617181920212223242526272829303132@Configuration@Repositorypublic class ElasticsearchConfig &#123; @Value(\"$&#123;xuecheng.elasticsearch.hostlist&#125;\") private String hostlist; @Bean public RestHighLevelClient restHighLevelClient()&#123; //解析hostlist配置信息 String[] split = hostlist.split(\",\"); //创建HttpHost数组，其中存放es主机和端口的配置信息 HttpHost[] httpHostArray = new HttpHost[split.length]; for(int i=0;i&lt;split.length;i++)&#123; String item = split[i]; httpHostArray[i] = new HttpHost(item.split(\":\")[0], Integer.parseInt(item.split(\":\")[1]), \"http\"); &#125; //创建RestHighLevelClient客户端 return new RestHighLevelClient(RestClient.builder(httpHostArray)); &#125; //项目主要使用RestHighLevelClient，对于低级的客户端暂时不用 @Bean public RestClient restClient()&#123; //解析hostlist配置信息 String[] split = hostlist.split(\",\"); //创建HttpHost数组，其中存放es主机和端口的配置信息 HttpHost[] httpHostArray = new HttpHost[split.length]; for(int i=0;i&lt;split.length;i++)&#123; String item = split[i]; httpHostArray[i] = new HttpHost(item.split(\":\")[0], Integer.parseInt(item.split(\":\")[1]), \"http\"); &#125; return RestClient.builder(httpHostArray).build(); &#125;&#125; 4.3 APIxc-service-api 工程下的 com.xuecheng.api.search.EsCourseControllerApi 12345@Api(value = \"课程搜索接口\",description = \"提供课程搜索功能\",tags = &#123;\"课程搜索\"&#125;)public interface EsCourseControllerApi &#123; @ApiOperation(\"课程综合搜索\") public QueryResponseResult&lt;CoursePub&gt; list(int page, int size, CourseSearchParam courseSearchParam)throws IOException;&#125; 4.4 ServiceService方法代码复杂，这里分三步完成。 4.4.1 按关键字搜索 在appliction.yml中配置source_ﬁeld 123456789101112server: port: $&#123;port:40100&#125;spring: application: name: xc-search-servicexuecheng: elasticsearch: hostlist: $&#123;eshostlist:127.0.0.1:9200&#125; #多个结点中间用逗号分隔 course: index: xc_course type: doc source_field: id,name,grade,mt,st,charge,valid,pic,qq,price,price_old,status,studymodel,teachmode,expires,pub_ time,start_time,end_time service完整代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Servicepublic class EsCourseService &#123; @Value(\"$&#123;xuecheng.elasticsearch.course.index&#125;\") private String index; @Value(\"$&#123;xuecheng.elasticsearch.course.type&#125;\") private String type; @Value(\"$&#123;xuecheng.elasticsearch.course.source_field&#125;\") private String source_field; @Autowired RestHighLevelClient restHighLevelClient; //课程综合搜索 public QueryResponseResult&lt;CoursePub&gt; list(int page, int size, CourseSearchParam courseSearchParam) &#123; if (courseSearchParam == null) &#123; courseSearchParam = new CourseSearchParam(); &#125; //创建搜索请求对象 SearchRequest searchRequest = new SearchRequest(index); //设置搜索类型 searchRequest.types(type); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //过滤源字段 String[] split_source_field = source_field.split(\",\"); searchSourceBuilder.fetchSource(split_source_field, new String[]&#123;&#125;); //创建布尔查询对象 BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); //搜索条件 //根据关键字搜索 if (StringUtils.isNotEmpty(courseSearchParam.getKeyword())) &#123; MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(courseSearchParam.getKeyword(), \"name\", \"description\", \"teachplan\") .minimumShouldMatch(\"70%\") .field(\"name\", 10); boolQueryBuilder.must(multiMatchQueryBuilder); &#125; //设置布尔查询到searchSourceBuilder searchSourceBuilder.query(boolQueryBuilder); searchRequest.source(searchSourceBuilder); QueryResult&lt;CoursePub&gt; queryResult = new QueryResult&lt;&gt;(); List&lt;CoursePub&gt; list = new ArrayList&lt;&gt;(); try &#123; //执行搜索 SearchResponse search = restHighLevelClient.search(searchRequest); SearchHits searchHits = search.getHits(); //匹配的总记录数 long totalHits = searchHits.totalHits; queryResult.setTotal(totalHits); SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) &#123; CoursePub coursePub = new CoursePub(); //源文档 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); coursePub.setName((String) sourceAsMap.get(\"name\")); coursePub.setPic((String) sourceAsMap.get(\"pic\")); Double price = null; if (sourceAsMap.get(\"price\")!=null)&#123; price= (Double) sourceAsMap.get(\"price\"); &#125; coursePub.setPrice(price); Double price_old = null; if (sourceAsMap.get(\"price_old\")!=null)&#123; price_old= (Double) sourceAsMap.get(\"price_old\"); &#125; coursePub.setPrice(price); coursePub.setPrice_old(price_old); list.add(coursePub); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; queryResult.setList(list); QueryResponseResult&lt;CoursePub&gt; queryResponseResult = new QueryResponseResult&lt;CoursePub&gt;(CommonCode.SUCCESS,queryResult); return queryResponseResult; &#125;&#125; 4.4.2 按分类和难度等级搜索按分类和难度等级搜索代码如下： 123456789101112131415//根据一级分类搜索if (StringUtils.isNotEmpty(courseSearchParam.getMt()))&#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"mt\",courseSearchParam.getMt()));&#125;//根据二级分类搜索if (StringUtils.isNotEmpty(courseSearchParam.getSt()))&#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"st\",courseSearchParam.getSt()));&#125;//根据难度等级搜索if (StringUtils.isNotEmpty(courseSearchParam.getGrade()))&#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"grade\",courseSearchParam.getGrade()));&#125;//设置布尔查询到searchSourceBuildersearchSourceBuilder.query(boolQueryBuilder);searchRequest.source(searchSourceBuilder); 4.4.3 分页与高亮123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122@Servicepublic class EsCourseService &#123; @Value(\"$&#123;xuecheng.elasticsearch.course.index&#125;\") private String index; @Value(\"$&#123;xuecheng.elasticsearch.course.type&#125;\") private String type; @Value(\"$&#123;xuecheng.elasticsearch.course.source_field&#125;\") private String source_field; @Autowired RestHighLevelClient restHighLevelClient; //课程综合搜索 public QueryResponseResult&lt;CoursePub&gt; list(int page, int size, CourseSearchParam courseSearchParam) &#123; if (courseSearchParam == null) &#123; courseSearchParam = new CourseSearchParam(); &#125; //创建搜索请求对象 SearchRequest searchRequest = new SearchRequest(index); //设置搜索类型 searchRequest.types(type); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); //过滤源字段 String[] split_source_field = source_field.split(\",\"); searchSourceBuilder.fetchSource(split_source_field, new String[]&#123;&#125;); //创建布尔查询对象 BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery(); //搜索条件 //根据关键字搜索 if (StringUtils.isNotEmpty(courseSearchParam.getKeyword())) &#123; MultiMatchQueryBuilder multiMatchQueryBuilder = QueryBuilders.multiMatchQuery(courseSearchParam.getKeyword(), \"name\", \"description\", \"teachplan\") .minimumShouldMatch(\"70%\") .field(\"name\", 10); boolQueryBuilder.must(multiMatchQueryBuilder); &#125; //根据一级分类搜索 if (StringUtils.isNotEmpty(courseSearchParam.getMt()))&#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"mt\",courseSearchParam.getMt())); &#125; //根据二级分类搜索 if (StringUtils.isNotEmpty(courseSearchParam.getSt()))&#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"st\",courseSearchParam.getSt())); &#125; //根据难度等级搜索 if (StringUtils.isNotEmpty(courseSearchParam.getGrade()))&#123; boolQueryBuilder.filter(QueryBuilders.termQuery(\"grade\",courseSearchParam.getGrade())); &#125; //分页 if (page&lt;=0)&#123; page=1; &#125; if (size&lt;=0)&#123; size=20; &#125; int start=(page-1)*size; searchSourceBuilder.from(start); searchSourceBuilder.size(size); //设置布尔查询到searchSourceBuilder searchSourceBuilder.query(boolQueryBuilder); //高亮设置 HighlightBuilder highlightBuilder=new HighlightBuilder(); highlightBuilder.preTags(\"&lt;font class='eslight'&gt;\"); highlightBuilder.postTags(\"&lt;/font&gt;\"); //设置高亮字段 highlightBuilder.fields().add(new HighlightBuilder.Field(\"name\")); searchSourceBuilder.highlighter(highlightBuilder); searchRequest.source(searchSourceBuilder); QueryResult&lt;CoursePub&gt; queryResult = new QueryResult&lt;&gt;(); List&lt;CoursePub&gt; list = new ArrayList&lt;&gt;(); try &#123; //执行搜索 SearchResponse search = restHighLevelClient.search(searchRequest); SearchHits searchHits = search.getHits(); //匹配的总记录数 long totalHits = searchHits.totalHits; queryResult.setTotal(totalHits); SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) &#123; CoursePub coursePub = new CoursePub(); //源文档 Map&lt;String, Object&gt; sourceAsMap = hit.getSourceAsMap(); String name = (String) sourceAsMap.get(\"name\"); //取出高亮字段 Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields(); if (highlightFields!=null)&#123; HighlightField nameField = highlightFields.get(\"name\"); if (nameField!=null)&#123; Text[] fragments = nameField.getFragments(); StringBuffer stringBuffer=new StringBuffer(); for (Text fragment : fragments) &#123; stringBuffer.append(fragment.string()); &#125; name=stringBuffer.toString(); &#125; &#125; coursePub.setName(name); coursePub.setPic((String) sourceAsMap.get(\"pic\")); Double price = null; if (sourceAsMap.get(\"price\")!=null)&#123; price= (Double) sourceAsMap.get(\"price\"); &#125; coursePub.setPrice(price); Double price_old = null; if (sourceAsMap.get(\"price_old\")!=null)&#123; price_old= (Double) sourceAsMap.get(\"price_old\"); &#125; coursePub.setPrice(price); coursePub.setPrice_old(price_old); list.add(coursePub); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; queryResult.setList(list); QueryResponseResult&lt;CoursePub&gt; queryResponseResult = new QueryResponseResult&lt;CoursePub&gt;(CommonCode.SUCCESS,queryResult); return queryResponseResult; &#125;&#125; 4.5 Controller12345678910111213@RestController@RequestMapping(\"/search/course\")public class EsCourseController implements EsCourseControllerApi &#123; @Autowired EsCourseService esCourseService; @Override @GetMapping(\"/list/&#123;page&#125;/&#123;size&#125;\") public QueryResponseResult&lt;CoursePub&gt; list(@PathVariable(\"page\") int page, @PathVariable(\"size\") int size, CourseSearchParam courseSearchParam) throws IOException &#123; return esCourseService.list(page,size,courseSearchParam); &#125;&#125; 4.6 测试http://localhost:40100/swagger-ui.html","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(十一.ElasticSearch(一))","slug":"学成在线(十一.ElasticSearch(一))","date":"2021-05-08T13:19:59.208Z","updated":"2020-04-29T02:44:38.088Z","comments":true,"path":"42236/","link":"","permalink":"http://tonymua.top/42236/","excerpt":"1.ElasticSearch介绍1.1 介绍​ ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。ElasticSearch用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。官方客户端在Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby和许多其他语言中都是可用的。根据DB-Engines的排名显示，Elasticsearch是最受欢迎的企业搜索引擎，其次是Apache Solr，也是基于Lucene。 官方网址：https://www.elastic.co/cn/products/elasticsearchGithub：https://github.com/elastic/elasticsearch 总结 ElasticSearch是一个基于Lucene的高扩展的分布式搜索服务器，支持开箱即用。 ElasticSearch隐藏了Lucene的复杂性，对外提供Restful接口来操作索引、搜索。 突出优点 扩展性好，可部署上百台服务器集群，处理PB级数据。 近实时的去索引数据、搜索数据。","text":"1.ElasticSearch介绍1.1 介绍​ ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。ElasticSearch用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。官方客户端在Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby和许多其他语言中都是可用的。根据DB-Engines的排名显示，Elasticsearch是最受欢迎的企业搜索引擎，其次是Apache Solr，也是基于Lucene。 官方网址：https://www.elastic.co/cn/products/elasticsearchGithub：https://github.com/elastic/elasticsearch 总结 ElasticSearch是一个基于Lucene的高扩展的分布式搜索服务器，支持开箱即用。 ElasticSearch隐藏了Lucene的复杂性，对外提供Restful接口来操作索引、搜索。 突出优点 扩展性好，可部署上百台服务器集群，处理PB级数据。 近实时的去索引数据、搜索数据。 1.2 原理与应用1.2.1 索引结构下图是ElasticSearch的索引结构，下边黑色部分是物理结构，上边黄色部分是逻辑结构，逻辑结构也是为了更好的去描述ElasticSearch的工作原理及去使用物理结构中的索引文件。 逻辑结构部分是一个倒排索引表： 将要搜索的文档内容分词，所有不重复的词组成分词列表。 将搜索的文档终以Document方式存储起来。 每个词和docment都有关联。 如下： 现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档： 两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法 ， 那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。 1.2.2 RESTful应用方法ElasticSearch提供 RESTful Api接口进行索引、搜索，并且支持多种客户端。 下图是es在项目中的应用方式： 用户在前端搜索关键字 项目前端通过http方式请求项目服务端 项目服务端通过Http RESTful方式请求ES集群进行搜索 ES集群从索引库检索数据。 2.ES快速入门2.1 创建索引库ES的索引库是一个逻辑概念，它包括了分词列表及文档列表，同一个索引库中存储了相同类型的文档。它就相当于 MySQL中的表，或相当于Mongodb中的集合。关于索引这个语：索引（名词）：ES是基于Lucene构建的一个搜索服务，它要从索引库搜索符合条件索引数据。索引（动词）：索引库刚创建起来是空的，将数据添加到索引库的过程称为索引。下边介绍两种创建索引库的方法，它们的工作原理是相同的，都是客户端向ES服务发送命令。 使用postman或curl这样的工具创建： put http://localhost:9200/索引库名称 12345678&#123; \"settings\":&#123; \"index\":&#123; \"number_of_shards\":1, \"number_of_replicas\":0 &#125; &#125; &#125; number_of_shards：设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为1number_of_replicas：设置副本的数量，设置副本是为了提高ES的高可靠性，单机环境设置为0如下是创建的例子，创建xc_course索引库，共1个分片，0个副本： 使用head插件创建 2.2 创建映射2.2.1 概念说明在索引中每个文档都包括了一个或多个ﬁeld，创建映射就是向索引库中创建ﬁeld的过程，下边是document和ﬁeld 与关系数据库的概念的类比：文档（Document）—————-Row记录字段（Field）——————-Columns列注意：6.0之前的版本有type（类型）概念，type相当于关系数据库的表，ES官方将在ES9.0版本中彻底删除type。上边讲的创建索引库相当于关系数据库中的数据库还是表？ 如果相当于数据库就表示一个索引库可以创建很多不同类型的文档，这在ES中也是允许的。 如果相当于表就表示一个索引库只能存储相同类型的文档，ES官方建议在一个索引库中只存储相同类型的文 档。 2.2.2 创建映射我们要把课程信息存储到ES中，这里我们创建课程信息的映射，先来一个简单的映射，如下：发送：post http://localhost:9200/索引库名称/类型名称/_mapping创建类型为xc_course的映射，共包括三个字段：name、description、studymondel由于ES6.0版本还没有将type彻底删除，所以暂时把type起一个没有特殊意义的名字。 post 请求：http://localhost:9200/xc_course/doc/_mapping表示：在xc_course索引库下的doc类型下创建映射。doc是类型名，可以自定义，在ES6.0中要弱化类型的概念， 给它起一个没有具体业务意义的名称。 12345678910111213&#123; \"properties\": &#123; \"name\": &#123; \"type\": \"text\" &#125;, \"description\": &#123; \"type\": \"text\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125; &#125; &#125; 2.3 创建文档ES中的文档相当于MySQL数据库表中的记录。发送：put 或Post http://localhost:9200/xc_course/doc/id值 （如果不指定id值ES会自动生成ID）http://localhost:9200/xc_course/doc/4028e58161bcf7f40161bcf8b77c0000 12345&#123; \"name\":\"Bootstrap开发框架\", \"description\":\"Bootstrap是由Twitter推出的一个前台页面开发框架，在行业之中使用较为广泛。此开发框架包 含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的 精美界面效果。\", \"studymodel\":\"201001\" &#125; 使用postman测试： 通过head查询数据： 2.4 搜索文档 根据课程id查询文档发送：Get http://localhost:9200/xc_course/doc/4028e58161bcf7f40161bcf8b77c0000使用postman测试： 查询所有记录发送 Get http://localhost:9200/xc_course/doc/_search 查询名称中包括spring 关键字的的记录 发送：Get http://localhost:9200/xc_course/doc/_search?q=name:bootstrap 查询学习模式为201001的记录 发送 Get http://localhost:9200/xc_course/doc/_search?q=studymodel:201001 2.4.1 查询结果分析分析上边查询结果： 123456789101112131415161718192021222324252627&#123; \"took\": 8, \"timed_out\": false, \"_shards\": &#123; \"total\": 1, \"successful\": 1, \"skipped\": 0, \"failed\": 0 &#125;, \"hits\": &#123; \"total\": 1, \"max_score\": 1.0, \"hits\": [ &#123; \"_index\": \"xc_course\", \"_type\": \"doc\", \"_id\": \"4028e58161bcf7f40161bcf8b77c0000\", \"_score\": 1.0, \"_source\": &#123; \"name\": \"Bootstrap开发框架\", \"description\": \"Bootstrap是由Twitter推出的一个前台页面开发框架，在行业之中使用较为广泛。此开发框架包 含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的 精美界面效果。\", \"studymodel\": \"201001\" &#125; &#125; ] &#125;&#125; took：本次操作花费的时间，单位为毫秒。timed_out：请求是否超时_shards：说明本次操作共搜索了哪些分片hits：搜索命中的记录hits.total ： 符合条件的文档总数hits.hits ：匹配度较高的前N个文档hits.max_score：文档匹配得分，这里为高分_score：每个文档都有一个匹配度得分，按照降序排列_source：显示了文档的原始内容。 3.IK分词器3.1 测试分词器在添加文档时会进行分词，索引中存放的就是一个一个的词（term），当你去搜索时就是拿关键字去匹配词，终 找到词关联的文档。测试当前索引库使用的分词器：post 发送：http://localhost:9200/_analyze 123&#123; \"text\":\"测试分词器，后边是测试内容：spring cloud实战\"&#125; 结果如下：会发现分词的效果将 “测试” 这个词拆分成两个单字“测”和“试”，这是因为当前索引库使用的分词器对中文就是单字分词。 3.2 IK分词器使用IK分词器可以实现对中文分词的效果。下载IK分词器：（Github地址：https://github.com/medcl/elasticsearch-analysis-ik） 测试分词效果：发送：post http://localhost:9200/_analyze 1234&#123; \"text\":\"测试分词器，后边是测试内容：spring cloud实战\", \"analyzer\":\"ik_max_word\" &#125; 3.3 两种分词模式ik分词器有两种分词模式：ik_max_word和ik_smart模式。 ik_max_word 会将文本做细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人民共和国、中华人民、中华、 华人、人民共和国、人民、共和国、大会堂、大会、会堂等词语。 ik_smart 会做粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和国、人民大会堂。 3.4 自定义词库如果要让分词器支持一些专有词语，可以自定义词库。iK分词器自带一个main.dic的文件，此文件为词库文件。 在上边的目录中新建一个my.dic文件（注意文件格式为utf-8（不要选择utf-8 BOM））可以在其中自定义词汇：比如定义：配置文件中配置my.dic， 4.映射4.1 映射维护方法 查询所有索引的映射：GET： http://localhost:9200/_mapping 创建映射 Post 请求：http://localhost:9200/xc_course/doc/_mapping 12345678910111213&#123; \"properties\": &#123; \"name\": &#123; \"type\": \"text\" &#125;, \"description\": &#123; \"type\": \"text\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125; &#125;&#125; 更新映射映射创建成功可以添加新字段，已有字段不允许更新。 删除映射通过删除索引来删除映射。 4.2 常用映射类型4.2.1 text文本字段下图是ES6.2核心的字段类型如下： 字符串包括text和keyword两种类型： text (1) analyzer 通过analyzer属性指定分词器。下边指定name的字段类型为text，使用ik分词器的ik_max_word分词模式。 1234 \"name\": &#123; \"type\": \"text\", \"analyzer\":\"ik_max_word\" &#125; 上边指定了analyzer是指在索引和搜索都使用ik_max_word，如果单独想定义搜索时使用的分词器则可以通过 search_analyzer属性。 对于ik分词器建议是索引时使用ik_max_word将搜索内容进行细粒度分词，搜索时使用ik_smart提高搜索精确性。 12345\"name\": &#123; \"type\": \"text\", \"analyzer\":\"ik_max_word\", \"search_analyzer\":\"ik_smart\" &#125; ​ (2) index 通过index属性指定是否索引。默认为index=true，即要进行索引，只有进行索引才可以从索引库搜索到。 但是也有一些内容不需要索引，比如：商品图片地址只被用来展示图片，不进行搜索图片，此时可以将index设置为false。 删除索引，重新创建映射，将pic的index设置为false，尝试根据pic去搜索，结果搜索不到数据 1234\"pic\": &#123; \"type\": \"text\", \"index\":false &#125; ​ (3) store 是否在source之外存储，每个文档索引后会在 ES中保存一份原始文档，存放在”source”中，一般情况下不需要设置 store为true，因为在source中已经有一份原始文档了。 测试 删除xc_course/doc下的映射 创建新映射：Post http://localhost:9200/xc_course/doc/_mapping 123456789101112131415161718192021&#123; \"properties\": &#123; \"name\": &#123; \"type\": \"text\", \"analyzer\":\"ik_max_word\", \"search_analyzer\":\"ik_smart\" &#125;, \"description\": &#123; \"type\": \"text\", \"analyzer\":\"ik_max_word\", \"search_analyzer\":\"ik_smart\" &#125;, \"pic\":&#123; \"type\":\"text\", \"index\":false &#125;, \"studymodel\":&#123; \"type\":\"text\" &#125; &#125;&#125; 插入文档：http://localhost:9200/xc_course/doc/4028e58161bcf7f40161bcf8b77c0000 12345&#123; \"name\":\"Bootstrap开发框架\", \"description\":\"Bootstrap是由Twitter推出的一个前台页面开发框架，在行业之中使用较为广泛。此开发框架包 含了大量的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的 精美界面效果。\", \"studymodel\":\"201001\" &#125; 查询测试：Get http://localhost:9200/xc_course/_search?q=name:开发Get http://localhost:9200/xc_course/_search?q=description:开发Get http://localhost:9200/xc_course/_search?q=pic:group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpgGet http://localhost:9200/xc_course/_search?q=studymodel:201002通过测试发现：name和description都支持全文检索，pic不可作为查询条件。 4.2.2 keyword关键字字段上边介绍的text文本字段在映射时要设置分词器，keyword字段为关键字字段，通常搜索keyword是按照整体搜 索，所以创建keyword字段的索引时是不进行分词的，比如：邮政编码、手机号码、身份证等。keyword字段通常 用于过滤、排序、聚合等。 测试 12345678910&#123; \"properties\": &#123; \"studymodel\":&#123; \"type\":\"keyword\" &#125;, \"name\":&#123; \"type\":\"keyword\" &#125; &#125; &#125; 插入文档： 123456&#123; \"name\": \"java编程基础\", \"description\": \"java语言是世界第一编程语言，在软件开发领域使用人数多。\", \"pic\":\"group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg\", \"studymodel\": \"201001\" &#125; 根据studymodel查询文档搜索：http://localhost:9200/xc_course/_search?q=name:javaname是keyword类型，所以查询方式是精确查询。 4.2.3 date日期类型日期类型不用设置分词器。通常日期类型的字段用于排序。format 通过format设置日期格式例子: 下边的设置允许date字段存储年月日时分秒、年月日及毫秒三种格式。 12345678&#123; \"properties\": &#123; \"timestamp\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd\" &#125; &#125; &#125; 插入文档：3Post :http://localhost:9200/xc_course/doc/3 1234567&#123; \"name\": \"spring开发基础\", \"description\": \"spring 在java领域非常流行，java程序员都在用。\", \"studymodel\": \"201001\", \"pic\":\"group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg\", \"timestamp\":\"2018‐07‐04 18:28:58\" &#125; 4.2.4 数值类型下边是ES支持的数值类型 尽量选择范围小的类型，提高搜索效率 对于浮点数尽量用比例因子，比如一个价格字段，单位为元，我们将比例因子设置为100这在ES中会按分存 储，映射如下： 1234\"price\": &#123; \"type\": \"scaled_float\", \"scaling_factor\": 100 &#125; 由于比例因子为100，如果我们输入的价格是23.45则ES中会将23.45乘以100存储在ES中。如果输入的价格是23.456，ES会将23.456乘以100再取一个接近原始值的数，得出2346。使用比例因子的好处是整型比浮点型更易压缩，节省磁盘空间。 如果比例因子不适合，则从下表选择范围小的去用 更新已有映射，并插入文档：http://localhost:9200/xc_course/doc/3 12345678&#123; \"name\": \"spring开发基础\", \"description\": \"spring 在java领域非常流行，java程序员都在用。\", \"studymodel\": \"201001\", \"pic\":\"group1/M00/00/01/wKhlQFqO4MmAOP53AAAcwDwm6SU490.jpg\", \"timestamp\":\"2018‐07‐04 18:28:58\", \"price\":38.6 &#125; 4.2.5 综合例子创建如下映射Post：http://localhost:9200/xc_course/doc/_mapping 12345678910111213141516171819202122232425262728&#123; \"properties\": &#123; \"description\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\" &#125;, \"name\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_smart\" &#125;, \"pic\":&#123; \"type\":\"text\", \"index\":false &#125;, \"price\": &#123; \"type\": \"float\" &#125;, \"studymodel\": &#123; \"type\": \"keyword\" &#125;, \"timestamp\": &#123; \"type\": \"date\", \"format\": \"yyyy‐MM‐dd HH:mm:ss||yyyy‐MM‐dd||epoch_millis\" &#125; &#125;&#125; 插入文档：Post: http://localhost:9200/xc_course/doc/1 1234567&#123; \"name\": \"Bootstrap开发\", \"description\": \"Bootstrap是由Twitter 推出的一个前台页面开发框架，是一个非常流行的开发框架，此框架集成了多种页面效果。此开发框架包含了大量 的CSS、JS程序代码，可以帮助开发者（尤其是不擅长页面开发的程序人员）轻松的实现一个不受浏览器限制的精 美界面效果。\", \"studymodel\": \"201002\", \"price\":38.6, \"timestamp\":\"2018‐04‐25 19:11:35\", \"pic\":\"group1/M00/00/00/wKhlQFs6RCeAY0pHAAJx5ZjNDEM428.jpg\"&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(十.课程预览, 课程发布)","slug":"学成在线(十.课程预览)","date":"2021-05-08T13:19:59.206Z","updated":"2020-04-29T06:00:32.559Z","comments":true,"path":"22867/","link":"","permalink":"http://tonymua.top/22867/","excerpt":"1.课程预览技术方案1.1 需求分析课程预览是为了保证课程发布后的正确性，通过课程预览可以直观的通过课程详情页面看到课程的信息是否正确， 通过课程预览看到的页面内容和课程发布后的页面内容是一致的。 1.2 课程详情页面技术方案课程预览所浏览到的页面就是课程详情页面，需要先确定课程详情页面的技术方案后方可确定课程预览的技术方 案。 1.2.1 技术需求","text":"1.课程预览技术方案1.1 需求分析课程预览是为了保证课程发布后的正确性，通过课程预览可以直观的通过课程详情页面看到课程的信息是否正确， 通过课程预览看到的页面内容和课程发布后的页面内容是一致的。 1.2 课程详情页面技术方案课程预览所浏览到的页面就是课程详情页面，需要先确定课程详情页面的技术方案后方可确定课程预览的技术方 案。 1.2.1 技术需求 课程详情页面是向用户展示课程信息的窗口，课程相当于网站的商品，本页面的访问量会非常大。此页面的内容设 计不仅要展示出课程核心重要的内容而且用户访问页面的速度要有保证，有统计显示打开一个页面超过4秒用户就 走掉了，所以本页面的性能要求是本页面的重要需求。本页面另一个需求就是SEO，要非常有利于爬虫抓取页面上信息，并且生成页面快照，利于用户通过搜索引擎搜索 课程信息。 1.2.2 解决方案如何在保证SEO的前提下提高页面的访问速度 ： 方案1：对于信息获取类的需求，要想提高页面速度就要使用缓存来减少或避免对数据库的访问，从而提高页面的访问速度。下图是使用缓存与不使用缓存的区别此页面为动态页面，会根据课程的不同而不同，方案一采用传统的JavaEE Servlet/jsp的方式在Tomcat完成页面渲 染，相比不加缓存速度会有提升。优点：使用redis作为缓存，速度有提升。缺点：采用Servlet/jsp动态页面渲染技术，服务器使用Tomcat，面对高并发量的访问存在性能瓶颈。 方案2：对于不会频繁改变的信息可以采用页面静态化的技术，提前让页面生成html静态页面存储在nginx服务器，用户直接访问nginx即可，对于一些动态信息可以访问服务端获取json数据在页面渲染。优点：使用Nginx作为web服务器，并且直接访问html页面，性能出色。缺点：需要维护大量的静态页面，增加了维护的难度。 选择方案2作为课程详情页面的技术解决方案，将课程详情页面生成Html静态化页面，并发布到Nginx上。 1.3 课程预览技术方案根据要求：课程详情页面采用静态化技术生成Html页面，课程预览的效果要与最终静态化的Html页面内容一致。 所以，课程预览功能也采用静态化技术生成Html页面，课程预览使用的模板与课程详情页面模板一致，这样就可 以保证课程预览的效果与最终课程详情页面的效果一致。操作流程： 1. 制作课程详情页面模板 2. 开发课程详情页面数据模型的查询接口（为静态化提供数据） 3. 调用cms课程预览接口通过浏览器浏览静态文件 2.课程详情页面静态化2.1 静态页面测试2.1.1 页面内容组成我们在编写一个页面时需要知道哪些信息是静态信息，哪些信息为动态信息，下图是页面的设计图： 打开静态页面，观察每部分的内容。红色表示动态信息，红色以外表示静态信息。红色动态信息：表示一个按钮，根据用户的登录状态、课程的购买状态显示按钮的名称及按钮的事件。包括以下信息内容：(1) 课程信息 课程标题、价格、课程等级、授课模式、课程图片、课程介绍、课程目录。(2) 课程统计信息 课程时长、评分、收藏人数(3) 教育机构信息 公司名称、公司简介(4) 教育机构统计信息 好评数、课程数、学生人数(5) 教师信息 老师名称、老师介绍 2.1.2 页面拆分将页面拆分成如下页面：(1) 页头本页头文件和门户使用的页头为同一个文件。参考：代码\\页面与模板\\include\\header.html(2) 页面尾本页尾文件和门户使用的页尾为同一个文件。参考：代码\\页面与模板\\include\\footer.html(3) 课程详情主页面每个课程对应一个文件，命名规则为：课程id.html（课程id动态变化） 模板页面参考：\\代码\\页面与模板\\course\\detail\\course_main_template.html(4) 教育机构页面每个教育机构对应一个文件，文件的命名规则为：company_info公司id.html（公司id动态变化）参考：代码\\页面与模板\\company\\company_info_template.html(5)老师信息页面 每个教师信息对应一个文件，文件的命名规则为：teacher_info教师id.html（教师id动态变化）参考：代码\\页面与模板\\teacher\\teacher_info_template01.html(6) 课程统计页面每个课程对应一个文件，文件的命名规则为：course_stat_课程id.json（课程id动态变化）参考：\\代码\\页面与模板\\stat\\course\\course_stat_template.json(7) 教育机构统计页面 每个教育机构对应一个文件，文件的命名规则为：company_stat公司id.json（公司id动态变化）参考：\\代码\\页面与模板\\stat\\company\\company_stat_template.json 2.1.3 静态页面测试2.1.3.1页面加载思路打开课程资料中的“静态页面目录”中的课程详情模板页面，研究页面加载的思路。模板页面路径如下： 1静态页面目录\\static\\course\\detail\\course_main_template.html (1) 主页面我们需要在主页面中通过SSI加载：页头、页尾、教育机构、教师信息(2) 异步加载课程统计与教育机构统计信息课程统计信息（json）、教育机构统计信息（json）(3) 马上学习按钮事件用户点击“马上学习”会根据课程收费情况、课程购买情况执行下一步操作。 2.1.3.2 静态资源虚拟主机1.配置静态资源虚拟主机静态资源虚拟主机负责处理课程详情、公司信息、老师信息、统计信息等页面的请求：将课程资料中的“静态页面目录”中的目录拷贝到F:/develop/xuecheng/static下在nginx中配置静态虚拟主机如下： 1234567891011121314151617181920#学成网静态资源 server&#123;listen 91;server_name localhost;#公司信息location /static/company/&#123; alias E:/IdeaProject/xuecheng/static/company/; &#125;#老师信息location /static/teacher/&#123; alias E:/IdeaProject/xuecheng/static/teacher/; &#125;#统计信息location /static/stat/&#123; alias E:/IdeaProject/xuecheng/static/stat/; &#125;location /course/detail/&#123; alias E:/IdeaProject/xuecheng/static/course/detail/; &#125;&#125; 2.通过www.xuecheng.com虚拟主机转发到静态资源由于课程页面需要通过SSI加载页头和页尾所以需要通过www.xuecheng.com虚拟主机转发到静态资源在www.xuecheng.com虚拟主机加入如下配置： 123456789101112location /static/company/&#123; proxy_pass http://static_server_pool;&#125;location /static/teacher/&#123; proxy_pass http://static_server_pool;&#125;location /static/stat/&#123; proxy_pass http://static_server_pool;&#125;location /course/detail/&#123; proxy_pass http://static_server_pool;&#125; 3.配置upstream实现请求转发到资源服务虚拟主机： 1234#静态资源服务upstream static_server_pool&#123;server 127.0.0.1:91 weight=10;&#125; 2.1.3.3 门户静态资源路径门户中的一些图片、样式等静态资源统一通过/static路径对外提供服务，在www.xuecheng.com虚拟主机中配置如下： 12345678910111213141516#静态资源,包括系统所需的图片 js css等静态资源location /static/img/&#123; alias E:/IdeaProject/xc-ui-pc-static-portal/img/;&#125;location /static/css/&#123; alias E:/IdeaProject/xc-ui-pc-static-portal/css/;&#125;location /static/js/&#123; alias E:/IdeaProject/xc-ui-pc-static-portal/js/;&#125;location /static/plugins/&#123; alias E:/IdeaProject/xc-ui-pc-static-portal/plugins/; add_header Access-Control-Allow-Origin http://ucenter.xuecheng.com; add_header Access-Control-Allow-Credentials true; add_header Access-Control-Allow-Methods GET;&#125; cors跨域参数：Access-Control-Allow-Origin：允许跨域访问的外域地址如果允许任何站点跨域访问则设置为*，通常这是不建议的。 Access-Control-Allow-Credentials： 允许客户端携带证书访问Access-Control-Allow-Methods：允许客户端跨域访问的方法 2.1.3.4 页面测试请求：http://www.xuecheng.com/course/detail/course_main_template.html测试课程详情页面模板是否可以正常浏览。 2.2 课程数据模型查询接口静态化操作需要模型数据方可进行静态化，课程数据模型由课程管理服务提供，仅供课程静态化程序调用使用。 2.2.1 接口定义1.响应结果类型 123456789@Data@ToString@NoArgsConstructorpublic class CourseView implements Serializable &#123; private CourseBase courseBase; private CoursePic coursePic; private CourseMarket courseMarket; private TeachplanNode teachplanNode;&#125; 2.请求类型 String：课程id 3.接口定义如下 12@ApiOperation(\"课程视图查询\")public CourseView courseview(String id); 2.2.2 Controller12345@Override@GetMapping(\"/courseview/&#123;id&#125;\")public CourseView courseview(@PathVariable(\"id\") String id) &#123; return courseService.getCourseView(id);&#125; 2.2.3 Dao需要对course_base、course_market、course_pic、teachplan等信息进行查询， 新建课程营销的dao，其它dao已经存在不用再建 12public interface CourseMarketRepository extends JpaRepository&lt;CourseMarket,String&gt; &#123;&#125; 2.2.4 Service12345678910111213141516public CourseView getCourseView(String id) &#123; CourseView courseView=new CourseView(); //查询课程基本信息 CourseBase courseBase = getCourseById(id); courseView.setCourseBase(courseBase); //查询课程图片 CoursePic coursePic = findCoursePic(id); courseView.setCoursePic(coursePic); //查询课程营销信息 CourseMarket courseMarket = getCourseMarketById(id); courseView.setCourseMarket(courseMarket); //查询课程计划信息 TeachplanNode teachplanNode = findTeachplanList(id); courseView.setTeachplanNode(teachplanNode); return courseView;&#125; 2.2.5 测试使用swagger-ui或postman测试本接口。 2.3 课程信息模板设计在确定了静态化所需要的数据模型之后，就可以编写页面模板了，课程详情页面由多个静态化页面组成，所以我们需要创建多个页面模板，本章节创建课程详情页面的主模板，即课程信息模板。 2.3.1 模板测试使用test-freemarker工程测试模板编写模板过程采用test-freemarker工程测试模板。 将course.ftl拷贝到test-freemarker工程的resources/templates下，并在test-freemarker工程的controller中添加测试方法: 1234567@RequestMapping(\"/course\")public String course(Map&lt;String,Object&gt; map)&#123; ResponseEntity&lt;Map&gt; forEntity = restTemplate.getForEntity(\"http://localhost:31200/course/courseview/4028e581617f945f01617f9dabc40000\", Map.class); Map body = forEntity.getBody(); map.putAll(body); return \"course\";&#125; 注意：上边的测试页面不显示样式，原因是页面通过SSI包含了页面头，而使用test-freemarker工程无法加载页 头，测试模板主要查看html页面内容是否正确，待课程预览时解决样式不显示问题 2.3.2 模板保存模板编写并测试通过后要在数据库保存：1.模板信息保存在xc_cms数据库(mongodb)的cms_template表2.模板文件保存在mongodb的GridFS中。 第一步：将模板文件上传到GridFS中 由于本教学项目中模板管理模块没有开发，所以我们使用Junit代码向GridFS中保存： 1234567@Testpublic void testStore2() throws FileNotFoundException &#123; File file=new File(\"e:/IdeaProject/xuecheng/test-freemarker/src/main/resources/templates/course.ftl\"); FileInputStream fileInputStream=new FileInputStream(file); ObjectId id = gridFsTemplate.store(fileInputStream, \"课程详情模板文件\"); System.out.println(id);&#125; 保存成功需要记录模板文件的id，即上边代码中的ﬁleId。 第二步：向cms_template表添加模板记录（请不要重复添加）使用Studio 3T连接mongodb，向cms_template添加记录： 12345678&#123; \"_id\" : ObjectId(\"5ad9a24d68db5239b8fef199\"), \"_class\" : \"com.xuecheng.framework.domain.cms.CmsTemplate\", \"siteId\" : \"5a751fab6abb5044e0d19ea1\", \"templateName\" : \"课程详情页面测试\", \"templateParameter\" : \"courseid\", \"templateFileId\" : \"5e09668d69ffad2fd40dc35d\"&#125; 2.3.3 其它模板除了课程详情主页面需要设计模板所有静态化的页面都要设计模板，如下：教育机构页面模板、教师信息页面模板、课程统计信息json模板、教育机构统计信息json模板。本项目我们实现课程详情主页面模板的制作和测试，其它页面模板的开发参考课程详情页面去实现。 3.课程预览功能开发3.1 需求分析课程预览功能将使用cms系统提供的页面预览功能，业务流程如下：(1) 用户进入课程管理页面，点击课程预览，请求到课程管理服务(2) 课程管理服务远程调用cms添加页面接口向cms添加课程详情页面(3) 课程管理服务得到cms返回课程详情页面id，并拼接生成课程预览Url(4) 课程管理服务将课程预览Url给前端返回(5) 用户在前端页面请求课程预览Url，打开新窗口显示课程详情内容 3.2 CMS页面预览测试CMS已经提供了页面预览功能，课程预览功能要使用CMS页面预览接口实现，下边通过cms页面预览接口测试课 程预览的效果。 1.向cms_page表插入一条页面记录或者从cms_page找一个页面进行测试。注意：页面配置一定要正确，需设置正确的模板id和dataUrl。如下，是一条页面的记录。 12345678910111213&#123; \"_id\" : ObjectId(\"5b3469f794db44269cb2bff1\"), \"_class\" : \"com.xuecheng.framework.domain.cms.CmsPage\", \"siteId\" : \"5a751fab6abb5044e0d19ea1\", \"pageName\" : \"4028e581617f945f01617f9dabc40000.html\", \"pageAliase\" : \"课程详情页面测试01\", \"pageWebPath\" : \"/course/detail/\", \"pagePhysicalPath\" : \"/course/detail/\", \"pageType\" : \"1\", \"pageCreateTime\" : ISODate(\"2018-02-25T01:37:25.974+0000\"), \"templateId\" : \"5ad9a24d68db5239b8fef199\", \"dataUrl\" : \"http://localhost:31200/course/courseview/4028e581617f945f01617f9dabc40000\"&#125; 2.课程详细页面使用ssi注意由于Nginx先请求cms的课程预览功能得到html页面，再解析页面中的ssi标签，这里必须保证cms页面预览返回的 页面的Content-Type为text/html;charset=utf-8 在cms页面预览的controller方法中添加： 1response.setHeader(\"Content-type\",\"text/html;charset=utf-8\"); 3.测试请求：http://www.xuecheng.com/cms/preview/5b3469f794db44269cb2bff1传入页面Id，测试效果如下: 3.3 CMS添加页面服务端cms服务对外提供添加页面接口，实现：如果不存在页面则添加，否则就更新页面信息。此接口由课程管理服务在课程预览时调用。 3.3.1 Api接口12@ApiOperation(\"保存页面\")public CmsPageResult save(CmsPage cmsPage); 3.3.2 Controller123456 @Override @PostMapping(\"/save\") public CmsPageResult save(@RequestBody CmsPage cmsPage) &#123; return pageService.save(cmsPage); &#125;&#125; 3.3.3 Service12345678910//添加页面，如果已存在则更新页面 public CmsPageResult save(CmsPage cmsPage) &#123; //校验页面是否存在，根据页面名称、站点Id、页面webpath查询 CmsPage cmsPage1 = cmsPageRepository.findByPageNameAndSiteIdAndPageWebPath(cmsPage.getPageName(), cmsPage.getSiteId(), cmsPage.getPageWebPath()); if (cmsPage1!=null)&#123; //更新 return edit(cmsPage1.getPageId(),cmsPage); &#125; return add(cmsPage);&#125; 3.4 课程预览服务端3.4.1 Api定义此Api是课程管理前端请求服务端进行课程预览的Api 请求：课程Id响应：课程预览Url 1.定义响应类型 12345678910@Data@ToString@NoArgsConstructorpublic class CoursePublishResult extends ResponseResult &#123; String previewUrl; public CoursePublishResult(ResultCode resultCode,String previewUrl)&#123; super(resultCode); this.previewUrl=previewUrl; &#125;&#125; 2.接口定义如下 12@ApiOperation(\"课程预览\")public CoursePublishResult preview(String id); 3.4.2 Controller12345@Override@PostMapping(\"/preview/&#123;id&#125;\")public CoursePublishResult preview(@PathVariable(\"id\") String id) &#123; return courseService.preview(id);&#125; 3.4.3 创建 Feign Client在课程管理工程创建CMS服务的Feign Client，通过此Client远程请求cms添加页面 123456@FeignClient(value = \"XC-SERVICE-MANAGE-CMS\")public interface CmsPageClient &#123; //保存页面 @PostMapping(\"/cms/page/save\") public CmsPageResult save(@RequestBody CmsPage cmsPage);&#125; 注意: CmsPageResult需要添加无参构造@NoArgsConstructor 3.4.4 Service(1) 配置添加页面参数信息在application.yml中配置： 1234567course‐publish: siteId: 5a751fab6abb5044e0d19ea1 templateId: 5ad9a24d68db5239b8fef199 previewUrl: http://www.xuecheng.com/cms/preview/ pageWebPath: /course/detail/ pagePhysicalPath: /course/detail/ dataUrlPre: http://localhost:31200/course/courseview/ (2) 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Value(\"$&#123;course‐publish.dataUrlPre&#125;\")private String publish_dataUrlPre;@Value(\"$&#123;course‐publish.pagePhysicalPath&#125;\")private String publish_page_physicalpath;@Value(\"$&#123;course‐publish.pageWebPath&#125;\")private String publish_page_webpath;@Value(\"$&#123;course‐publish.siteId&#125;\")private String publish_siteId;@Value(\"$&#123;course‐publish.templateId&#125;\")private String publish_templateId;@Value(\"$&#123;course‐publish.previewUrl&#125;\")private String previewUrl;//课程预览public CoursePublishResult preview(String id) &#123; //查询课程 CourseBase courseBase = findCourseBaseById(id); //请求cms添加页面 //准备cmsPage信息 CmsPage cmsPage=new CmsPage(); cmsPage.setSiteId(publish_siteId); cmsPage.setDataUrl(publish_dataUrlPre+id); cmsPage.setTemplateId(publish_templateId); cmsPage.setPageName(id+\".html\"); cmsPage.setPageAliase(courseBase.getName()); cmsPage.setPagePhysicalPath(publish_page_physicalpath); cmsPage.setPageWebPath(publish_page_webpath); //远程调用cms CmsPageResult cmsPageResult = cmsPageClient.save(cmsPage); if (!cmsPageResult.isSuccess())&#123; return new CoursePublishResult(CommonCode.FAIL,null); &#125; String pageId = cmsPageResult.getCmsPage().getPageId(); //拼接页面预览的url String url=previewUrl+pageId; //返回CoursePublishResult对象(当中包含了页面预览的url) return new CoursePublishResult(CommonCode.SUCCESS,url);&#125;public CourseBase findCourseBaseById(String courseId)&#123; Optional&lt;CourseBase&gt; optional = courseBaseRepository.findById(courseId); if (optional.isPresent())&#123; CourseBase courseBase = optional.get(); return courseBase; &#125; ExceptionCast.cast(CourseCode.COURSE_GET_NOTEXISTS); return null;&#125; 4.课程发布4.1 需求分析课程发布后将生成正式的课程详情页面，课程发布后用户即可浏览课程详情页面，并开始课程的学习。课程发布生成课程详情页面的流程与课程预览业务流程相同，如下：(1) 用户进入教学管理中心，进入某个课程的管理界面(2) 点击课程发布，前端请求到课程管理服务(3) 课程管理服务远程调用CMS生成课程发布页面，CMS将课程详情页面发布到服务器(4) 课程管理服务修改课程发布状态为 “已发布”，并向前端返回发布成功(5) 用户在教学管理中心点击“课程详情页面”链接，查看课程详情页面内容 4.2 CMS一键发布接口4.2.1 需求分析根据需求分析内容，需要在cms服务增加页面发布接口供课程管理服务调用，此接口的功能如下：(1) 接收课程管理服务发布的页面信息(2) 将页面信息添加到数据库（mongodb）(3) 对页面信息进行静态化(4) 将页面信息发布到服务器 4.2.2 接口定义1.创建响应结果类型 页面发布成功cms返回页面的url页面Url= cmsSite.siteDomain+cmsSite.siteWebPath+ cmsPage.pageWebPath + cmsPage.pageName 123456789@Data@NoArgsConstructorpublic class CmsPostPageResult extends ResponseResult &#123; String pageUrl; public CmsPostPageResult(ResultCode resultCode,String pageUrl)&#123; super(resultCode); this.pageUrl=pageUrl; &#125;&#125; 2.在api工程定义页面发布接口 12@ApiOperation(\"一键发布页面\")public CmsPostPageResult postPageQuick(CmsPage cmsPage); 4.2.3 服务端开发1. 站点dao接口中需要获取站点的信息（站点域名、站点访问路径等） 12public interface CmsSiteRepository extends MongoRepository&lt;CmsSite,String&gt; &#123;&#125; 2.Controller 12345@Override@PostMapping(\"/postPageQuick\")public CmsPostPageResult postPageQuick(@RequestBody CmsPage cmsPage) &#123; return pageService.postPageQuick(cmsPage);&#125; 3.Service 123456789101112131415161718192021222324252627282930313233343536373839404142//一键发布页面public CmsPostPageResult postPageQuick(CmsPage cmsPage) &#123; //添加页面 CmsPageResult save = save(cmsPage); if (!save.isSuccess()) &#123; return new CmsPostPageResult(CommonCode.FAIL, null); &#125; //要发布的页面id CmsPage cmsPage1 = save.getCmsPage(); String pageId = cmsPage1.getPageId(); //发布页面 ResponseResult post = post(pageId); if (!post.isSuccess()) &#123; return new CmsPostPageResult(CommonCode.FAIL, null); &#125; //得到页面的url //页面url=站点域名+站点webpath+页面webpath+页面名称 //站点id String siteId = cmsPage1.getSiteId(); //查询站点信息 CmsSite cmsSite = findCmsSiteById(siteId); //站点域名 String siteDomain = cmsSite.getSiteDomain(); //站点web路径 String siteWebPath = cmsSite.getSiteWebPath(); //页面web路径 String pageWebPath = cmsPage1.getPageWebPath(); //页面名称 String pageName = cmsPage1.getPageName(); //页面的web访问地址 String pageUrl=siteDomain+siteWebPath+pageWebPath+pageName; return new CmsPostPageResult(CommonCode.SUCCESS,pageUrl);&#125;//根据id查询站点信息public CmsSite findCmsSiteById(String siteId) &#123; Optional&lt;CmsSite&gt; optional = cmsSiteRepository.findById(siteId); if (optional.isPresent())&#123; return optional.get(); &#125; return null;&#125; 4.3 课程发布接口4.3.1 Api接口此Api接口由课程管理提供，由课程管理前端调用此Api接口，实现课程发布。 在api工程下课程管理包下定义接口： 12@ApiOperation(\"课程发布\")public CoursePublishResult publish(String id); 4.3.2 创建Feign Client在课程管理工程创建CMS服务页面发布的Feign Client 123456@FeignClient(value = \"XC-SERVICE-MANAGE-CMS\")public interface CmsPageClient &#123; //一键发布页面 @PostMapping(\"/cms/page/postPageQuick\") public CmsPostPageResult postPageQuick(CmsPage cmsPage);&#125; 4.3.3 Controller12345@Override@PostMapping(\"/publish/&#123;id&#125;\")public CoursePublishResult publish(@PathVariable(\"id\") String id) &#123; return courseService.publish(id);&#125; 4.3.4 Service123456789101112131415161718192021222324252627282930313233343536 @Transactional public CoursePublishResult publish(String id) &#123; //准备页面信息 //查询课程 CourseBase courseBase = findCourseBaseById(id); CmsPage cmsPage=new CmsPage(); cmsPage.setSiteId(publish_siteId); cmsPage.setDataUrl(publish_dataUrlPre+id); cmsPage.setTemplateId(publish_templateId); cmsPage.setPageName(id+\".html\"); cmsPage.setPageAliase(courseBase.getName()); cmsPage.setPagePhysicalPath(publish_page_physicalpath); cmsPage.setPageWebPath(publish_page_webpath); //调用CMS一键发布接口将课程详情页面发布到服务器 CmsPostPageResult cmsPostPageResult = cmsPageClient.postPageQuick(cmsPage); if (!cmsPostPageResult.isSuccess())&#123; return new CoursePublishResult(CommonCode.FAIL,null); &#125; //保存课程的发布状态为\"已发布\" CourseBase base = saveCoursePubState(id); if (base==null)&#123; return new CoursePublishResult(CommonCode.FAIL,null); &#125; //得到页面url String pageUrl = cmsPostPageResult.getPageUrl(); return new CoursePublishResult(CommonCode.SUCCESS,pageUrl); &#125; public CourseBase saveCoursePubState(String courseId)&#123; CourseBase courseBase = findCourseBaseById(courseId); //更新发布状态 courseBase.setStatus(\"202002\"); CourseBase save = courseBaseRepository.save(courseBase); return save; &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(六.页面发布, 课程管理)","slug":"学成在线(六.页面发布, 课程管理)","date":"2021-05-08T13:19:59.204Z","updated":"2020-04-29T05:55:44.626Z","comments":true,"path":"35259/","link":"","permalink":"http://tonymua.top/35259/","excerpt":"1.页面发布1.1 技术方案本项目使用MQ实现页面发布的技术方案如下：","text":"1.页面发布1.1 技术方案本项目使用MQ实现页面发布的技术方案如下： 技术方案说明：(1) 平台包括多个站点，页面归属不同的站点。(2) 发布一个页面应将该页面发布到所属站点的服务器上。(3) 每个站点服务部署cms client程序，并与交换机绑定，绑定时指定站点Id为routingKey。 指定站点id为routingKey就可以实现cms client只能接收到所属站点的页面发布消息。(4) 页面发布程序向MQ发布消息时指定页面所属站点Id为routingKey，将该页面发布到它所在服务器上的cms client。 路由模式分析如下：发布一个页面，需发布到该页面所属的每个站点服务器，其它站点服务器不发布。比如：发布一个门户的页面，需要发布到每个门户服务器上，而用户中心服务器则不需要发布。所以本项目采用routing模式，用站点id作为routingKey，这样就可以匹配页面只发布到所属的站点服务器上。 页面发布流程图如下(1) 前端请求cms执行页面发布。(2) cms执行静态化程序生成html文件。(3) cms将html文件存储到GridFS中。(4) cms向MQ发送页面发布消息(5) MQ将页面发布消息通知给Cms Client(6) Cms Client从GridFS中下载html文件(7) Cms Client将html保存到所在服务器指定目录 1.2 页面发布消费方1.2.1需求分析功能分析：创建Cms Client工程作为页面发布消费方，将Cms Client部署在多个服务器上，它负责接收到页面发布 的消息后从 GridFS中下载文件在本地保存。 需求如下：(1) 将cms Client部署在服务器，配置队列名称和站点ID。(2) cms Client连接RabbitMQ并监听各自的“页面发布队列”(3) cms Client接收页面发布队列的消息(4) 根据消息中的页面id从mongodb数据库下载页面到本地 调用dao查询页面信息，获取到页面的物理路径，调用dao查询站点信息，得到站点的物理路径页面物理路径=站点物理路径+页面物理路径+页面名称。从GridFS查询静态文件内容，将静态文件内容保存到页面物理路径下。 1.2.2 创建Cms Client工程(1) 创建maven工程 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;xc-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../xc-framework-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;xc‐service‐manage‐cms‐client&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; (2) 配置文件 在resources下配置application.yml和logback-spring.xml。 application.yml的内容如下： 123456789101112131415161718192021server: port: 31000spring: application: name: xc-service-manage-cms-client data: mongodb: uri: mongodb://root:547717253@localhost:27017 database: xc_cms rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtual-host: /xuecheng: mq: #cms客户端监控的队列名称（不同的客户端监控的队列不能重复） queue: queue_cms_postpage_01 routingKey: 5a751fab6abb5044e0d19ea1 #此routingKey为门户站点ID 说明：在配置文件中配置队列的名称，每个 cms client在部署时注意队列名称不要重 (3) 启动类 123456789@SpringBootApplication@EntityScan(\"com.xuecheng.framework.domain.cms\")@ComponentScan(basePackages = &#123;\"com.xuecheng.framework\"&#125;)@ComponentScan(basePackages = &#123;\"com.xuecheng.manage_cms_client\"&#125;)public class ManageCmsClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ManageCmsClientApplication.class); &#125;&#125; 1.2.3 RabbitmqConﬁg配置(1) 创建“ex_cms_postpage”交换机(2) 每个Cms Client创建一个队列与交换机绑定(3) 每个Cms Client程序配置队列名称和routingKey，将站点ID作为routingKey 12345678910111213141516171819202122232425262728293031323334353637package com.xuecheng.manage_cms_client.config;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitmqConfig &#123; //队列bean的名称 public static final String QUEUE_CMS_POSTPAGE = \"queue_cms_postpage\"; //交换机的名称 public static final String EX_ROUTING_CMS_POSTPAGE = \"ex_routing_cms_postpage\"; //队列的名称 @Value(\"$&#123;xuecheng.mq.queue&#125;\") public String queue_cms_postpage_name; @Value(\"$&#123;xuecheng.mq.routingKey&#125;\") public String routingKey; //交换机配置使用direct类型 @Bean(EX_ROUTING_CMS_POSTPAGE) public Exchange EXCHANGE_TOPICS_INFORM() &#123; return ExchangeBuilder.directExchange(EX_ROUTING_CMS_POSTPAGE).durable(true).build(); &#125; //声明队列 @Bean(QUEUE_CMS_POSTPAGE) public Queue QUEUE_CMS_POSTPAGE() &#123; Queue queue = new Queue(queue_cms_postpage_name); return queue; &#125; //绑定队列到交换机 @Bean public Binding BINDING_QUEUE_INFORM_SMS(@Qualifier(QUEUE_CMS_POSTPAGE)Queue queue, @Qualifier(EX_ROUTING_CMS_POSTPAGE)Exchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(routingKey).noargs(); &#125;&#125; 1.2.4 定义消息格式消息内容采用json格式存储数据，如下：页面id：发布页面的id 123&#123; \"pageId\":\"\" &#125; 1.2.5 PageDao(1) 使用CmsPageRepository 查询页面信息 12public interface CmsPageRepository extends MongoRepository&lt;CmsPage,String&gt; &#123;&#125; (2) 使用CmsSiteRepository查询站点信息，主要获取站点物理路径 12public interface CmsSiteRepository extends MongoRepository&lt;CmsSite,String&gt; &#123;&#125; 1.2.6 PageService在Service中定义保存页面静态文件到服务器物理路径方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Servicepublic class PageService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(PageService.class); @Autowired CmsPageRepository cmsPageRepository; @Autowired CmsSiteRepository cmsSiteRepository; @Autowired GridFsTemplate gridFsTemplate; @Autowired GridFSBucket gridFSBucket; //将页面html保存到页面物理路径 public void savePageToServerPath(String pageId) &#123; //根据pageId查询CmsPage CmsPage cmsPage = findCmsPageById(pageId); //得到html的文件id,从cmsPage中获取htmlFileId内容 String htmlFileId = cmsPage.getHtmlFileId(); //从gridFs中查询html文件 InputStream inputStream = getFileById(htmlFileId); if (inputStream == null) &#123; LOGGER.error(\"getFileById InputStream is null,htmlFileId:&#123;&#125;\", htmlFileId); return; &#125; //得到站点的信息 String siteId = cmsPage.getSiteId(); CmsSite cmsSite = findCmsSiteById(siteId); //站点物理路径 String sitePhysicaPath = cmsSite.getSitePhysicaPath(); //页面物理路径 String pagePath = sitePhysicaPath + cmsPage.getPagePhysicalPath() + cmsPage.getPageName(); //将文件内容保存到服务物理路径 FileOutputStream fileOutputStream = null; try &#123; fileOutputStream = new FileOutputStream(new File((pagePath))); IOUtils.copy(inputStream, fileOutputStream); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; inputStream.close(); fileOutputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; //根据文件Id从GridFs中查询文件内容 public InputStream getFileById(String fileId) &#123; try &#123; GridFSFile gridFSFile = gridFsTemplate.findOne(Query.query(Criteria.where(\"_id\").is(fileId))); GridFSDownloadStream gridFSDownloadStream = gridFSBucket.openDownloadStream(gridFSFile.getObjectId()); GridFsResource gridFsResource = new GridFsResource(gridFSFile, gridFSDownloadStream); return gridFsResource.getInputStream(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; //根据页面id查询页面信息 public CmsPage findCmsPageById(String pageId) &#123; Optional&lt;CmsPage&gt; optional = cmsPageRepository.findById(pageId); if (optional.isPresent()) &#123; return optional.get(); &#125; return null; &#125; //根据站点id查询站点信息 public CmsSite findCmsSiteById(String siteId) &#123; Optional&lt;CmsSite&gt; optional = cmsSiteRepository.findById(siteId); if (optional.isPresent()) &#123; return optional.get(); &#125; return null; &#125;&#125; 1.2.7 ConsumerPostPage在cms client工程的mq包下创建ConsumerPostPage类，ConsumerPostPage作为发布页面的消费客户端，监听 页面发布队列的消息，收到消息后从mongodb下载文件，保存在本地 12345678910111213141516171819202122@Componentpublic class ConsumerPostPage &#123; private static final Logger LOGGER= LoggerFactory.getLogger(ConsumerPostPage.class); @Autowired PageService pageService; @RabbitListener(queues =&#123;\"$&#123;xuecheng.mq.queue&#125;\"&#125; ) public void postPage(String msg)&#123; //解析消息 Map map = JSON.parseObject(msg, Map.class); //得到消息中的页面id String pageId = (String) map.get(\"pageId\"); //校验页面是否合法 CmsPage cmsPage = pageService.findCmsPageById(pageId); if (cmsPage==null)&#123; LOGGER.error(\"postPage msg, cmsPage is null, pageId:&#123;&#125;\",pageId); return; &#125; //将页面保存到服务器物理路径 pageService.savePageToServerPath(pageId); &#125;&#125; 1.3 页面发布生产方1.3.1 需求分析管理员通过 cms系统发布“页面发布”的消费，cms系统作为页面发布的生产方。需求如下：(1) 管理员进入管理界面点击“页面发布”，前端请求cms页面发布接口。(2) cms页面发布接口执行页面静态化，并将静态化页面存储至GridFS中。(3) 静态化成功后，向消息队列发送页面发布的消息。 1） 获取页面的信息及页面所属站点ID。 2） 设置消息内容为页面ID。（采用json格式，方便日后扩展） 3） 发送消息给ex_cms_postpage交换机，并将站点ID作为routingKey。 1.3.2 RabbitMQ配置(1) 配置Rabbitmq的连接参数在application.yml添加如下配置： 123456rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtualHost: / (2) 在pom.xml添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; (3) RabbitMQConﬁg配置 由于cms作为页面发布方要面对很多不同站点的服务器，面对很多页面发布队列，所以这里不再配置队列，只需要 配置交换机即可在cms工程只配置交换机名称即可 1234567891011@Configurationpublic class RabbitmqConfig &#123; //交换机的名称 public static final String EX_ROUTING_CMS_POSTPAGE=\"ex_routing_cms_postpage\"; //交换机配置使用direct类型 @Bean(EX_ROUTING_CMS_POSTPAGE) public Exchange EXCHANGE_TOPICS_INFORM()&#123; return ExchangeBuilder.directExchange(EX_ROUTING_CMS_POSTPAGE).durable(true).build(); &#125;&#125; 1.3.3 Api接口在api工程定义页面发布接口： 12@ApiOperation(\"发布页面\")public ResponseResult post(String pageId); 1.3.4 CmsPageController编写Controller实现api接口，接收页面请求，调用service执行页面发布 12345@Override@PostMapping(\"/postPage/&#123;pageId&#125;\")public ResponseResult post(@PathVariable(\"pageId\") String pageId) &#123; return pageService.post(pageId);&#125; 1.3.5 PageService在PageService中定义页面发布方法，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//页面发布public ResponseResult post(String pageId) &#123; //执行静态化 String pageHtml = getPageHtml(pageId); if (StringUtils.isEmpty(pageHtml))&#123; ExceptionCast.cast(CmsCode.CMS_GENERATEHTML_HTMLISNULL); &#125; //将页面静态化文件存储到GridFs中 CmsPage cmsPage = saveHtml(pageId, pageHtml); //向MQ发消息 sendPostPage(pageId); return new ResponseResult(CommonCode.SUCCESS);&#125;public void sendPostPage(String pageId)&#123; //得到页面信息 CmsPage cmsPage = findById(pageId); if (cmsPage==null)&#123; ExceptionCast.cast(CmsCode.CMS_PAGE_NOTEXISTS); &#125; //创建消息对象 HashMap&lt;String,String&gt; msg=new HashMap&lt;&gt;(); msg.put(\"pageId\",pageId); //转成json串 String jsonString = JSON.toJSONString(msg); //发送给mq //站点id String siteId = cmsPage.getSiteId(); rabbitTemplate.convertAndSend(RabbitmqConfig.EX_ROUTING_CMS_POSTPAGE,siteId,jsonString);&#125;public CmsPage saveHtml(String pageId,String htmlContent)&#123; //查询页面 Optional&lt;CmsPage&gt; optional = cmsPageRepository.findById(pageId); if (!optional.isPresent())&#123; ExceptionCast.cast(CmsCode.CMS_PAGE_NOTEXISTS); &#125; CmsPage cmsPage = optional.get(); //存储之前先删除 String htmlFileId = cmsPage.getHtmlFileId(); if (StringUtils.isNotEmpty(htmlFileId))&#123; gridFsTemplate.delete(Query.query(Criteria.where(\"_id\").is(htmlFileId))); &#125; //保存html文件到GridFS //将htmlContent内容转成输入流 InputStream inputStream = IOUtils.toInputStream(htmlContent); //将html文件内容保存到GridFS ObjectId objectId = gridFsTemplate.store(inputStream, cmsPage.getPageName()); //将html文件id更新到cmsPage中 cmsPage.setHtmlFileId(objectId.toHexString()); cmsPageRepository.save(cmsPage); return cmsPage;&#125; 1.4 测试这里测试轮播图页面修改、发布的流程：(1) 修改轮播图页面模板或修改轮播图地址注意：先修改页面原型，页面原型调试正常后再修改页面模板。(2) 执行页面预览(3)执行页面发布，查看页面是否写到网站目录(4) 刷新门户首页并观察轮播图是否变化。 1.5 思考1、如果发布到服务器的页面内容不正确怎么办？2、一个页面需要发布很多服务器，点击“发布”后如何知道详细的发布结果？3、一个页面发布到多个服务器，其中有一个服务器发布失败时怎么办？ 2.课程管理2.1 需求分析在线教育平台的课程信息相当于电商平台的商品。课程管理是后台管理功能中最重要的模块。本项目为教学机构提 供课程管理功能，教学机构可以添加属于自己的课程，供学生在线学习。课程管理包括如下功能需求：1、分类管理2、新增课程3、修改课程4、预览课程5、发布课程 2.2 环境搭建2.2.1 搭建数据库环境1) 创建数据库课程管理使用MySQL数据库，创建课程管理数据库：xc_course导入xc_course.sql脚本 2) 数据表介绍课程信息内容繁多，将课程信息分类保存在如下表中： 2.2.2 导入课程管理服务工程1）持久层技术介绍： 课程管理服务使用MySQL数据库存储课程信息，持久层技术如下：1、spring data jpa：用于表的基本CRUD2、mybatis：用于复杂的查询操作3、druid：使用阿里巴巴提供的spring boot 整合druid包druid-spring-boot-starter管理连接池。druid-spring-boot-starter地址：https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter 2）导入工程 2.2.3 导入课程管理前端工程课程管理属于教学管理子系统的功能，使用用户为教学机构的管理人员和老师，为保证系统的可维护性，单独创建 一个教学管理前端工程。 教学管理前端工程与系统管理前端的工程结构一样，也采用vue.js框架来实现 3.课程计划3.1 需求分析什么是课程计划？课程计划定义了课程的章节内容，学生通过课程计划进行在线学习，下图中右侧显示的就是课程计划。课程计划包括两级，第一级是课程的大章节、第二级是大章节下属的小章节，每个小章节通常是一段视频，学生点 击小章节在线学习。教学管理人员对课程计划如何管理？功能包括：添加课程计划、删除课程计划、修改课程计划等。 3.2 课程计划查询3.2.1 需求分析课程计划查询是将某个课程的课程计划内容完整的显示出来左侧显示的就是课程计划，课程计划是一个树型结构，方便扩展课程计划的级别。在上边页面中，点击“添加课程计划”即可对课程计划进行添加操作。点击修改可对某个章节内容进行修改。点击删除可删除某个章节。 3.2.2 API接口3.2.2.1 数据模型1、表结构 2、模型类课程计划为树型结构，由树根（课程）和树枝（章节）组成，为了保证系统的可扩展性，在系统设计时将课程计划 设置为树型结构。 1234567891011121314151617181920212223@Data@ToString@Entity@Table(name=\"teachplan\")@GenericGenerator(name = \"jpa-uuid\", strategy = \"uuid\")public class Teachplan implements Serializable &#123; private static final long serialVersionUID = -916357110051689485L; @Id @GeneratedValue(generator = \"jpa-uuid\") @Column(length = 32) private String id; private String pname; private String parentid; private String grade; private String ptype; private String description; private String courseid; private String status; private Integer orderby; private Double timelength; private String trylearn;&#125; 3.2.2.2 自定义模型类前端页面需要树型结构的数据来展示Tree组件，如下： 12345678[&#123; id: 1, label: '一级 1', children: [&#123; id: 4, label: '二级 1‐1' &#125;] &#125;] 自定义课程计划结点类如下： 1234567@Data@ToStringpublic class TeachplanNode extends Teachplan &#123; List&lt;TeachplanNode&gt; children;&#125; 3.2.2.3 接口定义根据课程id查询课程的计划接口如下，在api工程创建course包，创建CourseControllerApi接口类并定义接口方法 如下： 12345@Api(value = \"课程管理接口\")public interface CourseControllerApi &#123; @ApiOperation(\"课程计划查询\") public TeachplanNode findTeachplanList(String courseId);&#125; 3.2.3 课程管理服务3.2.3.1 Sql课程计划是树型结构，采用表的自连接方式进行查询，sql语句如下： 12345678910111213141516171819SELECT a.id one_id, a.pname one_pname, b.id two_id, b.pname two_pname, c.id three_id, c.pname three_pname FROM teachplan a LEFT JOIN teachplan b ON a.id = b.parentid LEFT JOIN teachplan c ON b.id = c.parentid WHERE a.parentid = '0' AND a.courseid = '402885816243d2dd016243f24c030002' ORDER BY a.orderby, b.orderby, c.orderby 3.2.3.2 Dao1) mapper接口 1234@Mapperpublic interface TeachplanMapper &#123; public TeachplanNode selectList(String courseId);&#125; 2）mapper映射文件 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.xuecheng.manage_course.dao.TeachplanMapper\"&gt; &lt;resultMap id=\"teachplanMap\" type=\"com.xuecheng.framework.domain.course.ext.TeachplanNode\"&gt; &lt;id property=\"id\" column=\"one_id\"/&gt; &lt;result property=\"pname\" column=\"one_pname\"/&gt; &lt;collection property=\"children\" ofType=\"com.xuecheng.framework.domain.course.ext.TeachplanNode\"&gt; &lt;id property=\"id\" column=\"two_id\"/&gt; &lt;result property=\"pname\" column=\"two_pname\"/&gt; &lt;collection property=\"children\" ofType=\"com.xuecheng.framework.domain.course.ext.TeachplanNode\"&gt; &lt;id property=\"id\" column=\"three_id\"/&gt; &lt;result property=\"pname\" column=\"three_pname\"/&gt; &lt;/collection&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id=\"selectList\" resultMap=\"teachplanMap\" parameterType=\"String\"&gt; select a.id one_id, a.pname one_pname, b.id two_id, b.pname two_pname, c.id three_id, c.pname three_pname from teachplan a left join teachplan b on a.id=b.parentid left join teachplan c on b.id=c.parentid where a.parentid='0' &lt;if test=\"_parameter!=null and _parameter!=''\"&gt; and a.courseid=#&#123;courseId&#125; &lt;/if&gt; order by a.orderby, b.orderby, c.orderby &lt;/select&gt;&lt;/mapper&gt; 说明：针对输入参数为简单类型#{}中可以是任意类型，判断参数是否为空要用 _parameter（它属于mybatis的内 置参数） 3.2.3.3 Service创建CourseService类，定义查询课程计划方法。 1234567891011@Servicepublic class CourseService &#123; @Autowired TeachplanMapper teachplanMapper; //查询课程计划 public TeachplanNode findTeachplanList(String courseId)&#123; TeachplanNode teachplanNode = teachplanMapper.selectList(courseId); return teachplanNode; &#125;&#125; 3.2.3.4 Controller12345678910111213@RestController@RequestMapping(\"/course\")public class CourseController implements CourseControllerApi &#123; @Autowired CourseService courseService; //查询课程计划 @Override @GetMapping(\"/teachplan/list/&#123;courseId&#125;\") public TeachplanNode findTeachplanList(@PathVariable(\"courseId\") String courseId) &#123; return courseService.findTeachplanList(courseId); &#125;&#125; 3.3 添加课程计划3.3.1 需求分析用户操作流程：1、进入课程计划页面，点击“添加课程计划”2、打开添加课程计划页面，输入课程计划信息 上级结点说明：不选择上级结点表示当前课程计划为该课程的一级结点。当添加该课程在课程计划中还没有节点时要自动添加课程的根结点。 3、点击提交。 3.3.2 API接口添加课程计划 12@ApiOperation(\"添加课程计划\")public ResponseResult addTeachplan(Teachplan teachplan); 3.3.3 课程管理服务3.3.3.1 Dao1234public interface TeachplanRepository extends JpaRepository&lt;Teachplan,String&gt; &#123; //定义方法根据课程id和父结点id查询出结点列表，可以使用此方法实现查询根结点 public List&lt;Teachplan&gt; findByCourseidAndParentid(String courseId,String parentId);&#125; 3.3.3.2 controller12345@Override@PostMapping(\"/teachplan/add\")public ResponseResult addTeachplan(@RequestBody Teachplan teachplan) &#123; return courseService.addTeachplan(teachplan);&#125; 3.3.3.3 Service12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 @Transactionalpublic ResponseResult addTeachplan(Teachplan teachplan) &#123; //校验课程id和课程计划名称 if (teachplan==null|| StringUtils.isEmpty(teachplan.getCourseid()))&#123; ExceptionCast.cast(CommonCode.INVALID_PARAM); &#125; //取出课程id String courseid = teachplan.getCourseid(); //取出父结点id String parentid = teachplan.getParentid(); if (StringUtils.isEmpty(parentid))&#123; //如果父结点为空则获取根结点 parentid=getTeachplanRoot(courseid); &#125; //取出父结点信息 Optional&lt;Teachplan&gt; optional = teachplanRepository.findById(parentid); if (!optional.isPresent())&#123; ExceptionCast.cast(CommonCode.INVALID_PARAM); &#125; //父结点 Teachplan teachplanParent = optional.get(); //父结点级别 String parentGrade = teachplanParent.getGrade(); //设置父结点 teachplan.setParentid(parentid); teachplan.setStatus(\"0\"); //未发布 //子结点的级别，根据父结点来判断 if (parentGrade.equals(\"1\"))&#123; teachplan.setGrade(\"2\"); &#125;else if (parentGrade.equals(\"2\"))&#123; teachplan.setGrade(\"3\"); &#125; //设置课程id teachplan.setCourseid(teachplanParent.getCourseid()); teachplanRepository.save(teachplan); return new ResponseResult(CommonCode.SUCCESS); &#125; //获取课程根结点，如果没有则添加根结点 public String getTeachplanRoot(String courseId)&#123; //校验课程id Optional&lt;CourseBase&gt; optional = courseBaseRepository.findById(courseId); if (!optional.isPresent())&#123; return null; &#125; CourseBase courseBase = optional.get(); //取出课程计划根结点 List&lt;Teachplan&gt; teachplanList = teachplanRepository.findByCourseidAndParentid(courseId, \"0\"); if (teachplanList==null||teachplanList.size()==0)&#123; //新增一个根结点 Teachplan teachplanRoot=new Teachplan(); teachplanRoot.setCourseid(courseId); teachplanRoot.setPname(courseBase.getName()); teachplanRoot.setParentid(\"0\"); teachplanRoot.setGrade(\"1\"); //1级 teachplanRoot.setStatus(\"0\"); //未发布 teachplanRepository.save(teachplanRoot); return teachplanRoot.getId(); &#125; Teachplan teachplan = teachplanList.get(0); return teachplan.getId(); &#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(八.课程图片管理)","slug":"学成在线(八.课程图片管理)","date":"2021-05-08T13:19:59.203Z","updated":"2020-04-29T02:44:38.054Z","comments":true,"path":"63452/","link":"","permalink":"http://tonymua.top/63452/","excerpt":"1.上传图片开发1.1 需求分析在很多系统都有上传图片/上传文件的需求，比如：上传课程图片、上传课程资料、上传用户头像等，为了提供系 统的可重用性专门设立文件系统服务承担图片/文件的管理，文件系统服务实现对文件的上传、删除、查询等功能 进行管理。各各子系统不再开发上传文件的请求，各各子系统通过文件系统服务进行文件的上传、删除等操作。文件系统服务 最终会将文件存储到fastDSF文件系统中。下图是各各子系统与文件系统服务之间的关系：","text":"1.上传图片开发1.1 需求分析在很多系统都有上传图片/上传文件的需求，比如：上传课程图片、上传课程资料、上传用户头像等，为了提供系 统的可重用性专门设立文件系统服务承担图片/文件的管理，文件系统服务实现对文件的上传、删除、查询等功能 进行管理。各各子系统不再开发上传文件的请求，各各子系统通过文件系统服务进行文件的上传、删除等操作。文件系统服务 最终会将文件存储到fastDSF文件系统中。下图是各各子系统与文件系统服务之间的关系： 下图是课程管理中上传图片处理流程：执行流程如下：(1) 管理员进入教学管理前端，点击上传图片(2) 图片上传至文件系统服务，文件系统请求fastDFS上传文件(3) 文件系统将文件入库，存储到文件系统服务数据库中。(4) 文件系统服务向前端返回文件上传结果，如果成功则包括文件的Url路径。(5)课程管理前端请求课程管理进行保存课程图片信息到课程数据库。(6) 课程管理服务将课程图片保存在课程数据库。 1.2 创建文件系统服务工程导入xc-service-base-ﬁlesystem工程 1）工程目录结构2）pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;xc-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../xc-framework-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;xc-service-base-filesystem&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-service-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.oschina.zcx7878&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）配置文件原测试程序中fastdfs-client.properties的配置信息统一放在application.ymlapplication.yml 1234567891011121314151617181920212223242526272829server: port: 22100spring: application: name: xc-service-base-filesystem#mongo配置 data: mongodb: database: xc_fs uri: mongodb://root:547717253@localhost:27017#SpringMVC上传文件配置 servlet: multipart: #默认支持文件上传. enabled: true #支持文件写入磁盘. file-size-threshold: 0 # 上传文件的临时目录 location: # 最大支持文件大小 max-file-size: 1MB # 最大支持请求大小 max-request-size: 30MBxuecheng: fastdfs: connect_timeout_in_seconds: 5 network_timeout_in_seconds: 30 charset: UTF-8 tracker_servers: 192.168.179.101:22122 #多个 trackerServer中间以逗号分隔 1.3 服务端1.3.1 模型类系统的文件信息（图片、文档等小文件的信息）在mongodb中存储，下边是文件信息的模型类。1) 模型如下： 1234567891011121314151617181920212223242526272829@Data@ToString@Document(collection = \"filesystem\")public class FileSystem &#123; @Id private String fileId; //文件请求路径 private String filePath; //文件大小 private long fileSize; //文件名称 private String fileName; //文件类型 private String fileType; //图片宽度 private int fileWidth; //图片高度 private int fileHeight; //用户id，用于授权 private String userId; //业务key private String businesskey; //业务标签 private String filetag; //文件元信息 private Map metadata;&#125; 说明： ﬁleId：fastDFS返回的文件ID。 ﬁlePath：请求fastDFS浏览文件URL。 ﬁletag：文件标签，由于文件系统服务是公共服务，文件系统服务会为使用文件系统服务的子系统分配文件标签， 用于标识此文件来自哪个系统。 businesskey：文件系统服务为其它子系统提供的一个业务标识字段，各子系统根据自己的需求去使用，比如：课 程管理会在此字段中存储课程id用于标识该图片属于哪个课程。 metadata：文件相关的元信息。2) collection 在mongodb创建数据库xc_fs（文件系统数据库），并创建集合 ﬁlesystem。 1.3.2 Api接口在api工程下创建com.xuecheng.api.ﬁlesystem包 123456@Api(value = \"文件管理接口\",description = \"文件管理接口\")public interface FileSystemControllerApi &#123; //上传文件 @ApiOperation(\"上传文件接口\") public UploadFileResult upload(MultipartFile multipartFile,String filetag,String businesskey,String metadata);&#125; 1.3.3 Dao将文件信息存入数据库，主要存储文件系统中的文件路径。 12public interface FileSystemRepository extends MongoRepository&lt;FileSystem,String&gt; &#123;&#125; 1.3.4 Service12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182@Servicepublic class FileSystemService &#123; @Autowired FileSystemRepository fileSystemRepository; @Value(\"$&#123;xuecheng.fastdfs.tracker_servers&#125;\") String tracker_servers; @Value(\"$&#123;xuecheng.fastdfs.connect_timeout_in_seconds&#125;\") int connect_timeout_in_seconds; @Value(\"$&#123;xuecheng.fastdfs.network_timeout_in_seconds&#125;\") int network_timeout_in_seconds; @Value(\"$&#123;xuecheng.fastdfs.charset&#125;\") String charset; //上传文件 public UploadFileResult upload(MultipartFile multipartFile,String filetag,String businesskey,String metadata)&#123; if (multipartFile==null)&#123; ExceptionCast.cast(FileSystemCode.FS_UPLOADFILE_FILEISNULL); &#125; //1.将文件上传到FastDFS中,得到一个文件id String fileId = fdfs_upload(multipartFile); if (StringUtils.isEmpty(fileId))&#123; ExceptionCast.cast(FileSystemCode.FS_UPLOADFILE_SERVERFAIL); &#125; //2.将文件id及其它文件信息存储到mongodb中 FileSystem fileSystem=new FileSystem(); fileSystem.setFileId(fileId); fileSystem.setFiletag(filetag); fileSystem.setBusinesskey(businesskey); fileSystem.setFileName(multipartFile.getOriginalFilename()); fileSystem.setFileType(multipartFile.getContentType()); if (StringUtils.isNotEmpty(metadata))&#123; try &#123; Map map = JSON.parseObject(metadata, Map.class); fileSystem.setMetadata(map); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; fileSystemRepository.save(fileSystem); return new UploadFileResult(CommonCode.SUCCESS,fileSystem); &#125; //将文件上传到FastDFS中 private String fdfs_upload(MultipartFile multipartFile)&#123; //初始化FastDFS环境 initfdfsConfig(); //创建trackerClient TrackerClient trackerClient=new TrackerClient(); try &#123; TrackerServer trackerServer = trackerClient.getConnection(); //得到storage服务器 StorageServer storeStorage = trackerClient.getStoreStorage(trackerServer); //创建storageClient来上传文件 StorageClient1 storageClient1=new StorageClient1(trackerServer,storeStorage); //上传文件 //得到文件字节 byte[] bytes = multipartFile.getBytes(); //得到文件原始名称 String originalFilename = multipartFile.getOriginalFilename(); //得到文件扩展名 String ext = originalFilename.substring(originalFilename.lastIndexOf(\".\") + 1); String fileId = storageClient1.upload_file1(bytes, ext, null); return fileId; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; //初始化FastDFS环境 private void initfdfsConfig()&#123; try &#123; //初始化tracker服务地址(多个tracker中间以半角逗号分隔) ClientGlobal.initByTrackers(tracker_servers); ClientGlobal.setG_charset(charset); ClientGlobal.setG_network_timeout(network_timeout_in_seconds); ClientGlobal.setG_connect_timeout(connect_timeout_in_seconds); &#125; catch (Exception e) &#123; e.printStackTrace(); //抛出异常 ExceptionCast.cast(FileSystemCode.FS_INITFDFSERROR); &#125; &#125;&#125; 1.3.5 Controller12345678910111213141516@RestController@RequestMapping(\"/filesystem\")public class FileSystemController implements FileSystemControllerApi &#123; @Autowired FileSystemService fileSystemService; @Override @PostMapping(\"/upload\") public UploadFileResult upload(@RequestParam(\"file\") MultipartFile file, @RequestParam(value = \"filetag\",required = true)String filetag, @RequestParam(value = \"businesskey\",required = false) String businesskey, @RequestParam(value = \"metadata\",required = false) String metadata) &#123; return fileSystemService.upload(file,filetag,businesskey,metadata); &#125;&#125; 1.4 测试使用swagger-ui或postman进行测试。 下图是使用swagger-ui进行测试的界面： 2.保存课程图片2.1 需求分析图片上传到文件系统后，其它子系统如果想使用图片可以引用图片的地址，课程管理模块使用图片的方式是将图片 地址保存到课程数据库中。业务流程如下：(1) 上传图片到文件系统服务(2) 保存图片地址到课程管理服务 在课程管理服务创建保存课程与图片对应关系的表 course_pic。(3) 在course_pic保存图片成功后方可查询课程图片信息。 通过查询course_pic表数据则查询到某课程的图片信息。 2.2 课程管理服务端开发2.2.1 API课程管理需要使用图片则在课程管理服务中要提供保存课程图片的api 12@ApiOperation(\"添加课程图片\")public ResponseResult addCoursePic(String courseId,String pic); 2.2.2 模型类1234567891011121314@Data@ToString@Entity@Table(name=\"course_pic\")@GenericGenerator(name = \"jpa-assigned\", strategy = \"assigned\")public class CoursePic implements Serializable &#123; private static final long serialVersionUID = -916357110051689486L; @Id @GeneratedValue(generator = \"jpa-assigned\") private String courseid; private String pic;&#125; 2.2.3 Dao12public interface CoursePicRepository extends JpaRepository&lt;CoursePic,String&gt; &#123;&#125; 2.2.4 Controller123456@Override@PostMapping(\"/coursepic/add\")public ResponseResult addCoursePic(@RequestParam(\"courseId\") String courseId, @RequestParam(\"pic\") String pic) &#123; //保存课程图片 return courseService.saveCoursePic(courseId,pic);&#125; 2.2.5 Service123456789101112131415161718@Transactionalpublic ResponseResult saveCoursePic(String courseId, String pic) &#123; //查询课程图片 Optional&lt;CoursePic&gt; optional = coursePicRepository.findById(courseId); CoursePic coursePic = null; if (optional.isPresent()) &#123; coursePic = optional.get(); &#125; //没有课程图片则新建对象 if (coursePic==null)&#123; coursePic=new CoursePic(); &#125; coursePic.setCourseid(courseId); coursePic.setPic(pic); //保存课程图片 coursePicRepository.save(coursePic); return new ResponseResult(CommonCode.SUCCESS);&#125; 3.图片查询3.1 需求分析课程图片上传成功，再次进入课程上传页面应该显示出来已上传的图片。 3.2 课程管理服务开发3.2.1 Api12@ApiOperation(\"查询课程图片\")public CoursePic findCoursePic(String courseId); 3.2.2 Dao使用CoursePicRepository即可，无需再开发。 3.2.3 Controller12345@Override@GetMapping(\"/coursepic/list/&#123;courseId&#125;\")public CoursePic findCoursePic(@PathVariable(\"courseId\") String courseId) &#123; return courseService.findCoursePic(courseId);&#125; 3.2.4 Service1234567public CoursePic findCoursePic(String courseId) &#123; Optional&lt;CoursePic&gt; optional = coursePicRepository.findById(courseId); if (optional.isPresent())&#123; return optional.get(); &#125; return null;&#125; 4.课程图片删除4.1 需求分析课程图片上传成功后，可以重新上传，方法是先删除现有图片再上传新图片。注意：此删除只删除课程数据库的课程图片信息，不去删除文件数据库的文件信息及文件系统服务器上的文件，由 于课程图片来源于该用户的文件库，所以此图片可能存在多个地方共用的情况，所以要删除文件系统中的文件需要 到图片库由用户确认后再删除。 4.2 课程管理服务开发4.2.1 API在课程管理服务添加删除课程图片api： 12@ApiOperation(\"删除课程图片\")public ResponseResult deleteCoursePic(String courseId); 4.2.2 DaoCoursePicRepository父类提供的delete方法没有返回值，无法知道是否删除成功，这里我们在 CoursePicRepository下边自定义方法： 12//删除成功返回1否则返回0long deleteByCourseid(String courseId); 4.2.3 Controller12345@Override@DeleteMapping(\"/coursepic/delete\")public ResponseResult deleteCoursePic(@RequestParam(\"courseId\") String courseId) &#123; return courseService.deleteCoursePic(courseId);&#125; 4.2.4 Service123456789@Transactionalpublic ResponseResult deleteCoursePic(String courseId) &#123; //执行删除，返回1表示删除成功，返回0表示删除失败 long result = coursePicRepository.deleteByCourseid(courseId); if (result&gt;0)&#123; return new ResponseResult(CommonCode.SUCCESS); &#125; return new ResponseResult(CommonCode.FAIL);&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(五.消息中间件RabbitMQ)","slug":"学成在线(五.消息中间件RabbitMQ)","date":"2021-05-08T13:19:59.201Z","updated":"2020-04-29T02:44:38.128Z","comments":true,"path":"54337/","link":"","permalink":"http://tonymua.top/54337/","excerpt":"1.页面发布1.1 需求分析 业务流程如下：","text":"1.页面发布1.1 需求分析 业务流程如下： 1、管理员进入管理界面点击“页面发布”，前端请求cms页面发布接口。 2、cms页面发布接口执行页面静态化，并将静态化页面(html文件)存储至GridFS中。 3、静态化成功后，向消息队列发送页面发布的消息。 页面发布的最终目标是将页面发布到服务器。 通过消息队列将页面发布的消息发送给各服务器。 4、消息队列负责将消息发送给各服务器上部署的Cms Client(Cms客户端)。 在服务器上部署Cms Client(Cms客户端)，客户端接收消息队列的通知。 5、每个接收到页面发布消息的Cms Client从GridFS获取Html页面文件，并将Html文件存储在本地服务器。 CmsClient根据页面发布消息的内容请求GridFS获取页面文件，存储在本地服务器。RabbitMQ研究1.介绍1.1 RabbitMQMQ全称为Message Queue，即消息队列， RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开 发中应用非常广泛。RabbitMQ官方地址：http://www.rabbitmq.com/ 开发中消息队列通常有如下应用场景：(1) 任务异步处理。将不需要同步处理的并且耗时长的操作由消息队列通知消息接收方进行异步处理。提高了应用程序的响应时间。(2) 应用程序解耦合, MQ相当于一个中介，生产方通过MQ与消费方交互，它将应用程序进行解耦合。 市场上还有哪些消息队列？ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ、Redis。 为什么使用RabbitMQ呢？1、使得简单，功能强大。2、基于AMQP协议。3、社区活跃，文档完善。4、高并发性能好，这主要得益于Erlang语言。5、Spring Boot默认已集成RabbitMQ 1.2 其它相关知识 AMQP是什么 ？AMQP是一套公开的消息队列协议，最早在2003年被提出，它旨在从协议层定义消息通信数据的标准格式， 为的就是解决MQ市场上协议不统一的问题。RabbitMQ就是遵循AMQP标准协议开发的MQ服务。 官方：http://www.amqp.org/ JMS是什么 ？JMS是java提供的一套消息服务API标准，其目的是为所有的java应用程序提供统一的消息通信的标准，类似java的 jdbc，只要遵循jms标准的应用程序之间都可以进行消息通信。它和AMQP有什么 不同，jms是java语言专属的消息服务标准，它是在api层定义标准，并且只能用于java应用；而AMQP是在协议层定义的标准，是跨语言的 。 2.快速入门2.1 RabbitMQ的工作原理下图是RabbitMQ的基本结构： 组成部分说明如下： Broker：消息队列服务进程，此进程包括两个部分：Exchange和Queue。 Exchange：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过滤。 Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方。 Producer：消息生产者，即生产方客户端，生产方客户端将消息发送到MQ。 Consumer：消息消费者，即消费方客户端，接收MQ转发的消息。 消息发布接收流程：发送消息1、生产者和Broker建立TCP连接。2、生产者和Broker建立通道。3、生产者通过通道消息发送给Broker，由Exchange将消息进行转发。4、Exchange将消息转发到指定的Queue（队列）接收消息1、消费者和Broker建立TCP连接2、消费者和Broker建立通道3、消费者监听指定的Queue（队列）4、当有消息到达Queue时Broker默认将消息推送给消费者。5、消费者接收到消息。 2.2 Hello World (简单模式)按照官方教程(http://www.rabbitmq.com/getstarted.html)测试hello world: 2.2.1搭建环境(1) java client 生产者和消费者都属于客户端，rabbitMQ的java客户端如下： 我们先用 rabbitMQ官方提供的java client测试，目的是对RabbitMQ的交互过程有个清晰的认识。参考 ：https://github.com/rabbitmq/rabbitmq-java-client/ (2) 创建maven工程 创建生产者工程和消费者工程，分别加入RabbitMQ java client的依赖。test-rabbitmq-producer：生产者工程test-rabbitmq-consumer：消费者工程 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.7.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.2.2 生产者在生产者工程下的test中创建测试类如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Producer01 &#123; //队列名称 private static final String QUEUE = \"helloworld\"; //消息内容 private static final String MESSAGE = \"helloworld\" + System.currentTimeMillis(); public static void main(String[] args) throws IOException, TimeoutException &#123; //通过连接工厂创建新的连接和mq建立连接 ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\"127.0.0.1\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); //设置虚拟机 //rabbitmq默认虚拟机名称为“/”，一个mq服务可以设置多个虚拟机,每个虚拟机相当于一个独立的mq服务器 connectionFactory.setVirtualHost(\"/\"); Connection connection = null; Channel channel = null; try &#123; connection = connectionFactory.newConnection(); //创建与Exchange的通道，每个连接可以创建多个通道，每个通道代表一个会话任务 channel = connection.createChannel(); /** * 声明队列，如果Rabbit中没有此队列将自动创建 * param1:队列名称 * param2:是否持久化 * param3:队列是否独占此连接 * param4:队列不再使用时是否自动删除此队列 * param5:队列参数 * */ channel.queueDeclare(QUEUE, true, false, false, null); /** * 消息发布方法 * param1：Exchange的名称，如果没有指定，则使用Default Exchange * param2:routingKey,消息的路由Key，是用于Exchange（交换机）将消息转发到指定的消息队列 * param3:消息包含的属性 * param4：消息体 */ /** * 这里没有指定交换机，消息将发送给默认交换机，每个队列也会绑定那个默认的交换机，但是不能显 示绑定或解除绑定 * 默认的交换机，routingKey等于队列名称 * */ channel.basicPublish(\"\", QUEUE, null, MESSAGE.getBytes()); System.out.println(\"Send Message is:\" + MESSAGE); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (channel!=null)&#123; channel.close(); &#125; if (connection!=null)&#123; connection.close(); &#125; &#125; &#125;&#125; 2.2.3 消费者在消费者工程下的test中创建测试类如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Consumer01 &#123; private static final String QUEUE = \"helloworld\"; public static void main(String[] args) &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\"127.0.0.1\"); connectionFactory.setPort(5672);/* connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); connectionFactory.setVirtualHost(\"/\");*/ try &#123; Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE, true, false, false, null); /** * 监听队列String queue, boolean autoAck,Consumer callback * 参数明细 * 1、队列名称 * 2、是否自动回复，设置为true为表示消息接收到自动向mq回复接收到了，mq接收到回复会删除消息，设置为false则需要手动回复 * 3、消费消息的方法，消费者接收到消息后调用此方法 **/ //定义消费方法 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; /** * 消费者接收消息调用此方法 * @param consumerTag 消费者的标签，在channel.basicConsume()去指定 * @param envelope 消息包的内容，可从中获取消息id，消息routingkey，交换机，消息和重传标志 (收到消息失败后是否需要重新发送) * @param properties * @param body * @throws IOException */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; //交换机 String exchange = envelope.getExchange(); //路由key String routingKey = envelope.getRoutingKey(); //消息id long deliveryTag = envelope.getDeliveryTag(); //消息内容 String message = new String(body, \"utf-8\"); System.out.println(\"Receive message:\" + message); &#125; &#125;; channel.basicConsume(QUEUE, true, consumer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.2.4 总结 发送端操作流程(1) 创建连接(2) 创建通道(3) 声明队列(4) 发送消息 接收端(1) 创建连接(2) 创建通道(3) 声明队列(4) 监听队列(5) 接收消息(6) ack回复 3. 工作模式RabbitMQ有以下几种工作模式 ： 1、Work queues2、Publish/Subscribe3、Routing4、Topics5、Header6、RPC 3.1 Work queues (工作队列模式)3.1.1 工作模式 work queues与入门程序相比，多了一个消费端，两个消费端共同消费同一个队列中的消息。应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 3.1.2 测试(1) 使用入门程序，启动多个消费者。(2) 生产者发送多个消息。结果：(1) 一条消息只会被一个消费者接收；(2) rabbit采用轮询的方式将消息是平均发送给消费者的；(3) 消费者在处理完某条消息后，才会收到下一条消息。 3.2 Publish/subscribe (发布/订阅模式)3.2.1 工作模式 发布订阅模式： (1) 每个消费者监听自己的队列。 (2) 生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息 3.2.2代码案例：用户通知，当用户充值成功或转账完成系统通知用户，通知方式有短信、邮件多种方法 。 生产者声明Exchange_fanout_inform交换机声明两个队列并且绑定到此交换机，绑定时不需要指定routingkey发送消息时不需要指定routingkey 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class Producer02_publish &#123; private static final String QUEUE_EMAIL=\"email\"; private static final String QUEUE_SMS=\"sms\"; private static final String EXCHANGE=\"exchange\"; public static void main(String[] args) &#123; ConnectionFactory connectionFactory=new ConnectionFactory(); connectionFactory.setHost(\"127.0.0.1\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); connectionFactory.setVirtualHost(\"/\"); Connection connection=null; Channel channel=null; try &#123; connection = connectionFactory.newConnection(); channel = connection.createChannel(); //声明交换机 String exchange, BuiltinExchangeType type /** * 参数明细 * 1、交换机名称 * 2、交换机类型，fanout、topic、direct、headers */ channel.exchangeDeclare(EXCHANGE, BuiltinExchangeType.FANOUT); channel.queueDeclare(QUEUE_EMAIL,true,false,false,null); channel.queueDeclare(QUEUE_SMS,true,false,false,null); //交换机和队列绑定String queue, String exchange, String routingKey /** * 参数明细 * 1、队列名称 * 2、交换机名称 * 3、路由key */ channel.queueBind(QUEUE_EMAIL,EXCHANGE,\"\"); channel.queueBind(QUEUE_SMS,EXCHANGE,\"\"); //发送消息 for (int i = 0; i &lt; 10; i++) &#123; String message=\"inform to user\"+i; //向交换机发送消息 String exchange, String routingKey, BasicProperties props, byte[] body /** * 参数明细 * 1、交换机名称，不指令使用默认交换机名称 Default Exchange * 2、routingKey（路由key），根据key名称将消息转发到具体的队列，这里填写队列名称表示消 息将发到此队列 * 3、消息属性 * 4、消息内容 */ channel.basicPublish(EXCHANGE,\"\",null,message.getBytes()); System.out.println(\"Send Message is:\"+message); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (channel!=null)&#123; try &#123; channel.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; if (connection!=null)&#123; try &#123; connection.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 消费者 123456789101112131415161718192021222324252627282930313233343536373839public class Consumer02_subscribe_email &#123; private static final String QUEUE_EMAIL = \"email\"; private static final String EXCHANGE = \"exchange\"; public static void main(String[] args) &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setVirtualHost(\"127.0.0.1\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); connectionFactory.setVirtualHost(\"/\"); try &#123; Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE, BuiltinExchangeType.FANOUT); channel.queueDeclare(QUEUE_EMAIL, true, false, false, null); channel.queueBind(QUEUE_EMAIL, EXCHANGE, \"\"); DefaultConsumer defaultConsumer = new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); String exchange = envelope.getExchange(); String message = new String(body, \"utf-8\"); System.out.println(message); &#125; &#125;; /** * 监听队列String queue, boolean autoAck,Consumer callback * 参数明细 * 1、队列名称 * 2、是否自动回复，设置为true为表示消息接收到自动向mq回复接收到了，mq接收到回复会删除消息，设置为false则需要手动回复 * 3、消费消息的方法，消费者接收到消息后调用此方法 */ channel.basicConsume(QUEUE_EMAIL, true, defaultConsumer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 短信发送消费者参考上边的邮件发送消费者代码编写 3.2.3测试使用生产者发送若干条消息，每条消息都转发到各各队列，每消费者都接收到了消息。 3.2.4 思考 publish/subscribe与work queues有什么区别。区别：(1) work queues不用定义交换机，而publish/subscribe需要定义交换机。(2) publish/subscribe的生产方是面向交换机发送消息，work queues的生产方是面向队列发送消息(底层使用默认 交换机)。(3) publish/subscribe需要设置队列和交换机的绑定，work queues不需要设置，实质上work queues会将队列绑 定到默认的交换机 。相同点：所以两者实现的发布/订阅的效果是一样的，多个消费端监听同一个队列不会重复消费消息。 实质工作用什么 publish/subscribe还是work queues。建议使用 publish/subscribe，发布订阅模式比工作队列模式更强大，并且发布订阅模式可以指定自己专用的交换机。 3.3 Routing (路由模式)3.3.1 工作模式 路由模式：(1) 每个消费者监听自己的队列，并且设置routingkey。(2) 生产者将消息发给交换机，由交换机根据routingkey来转发消息到指定的队列。 3.3.2 代码生产者声明exchange_routing_inform交换机。声明两个队列并且绑定到此交换机，绑定时需要指定routingkey发送消息时需要指定routingkey 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Producer03_routing &#123; private static final String QUEUE_EMAIL = \"email\"; private static final String QUEUE_SMS = \"sms\"; private static final String EXCHANGE_ROUTING = \"exchange_routing\"; private static final String ROUTINGKEY_EMAIL = \"email\"; private static final String ROUTINGKEY_SMS = \"sms\"; public static void main(String[] args) &#123; Connection connection = null; Channel channel = null; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(\"127.0.0.1\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); connectionFactory.setVirtualHost(\"/\"); try &#123; connection = connectionFactory.newConnection(); channel=connection.createChannel(); channel.exchangeDeclare(EXCHANGE_ROUTING, BuiltinExchangeType.DIRECT); channel.queueDeclare(QUEUE_EMAIL,true,false,false,null); channel.queueDeclare(QUEUE_SMS,true,false,false,null); //交换机和队列绑定String queue, String exchange, String routingKey /** * 参数明细 * 1、队列名称 * 2、交换机名称 * 3、路由key */ channel.queueBind(QUEUE_EMAIL,EXCHANGE_ROUTING,ROUTINGKEY_EMAIL); channel.queueBind(QUEUE_SMS,EXCHANGE_ROUTING,ROUTINGKEY_SMS); for (int i = 0; i &lt; 10; i++) &#123; //发送消息指定routingKey String message=\"inform to user\"+i; channel.basicPublish(EXCHANGE_ROUTING,ROUTINGKEY_EMAIL,null,message.getBytes()); System.out.println(\"Send Message is:\"+message); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; &#125; &#125;&#125; 邮件发送消费者 123456789101112131415161718192021222324252627282930313233public class Consumer03_routing_email &#123; private static final String QUEUE_EMAIL = \"email\"; private static final String EXCHANGE_ROUTING = \"exchange_routing\"; private static final String ROUTINGKEY_EMAIL = \"email\"; public static void main(String[] args) &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setVirtualHost(\"127.0.0.1\"); connectionFactory.setPort(5672); connectionFactory.setUsername(\"guest\"); connectionFactory.setPassword(\"guest\"); connectionFactory.setVirtualHost(\"/\"); try &#123; Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.exchangeDeclare(EXCHANGE_ROUTING, BuiltinExchangeType.DIRECT); channel.queueDeclare(QUEUE_EMAIL,true,false,false,null); channel.queueBind(QUEUE_EMAIL,EXCHANGE_ROUTING,ROUTINGKEY_EMAIL); DefaultConsumer defaultConsumer=new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); String exchange = envelope.getExchange(); String message = new String(body, \"utf-8\"); System.out.println(message); &#125; &#125;; channel.basicConsume(QUEUE_EMAIL,true,defaultConsumer); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 参考邮件发送消费者的代码流程，编写短信通知的代码。 3.3.3 测试使用生产者发送若干条消息，交换机根据routingkey转发消息到指定的队列 3.4.4思考 Routing模式和Publish/subscibe有啥区别？Routing模式要求队列在绑定交换机时要指定routingkey，消息会转发到符合routingkey的队列。 3.4 Topics (统配符模式)3.4.1 代码工作模式 (1) 一个交换机可以绑定多个队列, 每个队列可以设置一个或多个带统配符的routingkey (2) 生产者将消息发给交换机, 交换机根据routingkey的值来匹配队列, 匹配时采用统配符方式, 匹配成功的将消息转发到指定的队列 Topics与Routing的区别 routingKey的匹配方式不同: Routing模式是相等匹配, topics模式是统配符匹配 12符号#:匹配一个或多个词(每个词中间以.分隔), 比如inform.#可以匹配inform.sms, infrom.email, inform.sms.email符号*:只能匹配一个词, 比如infrom.*可以匹配infrom.sms infrom.email 3.4.2 代码12345678//声明队列channel.queueDeclare(QUEUE_INFORM_EMAIL, true, false, false, null); channel.queueDeclare(QUEUE_INFORM_SMS, true, false, false, null); //声明交换机 channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC); //绑定email通知队列 channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_TOPICS_INFORM,\"inform.#.email.#\"); //绑定sms通知队列channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_TOPICS_INFORM,\"inform.#.sms.#\"); 3.4.3 测试使用生产者发送若干条消息，交换机根据routingkey统配符匹配并转发消息到指定的队列 3.4.4 思考 本案例的需求使用Routing工作模式能否实现？ 使用Routing模式也可以实现本案例，共设置三个 routingkey，分别是email、sms、all，email队列绑定email和 all，sms队列绑定sms和all，这样就可以实现上边案例的功能，实现过程比topics复杂。Topic模式更多加强大，它可以实现Routing、publish/subscirbe模式的功能。 3.5 Header模式header模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。 案例：根据用户的通知设置去通知用户，设置接收Email的用户只接收Email，设置接收sms的用户只接收sms，设置两种 通知类型都接收的则两种通知都有效。 代码: 生产者队列与交换机绑定的代码与之前不同，如下： 1Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;(); headers_email.put(\"inform_type\", \"email\"); Map&lt;String, Object&gt; headers_sms = new Hashtable&lt;String, Object&gt;(); headers_sms.put(\"inform_type\", \"sms\"); channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,\"\",headers_email); channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_HEADERS_INFORM,\"\",headers_sms); 通知 1234String message = \"email inform to user\"+i; Map&lt;String,Object&gt; headers = new Hashtable&lt;String, Object&gt;(); headers.put(\"inform_type\", \"email\");//匹配email通知消费者绑定的header //headers.put(\"inform_type\", \"sms\");//匹配sms通知消费者绑定的header AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties.Builder(); properties.headers(headers); //Email通知 channel.basicPublish(EXCHANGE_HEADERS_INFORM, \"\", properties.build(), message.getBytes(); 发送邮件消费者 12345channel.exchangeDeclare(EXCHANGE_HEADERS_INFORM, BuiltinExchangeType.HEADERS); Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;(); headers_email.put(\"inform_email\", \"email\"); //交换机和队列绑定 channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,\"\",headers_email); //指定消费队列 channel.basicConsume(QUEUE_INFORM_EMAIL, true, consumer); 3.6 RPC RPC即客户端远程调用服务端的方法 ，使用MQ可以实现RPC的异步调用，基于Direct交换机实现，流程如下： 1、客户端即是生产者也是消费者，向RPC请求队列发送RPC调用消息，同时监听RPC响应队列 2、服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果 3、服务端将RPC方法 的结果发送到RPC响应队列 4、客户端（RPC调用方）监听RPC响应队列，接收到RPC调用结果 4.Spring整合RibbitMQ4.1 搭建SpringBoot环境我们选择基于Spring-Rabbit去操作RabbitMQ https://github.com/spring-projects/spring-amqp 使用spring-boot-starter-amqp会自动添加spring-rabbit依赖，如下： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 4.2 配置(1) 配置application.yml 配置连接rabbitmq的参数 1234567891011server: port: 44000spring: application: name: test-rabbitmq-producer rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest virtualHost: / (2) 定义RabbitConﬁg类，配置Exchange、Queue、及绑定交换机。 本例配置Topic交换机 1234567891011121314151617181920212223242526272829303132333435363738394041package com.xuecheng.test.rabbitmq.config;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitmqConfig &#123; public static final String QUEUE_INFORM_EMAIL = \"queue_inform_email\"; public static final String QUEUE_INFORM_SMS = \"queue_inform_sms\"; public static final String EXCHANGE_TOPICS_INFORM = \"exchange_topics_inform\"; private static final String ROUTINGKEY_EMAIL = \"inform.#.email.#\"; private static final String ROUTINGKEY_SMS = \"inform.#.sms.#\"; //声明交换机 @Bean(EXCHANGE_TOPICS_INFORM) public Exchange EXCHANGE_TOPICS_INFORM()&#123; //durable(true) 持久化,mq重启之后交换机还在 return ExchangeBuilder.topicExchange(EXCHANGE_TOPICS_INFORM).durable(true).build(); &#125; //声明队列 @Bean(QUEUE_INFORM_EMAIL) public Queue QUEUE_INFORM_EMAIL()&#123; return new Queue(QUEUE_INFORM_EMAIL); &#125; @Bean(QUEUE_INFORM_SMS) public Queue QUEUE_INFORM_SMS()&#123; return new Queue(QUEUE_INFORM_SMS); &#125; //交换机和队列绑定 @Bean public Binding binding_email(@Qualifier(QUEUE_INFORM_EMAIL)Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM)Exchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_EMAIL).noargs(); &#125; @Bean public Binding binding_sms(@Qualifier(QUEUE_INFORM_SMS)Queue queue, @Qualifier(EXCHANGE_TOPICS_INFORM)Exchange exchange)&#123; return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_SMS).noargs(); &#125;&#125; 4.3 生产端 使用RarbbitTemplate发送消息 12345678910111213141516@SpringBootTest@RunWith(SpringRunner.class)public class Producer05_topics_springboot &#123; @Autowired RabbitTemplate rabbitTemplate; @Test public void testSendByTopics()&#123; for (int i = 0; i &lt; 10; i++) &#123; //发送消息指定routingKey String message=\"inform to user\"+i; rabbitTemplate.convertAndSend(RabbitmqConfig.EXCHANGE_TOPICS_INFORM,\"inform.sms\",message); System.out.println(\"Send Message is:\"+message); &#125; &#125;&#125; 4.4 消费端创建消费端工程，添加依赖, 配置application.yml, 定义RabbitConﬁg类 使用@RabbitListener注解监听队列 1234567891011121314@Componentpublic class ReceiveHandler &#123; //监听email队列 @RabbitListener(queues = &#123;RabbitmqConfig.QUEUE_INFORM_EMAIL&#125;) public void receive_email(String msg, Message message, Channel channel) &#123; System.out.println(msg); &#125; //监听sms队列 @RabbitListener(queues = &#123;RabbitmqConfig.QUEUE_INFORM_SMS&#125;) public void receive_sms(String msg, Message message, Channel channel) &#123; System.out.println(msg); &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(二.CMS前端开发)","slug":"学成在线(二.CMS前端开发)","date":"2021-05-08T13:19:59.200Z","updated":"2020-04-29T02:44:38.012Z","comments":true,"path":"32706/","link":"","permalink":"http://tonymua.top/32706/","excerpt":"1.CMS前端页面查询开发1.1 Api调用1.1.1 Api方法定义在cms模块的api目录定义cms.js， 在cms.js中定义如下js方法，此方法实现http请求服务端页面查询接口 1234567import http from '@/base/api/public'/*页面列表*/export const page_list = (page,size,params) =&gt; &#123; //params为json格式 //使用querystring将json对象转成key/value串 return http.requestQuickGet('/cms/page/list/'+page+'/'+size+'/?'+querys)&#125;","text":"1.CMS前端页面查询开发1.1 Api调用1.1.1 Api方法定义在cms模块的api目录定义cms.js， 在cms.js中定义如下js方法，此方法实现http请求服务端页面查询接口 1234567import http from '@/base/api/public'/*页面列表*/export const page_list = (page,size,params) =&gt; &#123; //params为json格式 //使用querystring将json对象转成key/value串 return http.requestQuickGet('/cms/page/list/'+page+'/'+size+'/?'+querys)&#125; axios实现了http方法的封装，vue.js官方不再继续维护vue-resource,推荐使用 axios 1.1.2 Api调用前端页面(page_list.vue)导入cms.js，调用js方法请求服务端页面查询接口 (1) 导入cms.js 1import * as cmsApi from '../api/cms' (2) 在query方法中调用 page_list方法 1234567query()&#123; cmsApi.page_list(this.params.page,this.params.size,this.params).then((res)=&gt;&#123; console.log(res) this.total = res.queryResult.total this.list = res.queryResult.list &#125;)&#125; 1.2 跨域问题解决测试上边的代理 ，结果 报错如下 ：No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource. Origin &#39;http://localhost:11000&#39; is therefore not allowed access.原因：浏览器的同源策略不允许跨域访问，所谓同源策略是指协议、域名、端口相同。解决：采用proxyTable解决 proxyTable是什么？vue-cli提供的解决vue开发环境下跨域问题的方法，proxyTable的底层使用了http-proxymiddleware（https://github.com/chimurai/http-proxy-middleware），它是http代理中间件，它依赖node.js， 基本原理是用服务端代理解决浏览器跨域： cms跨域解决原理： (1) 访问页面http://localhost:11000/(2) 页面请求http://localhost:11000/cms 由于url由http://localhost:31001/cms...改为“http://localhost:11000/cms.&quot;，所以不存在跨域(3) 通过proxyTable由node服务器代理请求 http://localhost:31001/cms.服务端不存在跨域问题 具体的配置如下：(1) 修改api方法中url的定义 请求前加/api前缀 12345678910import http from '@/base/api/public'let sysConfig = require('@/../config/sysConfig')let apiUrl = sysConfig.xcApiUrlPre;/*页面列表*/export const page_list = (page,size,params) =&gt; &#123; //params为json格式 //使用querystring将json对象转成key/value串 let querys = querystring.stringify(params) return http.requestQuickGet(apiUrl+'/cms/page/list/'+page+'/'+size+'/?'+querys)&#125; (2) 在conﬁg/index.js下配置proxyTable 以/api/cms开头的请求，代理请求http://localhost:31001 1234567'/api/cms': &#123; target: 'http://localhost:31001', pathRewrite: &#123; '^/api': '' &#125; //target: 'http://127.0.0.1:50201'&#125; 1.3 分页查询(1) 定义分页视图使用v-on监听更改分页事件 12345678&lt;!--分页--&gt;&lt;el-col :span=\"24\" class=\"toolbar\"&gt; &lt;el-pagination background layout=\"prev, pager, next\" @current-change=\"changePage\" :page-size=\"this.params.size\" :total=\"total\" :current-page=\"this.params.page\" style=\"float:right;\"&gt; &lt;/el-pagination&gt;&lt;/el-col&gt; (2) 定义数据模型对象 12345678910111213data()&#123; return &#123; params:&#123; page:1,//页码 size:5,//每页显示个数 siteId:''//站点id &#125;, listLoading:false, list:[], total:0, siteList:[]//站点列表 &#125;&#125; (3) 定义分页方法，接收页码参数 1234changePage(page)&#123; this.params.page = page; this.query()&#125; 1.4 进入页面立即查询目前实现的功能是进入页面点击查询按钮向服务端表求查询，实际的需求是进入页面立即查询。如何实现？这要用到vue的钩子函数，每个 Vue 实例在被创建时都要经过一系列的初始化过程——例如，需要设置数据监听、 编译模板、将实例挂载到 DOM 并在数据变化时更新 DOM 等。同时在这个过程中也会运行一些叫做生命周期钩子 的函数，这给了用户在不同阶段添加自己的代码的机会。 通常使用最多的是created和mounted两个钩子：created：vue实例已创建但是DOM元素还没有渲染生成。mounted：DOM元素渲染生成完成后调用。 本例子在两个方法的任意一个都满足需求：添加如下代码： 1234mounted() &#123; //默认查询页面 this.query()&#125; 2.前后端请求响应流程小结 (1) 在浏览器输入前端url (2) 前端框架vue.js根据url解析路由，根据路由找到page_list.vue页面 (3) 首先执行page_list.vue中的钩子方法 (4) 在钩子方法中调用query方法。 (5) 在query方法中调用cms.js中的page_list方法 (6) cms.js中的page_list方法通过axios请求服务端接口 (7) 采用proxyTable解决跨域问题，node.js将请求转发到服务端(http://localhost:31001/cms/page/list) (8) 服务端处理，将查询结果响应给前端 (9) 成功响应调用then方法，在then方法中处理响应结果，将查询结果赋值给数据模型中的total和list变量。 (10) vue.js通过双向数据绑定将list数据渲染输出。","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(九.Eureka, Feign)","slug":"学成在线(九.Eureka, Feign)","date":"2021-05-08T13:19:59.198Z","updated":"2020-04-29T05:55:53.037Z","comments":true,"path":"56946/","link":"","permalink":"http://tonymua.top/56946/","excerpt":"1.Eureka注册中心1.1 需求分析在前后端分离架构中，服务层被拆分成了很多的微服务，微服务的信息如何管理？Spring Cloud中提供服务注册中 心来管理微服务信息。 为什么要用注册中心？(1) 微服务数量众多，要进行远程调用就需要知道服务端的ip地址和端口，注册中心帮助我们管理这些服务的ip和端口。(2) 微服务会实时上报自己的状态，注册中心统一管理这些微服务的状态，将存在问题的服务踢出服务列表，客户端获取到可用的服务进行调用。","text":"1.Eureka注册中心1.1 需求分析在前后端分离架构中，服务层被拆分成了很多的微服务，微服务的信息如何管理？Spring Cloud中提供服务注册中 心来管理微服务信息。 为什么要用注册中心？(1) 微服务数量众多，要进行远程调用就需要知道服务端的ip地址和端口，注册中心帮助我们管理这些服务的ip和端口。(2) 微服务会实时上报自己的状态，注册中心统一管理这些微服务的状态，将存在问题的服务踢出服务列表，客户端获取到可用的服务进行调用。 1.3 Eureka注册中心1.3.1 Eureka介绍 Spring Cloud Eureka 是对Netﬂix公司的Eureka的二次封装，它实现了服务治理的功能，Spring Cloud Eureka提 供服务端与客户端，服务端即是Eureka服务注册中心，客户端完成微服务向Eureka服务的注册与发现。服务端和 客户端均采用Java语言编写。下图显示了Eureka Server与Eureka Client的关系：(1) Eureka Server是服务端，负责管理各各微服务结点的信息和状态。(2) 在微服务上部署Eureka Client程序，远程访问Eureka Server将自己注册在Eureka Server。(3) 微服务需要调用另一个微服务时从Eureka Server中获取服务调用地址，进行远程调用。 1.3.2 Eureka Server搭建1.3.2.1 单机环境搭建(1) 创建xc-govern-center工程：包结构：com.xuecheng.govern.center(2) 添加依赖在父工程添加:（有了则不用重复添加） 1234567&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Finchley.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 在Eureka Server工程添加： 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 导入Eureka服务的依赖 --&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; (3) 启动类 1234567@EnableEurekaServer //标识这是一个Eureka服务 @SpringBootApplicationpublic class GovernCenterApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GovernCenterApplication.class); &#125;&#125; (4) @EnableEurekaServer需要在启动类上用@EnableEurekaServer标识此服务为Eureka服务(5) 从其它服务拷贝application.yml和logback-spring.xml。application.yml的配置内容如下： 1234567891011121314server: port: 50101spring: application: name: xc-govern-centereureka: client: register-with-eureka: false #服务注册，是否将自己注册到Eureka服务中 fetch-registry: false service-url: #Eureka客户端与Eureka服务端的交互地址，高可用状态配置对方的地址，单机状态配置自己（如果 不配置则默认本机8761端口） defaultZone: http://localhost:50101/eureka/ server: enable-self-preservation: false #是否开启自我保护模式 eviction-interval-timer-in-ms: 60000 #服务注册表清理间隔（单位毫秒，默认是60*1000） registerWithEureka：被其它服务调用时需向Eureka注册fetchRegistry：需要从Eureka中查找要调用的目标服务时需要设置为trueserviceUrl.defaultZone 配置上报Eureka服务地址高可用状态配置对方的地址，单机状态配置自己 enable-self-preservation：自保护设置，下边有介绍。eviction-interval-timer-in-ms：清理失效结点的间隔，在这个时间段内如果没有收到该结点的上报则将结点从服务列表中剔除。 (6) 启动Eureka Server启动Eureka Server，浏览50101端口。 说明：上图红色提示信息： THE SELF PRESERVATION MODE IS TURNED OFF.THIS MAY NOT PROTECT INSTANCE EXPIRY IN CASE OF NETWORK/OTHER PROBLEMS. 自我保护模式被关闭。在网络或其他问题的情况下可能不会保护实例失效。 Eureka Server有一种自我保护模式，当微服务不再向Eureka Server上报状态，Eureka Server会从服务列表将此 服务删除，如果出现网络异常情况（微服务正常），此时Eureka server进入自保护模式，不再将微服务从服务列 表删除。在开发阶段建议关闭自保护模式。 1.3.2.2 高可用环境搭建Eureka Server 高可用环境需要部署两个Eureka server，它们互相向对方注册。如果在本机启动两个Eureka需要 注意两个Eureka Server的端口要设置不一样，这里我们部署一个Eureka Server工程，将端口可配置，制作两个 Eureka Server启动脚本，启动不同的端口，如下图： (1) 在实际使用时Eureka Server至少部署两台服务器，实现高可用。(2) 两台Eureka Server互相注册。(3) 微服务需要连接两台Eureka Server注册，当其中一台Eureka死掉也不会影响服务的注册与发现。(4) 微服务会定时向Eureka server发送心跳，报告自己的状态。(5)微服务从注册中心获取服务地址以RESTful方式发起远程调用。 配置如下：(1) 端口可配置 12server: port: $&#123;Port:50101&#125; #服务端口 (2) Eureka服务端的交互地址可配置 123456eureka: client: register-with-eureka: true #服务注册，是否将自己注册到Eureka服务中 fetch-registry: true service-url: #Eureka客户端与Eureka服务端的交互地址，高可用状态配置对方的地址，单机状态配置自己（如果 不配置则默认本机8761端口） defaultZone: $&#123;EUREKA_SERVER:http://eureka02:50102/eureka/&#125; (3) 配置hostnameEureka 组成高可用，两个Eureka互相向对方注册，这里需要通过域名或主机名访问，这里我们设置两个Eureka服 务的主机名分别为 eureka01、eureka02。 完整的eureka配置如下： 12345678910111213141516server: port: $&#123;Port:50101&#125; #服务端口spring: application: name: xc-govern-centereureka: client: register-with-eureka: true #服务注册，是否将自己注册到Eureka服务中 fetch-registry: true service-url: #Eureka客户端与Eureka服务端的交互地址，高可用状态配置对方的地址，单机状态配置自己（如果 不配置则默认本机8761端口） defaultZone: $&#123;EUREKA_SERVER:http://eureka02:50102/eureka/&#125; server: enable-self-preservation: false #是否开启自我保护模式 eviction-interval-timer-in-ms: 60000 #服务注册表清理间隔（单位毫秒，默认是60*1000） instance: hostname: $&#123;EUREKA_DOMAIN:eureka01&#125; (4) 在IDEA中制作启动脚本启动1: 启动2: 运行两个启动脚本，分别浏览：http://localhost:50101/http://localhost:50102/ 1.3.3 服务注册1.3.3.1 将cms注册到Eureka Server下边实现cms向Eureka Server注册 (1) 在cms服务中添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; (2) 在application.yml配置 12345678910eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: $&#123;EUREKA_SERVER:http://eureka01:50101/eureka/&#125; instance: prefer-ip-address: true #将自己的ip地址注册到Eureka服务中 ip-address: $&#123;IP_ADDRESS:127.0.0.1&#125; instance-id: $&#123;spring.application.name&#125;:$&#123;server.port&#125; #指定实例id (3) 在启动类上添加注解在启动类上添加注解 @EnableDiscoveryClient ，表示它是一个Eureka的客户端 (4) 刷新Eureka Server查看注册情况 将其它服务注册到Eureka Server方法同上 2.Feign远程调用在前后端分离架构中，服务层被拆分成了很多的微服务，服务与服务之间难免发生交互，比如：课程发布需要调用 CMS服务生成课程静态化页面，本节研究微服务远程调用所使用的技术。 下图是课程管理服务远程调用CMS服务的流程图： 工作流程如下： (1) cms服务将自己注册到注册中心。 (2) 课程管理服务从注册中心获取cms服务的地址。 (3) 课程管理服务远程调用cms服务。 2.1 Ribbon2.1.1 Ribbon介绍Ribbon是Netﬂix公司开源的一个负载均衡的项目（https://github.com/Netﬂix/ribbon），它是一个**基于HTTP、 TCP的客户端负载均衡器**。 1.什么是负载均衡？负载均衡是微服务架构中必须使用的技术，通过负载均衡来实现系统的高可用、集群扩容等功能。负载均衡可通过 硬件设备及软件来实现，硬件比如：F5、Array等，软件比如：LVS、Nginx等。如下图是负载均衡的架构图： 用户请求先到达负载均衡器（也相当于一个服务），负载均衡器根据负载均衡算法将请求转发到微服务。负载均衡 算法有：轮训、随机、加权轮训、加权随机、地址哈希等方法，负载均衡器维护一份服务列表，根据负载均衡算法 将请求转发到相应的微服务上，所以负载均衡可以为微服务集群分担请求，降低系统的压力。 2.什么是客户端负载均衡？上图是服务端负载均衡，客户端负载均衡与服务端负载均衡的区别在于客户端要维护一份服务列表，Ribbon从 Eureka Server获取服务列表，Ribbon根据负载均衡算法直接请求到具体的微服务，中间省去了负载均衡服务。 如下图是Ribbon负载均衡的流程图： (1) 在消费微服务中使用Ribbon实现负载均衡，Ribbon先从EurekaServer中获取服务列表。(2) Ribbon根据负载均衡的算法去调用微服务。 2.1.2 Ribbon测试Spring Cloud引入Ribbon配合 restTemplate 实现客户端负载均衡。Java中远程调用的技术有很多，如： webservice、socket、rmi、Apache HttpClient、OkHttp等，互联网项目使用基于http的客户端较多，本项目使 用OkHttp。 1.在客户端添加Ribbon依赖： 这里在课程管理服务配置ribbon依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 由于依赖了spring-cloud-starter-eureka，会自动添加spring-cloud-starter-ribbon依赖 2.配置Ribbon参数这里在课程管理服务的application.yml中配置ribbon参数 123456ribbon: MaxAutoRetries: 2 #最大重试次数，当Eureka中可以找到服务，但是服务连不上时将会重试 MaxAutoRetriesNextServer: 3 #切换实例的重试次数 OkToRetryOnAllOperations: false #对所有操作请求都进行重试，如果是get则可以，如果是post，put等操作 ConnectTimeout: 5000 #请求连接的超时时间 ReadTimeout: 6000 #请求处理的超时时间 3.负载均衡测试 (1) 启动两个cms服务，注意端口要不一致启动完成观察Eureka Server的服务列表(2) 定义RestTemplate，使用@LoadBalanced注解 在课程管理服务的启动类中定义RestTemplate 12345@Bean@LoadBalanced //开启客户端负载均衡public RestTemplate restTemplate()&#123; return new RestTemplate(new OkHttp3ClientHttpRequestFactory());&#125; (3) 测试代码在课程管理服务工程创建单元测试代码，远程调用cms的查询页面接口： 12345678910111213141516171819@SpringBootTest@RunWith(SpringRunner.class)public class TestRibbon &#123; @Autowired RestTemplate restTemplate; //负载均衡调用 @Test public void testRibbon()&#123; //服务id String serviceId=\"XC-SERVICE-MANAGE-CMS\"; for (int i = 0; i &lt; 10; i++) &#123; //通过服务id调用 ResponseEntity&lt;CmsPage&gt; forEntity = restTemplate.getForEntity(\"http://\" + serviceId + \"/cms/page/get/5a754adf6abb500ad05688d9\", CmsPage.class); CmsPage cmsPage = forEntity.getBody(); System.out.println(cmsPage); &#125; &#125;&#125; (4) 负载均衡测试添加@LoadBalanced注解后，restTemplate会走LoadBalancerInterceptor拦截器，此拦截器中会通过 RibbonLoadBalancerClient查询服务地址，可以在此类打断点观察每次调用的服务地址和端口，两个cms服务会轮流被调用。 2.2 Feign2.2.1 Feign介绍Feign是Netﬂix公司开源的轻量级rest客户端，使用Feign可以非常方便的实现Http 客户端。Spring Cloud引入 Feign并且集成了Ribbon实现客户端负载均衡调用。 2.2.2 Feign测试1.在客户端添加依赖在课程管理服务添加下边的依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 2.定义FeignClient接口参考Swagger文档定义FeignClient，注意接口的Url、请求参数类型、返回值类型与Swagger接口一致。在课程管理服务中创建client包，定义查询cms页面的客户端该用接口 123456@FeignClient(value = \"XC-SERVICE-MANAGE-CMS\")public interface CmsPageClient &#123; //根据页面id查询页面信息,远程用Cms请求数据 @GetMapping(\"/cms/page/get/&#123;id&#125;\") //用GetMapping标识远程调用的http的方法类型 public CmsPage findCmsPageById(@PathVariable(\"id\") String id);&#125; 3.启动类添加@EnableFeignClients注解 4.测试 1234567891011121314@SpringBootTest@RunWith(SpringRunner.class)public class TestFeign &#123; @Autowired CmsPageClient cmsPageClient; //接口代理对象,由feign生成代理对象 //负载均衡调用 @Test public void testFeign()&#123; //发起远程调用 CmsPage cmsPage = cmsPageClient.findCmsPageById(\"5a754adf6abb500ad05688d9\"); System.out.println(cmsPage); &#125;&#125; Feign工作原理如下： (1) 启动类添加@EnableFeignClients注解，Spring会扫描标记了@FeignClient注解的接口，并生成此接口的代理 对象(2) @FeignClient(value = XcServiceList.XC_SERVICE_MANAGE_CMS)即指定了cms的服务名称，Feign会从注册中 心获取cms服务列表，并通过负载均衡算法进行服务调用。(3) 在接口方法 中使用注解@GetMapping(“/cms/page/get/{id}”)，指定调用的url，Feign将根据url进行远程调用。 2.2.3 Feign注意点SpringCloud对Feign进行了增强兼容了SpringMVC的注解 ，我们在使用SpringMVC的注解时需要注意： feignClient接口 有参数在参数必须加@PathVariable(“XXX”)和@RequestParam(“XXX”) feignClient返回值为复杂对象时其类型必须有无参构造函数。","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(三.CMS页面管理开发, 异常处理)","slug":"学成在线(三.CMS页面管理开发, 异常处理)","date":"2021-05-08T13:19:59.197Z","updated":"2020-04-29T05:55:36.223Z","comments":true,"path":"13890/","link":"","permalink":"http://tonymua.top/13890/","excerpt":"1.自定义条件查询1.1 需求分析在页面输入查询条件，查询符合条件的页面信息。查询条件如下：站点Id：精确匹配模板Id：精确匹配页面别名：模糊匹配……","text":"1.自定义条件查询1.1 需求分析在页面输入查询条件，查询符合条件的页面信息。查询条件如下：站点Id：精确匹配模板Id：精确匹配页面别名：模糊匹配…… 1.2 服务端1.2.1 Dao使用 CmsPageRepository中的findAll(Example&lt;S&gt; var1, Pageable var2)方法实现，无需定义。 下边测试ﬁndAll方法实现自定义条件查询 123456789101112131415161718192021//自定义条件查询@Testpublic void testFindAllByExample() &#123; //分页参数 int page = 0; //页码从0开始 int size = 10; Pageable pageable = PageRequest.of(page, size); //条件值对象 CmsPage cmsPage = new CmsPage(); cmsPage.setSiteId(\"5a751fab6abb5044e0d19ea1\"); cmsPage.setTemplateId(\"5a962c16b00ffc514038fafd\"); cmsPage.setPageAliase(\"轮播\"); //条件匹配器 根据别名模糊查询 ExampleMatcher exampleMatcher = ExampleMatcher.matching() .withMatcher(\"pageAliase\", ExampleMatcher.GenericPropertyMatchers.contains()); //定义Example Example&lt;CmsPage&gt; example = Example.of(cmsPage, exampleMatcher); Page&lt;CmsPage&gt; all = cmsPageRepository.findAll(example, pageable); List&lt;CmsPage&gt; content = all.getContent(); System.out.println(content);&#125; 1.2.2 Service在PageService的ﬁndlist方法中增加自定义条件查询代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Servicepublic class PageService &#123; @Autowired CmsPageRepository cmsPageRepository; /** * 页面列表分页查询 * @param page 当前页码 * @param size 页面显示个数 * @param queryPageRequest 查询条件 * @return 页面列表 */ //页面查询方法 public QueryResponseResult findList(int page, int size, QueryPageRequest queryPageRequest)&#123; if (queryPageRequest==null)&#123; queryPageRequest=new QueryPageRequest(); &#125; //自定义条件查询 //条件匹配器 ExampleMatcher exampleMatcher = ExampleMatcher.matching() .withMatcher(\"pageAliase\", ExampleMatcher.GenericPropertyMatchers.contains()); //条件值对象 CmsPage cmsPage=new CmsPage(); //设置条件值 if (StringUtils.isNotEmpty(queryPageRequest.getSiteId()))&#123; cmsPage.setSiteId(queryPageRequest.getSiteId()); &#125; if (StringUtils.isNotEmpty(queryPageRequest.getTemplateId()))&#123; cmsPage.setTemplateId(queryPageRequest.getTemplateId()); &#125; if (StringUtils.isNotEmpty(queryPageRequest.getPageAliase()))&#123; cmsPage.setPageAliase(queryPageRequest.getPageAliase()); &#125; //定义条件对象 Example&lt;CmsPage&gt; example = Example.of(cmsPage, exampleMatcher); if (page&lt;=0)&#123; page=1; &#125; page=page-1; //为了适应mongodb的接口将页码减1 if (size&lt;=0)&#123; size=10; &#125; Pageable pageable= PageRequest.of(page,size); Page&lt;CmsPage&gt; all = cmsPageRepository.findAll(example,pageable); QueryResult&lt;CmsPage&gt; queryResult=new QueryResult&lt;&gt;(); queryResult.setList(all.getContent()); //数据列表 queryResult.setTotal(all.getTotalElements()); //数据总记录数 QueryResponseResult queryResponseResult=new QueryResponseResult(CommonCode.SUCCESS,queryResult); return queryResponseResult; &#125;&#125; 1.2.3 Controller无需修改 1.2.4 测试使用SwaggerUI测试 http://localhost:31001/swagger-ui.html 2.新增页面2.1 新增页面接口定义(1) 定义响应模型 12345678@Datapublic class CmsPageResult extends ResponseResult &#123; CmsPage cmsPage; public CmsPageResult(ResultCode resultCode,CmsPage cmsPage) &#123; super(resultCode); this.cmsPage = cmsPage; &#125;&#125; (2)定义添加Api 在api工程(CmsPageControllerApi)中添加接口： 123//新增页面@ApiOperation(\"添加页面\")public CmsPageResult add(CmsPage cmsPage); 2.2 新增页面服务端开发2.2.1 页面唯一索引在cms_page集中上创建页面名称、站点Id、页面webpath为唯一索引 2.2.2 Dao(1) 添加根据页面名称、站点Id、页面webpath查询页面方法，此方法用于校验页面是否存在(CmsPageRepository) 1234public interface CmsPageRepository extends MongoRepository&lt;CmsPage, String&gt; &#123; //根据页面名称,站点Id,页面webpath查询 CmsPage findByPageNameAndSiteIdAndPageWebPath(String pageName,String siteId,String webPath);&#125; (2) 使用 CmsPageRepository提供的save方法 2.2.3 Service1234567891011121314//新增页面public CmsPageResult add(CmsPage cmsPage)&#123; //校验页面名称,站点Id,页面webpath的唯一性 //根据页面名称,站点Id,页面webpath查询,如果查询到说明此页面已经存在,如果查不到再添加 CmsPage page = cmsPageRepository.findByPageNameAndSiteIdAndPageWebPath(cmsPage.getPageName(), cmsPage.getSiteId(), cmsPage.getPageWebPath()); if (page==null)&#123; //调用dao新增页面 cmsPage.setPageId(null); cmsPageRepository.save(cmsPage); return new CmsPageResult(CommonCode.SUCCESS,cmsPage); &#125; //添加失败 return new CmsPageResult(CommonCode.FAIL,null);&#125; 2.2.4 Controller处理JSON:@RequestBody 12345@Override@PostMapping(\"/add\")public CmsPageResult add(@RequestBody CmsPage cmsPage) &#123; return pageService.add(cmsPage);&#125; 3.修改页面修改页面用户操作流程：(1) 用户进入修改页面，在页面上显示了修改页面的信息(2) 用户修改页面的内容，点击“提交”，提示“修改成功”或“修改失败” 3.1 修改页面接口定义修改页面需要定义的API如下： 12345@ApiOperation(\"通过id查询页面\")public CmsPage findById(String id);@ApiOperation(\"修改页面\")public CmsPageResult edit(String id,CmsPage cmsPage); 说明：提交数据使用post、put都可以，只是根据http方法的规范，put方法是对服务器指定资源进行修改，所以这里使用put方法对页面修改进行修改。 3.2 修改页面服务端开发3.2.1 Dao使用 Spring Data提供的ﬁndById方法完成根据主键查询使用 Spring Data提供的save方法完成数据保存 3.2.2 Service12345678910111213141516171819202122//修改页面信息public CmsPageResult edit(String id,CmsPage cmsPage)&#123; //根据id查询页面信息 CmsPage one = this.findById(id); if (one!=null)&#123; one.setTemplateId(cmsPage.getTemplateId()); one.setSiteId(cmsPage.getSiteId()); one.setPageAliase(cmsPage.getPageAliase()); one.setPageName(cmsPage.getPageName()); one.setPageWebPath(cmsPage.getPageWebPath()); one.setPagePhysicalPath(cmsPage.getPagePhysicalPath()); //执行更新 CmsPage save = cmsPageRepository.save(cmsPage); if (save!=null)&#123; //返回成功 CmsPageResult cmsPageResult=new CmsPageResult(CommonCode.SUCCESS,save); return cmsPageResult; &#125; &#125; //返回失败 return new CmsPageResult(CommonCode.FAIL,null);&#125; 3.2.3 Controller(1) 根据id查询页面 12345@Override@GetMapping(\"/get/&#123;id&#125;\")public CmsPage findById(@PathVariable(\"id\") String id) &#123; return pageService.findById(id);&#125; (2) 保存页面信息 12345@Override@PutMapping(\"/edit/&#123;id&#125;\") //这里使用put方法，http 方法中put表示更新public CmsPageResult edit(@PathVariable(\"id\") String id, @RequestBody CmsPage cmsPage) &#123; return pageService.edit(id,cmsPage);&#125; 4.删除页面用户操作流程：(1) 用户进入用户列表，点击“删除” (2) 执行删除操作，提示“删除成功”或“删除失败” 4.1 删除页面接口定义12@ApiOperation(\"通过id删除页面\")public ResponseResult delete(String id); 4.2 删除页面服务端开发4.2.1 Dao使用 Spring Data提供的deleteById方法完成删除操作 。 4.2.2 Service12345678910//删除页面public ResponseResult delet(String id) &#123; CmsPage one = this.findById(id); if (one!=null)&#123; //删除页面 cmsPageRepository.deleteById(id); return new ResponseResult(CommonCode.SUCCESS); &#125; return new ResponseResult(CommonCode.FAIL);&#125; 4.2.3 Controller12345@Override@DeleteMapping(\"/del/&#123;id&#125;\")public ResponseResult delete(@PathVariable(\"id\") String id) &#123; return pageService.delet(id);&#125; 5.异常处理5.1 异常处理的问题分析从添加页面的service方法中找问题： 1234567891011121314//新增页面public CmsPageResult add(CmsPage cmsPage)&#123; //校验页面名称,站点Id,页面webpath的唯一性 //根据页面名称,站点Id,页面webpath查询,如果查询到说明此页面已经存在,如果查不到再添加 CmsPage page = cmsPageRepository.findByPageNameAndSiteIdAndPageWebPath(cmsPage.getPageName(), cmsPage.getSiteId(), cmsPage.getPageWebPath()); if (page==null)&#123; //调用dao新增页面 cmsPage.setPageId(null); cmsPageRepository.save(cmsPage); return new CmsPageResult(CommonCode.SUCCESS,cmsPage); &#125; //添加失败 return new CmsPageResult(CommonCode.FAIL,null);&#125; 问题：(1) 上边的代码只要操作不成功仅向用户返回“错误代码：11111，失败信息：操作失败”，无法区别具体的错误信 息。(2) service方法在执行过程出现异常在哪捕获？在service中需要都加try/catch，如果在controller也需要添加 try/catch，代码冗余严重且不易维护。解决方案：(1) 在Service方法中的编码顺序是先校验判断，有问题则抛出具体的异常信息，最后执行具体的业务操作，返回成 功信息。 代码模板如下： 123456789101112131415161718//新增页面public CmsPageResult add(CmsPage cmsPage)&#123; //校验cmsPage是否为空 if (cmsPage==null)&#123; //抛出异常,非法参数异常 &#125; //校验页面名称,站点Id,页面webpath的唯一性 //根据页面名称,站点Id,页面webpath查询,如果查询到说明此页面已经存在,如果查不到再添加 CmsPage page = cmsPageRepository.findByPageNameAndSiteIdAndPageWebPath(cmsPage.getPageName(), cmsPage.getSiteId(), cmsPage.getPageWebPath()); if (page!=null)&#123; //页面已存在 //抛出异常,页面已存在异常 &#125; //调用dao新增页面 cmsPage.setPageId(null); cmsPageRepository.save(cmsPage); return new CmsPageResult(CommonCode.SUCCESS,cmsPage);&#125; (2) 在统一异常处理类中去捕获异常，无需controller捕获异常，向用户返回统一规范的响应信息。 5.2 异常处理流程系统对异常的处理使用统一的异常处理流程： (1) 自定义异常类型。(2) 自定义错误代码及错误信息。(3) 对于可预知的异常由程序员在代码中主动抛出，由SpringMVC统一捕获。 可预知异常是程序员在代码中手动抛出本系统定义的特定异常类型，由于是程序员抛出的异常，通常异常信息比较 齐全，程序员在抛出时会指定错误代码及错误信息，获取异常信息也比较方便。(4) 对于不可预知的异常（运行时异常）由SpringMVC统一捕获Exception类型的异常。 不可预知异常通常是由于系统出现bug、或一些不要抗拒的错误（比如网络中断、服务器宕机等），异常类型为 RuntimeException类型（运行时异常）。(5) 可预知的异常及不可预知的运行时异常最终会采用统一的信息格式（错误代码+错误信息）来表示，最终也会随 请求响应给客户端。 异常抛出及处理流程： (1) 在controller、service、dao中程序员抛出自定义异常；springMVC框架抛出框架异常类型(2) 统一由异常捕获类捕获异常，并进行处理(3) 捕获到自定义异常则直接取出错误代码及错误信息，响应给用户 5.3 可预知异常处理5.3.1 自定义异常类在common工程定义异常类型 12345678910111213public class CustomException extends RuntimeException &#123; private ResultCode resultCode; public CustomException(ResultCode resultCode) &#123; //异常信息为错误代码+异常信息 super(\"错误代码：\" + resultCode.code() + \"错误信息：\" + resultCode.message()); this.resultCode = resultCode; &#125; public ResultCode getResultCode() &#123; return resultCode; &#125;&#125; 5.3.2 异常抛出类123456public class ExceptionCast &#123; //使用此静态方法抛出自定义异常 public static void cast(ResultCode resultCode)&#123; throw new CustomException(resultCode); &#125;&#125; 5.3.3 异常捕获类使用 @ControllerAdvice和@ExceptionHandler注解来捕获指定类型的异常 1234567891011121314@ControllerAdvice //控制器增强public class ExceptionCatch &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ExceptionCatch.class); //捕获 CustomException异常 @ExceptionHandler(CustomException.class) @ResponseBody public ResponseResult customException(CustomException customException) &#123; //记录日志 LOGGER.error(\"catch exception:&#123;&#125;\",customException); ResultCode resultCode = customException.getResultCode(); return new ResponseResult(resultCode); &#125;&#125; 5.3.4异常处理测试5.3.4.1 定义错误代码每个业务操作的异常使用异常代码去标识 12345678910111213141516171819202122232425262728293031323334353637@ToStringpublic enum CmsCode implements ResultCode &#123; CMS_ADDPAGE_EXISTSNAME(false, 24001, \"页面名称已存在！\"), CMS_GENERATEHTML_DATAURLISNULL(false, 24002, \"从页面信息中找不到获取数据的url！\"), CMS_GENERATEHTML_DATAISNULL(false, 24003, \"根据页面的数据url获取不到数据！\"), CMS_GENERATEHTML_TEMPLATEISNULL(false, 24004, \"页面模板为空！\"), CMS_GENERATEHTML_HTMLISNULL(false, 24005, \"生成的静态html为空！\"), CMS_GENERATEHTML_SAVEHTMLERROR(false, 24005, \"保存静态html出错！\"), CMS_COURSE_PERVIEWISNULL(false, 24007, \"预览页面为空！\"); //操作代码 boolean success; //操作代码 int code; //提示信息 String message; private CmsCode(boolean success, int code, String message) &#123; this.success = success; this.code = code; this.message = message; &#125; @Override public boolean success() &#123; return success; &#125; @Override public int code() &#123; return code; &#125; @Override public String message() &#123; return message; &#125;&#125; 5.3.4.2 异常处理测试(1) 抛出异常 在controller、service、 dao中都可以抛出异常。 修改PageService的add方法，添加抛出异常的代码 12345678//校验页面名称,站点Id,页面webpath的唯一性//根据页面名称,站点Id,页面webpath查询,如果查询到说明此页面已经存在,如果查不到再添加CmsPage page = cmsPageRepository.findByPageNameAndSiteIdAndPageWebPath(cmsPage.getPageName(), cmsPage.getSiteId(), cmsPage.getPageWebPath());if (page!=null)&#123; //页面已存在 //抛出异常,页面已存在异常 ExceptionCast.cast(CmsCode.CMS_ADDPAGE_EXISTSNAME);&#125; (2) 启动工程，扫描到异常捕获的类ExceptionCatch在springBoot的启动类中添加 1@ComponentScan(basePackages = &#123;\"com.xuecheng.framework\"&#125;) //扫描common工程下的类 (3) 前端展示异常信息 页面提取异常处理 12345678910111213141516171819202122232425262728addSubmit()&#123; this.$refs.pageForm.validate((valid) =&gt; &#123; if (valid) &#123; this.$confirm('确认提交吗？', '提示', &#123;&#125;).then(() =&gt; &#123; this.addLoading = true; cmsApi.page_add(this.pageForm).then((res) =&gt; &#123; console.log(res); if(res.success)&#123; this.addLoading = false; //NProgress.done(); this.$message(&#123; message: '提交成功', type: 'success' &#125;); this.$refs['pageForm'].resetFields(); &#125;else if(res.message)&#123; this.addLoading = false; this.$message.error(res.message); &#125;else&#123; this.addLoading = false; this.$message.error('提交失败'); &#125; &#125;); &#125;); &#125; &#125;);&#125; 5.4 不可预知异常处理5.4.1 定义异常捕获方法(1) 我们在map中配置HttpMessageNotReadableException和错误代码。(2) 在异常捕获类中对Exception异常进行捕获，并从map中获取异常类型对应的错误代码，如果存在错误代码则返 回此错误，否则统一返回99999错误。具体的开发实现如下： (1) 在通用错误代码类CommCode中配置非法参数异常 1INVALID_PARAM(false,10003,\"非法参数!\"), (2) 在异常捕获类中配置 HttpMessageNotReadableException 为非法参数异常。 异常捕获类代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940@ControllerAdvice //控制器增强public class ExceptionCatch &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ExceptionCatch.class); //定义map,配置异常类型所对应的错误代码 //使用EXCEPTIONS存放异常类型和错误代码的映射，ImmutableMap的特点的一旦创建不可改变，并且线程安全 private static ImmutableMap&lt;Class&lt;? extends Throwable&gt;,ResultCode&gt; EXCEPTIONS; //使用builder来构建一个异常类型和错误代码的异常 protected static ImmutableMap.Builder&lt;Class&lt;? extends Throwable&gt;,ResultCode&gt; builder=ImmutableMap.builder(); //捕获 CustomException异常 @ExceptionHandler(CustomException.class) @ResponseBody public ResponseResult customException(CustomException customException) &#123; //记录日志 LOGGER.error(\"catch exception:&#123;&#125;\",customException); ResultCode resultCode = customException.getResultCode(); return new ResponseResult(resultCode); &#125; //捕获Exception异常 @ExceptionHandler(Exception.class) @ResponseBody public ResponseResult exception(Exception exception) &#123; //记录日志 LOGGER.error(\"catch exception:&#123;&#125;\",exception); if (EXCEPTIONS==null)&#123; builder.build(); //EXCEPTIONS构建成功 &#125; //从EXCEPTIONS中找出异常类型所对应的错误代码,如果找到了将错误代码响应给用户,否则响应99999 ResultCode resultCode = EXCEPTIONS.get(exception.getClass()); if (resultCode!=null)&#123; return new ResponseResult(resultCode); &#125;else &#123; return new ResponseResult(CommonCode.SERVER_ERROR); &#125; &#125; static &#123; //在这里加入一些基础的异常类型判断 builder.put(HttpMessageNotReadableException.class,CommonCode.INVALID_PARAM); &#125;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(七.课程管理)","slug":"学成在线(七.课程管理)","date":"2021-05-08T13:19:59.196Z","updated":"2020-04-29T02:44:38.084Z","comments":true,"path":"20521/","link":"","permalink":"http://tonymua.top/20521/","excerpt":"1.我的课程1.1 需求分析课程添加完成后可通过我的课程进入课程修改页面，此页面显示我的课程列表，可分页查询。 上边的查询要实现分页、会存在多表关联查询，所以建议使用mybatis实现我的课程查询。","text":"1.我的课程1.1 需求分析课程添加完成后可通过我的课程进入课程修改页面，此页面显示我的课程列表，可分页查询。 上边的查询要实现分页、会存在多表关联查询，所以建议使用mybatis实现我的课程查询。 1.2 API接口输入参数：页码、每页显示个数、查询条件输出结果类型：QueryResponseResult&lt;自定义类型&gt;在api工程创建course包，创建CourseControllerApi接口 1234567//查询课程列表@ApiOperation(\"查询我的课程列表\")public QueryResponseResult findCourseList( int page, int size, CourseListRequest courseListRequest); 1.3 课程管理服务1.3.1 PageHelperPageHelper是mybatis的通用分页插件，通过mybatis的拦截器实现分页功能，拦截sql查询请求，添加分页语句， 最终实现分页查询功能。我的课程具有分页功能，本项目使用Pagehelper实现Mybatis分页功能开发，由于本项目使用springboot开发，在 springboot上集成pagehelper（https://github.com/pagehelper/pagehelper-spring-boot）PageHelper的使用方法及原理如下： 在调用dao的service方法中设置分页参数：PageHelper.startPage(page, size)，分页参数会设置在ThreadLocal中PageHelper在mybatis执行sql前进行拦截，从ThreadLocal取出分页参数，修改当前执行的sql语句，添加分页 sql。 最后执行添加了分页sql的sql语句，实现分页查询。 1）添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt;&lt;/dependency&gt; 2）配置pageHelper 在application.yml中配置pageHelper操作的数据库类型： 12pagehelper: helper-dialect: mysql 1.3.2 Dao1）mapper 接口 1Page&lt;CourseInfo&gt; findCourseListPage(CourseListRequest courseListRequest); 2）mapper.xml映射文件 12345678&lt;select id=\"findCourseListPage\" resultType=\"com.xuecheng.framework.domain.course.ext.CourseInfo\" parameterType=\"com.xuecheng.framework.domain.course.request.CourseListRequest\"&gt; select course_base.*, (select pic from course_pic where courseid=course_base.id) pic from course_base&lt;/select&gt; 3）测试Dao 12345678@Testpublic void testPageHelper()&#123; PageHelper.startPage(2,1); CourseListRequest courseListRequest=new CourseListRequest(); Page&lt;CourseInfo&gt; courseListPage = courseMapper.findCourseListPage(courseListRequest); List&lt;CourseInfo&gt; result = courseListPage.getResult(); System.out.println(result); &#125; 1.3.3 Controller12345@Override@GetMapping(\"/coursebase/list/&#123;page&#125;/&#123;size&#125;\")public QueryResponseResult findCourseList(@PathVariable(\"page\") int page, @PathVariable(\"size\") int size, CourseListRequest courseListRequest) &#123; return courseService.findCourseList(page,size,courseListRequest);&#125; 1.3.4 Service定义CourseService.java类，用于课程管理的service定义 12345678910111213141516171819202122232425//课程列表分页查询public QueryResponseResult findCourseList(int page, int size, CourseListRequest courseListRequest) &#123; if (courseListRequest==null)&#123; courseListRequest=new CourseListRequest(); &#125; if (page&lt;=0)&#123; page=0; &#125; if (size&lt;=0)&#123; size=20; &#125; //设置分页参数 PageHelper.startPage(page,size); //分页查询 Page&lt;CourseInfo&gt; courseListPage = courseMapper.findCourseListPage(courseListRequest); //查询列表 List&lt;CourseInfo&gt; list = courseListPage.getResult(); //总记录数 long total = courseListPage.getTotal(); //查询结果集 QueryResult&lt;CourseInfo&gt; courseInfoQueryResult=new QueryResult&lt;&gt;(); courseInfoQueryResult.setList(list); courseInfoQueryResult.setTotal(total); return new QueryResponseResult(CommonCode.SUCCESS,courseInfoQueryResult);&#125; 2.新增课程2.1 需求分析用户操作流程如下：(1) 用户进入“我的课程”页面，点击“新增课程”，进入新增课程页面(2) 填写课程信息，选择课程分类、课程等级、学习模式等。(3)信息填写完毕，点击“提交”，课程添加成功或课程添加失败并提示失败原因 需要解决的是在新增页面上输入的信息：(1) 课程分类多级分类，需要方便用户去选择。(2) 课程等级、学习模式等这些选项建议是可以配置的 2.2 课程分类查询2.2.1介绍在新增课程界面需要选择课程所属分类， 分类信息是整个项目非常重要的信息，课程即商品，分类信息设置的好 坏直接影响用户访问量 分类信息在哪里应用？(1) 首页分类导航(2) 课程的归属地 添加课程时要选择课程的所属分类 2.2.2 数据结构分类表category的结构如下： 2.2.3 分类查询2.2.3.1 数据格式在添加课程时需要选择课程所属的分类，这里需要定义课程分类查询接口。接口格式要根据前端需要的数据格式来定义，前端展示课程分类使用elemenet-ui的cascader（级联选择器）组 件。 数据格式例子如下： 1234567891011121314151617181920212223[ &#123; value: 'zhinan', label: '指南', children: [&#123; value: 'shejiyuanze', label: '设计原则', children: [&#123; value: 'yizhi', label: '一致' &#125;, &#123; value: 'fankui', label: '反馈' &#125;, &#123; value: 'xiaolv', label: '效率' &#125;, &#123; value: 'kekong', label: '可控' &#125;] &#125;] &#125; ] 2.2.3.2 数据模型1）定义category的模型 ​ category模型对数据字段对应，如下 1234567891011121314151617181920@Data@ToString@Entity@Table(name=\"category\")@GenericGenerator(name = \"jpa-assigned\", strategy = \"assigned\")//@GenericGenerator(name = \"jpa-uuid\", strategy = \"uuid\")public class Category implements Serializable &#123; private static final long serialVersionUID = -906357110051689484L; @Id @GeneratedValue(generator = \"jpa-assigned\") @Column(length = 32) private String id; private String name; private String label; private String parentid; private String isshow; private Integer orderby; private String isleaf;&#125; 2）定义数据返回格式 1234567@Data@ToStringpublic class CategoryNode extends Category &#123; List&lt;CategoryNode&gt; children;&#125; 2.2.3.3 Api接口12345@Api(value = \"课程分类管理\",description = \"课程分类管理\",tags = &#123;\"课程分类管理\"&#125;)public interface CategoryControllerApi &#123; @ApiOperation(\"查询分类\") public CategoryNode findList();&#125; 2.2.3.4 dao根据数据格式的分析，此查询需要返回树型数据格式，为了开发方便我们使用mybatis实现查询 1）定义mapper 123456@Mapper@Repositorypublic interface CategoryMapper &#123; //查询分类 public CategoryNode findList();&#125; 2）定义mapper映射文件采用表的自连接方式输出树型结果集 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.xuecheng.manage_course.dao.CategoryMapper\"&gt; &lt;resultMap id=\"categoryMap\" type=\"com.xuecheng.framework.domain.course.ext.CategoryNode\"&gt; &lt;id property=\"id\" column=\"one_id\"/&gt; &lt;result property=\"name\" column=\"one_name\"/&gt; &lt;result property=\"label\" column=\"one_label\"/&gt; &lt;result property=\"isshow\" column=\"one_isshow\"/&gt; &lt;result property=\"isleaf\" column=\"one_isleaf\"/&gt; &lt;result property=\"orderby\" column=\"one_orderby\"/&gt; &lt;result property=\"parentid\" column=\"one_parentid\"/&gt; &lt;collection property=\"children\" ofType=\"com.xuecheng.framework.domain.course.ext.CategoryNode\"&gt; &lt;id property=\"id\" column=\"two_id\"/&gt; &lt;result property=\"name\" column=\"two_name\"/&gt; &lt;result property=\"label\" column=\"two_label\"/&gt; &lt;result property=\"isshow\" column=\"two_isshow\"/&gt; &lt;result property=\"isleaf\" column=\"two_isleaf\"/&gt; &lt;result property=\"orderby\" column=\"two_orderby\"/&gt; &lt;result property=\"parentid\" column=\"two_parentid\"/&gt; &lt;collection property=\"children\" ofType=\"com.xuecheng.framework.domain.course.ext.CategoryNode\"&gt; &lt;id property=\"id\" column=\"three_id\"/&gt; &lt;result property=\"name\" column=\"three_name\"/&gt; &lt;result property=\"label\" column=\"three_label\"/&gt; &lt;result property=\"isshow\" column=\"three_isshow\"/&gt; &lt;result property=\"isleaf\" column=\"three_isleaf\"/&gt; &lt;result property=\"orderby\" column=\"three_orderby\"/&gt; &lt;result property=\"parentid\" column=\"three_parentid\"/&gt; &lt;/collection&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id=\"findList\" resultMap=\"categoryMap\"&gt; SELECT a.id one_id, a.name one_name, a.label one_label, a.isshow one_isshow, a.isleaf one_isleaf, a.orderby one_orderby, a.parentid one_parentid, b.id two_id, b.name two_name, b.label two_label, b.isshow two_isshow, b.isleaf two_isleaf, b.orderby two_orderby, b.parentid two_parentid, c.id three_id, c.name three_name, c.label three_label, c.isshow three_isshow, c.isleaf three_isleaf, c.orderby three_orderby, c.parentid three_parentid FROM category a LEFT JOIN category b ON a.id = b.parentid LEFT JOIN category c ON b.id = c.parentid WHERE a.parentid = '0' ORDER BY a.orderby, b.orderby, c.orderby &lt;/select&gt;&lt;/mapper&gt; 2.2.3.5 Controller123456789101112@RestController@RequestMapping(\"/category\")public class CategoryController implements CategoryControllerApi &#123; @Autowired CategoryService categoryService; @Override @GetMapping(\"/list\") public CategoryNode findList() &#123; return categoryService.findList(); &#125;&#125; 2.2.3.6 Service12345678@Servicepublic class CategoryService &#123; @Autowired CategoryMapper categoryMapper; public CategoryNode findList() &#123; return categoryMapper.findList(); &#125;&#125; 2.3 数据字典2.3.1 介绍在新增课程界面需要选择课程等级、课程状态等，这些信息统一采用数据字典管理的方式。 本项目对一些业务的分类配置信息，比如：课程等级、课程状态、用户类型、用户状态等进行统一管理，通过在数据库创建数据字典表来维护这些分类信息。 ​ 数据字典对系统的业务分类进行统一管理，并且也可以解决硬编码问题，比如添加课程时选择课程等级，下拉框中的课程等级信息如果在页面硬编码将造成不易修改维护的问题，所以从数据字典表中获取，如果要修改名称则在数据字典修改即可，提高系统的可维护性。 2.3.2 数据模型在mongodb中创建数据字典表sys_dictionary 一个字典信息如下： 12345678910111213141516171819202122&#123; \"_id\" : ObjectId(\"5a7e8d2dd019f15418fa2b71\"), \"d_name\" : \"课程等级\", \"d_type\" : \"200\", \"d_value\" : [ &#123; \"sd_name\" : \"低级\", \"sd_id\" : \"200001\", \"sd_status\" : \"1\" &#125;, &#123; \"sd_name\" : \"中级\", \"sd_id\" : \"200002\", \"sd_status\" : \"1\" &#125;, &#123; \"sd_name\" : \"高级\", \"sd_id\" : \"200003\", \"sd_status\" : \"1\" &#125; ]&#125; 字段说明如下： d_name：字典名称 d_type：字典分类 d_value：字典数据 sd_name：项目名称 sd_id：项目id sd_status：项目状态（1：可用，0不可用） 数据模型类： 123456789101112131415161718@Data@ToString@Document(collection = \"sys_dictionary\")public class SysDictionary &#123; @Id private String id; @Field(\"d_name\") private String dName; @Field(\"d_type\") private String dType; @Field(\"d_value\") private List&lt;SysDictionaryValue&gt; dValue;&#125; SysDictionaryValue类型： 1234567891011121314@Data@ToStringpublic class SysDictionaryValue &#123; @Field(\"sd_id\") private String sdId; @Field(\"sd_name\") private String sdName; @Field(\"sd_status\") private String sdStatus;&#125; 2.3.3 字典查询接口2.3.3.1 API接口为了方便其它子系统使用，在cms模块下创建字典查询接口，根据字典的type查询字典信息，接口定义如下： 123456@Api(value = \"数据字典接口\",description =\"提供数据字典接口的管理,查询接口\",tags = \"数据字典接口\")public interface SysDicthinaryControllerApi &#123; //数据字典 @ApiOperation(\"数据字典查询接口\") public SysDictionary getByType(String type);&#125; 2.3.3.2 Dao在cms模块下创建数据库的dao、service等类 12345@Repositorypublic interface SysDictionaryDao extends MongoRepository&lt;SysDictionary,String&gt; &#123; //根据字典分类查询字典信息 SysDictionary findByDType(String dtype);&#125; 2.3.3.3 Service123456789@Servicepublic class SysdictionaryService &#123; @Autowired SysDictionaryDao sysDictionaryDao; //根据字典分类type查询字典信 public SysDictionary findByType(String type)&#123; return sysDictionaryDao.findByDType(type); &#125;&#125; 2.3.3.4 Controller123456789101112@RestController@RequestMapping(\"/sys/dictionary\")public class SysDictionaryController implements SysDicthinaryControllerApi &#123; @Autowired SysdictionaryService sysdictionaryService; @Override @GetMapping(\"/get/&#123;type&#125;\") public SysDictionary getByType(@PathVariable(\"type\") String type) &#123; return sysdictionaryService.findByType(type); &#125;&#125; 2.4 新增课程2.4.1 API接口12@ApiOperation(\"添加课程基础信息\")public AddCourseResult addCourse(CourseBase courseBase); 2.4.2 Dao12public interface CourseBaseRepository extends JpaRepository&lt;CourseBase,String&gt; &#123;&#125; 2.4.3 Controller12345@Override@PostMapping(\"/coursebase/add\")public AddCourseResult addCourse(@RequestBody CourseBase courseBase) &#123; return courseService.addCourse(courseBase);&#125; 2.4.3 Service12345678//添加课程提交@Transactionalpublic AddCourseResult addCourse(CourseBase courseBase) &#123; //课程状态默认为未发布 courseBase.setStatus(\"202001\"); courseBaseRepository.save(courseBase); return new AddCourseResult(CommonCode.SUCCESS,courseBase.getId());&#125; 3.课程信息修改3.1 需求分析课程添加成功进入课程管理页面，通过课程管理页面修改课程的基本信息、编辑课程图片、编辑课程营销信息等。本小节实现修改课程。 3.2 Api接口修改课程需要如下接口：1、根据id查询课程信息2、修改课程提交接口定义如下：1) 根据课程ID查询课程信息 12@ApiOperation(\"获取课程基础信息\")public CourseBase getCourseById(String courseId); 2) 修改课程信息 12@ApiOperation(\"更新课程基础信息\")public ResponseResult updateCourse(String id, CourseBase courseBase); 3.3 服务端3.3.1 Dao12public interface CourseBaseRepository extends JpaRepository&lt;CourseBase,String&gt; &#123;&#125; 3.3.2 Controller1234567891011@Override@GetMapping(\"/coursebase/get/&#123;courseId&#125;\")public CourseBase getCourseById(@PathVariable(\"courseId\") String courseId) &#123; return courseService.getCourseById(courseId);&#125;@Override@PutMapping(\"/coursebase/update/&#123;id&#125;\")public ResponseResult updateCourse(@PathVariable(\"id\") String id, @RequestBody CourseBase courseBase) &#123; return courseService.updateCourse(id,courseBase);&#125; 3.3.3 Service123456789101112131415161718192021222324public CourseBase getCourseById(String courseId) &#123; Optional&lt;CourseBase&gt; optional = courseBaseRepository.findById(courseId); if (optional.isPresent())&#123; return optional.get(); &#125; return null;&#125;@Transactionalpublic ResponseResult updateCourse(String id, CourseBase courseBase) &#123; CourseBase course = getCourseById(id); if (course==null)&#123; ExceptionCast.cast(CommonCode.INVALID_PARAM); &#125; //修改课程信息 course.setName(courseBase.getName()); course.setMt(courseBase.getMt()); course.setGrade(courseBase.getGrade()); course.setStudymodel(courseBase.getStudymodel()); course.setUsers(courseBase.getUsers()); course.setDescription(courseBase.getDescription()); CourseBase save = courseBaseRepository.save(course); return new ResponseResult(CommonCode.SUCCESS);&#125; 4.课程营销4.1 需求分析课程营销信息包括课程价格、课程有效期等信息 4.2 数据模型课程营销信息使用course_market表存储数据模型如下： 12345678910111213141516171819202122@Data@ToString@Entity@Table(name=\"course_market\")@GenericGenerator(name = \"jpa-assigned\", strategy = \"assigned\")public class CourseMarket implements Serializable &#123; private static final long serialVersionUID = -916357110051689486L; @Id @GeneratedValue(generator = \"jpa-assigned\") @Column(length = 32) private String id; private String charge; private String valid; private String qq; private Float price; private Float price_old;// private Date expires; @Column(name = \"start_time\") private Date startTime; @Column(name = \"end_time\") private Date endTime;&#125; 4.3 API1) 查询课程营销信息 12@ApiOperation(\"获取课程营销信息\")public CourseMarket getCourseMarketById(String courseId); 2) 更新课程营销信息 12@ApiOperation(\"更新课程营销信息\")public ResponseResult updateCourseMarket(String id,CourseMarket courseMarket); 4.4 课程管理服务4.4.1 Dao12public interface CourseMarketRepository extends JpaRepository&lt;CourseMarket,String&gt; &#123;&#125; 4.4.2 Controller12345678910111213141516@Override@GetMapping(\"/coursemarket/get/&#123;courseId&#125;\")public CourseMarket getCourseMarketById(@PathVariable(\"courseId\") String courseId) &#123; return courseService.getCourseMarketById(courseId);&#125;@Override@PostMapping(\"/coursemarket/update/&#123;id&#125;\")public ResponseResult updateCourseMarket(@PathVariable(\"id\") String id, @RequestBody CourseMarket courseMarket) &#123; CourseMarket market = courseService.updateCourseMarket(id, courseMarket); if (market!=null)&#123; return new ResponseResult(CommonCode.SUCCESS); &#125;else &#123; return new ResponseResult(CommonCode.FAIL); &#125;&#125; 4.4.3 Service1234567891011121314151617181920212223242526public CourseMarket getCourseMarketById(String courseId) &#123; Optional&lt;CourseMarket&gt; optional = courseMarketRepository.findById(courseId); if (optional.isPresent())&#123; return optional.get(); &#125; return null;&#125;@Transactionalpublic CourseMarket updateCourseMarket(String id, CourseMarket courseMarket) &#123; CourseMarket market = getCourseMarketById(id); if (market!=null)&#123; market.setCharge(courseMarket.getCharge()); market.setStartTime(courseMarket.getStartTime());//课程有效期，开始时间 market.setEndTime(courseMarket.getEndTime());//课程有效期，结束时间 market.setPrice(courseMarket.getPrice()); market.setQq(courseMarket.getQq()); market.setValid(courseMarket.getValid()); courseMarketRepository.save(market); &#125;else &#123; //添加课程营销信息 market=new CourseMarket(); BeanUtils.copyProperties(courseMarket,market); &#125; return market;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"学成在线(一.CMS服务端开发)","slug":"学成在线(一.CMS服务端开发)","date":"2021-05-08T13:19:59.194Z","updated":"2020-04-29T02:44:38.109Z","comments":true,"path":"42599/","link":"","permalink":"http://tonymua.top/42599/","excerpt":"1.CMS需求分析1.1 什么是CMS(1) CMS是什么 ？ CMS （Content Management System）即内容管理系统，不同的项目对CMS的定位不同，比如：一个在线教育网站，有些公司认为CMS系统是对所有的课程资源进行管理，而在早期网站刚开始盛行时很多公司的业务是网站制作，当时对CMS的定位是创建网站，即对网站的页面、图片等静态资源进行管理。(2) CMS有哪些类型？ 上边也谈到每个公司对每个项目的CMS定位不同，CMS基本上分为：针对后台数据内容的管理、针对前端页面的 管理、针对样式风格的管理等 。比如：一个给企业做网站的公司，其CMS系统主要是网站页面管理及样式风格的 管理。 (3) 本项目CMS的定位是什么？ 本项目作为一个大型的在线教育平台，对CMS系统的定位是对各各网站（子站点）页面的管理，主要管理运营需要而经常变动的页面，从而实现根据运营需要快速进行页面开发、上线的需求。","text":"1.CMS需求分析1.1 什么是CMS(1) CMS是什么 ？ CMS （Content Management System）即内容管理系统，不同的项目对CMS的定位不同，比如：一个在线教育网站，有些公司认为CMS系统是对所有的课程资源进行管理，而在早期网站刚开始盛行时很多公司的业务是网站制作，当时对CMS的定位是创建网站，即对网站的页面、图片等静态资源进行管理。(2) CMS有哪些类型？ 上边也谈到每个公司对每个项目的CMS定位不同，CMS基本上分为：针对后台数据内容的管理、针对前端页面的 管理、针对样式风格的管理等 。比如：一个给企业做网站的公司，其CMS系统主要是网站页面管理及样式风格的 管理。 (3) 本项目CMS的定位是什么？ 本项目作为一个大型的在线教育平台，对CMS系统的定位是对各各网站（子站点）页面的管理，主要管理运营需要而经常变动的页面，从而实现根据运营需要快速进行页面开发、上线的需求。 1.2 SSI服务端包含技术(1) 页面内容多如何管理？ 将页面拆分成一个一个的小页面，通过cms去管理这些小页面，当要更改部分页面内容时只需要更改具体某个小页面即可。(2) 页面拆出来怎么样通过web服务浏览呢？ 使用web服务(例如nginx)的SSI技术，将多个子页面合并渲染输出。(3) SI是什么？ ssi包含类似于jsp页面中的incluce指令，SSI是在web服务端将include指定的页面包含在网页中，渲染html网页响应给客户端 。nginx、apache等多数web容器都支持SSI指令。 SSI指令如下： 1&lt;!‐‐#include virtual=\"/../....html\"‐‐&gt; (4) 将首页拆分成 12345index.html：首页主体内容 include/header.html：头部区域 include/index_banner.html：轮播图 include/index_category.html：左侧列表导航 include/footer.html：页尾 (5) 在nginx虚拟主机中开通SSI 123456server&#123; listen 80; server_name www.xuecheng.com; ssi on; ssi_silent_errors on; ..... SSI的配置参数如下： ​ ssi on： 开启ssi支持 ​ ssi_silent_errors on：默认为oﬀ，设置为on则在处理SSI文件出错时不输出错误信息 ​ ssi_types：默认为 ssi_types text/html，如果需要支持shtml（服务器执行脚本，类似于jsp）则需要设置为 ssi_types text/shtml 1.3 CMS页面管理需求 这些页面的管理流程是什么？(1) 创建站点一个网站有很多子站点，比如：学成在线有主门户、学习中心、问答系统等子站点。具体的哪个页面是归属于具体的站点，所以要管理页面，先要管理页面所属的站点。(2) 创建模板页面如何创建呢？比如电商网站的商品详情页面，每个页面的内容布局、板式是相同的，不同的只是内容，这个页面的布局、板式就是页面模板，模板+数据就组成一个完整的页面，最终要创建一个页面文件需要先定义此页面的模板，最终拿到页面的数据再结合模板就拼装成一个完整的页面。 (3) 创建页面 创建页面是指填写页面的基本信息，如：页面的名称、页面的url地址等。(4) 页面预览页面预览是页面发布前的一项工作，页面预览使用静态化技术根据页面模板和数据生成页面内容，并通过浏览器预览页面。页面发布前进行页面预览的目是为了保证页面发布后的正确性。(5) 页面发布使用计算机技术将页面发送到页面所在站点的服务器，页面发布成功就可以通过浏览器来访问了。 本项目要实现什么样的功能？ (1) 页面管理管理员在后台添加、修改、删除页面信息(2) 页面预览管理员通过页面预览功能预览页面发布后的效果。(3) 页面发布管理员通过页面发布功能将页面发布到远程门户服务器。页面发布成功，用户即可在浏览器浏览到最新发布的页面，整个页面添加、发布的过程由于软件自动执行，无需人 工登录服务器操作。 2.CMS服务端工程搭建2.1 工程结构CMS及其它服务端工程基于maven进行构建，首先需要创建如下基础工程： ​ parent工程：父工程，提供依赖管理 ​ common工程：通用工程，提供各层封装 ​ model工程：模型工程，提供统一的模型类管理 ​ utils工程：工具类工程，提供本项目所使用的工具类 ​ Api工程：接口工程，统一管理本项目的服务接口 2.2 MongoDB数据导入 3.页面查询接口定义3.1 定义模型3.1.1 需求分析在梳理完用户需求后就要去定义前后端的接口，接口定义后前端和后端就可以依据接口去开发功能了。本次定义页面查询接口，本接口供前端请求查询页面列表，支持分页及自定义条件查询方式。具体需求如下：(1) 分页查询CmsPage 集合下的数据 (2) 根据站点Id、模板Id、页面别名查询页面信息 (3) 接口基于Http Get请求，响应Json数据 3.1.2 模型类介绍接口的定义离不开数据模型，根据前边对需求的分析，整个页面管理模块的数据模型如下： CmsSite：站点模型 CmsTemplate：页面模板 CmsPage：页面信息页面信息如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Data@ToString@Document(collection = \"cms_page\")public class CmsPage &#123; /** * 页面名称、别名、访问地址、类型（静态/动态）、页面模版、状态 */ //站点ID private String siteId; //页面ID @Id private String pageId; //页面名称 private String pageName; //别名 private String pageAliase; //访问地址 private String pageWebPath; //参数 private String pageParameter; //物理路径 private String pagePhysicalPath; //类型（静态/动态） private String pageType; //页面模版 private String pageTemplate; //页面静态化内容 private String pageHtml; //状态 private String pageStatus; //创建时间 private Date pageCreateTime; //模版id private String templateId; //参数列表 private List&lt;CmsPageParam&gt; pageParams; //模版文件Id// private String templateFileId; //静态文件Id private String htmlFileId; //数据Url private String dataUrl;&#125; 属性说明：(1) 定义一个页面需要指定页面所属站点一个站点包括多个页面，比如：学成在线的门户站点（网站）包括了多个页面。(2) 定义一个页面需要指定页面使用的模板多个页面可以使用相同的模板，比如：商品信息模板，每个商品就是一个页面，所有商品使用同一个商品信息模板注解说明： @Data、@ToString、@Document注解表示什么意思？ @Data、@ToString：是Lombok提供的注解 @Document：是Spring Data mongodb提供的注解，最终CMS的开发会使用Mongodb数据库。 3.2 定义接口3.2.1 定义请求及响应类型(1) 定义请求模型QueryPageRequest，此模型作为查询条件类型 ​ 为后期扩展需求，请求类型统一继承RequestData类型 1234567891011121314@Datapublic class QueryPageRequest &#123; //站点id private String siteId; //页面id private String pageId; //页面名称 private String pageName; //别名 private String pageAliase; //模板id private String templateId;&#125; (2) 响应结果类型，分页查询统一使用QueryResponseResult 3.2.2 定义接口在Api接口工程专门定义接口，在Api工程单独定义接口的原因如下： (1) 接口集中管理 (2) Api工程的接口将作为各微服务远程调用使用。页面查询接口定义如下： 1234public interface CmsPageControllerApi &#123; //页面查询 public QueryResponseResult findList(int page, int size, QueryPageRequest queryPageRequest);&#125; 此接口编写后会在CMS服务工程编写Controller类实现此接口 4.页面查询服务端开发4.1 创建CMS服务工程4.1.1 创建CMS工程结构(1) 创建maven工程， CMS工程的名称为 xc-service-manage-cms，父工程为xc-framework-parent pom.xml如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;xc-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../xc-framework-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-service-manage-cms&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-common&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-utils&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-framework-model&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xc-service-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!-- &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;2.0.14.RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt;--&gt; &lt;/dependencies&gt;&lt;/project&gt; (2) 创建基本的包结构： com.xuecheng.manage_cms.conﬁg：配置类目录，数据库配置、MQ配置等 com.xuecheng.manage_cms.dao：dao接口目录 com.xuecheng.manage_cms.service：service类目录 com.xuecheng.manage_cms.web.controller：controller类目录工程结构如下： (3) 配置文件在resources下配置application.yml 123456789server: port: $&#123;PORT:31001&#125;spring: application: name: xc-service-manage-cms data: mongodb: uri: mongodb://root:root@localhost:27017 database: xc_cms logback-spring.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;!--定义日志文件的存储地址,使用绝对路径--&gt; &lt;property name=\"LOG_HOME\" value=\"e:/logs\"/&gt; &lt;!-- Console 输出设置 --&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/xc.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 异步输出 --&gt; &lt;appender name=\"ASYNC\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt; &lt;!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 --&gt; &lt;discardingThreshold&gt;0&lt;/discardingThreshold&gt; &lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为256 --&gt; &lt;queueSize&gt;512&lt;/queueSize&gt; &lt;!-- 添加附加的appender,最多只能添加一个 --&gt; &lt;appender-ref ref=\"FILE\"/&gt; &lt;/appender&gt; &lt;logger name=\"org.apache.ibatis.cache.decorators.LoggingCache\" level=\"DEBUG\" additivity=\"false\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;/logger&gt; &lt;logger name=\"org.springframework.boot\" level=\"DEBUG\"/&gt; &lt;root level=\"info\"&gt; &lt;!--&lt;appender-ref ref=\"ASYNC\"/&gt;--&gt; &lt;appender-ref ref=\"FILE\"/&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;/root&gt;&lt;/configuration&gt; (4) SpringBoot 启动类 Spring Boot应用需要创建一个应用启动类，启动过程中会扫描Bean并注入spring 容器 注意：此类创建在本工程com.xuecheng.manage_cms包下 : 123456789@SpringBootApplication@EntityScan(\"com.xuecheng.framework.domain.cms\") //扫描实体类@ComponentScan(basePackages = &#123;\"com.xuecheng.api\"&#125;) //扫描接口@ComponentScan(basePackages = &#123;\"com.xuecheng.manage_cms\"&#125;) //扫描本项目下的所有类public class ManageCmsApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ManageCmsApplication.class); &#125;&#125; 4.1.2 测试Controller使用springMVC完成接口实现开发，这里暂时使用测试数据，稍后会让controller调用service来查询数据 123456789101112131415161718@RestController@RequestMapping(\"/cms/page\")public class CmsPageController implements CmsPageControllerApi &#123; @Override @GetMapping(\"/list/&#123;page&#125;/&#123;size&#125;\") public QueryResponseResult findList(@PathVariable(\"page\") int page, @PathVariable(\"size\") int size, QueryPageRequest queryPageRequest) &#123; //暂时采用测试数据，测试接口是否可以正常运行 QueryResult&lt;CmsPage&gt; queryResult=new QueryResult&lt;&gt;(); List&lt;CmsPage&gt; list=new ArrayList&lt;&gt;(); CmsPage cmsPage=new CmsPage(); cmsPage.setPageName(\"测试页面\"); list.add(cmsPage); queryResult.setList(list); queryResult.setTotal(1); QueryResponseResult queryResponseResult=new QueryResponseResult(CommonCode.SUCCESS,queryResult); return queryResponseResult; &#125;&#125; 使用浏览器测试输入：http://localhost:31001/cms/page/list/1/2 4.2 Dao4.2.1 分页查询测试4.2.1.1 定义Dao接口本项目使用Spring Data Mongodb完成Mongodb数据库的查询，Spring Data Mongodb提供一套快捷操作 mongodb的方法。 创建Dao，继承MongoRepository，并指定实体类型和主键类型。 12public interface CmsPageRepository extends MongoRepository&lt;CmsPage,String&gt; &#123;&#125; 4.2.1.2编写测试类test下的包路径与main下的包路径保持一致。 测试程序使用@SpringBootTest和@RunWith(SpringRunner.class)注解，启动测试类会从main下找springBoot启 动类，加载spring容器。测试代码如下： 1234567891011121314151617181920212223@SpringBootTest@RunWith(SpringRunner.class)public class CmsPageRepositoryTest &#123; @Autowired CmsPageRepository cmsPageRepository; @Test public void testFindAll() &#123; List&lt;CmsPage&gt; all = cmsPageRepository.findAll(); System.out.println(all); &#125; //测试分页查询 @Test public void testFindPage()&#123; //分页参数 int page=0; //页码从0开始 int size=10; Pageable pageable = PageRequest.of(page, size); Page&lt;CmsPage&gt; all = cmsPageRepository.findAll(pageable); System.out.println(all); &#125;&#125; 4.2.2 基础方法测试 这里Dao接口继承了MongoRepository，在MongoRepository中定义了很多现成的方法，如save、delete等，通 过下边的代码来测试这里父类方法。 1234567891011121314151617181920212223242526272829303132333435//添加 @Test public void testInsert() &#123; //定义实体类 CmsPage cmsPage = new CmsPage(); cmsPage.setSiteId(\"s001\"); cmsPage.setTemplateId(\"t001\"); cmsPage.setPageName(\"测试页面\"); cmsPage.setPageCreateTime(new Date()); List&lt;CmsPageParam&gt; cmsPageParams = new ArrayList&lt;&gt;(); CmsPageParam cmsPageParam = new CmsPageParam(); cmsPageParam.setPageParamName(\"param1\"); cmsPageParam.setPageParamValue(\"value1\"); cmsPageParams.add(cmsPageParam); cmsPage.setPageParams(cmsPageParams); //添加 cmsPageRepository.save(cmsPage); System.out.println(cmsPage); &#125; //删除 @Test public void testDelete()&#123; cmsPageRepository.deleteById(\"5b17a2c511fe5e0c409e5eb3\"); &#125; //修改 @Test public void testUpdate()&#123; Optional&lt;CmsPage&gt; optional = cmsPageRepository.findById(\"5b17a2c511fe5e0c409e5eb3\"); if (optional.isPresent())&#123; CmsPage cmsPage = optional.get(); cmsPage.setPageName(\"测试页面01\"); cmsPageRepository.save(cmsPage); &#125; 关于Optional： Optional是jdk1.8引入的类型，Optional是一个容器对象，它包括了我们需要的对象，使用isPresent方法判断所包 含对象是否为空，isPresent方法返回false则表示Optional包含对象为空，否则可以使用get()取出对象进行操作。Optional的优点是： (1) 提醒你非空判断。(2) 将对象非空检测标准化。 4.2.3 自定义Dao方法同Spring Data JPA一样Spring Data mongodb也提供自定义方法的规则，如下： 按照ﬁndByXXX，ﬁndByXXXAndYYY、countByXXXAndYYY等规则定义方法，实现查询操作。 12345678910111213public interface CmsPageRepository extends MongoRepository&lt;CmsPage, String&gt; &#123; //根据页面名称查询 CmsPage findByPageName(String pageName); //根据页面名称和类型查询 CmsPage findByPageNameAndPageType(String pageName, String pageType); //根据站点和页面类型查询记录数 int countBySiteIdAndPageType(String siteId, String pageType); //根据站点和页面类型分页查询 Page&lt;CmsPage&gt; findBySiteIdAndPageType(String siteId, String pageType, Pageable pageable);&#125; Test: 123456//根据页面名称查询@Testpublic void testFindByPageName()&#123; CmsPage cmsPage = cmsPageRepository.findByPageName(\"测试页面01\"); System.out.println(cmsPage);&#125; 4.3 Service定义页面查询方法，根据条件查询暂时不实现： 123456789101112131415161718192021222324252627282930@Servicepublic class PageService &#123; @Autowired CmsPageRepository cmsPageRepository; /** * 页面列表分页查询 * @param page 当前页码 * @param size 页面显示个数 * @param queryPageRequest 查询条件 * @return 页面列表 */ //页面查询方法 public QueryResponseResult findList(int page, int size, QueryPageRequest queryPageRequest)&#123; if (page&lt;=0)&#123; page=1; &#125; page=page-1; //为了适应mongodb的接口将页码减1 if (size&lt;=0)&#123; size=10; &#125; Pageable pageable= PageRequest.of(page,size); Page&lt;CmsPage&gt; all = cmsPageRepository.findAll(pageable); QueryResult&lt;CmsPage&gt; queryResult=new QueryResult&lt;&gt;(); queryResult.setList(all.getContent()); //数据列表 queryResult.setTotal(all.getTotalElements()); //数据总记录数 QueryResponseResult queryResponseResult=new QueryResponseResult(CommonCode.SUCCESS,queryResult); return queryResponseResult; &#125;&#125; 4.4 Controller使用springMVC完成接口实现开发 1234567891011121314@RestController@RequestMapping(\"/cms/page\")public class CmsPageController implements CmsPageControllerApi &#123; @Autowired PageService pageService; @Override @GetMapping(\"/list/&#123;page&#125;/&#123;size&#125;\") public QueryResponseResult findList(@PathVariable(\"page\") int page, @PathVariable(\"size\") int size, QueryPageRequest queryPageRequest) &#123; //调用Service return pageService.findList(page,size,queryPageRequest); &#125;&#125; 使用浏览器测试输入：http://localhost:31001/cms/page/list/1/10 查询第1页，每页显示10条记录 4.5 接口开发规范4.5.1 Api请求及响应规范为了严格按照接口进行开发，提高效率，对请求及响应格式进行规范化。(1) get 请求时，采用key/value格式请求，SpringMVC可采用基本类型的变量接收，也可以采用对象接收。(2) Post请求时，可以提交form表单数据（application/x-www-form-urlencoded）和Json数据（ContentType=application/json），文件等多部件类型（multipart/form-data）三种数据格式，SpringMVC接收Json数据 使用@RequestBody注解解析请求的json数据。(3) 响应结果统一信息为：是否成功、操作代码、提示信息及自定义数据。(4) 响应结果统一格式为json。 4.5.2 Api定义约束Api定义使用SpringMVC来完成，由于此接口后期将作为微服务远程调用使用，在定义接口时有如下限制： (1) @PathVariable 统一指定参数名称，如：@PathVariable(“id”)(2) @RequestParam统一指定参数名称，如： @RequestParam（”id”） 5 页面查询接口测试上边的代码是基于服务端编写接口，如果前端人员等待服务端人员将接口开发完毕再去开发前端内容这样做效率是非常低下的，所以当接口定义完成，可以使用工具生成接口文档，前端人员查看接口文档即可进行前端开发，这样前端和服务人员并行开发，大大提高了生产效率。本章节介绍两种接口开发工具，Swagger和Postman。 5.1 Swagger5.1.1 Swagger介绍​ OpenAPI规范（OpenAPI Speciﬁcation 简称OAS）是Linux基金会的一个项目，试图通过定义一种用来描述API格式或API定义的语言，来规范RESTful服务开发过程，目前版本是V3.0，并且已经发布并开源在github上。​ Swagger是全球最大的OpenAPI规范（OAS）API开发工具框架，支持从设计和文档到测试和部署的整个API生命周期的开发。 (https://swagger.io/)​ Spring Boot 可以集成Swagger，生成Swagger接口，Spring Boot是Java领域的神器，它是Spring项目下快速构建项目的框架。 5.1.2 Swagger常用注解在Java类中添加Swagger的注解即可生成Swagger接口，常用Swagger注解如下： @Api：修饰整个类，描述Controller的作用@ApiOperation：描述一个类的一个方法，或者说一个接口@ApiParam：单个参数描述@ApiModel：用对象来接收参数@ApiModelProperty：用对象接收参数时，描述对 象的一个字段@ApiResponse：HTTP响应其中1个描述 @ApiResponses：HTTP响应整体描述@ApiIgnore：使用 该注解忽略这个API@ApiError ：发生错误返回的信息@ApiImplicitParam：一个请求参数@ApiImplicitParams：多个请求参数 @ApiImplicitParam属性： 属性 取值 作用 paramType 查询参数类型 path 以地址的形式提交数据 query 直接跟参数完成自动映射赋值 body 以流的形式提交 仅支持POST header 参数在request headers 里边提交 form 以form表单的形式提交 仅支持POST dataType 参数的数据类型 只作为标志说明，并没有实际验证 Long String name 接收参数名 value 接收参数的意义描述 required 参数是否必填 true 必填 false 非必填 defaultValue 默认值 5.1.3 Swagger接口定义修改接口工程中页面查询接口，添加Swagger注解 12345678910@Api(value=\"cms页面管理接口\",description=\"cms页面管理接口，提供页面的增、删、改、查\")public interface CmsPageControllerApi &#123; //页面查询 @ApiOperation(\"分页查询页面列表\") @ApiImplicitParams(&#123; @ApiImplicitParam(name = \"page\",value = \"页码\",required = true,paramType =\"path\", dataType = \"int\"), @ApiImplicitParam(name = \"size\",value = \"每页记录数\",required = true,paramType =\"path\", dataType = \"int\") &#125;) public QueryResponseResult findList(int page, int size, QueryPageRequest queryPageRequest);&#125; 在QueryPageRequest类中使用注解 ApiModelProperty 对属性注释 123456789101112131415161718@Datapublic class QueryPageRequest &#123; //站点id @ApiModelProperty(\"站点id\") private String siteId; //页面id @ApiModelProperty(\"页面id\") private String pageId; //页面名称 @ApiModelProperty(\"页面名称\") private String pageName; //别名 @ApiModelProperty(\"别名\") private String pageAliase; //模板id @ApiModelProperty(\"模板id\") private String templateId;&#125; 5.1.4 Swagger接口测试Swagger接口生成工作原理：(1) 系统启动，扫描到api工程中的Swagger2Conﬁguration类(2) 在此类中指定了包路径com.xuecheng，找到在此包下及子包下标记有@RestController注解的controller类(3) 根据controller类中的Swagger注解生成接口文档。 启动cms服务工程，查看接口文档，请求：http://localhost:31001/swagger-ui.html 点击“分页查询页面列表”，打开接口详情 使用Swagger工具测试服务接口：(1) 在cms服务接口中打断点(2)打开接口文档页面，输入请求参数，点击“Try it out”发起请求。 5.2 PostmanPostman是一款功能强大的http接口测试工具，使用postman可以完成http各种请求的功能测试。官方地址：https://www.getpostman.com/ (1) 安装Postman本教程使用，双击打开 Postman-win64-6.0.10-Setup.exe新建一个Postman窗口 (2) 使用postman测试http接口 (3) 请求参数设置 form-data：将表单的数据转为键值对，并且可以包括文件 x-www-form-urlencoded: content-type为application/x-www-from-urlencoded，将表单的数据转为键值对raw：请求text、json、xml、html，比如如果请求json数据则使用此格式binary：content-type为application/octet-stream，可用于上传文件","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"四种常见的排序算法","slug":"四种常见的排序算法","date":"2021-05-08T13:19:59.192Z","updated":"2020-04-29T02:44:38.011Z","comments":true,"path":"23116/","link":"","permalink":"http://tonymua.top/23116/","excerpt":"1.冒泡排序思想: 每一趟将待排序序列中最大元素移到最后，剩下的为新的待排序序列, 重复上述步骤直到排完所有元素。这只是冒泡排序的一种, 当然也可以从后往前排 平均时间复杂度: O(n^2)","text":"1.冒泡排序思想: 每一趟将待排序序列中最大元素移到最后，剩下的为新的待排序序列, 重复上述步骤直到排完所有元素。这只是冒泡排序的一种, 当然也可以从后往前排 平均时间复杂度: O(n^2) 1234567891011121314151617181920public class Demo &#123; public void bubbleSort(int arr[]) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] arr=&#123;4, 8, 7, 5, 6, 3, 1&#125;; Demo d = new Demo(); d.selectSort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 2.选择排序思想: 每一趟从待排序序列选择一个最小的元素放在已排好序列的末尾, 剩下的为待排序序列, 重复上述步骤直至完成排序 平均时间复杂度: O(n^2) 123456789101112131415161718192021public void selectSort(int arr[]) &#123; //选择 for (int i = 0; i &lt; arr.length; i++) &#123; //默认第一个是最小的。 int min = arr[i]; //记录最小的下标 int index = i; //通过与后面的数据进行比较得出，最小值和下标 for (int j = i + 1; j &lt; arr.length; j++) &#123; if (min &gt; arr[j]) &#123; min = arr[j]; index = j; &#125; &#125; //然后将最小值与本次循环的，开始值交换 int temp = arr[i]; arr[i] = min; arr[index] = temp; //说明：将i前面的数据看成一个排好的队列，i后面的看成一个无序队列。每次只需要找无需的最小值，做替换 &#125;&#125; 3.插入排序思想: 1. 默认从第二个数据开始比较。 2.如果第二个数据比第一个小，则交换。然后在用第三个数据比较，如果比前面小，则插入（狡猾）。否则，退出循环 3.说明：默认将第一数据看成有序列表，后面无序的列表循环每一个数据，如果比前面的数据小则插入（交换）。否则退出 平均时间复杂度: O(n^2) 1234567891011121314151617public void insertSort(int arr[]) &#123; //插入排序 for (int i = 1; i &lt; arr.length; i++) &#123; //外层循环，从第二个开始比较 for (int j = i; j &gt; 0; j--) &#123; //内存循环，与前面排好序的数据比较，如果后面的数据小于前面的则交换 if (arr[j] &lt; arr[j - 1]) &#123; int temp = arr[j - 1]; arr[j - 1] = arr[j]; arr[j] = temp; &#125; else &#123; //如果不小于，说明插入完毕，退出内层循环 break; &#125; &#125; &#125;&#125; 4.快速排序采用分治法的思想：首先设置一个轴值pivot，然后以这个轴值为划分基准将待排序序列分成比pivot大和比pivot小的两部分，接下来对划分完的子序列进行快排直到子序列为一个元素为止。 平均时间复杂度: O(n*log(n)) 123456789101112131415161718192021222324252627282930public class Demo &#123; public void quickSort(int arr[], int low, int high) &#123; //pivot:位索引;p_pos:轴值 int pivot, p_pos, i, temp; if (low &lt; high) &#123; p_pos = low; pivot = arr[p_pos]; for (i = low + 1; i &lt;= high; i++) &#123; if (arr[i] &gt; pivot) &#123; p_pos++; temp = arr[p_pos]; arr[p_pos] = arr[i]; arr[i] = temp; &#125; &#125; temp = arr[low]; arr[low] = arr[p_pos]; arr[p_pos] = temp; //分而治之 quickSort(arr, low, p_pos - 1);//排序左半部分 quickSort(arr, p_pos + 1, high);//排序右半部分 &#125; &#125; public static void main(String[] args) &#123; int[] arr = &#123;4, 8, 7, 5, 6, 3, 1&#125;; Demo d = new Demo(); d.quickSort(arr, 0, arr.length - 1); System.out.println(Arrays.toString(arr)); &#125;&#125; 注: 各排序时间复杂度 排序方法 平均情况 最好情况 最坏情况 辅助空间 稳定性 冒泡排序 O(n^2) O(n) O(n^2) O(1) 稳定 选择排序 O(n^2) O(n^2) O(n^2) O(1) 不稳定 插入排序 O(n^2) O(n) O(n^2) O(1) 稳定 希尔排序O(n*log(n))~O(n^2) O(n^1.3) O(n^2) O(1) 不稳定 堆排序 O(nlog(n)) O(nlog(n)) O(n*log(n)) O(1) 不稳定 归并排序 O(nlog(n)) O(nlog(n)) O(n*log(n)) O(n) 稳定 快速排序 O(nlog(n)) O(nlog(n)) O(n^2) O(1) 不稳定","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"初始ElasticSearch集群","slug":"初始ElasticSearch集群","date":"2021-05-08T13:19:59.191Z","updated":"2020-04-29T02:44:38.009Z","comments":true,"path":"31824/","link":"","permalink":"http://tonymua.top/31824/","excerpt":"1.集群管理1.1 集群结构ES通常以集群方式工作，这样做不仅能够提高ES的搜索能力还可以处理大数据搜索的能力，同时也增加了系统的 容错能力及高可用，ES可以实现PB级数据的搜索。","text":"1.集群管理1.1 集群结构ES通常以集群方式工作，这样做不仅能够提高ES的搜索能力还可以处理大数据搜索的能力，同时也增加了系统的 容错能力及高可用，ES可以实现PB级数据的搜索。 下图是ES集群结构的示意图： 从上图总结以下概念： 结点 ES集群由多个服务器组成，每个服务器即为一个Node结点(该服务只部署了一个ES进程)。 分片 当我们的文档量很大时，由于内存和硬盘的限制，同时也为了提高ES的处理能力、容错能力及高可用能力，我们将索引分成若干分片，每个分片可以放在不同的服务器，这样就实现了多个服务器共同对外提供索引及搜索服务。一个搜索请求过来，会分别从各各分片去查询，后将查询到的数据合并返回给用户。 副本 为了提高ES的高可用同时也为了提高搜索的吞吐量，我们将分片复制一份或多份存储在其它的服务器，这样即使当前的服务器挂掉了，拥有副本的服务器照常可以提供服务。 主结点 一个集群中会有一个或多个主结点，主结点的作用是集群管理，比如增加节点，移除节点等，主结点挂掉后ES会重新选一个主结点。 结点转发 每个结点都知道其它结点的信息，我们可以对任意一个结点发起请求，接收请求的结点会转发给其它结点查询数据。 1.2 搭建集群下边的例子实现创建一个2结点的集群，并且索引的分片我们设置2片，每片一个副本。 1.2.1 结点的三个角色主结点：master节点主要用于集群的管理及索引比如新增结点、分片分配、索引的新增和删除等。数据结点： data 节点上保存了数据分片，它负责索引和搜索操作。客户端结点：client 节点仅作为请求客户端存在，client的作用也作为负载均衡器，client 节点不存数据，只是将请求均衡转发到其它结点。 通过下边两项参数来配置结点的功能：node.master: #是否允许为主结点node.data: #允许存储数据作为数据结点node.ingest: #是否允许成为协调节点四种组合方式：master=true，data=true：即是主结点又是数据结点master=false，data=true：仅是数据结点master=true，data=false：仅是主结点，不存储数据master=false，data=false：即不是主结点也不是数据结点，此时可设置ingest为true表示它是一个客户端。 1.2.2 创建结点 1解压elasticsearch-6.2.1.zip 到 F:\\devenv\\elasticsearch\\es-cloud-1\\elasticsearch-6.2.1结点1对外服务的http端口是：9200集群管理端口是9300配置elasticsearch.yml 结点名：xc_node_1elasticsearch.yml内容如下 12345678910111213cluster.name: xuecheng node.name: xc_node_1 network.host: 0.0.0.0 http.port: 9200 transport.tcp.port: 9300 node.master: true node.data: true discovery.zen.ping.unicast.hosts: [\"0.0.0.0:9300\", \"0.0.0.0:9301\"] discovery.zen.minimum_master_nodes: 1 node.ingest: true node.max_local_storage_nodes: 2 path.data: D:\\ElasticSearch\\elasticsearch‐6.2.1‐1\\data path.logs: D:\\ElasticSearch\\elasticsearch‐6.2.1‐1\\logs http.cors.enabled: true http.cors.allow‐origin: /.*/ 启动结点1 1.2.3 创建结点 2解压elasticsearch-6.2.1.zip 到 F:\\devenv\\elasticsearch\\es-cloud-2\\elasticsearch-6.2.1结点2对外服务的http端口是：9201集群管理端口是9302结点名：xc_node_2elasticsearch.yml内容如下 12345678910111213cluster.name: xuecheng node.name: xc_node_2 network.host: 0.0.0.0 http.port: 9201 transport.tcp.port: 9301 node.master: true node.data: true discovery.zen.ping.unicast.hosts: [\"0.0.0.0:9300\", \"0.0.0.0:9301\"] discovery.zen.minimum_master_nodes: 1 node.ingest: true node.max_local_storage_nodes: 2 path.data: D:\\ElasticSearch\\elasticsearch‐6.2.1‐2\\data path.logs: D:\\ElasticSearch\\elasticsearch‐6.2.1‐2\\logs http.cors.enabled: true http.cors.allow‐origin: /.*/ 启动结点2 1.2.4 创建索引库 使用head连上其中一个结点 下边创建索引库，共2个分片，每个分片一个副本。 上图可以看到共有4个分片，其中两个分片是副本。 每个结点安装IK分词器 1.2.5 集群的健康通过访问 GET /_cluster/health 来查看Elasticsearch的集群健康情况。用三种颜色来展示健康状态： green 、 yellow 或者 red 。 green：所有的主分片和副本分片都正常运行。yellow：所有的主分片都正常运行，但有些副本分片运行不正常。red：存在主分片运行不正常。 Get请求：http://localhost:9200/_cluster/health 1.3 测试 创建映射并写入文档连接其中任意一台结点，创建映射写入文档。Post http://localhost:9200/xc_course/doc/3 12345&#123; \"name\": \"spring开发基础\", \"description\": \"spring 在java领域非常流行，java软件开发人员都在用。\", \"studymodel\": \"201001\", \"price\":66.6 &#125; 搜索向其它一个结点发起搜索请求，查询全部数据。 关闭一个结点ES会重新选中一个主结点（前提在配置结点时允许它可以为主结点）此时向活的结点发起搜索请求，仍然正常。 添加一个结点添加结点3，端口设置为： http端口是：9202 集群管理端口是9302 结点名：xc_node_3此结点的配置：node.master: false node.data: true启动结点3，刷新head，下图显示ES将分片分在了3个结点向结点3发起搜索请求： Get： http://127.0.0.1:9202/xc_course/doc/_search 全部数据可被正常搜索到。","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"分布式文件系统 FastDFS研究","slug":"分布式文件系统-FastDFS研究","date":"2021-05-08T13:19:59.190Z","updated":"2020-04-29T02:44:38.051Z","comments":true,"path":"22469/","link":"","permalink":"http://tonymua.top/22469/","excerpt":"1.什么是分布式文件系统1.1 技术应用场景分布式文件系统解决了海量文件存储及传输访问的瓶颈问题，对海量视频的管理、对海量图片的管理等。 1.2 什么是分布式文件系统引用“百度百科”中的描述：","text":"1.什么是分布式文件系统1.1 技术应用场景分布式文件系统解决了海量文件存储及传输访问的瓶颈问题，对海量视频的管理、对海量图片的管理等。 1.2 什么是分布式文件系统引用“百度百科”中的描述： 为什么会有分布文件系统呢？ 分布式文件系统是面对互联网的需求而产生，互联网时代对海量数据如何存储？靠简单的增加硬盘的个数已经满足不了我们的要求，因为硬盘传输速度有限但是数据在急剧增长，另外我们还要要做好数据备份、数据安全等。 采用分布式文件系统可以将多个地点的文件系统通过网络连接起来，组成一个文件系统网络，结点之间通过网络进 行通信，一台文件系统的存储和传输能力有限，我们让文件在多台计算机上存储，通过多台计算机共同传输。如下 图： 好处: 一台计算机的文件系统处理能力扩充到多台计算机同时处理 一台计算机挂了还有另外副本计算机提供数据 每台计算机可以放在不同的地域，这样用户就可以就近访问，提高访问速度 1.3 主流的分布式文件系统(1) NFS ​ NFS是基于UDP/IP协议的应用，其实现主要是采用远程过程调用RPC机制，RPC提供了一组与机器、操作系统以及低层传送协议无关的存取远程文件的操作。RPC采用了XDR的支持。XDR是一种与机器无关的数据描述编码的协议，他以独立与任意机器体系结构的格式对网上传送的数据进行编码和解码，支持在异构系统之间数据的传送。 1）在客户端上映射NFS服务器的驱动器。2）客户端通过网络访问NFS服务器的硬盘完全透明。 (2) GFS ​ GFS是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。它运行于廉价的普通硬件上，并提供容错功能。它可以给大量的用户提供总体性能较高的服务。 1）GFS采用主从结构，一个GFS集群由一个master和大量的chunkserver组成。2）master存储了数据文件的元数据，一个文件被分成了若干块存储在多个chunkserver中。 3）用户从master中获取数据元信息，从chunkserver存储数据。 (3) HDFS 1）HDFS采用主从结构，一个HDFS集群由一个名称结点和若干数据结点组成 名称结点存储数据的元信息，一个完整的数据文件分成若干块存储在数据结点。2）客户端从名称结点获取数据的元信息及数据分块的信息，得到信息客户端即可从数据块来存取数据。 1.4 分布式文件服务提供商1）阿里的OSS2）七牛云存储3）百度云存储 2.什么是FastDFS2.1 FastDSF介绍FastDFS是用c语言编写的一款开源的分布式文件系统，它是由淘宝资深架构师余庆编写并开源。FastDFS专为互联 网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很 容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 为什么要使用fastDFS呢？ 上边介绍的NFS、GFS都是通用的分布式文件系统，通用的分布式文件系统的优点的是开发体验好，但是系统复杂性高、性能一般，而专用的分布式文件系统虽然开发体验性差，但是系统复杂性低并且性能高。FastDFS非常适合存储图片等那些小文件，FastDFS不对文件进行分块，所以它就没有分块合并的开销，FastDFS网络通信采用 socket，通信速度很快。 2.2 FastDSF工作原理2.2.1 FastDSF架构FastDFS架构包括 Tracker server和Storageserver。客户端请求Tracker server进行文件上传、下载，通过Tracker server调度最终由Storage server完成文件上传和下载。 如下图： 1）TrackerTracker Server作用是负载均衡和调度，通过Tracker server在文件上传时可以根据一些策略找到Storage server提 供文件上传服务。可以将tracker称为追踪服务器或调度服务器。 FastDFS集群中的Tracker server可以有多台，Tracker server之间是相互平等关系同时提供服务，Tracker server 不存在单点故障。客户端请求Tracker server采用轮询方式，如果请求的tracker无法提供服务则换另一个tracker。 2）StorageStorage Server作用是文件存储，客户端上传的文件最终存储在Storage服务器上，Storage server没有实现自己 的文件系统而是使用操作系统的文件系统来管理文件。可以将storage称为存储服务器。 Storage集群采用了分组存储方式。storage集群由一个或多个组构成，集群存储总容量为集群中所有组的存储容 量之和。一个组由一台或多台存储服务器组成，组内的Storage server之间是平等关系，不同组的Storage server 之间不会相互通信，同组内的Storage server之间会相互连接进行文件同步，从而保证同组内每个storage上的文件完全一致的。一个组的存储容量为该组内的存储服务器容量最小的那个，由此可见组内存储服务器的软硬件配置最好是一致的。 采用分组存储方式的好处是灵活、可控性较强。比如上传文件时，可以由客户端直接指定上传到的组也可以由 tracker进行调度选择。一个分组的存储服务器访问压力较大时，可以在该组增加存储服务器来扩充服务能力（纵向扩容）。当系统容量不足时，可以增加组来扩充存储容量（横向扩容）。 3）Storage状态收集 Storage server会连接集群中所有的Tracker server，定时向他们报告自己的状态，包括磁盘剩余空间、文件同步 状况、文件上传下载次数等统计信息。 2.2.2 文件上传流程客户端上传文件后存储服务器将文件ID返回给客户端，此文件ID用于以后访问该文件的索引信息。文件索引信息 包括：组名，虚拟磁盘路径，数据两级目录，文件名。 http://192.168.179.101/group1/M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png 组名：文件上传后所在的storage组名称，在文件上传成功后有storage服务器返回，需要客户端自行保存。 虚拟磁盘路径：storage配置的虚拟路径，与磁盘选项store_path*对应。如果配置了store_path0则是M00， 如果配置了store_path1则是M01，以此类推。 数据两级目录：storage服务器在每个虚拟磁盘路径下创建的两级目录，用于存储数据文件。 文件名：与文件上传时不同。是由存储服务器根据特定信息生成，文件名包含：源存储服务器IP地址、文件创 建时间戳、文件大小、随机数和文件拓展名等信息。 2.2.3 文件下载流程tracker根据请求的文件路径即文件ID 来快速定义文件。比如请求下边的文件： http://192.168.179.101/group1/M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png (1) 通过组名tracker能够很快的定位到客户端需要访问的存储服务器组是group1，并选择合适的存储服务器提供客户端访问。(2) 存储服务器根据“文件存储虚拟磁盘路径”和“数据文件两级目录”可以很快定位到文件所在目录，并根据文件名找到客户端需要访问的文件。 3.fastDFS入门3.1 文件上传下载测试3.1.1 搭建环境这里我们使用javaApi测试文件的上传，java版本的fastdfs-client地址在： https://github.com/happyﬁsh100/fastdfs-client-java，参考此工程编写测试用例。 1）创建maven工程 1234567891011121314151617181920212223242526272829&lt;parent&gt; &lt;artifactId&gt;xc-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../xc-framework-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;test-fastdfs&lt;/artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2) 配置文件 在classpath:conﬁg下创建fastdfs-client.properties文件 1234fastdfs.connect_timeout_in_seconds = 5fastdfs.network_timeout_in_seconds = 30fastdfs.charset = UTF-8fastdfs.tracker_servers = 192.168.179.101:22122 3.1.2 文件上传1234567891011121314151617181920212223242526272829//上传文件@Testpublic void testUpload() &#123; try &#123; ClientGlobal.initByProperties(\"config/fastdfs-client.properties\"); System.out.println(\"network_timeout=\"+ClientGlobal.g_network_timeout+\"ms\"); System.out.println(\"charset=\"+ClientGlobal.g_charset); //创建客户端 TrackerClient trackerClient=new TrackerClient(); //连接tracker Server TrackerServer trackerServer = trackerClient.getConnection(); if (trackerServer==null)&#123; System.out.println(\"getConnection return null\"); &#125; //获取一个storage server StorageServer storageServer = trackerClient.getStoreStorage(trackerServer); if (storageServer==null)&#123; System.out.println(\"getStoreStorage return null\"); &#125; //创建一个storage存储客户端 StorageClient1 storageClient1=new StorageClient1(trackerServer,storageServer); NameValuePair[] meta_list=null; //new NameValuePair[0]; String item=\"E:\\\\test.png\"; String fileid=(storageClient1.upload_file1(item,\"png\",meta_list)); System.out.println(\"Upload local file\"+item+\"ok,fileid=\"+fileid); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 3.1.3 文件查询123456789101112131415//查询文件@Testpublic void testQueryFile()&#123; try &#123; ClientGlobal.initByProperties(\"config/fastdfs-client.properties\"); TrackerClient trackerClient=new TrackerClient(); TrackerServer trackerServer=trackerClient.getConnection(); StorageServer storageServer=null; StorageClient storageClient=new StorageClient(trackerServer,storageServer); FileInfo fileInfo = storageClient.query_file_info(\"group1\", \"M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png\"); System.out.println(fileInfo); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 3.1.4 文件下载123456789101112131415161718//下载文件@Testpublic void testDownload() &#123; try &#123; ClientGlobal.initByProperties(\"config/fastdfs-client.properties\"); TrackerClient trackerClient=new TrackerClient(); TrackerServer trackerServer = trackerClient.getConnection(); StorageServer storageServer=null; StorageClient1 storageClient1=new StorageClient1(trackerServer,storageServer); byte[] result = storageClient1.download_file1(\"M00/00/00/wKizZV3s2muAO7pFAACd4a31kFU720.png\"); File file=new File(\"E:/1.png\"); FileOutputStream fileOutputStream=new FileOutputStream(file); fileOutputStream.write(result); fileOutputStream.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125;","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"使用tree命令导出文件夹/文件的目录树","slug":"使用tree命令导出文件夹或文件的目录树","date":"2021-05-08T13:19:59.188Z","updated":"2020-05-01T13:37:12.901Z","comments":true,"path":"shell_tree/","link":"","permalink":"http://tonymua.top/shell_tree/","excerpt":"Windows和Linux都有tree命令，主要功能是创建文件列表，将所有文件以树的形式列出来 1.Windows的tree命令使用tree命令导出windows的文件夹/文件的目录树","text":"Windows和Linux都有tree命令，主要功能是创建文件列表，将所有文件以树的形式列出来 1.Windows的tree命令使用tree命令导出windows的文件夹/文件的目录树 1234TREE [drive:][path] [/F] [/A]/F 显示每个文件夹中文件的名称。（带扩展名）/A 使用 ASCII 字符，而不使用扩展字符。(如果要显示中文，例如 tree /f /A &gt;tree.txt)tree /f &gt; list.txt 将带扩展名的文件目录输出到list.txt文件中 2.Linux的tree命令Linux下的tree就比较强大了，但一般系统并不自带这个命令，需要手动下载安装：sudo apt-get install tree 。 1234567891011121314151617181920-a 显示所有文件和目录。-A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。-C 在文件和目录清单加上色彩，便于区分各种类型。-d 显示目录名称而非内容。-D 列出文件或目录的更改时间。-f 在每个文件或目录之前，显示完整的相对路径名称。-F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上\"*\",\"/\",\"=\",\"@\",\"|\"号。-g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。-i 不以阶梯状列出文件或目录名称。-I 不显示符合范本样式的文件或目录名称。-l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。-n 不在文件和目录清单加上色彩。-N 直接列出文件和目录名称，包括控制字符。-p 列出权限标示。-P 只显示符合范本样式的文件或目录名称。-q 用\"?\"号取代控制字符，列出文件和目录名称。-s 列出文件或目录大小。-t 用文件和目录的更改时间排序。-u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。-x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。 3.测试执行命令行tree /f &gt; tree.txt","categories":[{"name":"shell","slug":"shell","permalink":"http://tonymua.top/categories/shell/"}],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Vue开发常用命令","slug":"Vue开发常用命令","date":"2021-05-08T13:19:59.186Z","updated":"2020-05-28T06:27:34.810Z","comments":true,"path":"Vue_shell/","link":"","permalink":"http://tonymua.top/Vue_shell/","excerpt":"1.创建vue脚手架项目 1vue init webpack 项目名 2.axios 安装axios 1npm install axios --save-dev 配置main.js中引入axios","text":"1.创建vue脚手架项目 1vue init webpack 项目名 2.axios 安装axios 1npm install axios --save-dev 配置main.js中引入axios 123import axios from 'axios';Vue.prototype.$http=axios; 使用axios在需要发送异步请求的位置:123456this.$http.get( \"url\" ) .then(res =&gt; &#123; &#125;); 3.ElementUI 安装ElementUI 1npm i element-ui -S 配置main.js中引入ElementUI 12345import ElementUI from 'element-ui';import 'element-ui/lib/theme-chalk/index.css';//在vue脚手架中使用elementuiVue.use(ElementUI) 4.项目打包 打包在项目根目录中执行如下命令: 1npm run build 注意:vue脚手架打包的项目必须在服务器上运行不能直接双击运行 打包之后当前项目中变化在打包之后项目中出现dist目录,dist目录就是vue脚手架项目生产目录或者说是直接部署目录 与后端合并部署复制dist目录到Java工程resource下的static文件夹,index.html中修改路径 1234&lt;link href=/dist/static/css/app...../&gt;...&lt;script type=text/javascript src=/dist/static/js/ma....&gt;&lt;/script&gt;... 访问项目浏览器访问: http://localhost:8080/dist/index.html","categories":[{"name":"前端","slug":"前端","permalink":"http://tonymua.top/categories/前端/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://tonymua.top/tags/Vue/"}]},{"title":"top K问题的优化解法","slug":"top-K问题的优化解法","date":"2021-05-08T13:19:59.185Z","updated":"2020-04-29T02:44:38.006Z","comments":true,"path":"1060/","link":"","permalink":"http://tonymua.top/1060/","excerpt":"top K问题的优化解法​ 在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。","text":"top K问题的优化解法​ 在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。 100亿数据找出最大的1000个数字 对于海量数据处理，思路基本上是：必须分块处理，然后再合并起来。 1.局部淘汰法​ 用一个容器保存前1000个数，然后将剩余的所有数字一一与容器内的最小数字相比，如果所有后续的元素都比容器内的1000个数还小，那么容器内这个1000个数就是最大1000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O(n+m^2)，其中m为容器的大小。 ​ 这个容器可以用（小顶堆）最小堆来实现。我们知道完全二叉树有几个非常重要的特性，就是假如该二叉树中总共有N个节点，那么该二叉树的深度就是log2N，对于小顶堆来说移动根元素到底部或者移动底部元素到根部只需要log2N，相比N来说时间复杂度优化太多了（1亿的logN值是26-27的一个浮点数）。基本的思路就是先从文件中取出1000个元素构建一个小顶堆数组k，然后依次对剩下的100亿-1000个数字进行遍历m，如果m大于小顶堆的根元素，即k[0]，那么用m取代k[0]，对新的数组进行重新构建组成一个新的小顶堆。这个算法的时间复杂度是O((100亿-1000)log(1000))，即O((N-M)logM)，空间复杂度是M 这个算法优点是性能尚可，空间复杂度低，IO读取比较频繁，对系统压力大。 2.分治法(1) 将100亿个数据分为1000个大分区，每个区1000万个数据 (2) 每个大分区再细分成100个小分区。总共就有1000*100=10万个分区 (3) 计算每个小分区上最大的1000个数 (4) 合并每个大分区细分出来的小分区。每个大分区有100个小分区，我们已经找出了每个小分区的前1000个数。将这100个分区的1000*100个数合并，找出每个大分区的前1000个数 (5) 合并大分区。我们有1000个大分区，上一步已找出每个大分区的前1000个数。我们将这1000*1000个数合并，找出前1000.这1000个数就是所有数据中最大的1000个数 3.Hash法​ 如果这1亿个数据里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的1000个数。","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"http://tonymua.top/tags/算法/"}]},{"title":"SVN, AdminLTE","slug":"SVN, AdminLTE","date":"2021-05-08T13:19:59.184Z","updated":"2020-04-29T06:03:28.172Z","comments":true,"path":"36764/","link":"","permalink":"http://tonymua.top/36764/","excerpt":"1.SVN介绍​ SVN是Subversion的简称，是一个自由开源的版本控制系统。 Subversion将文件存放在中心版本库里，这个版本库很像一个普通的文件服务器，不同的是，它可以记录每一次文 件和目录的修改情况，这样就可以借此将数据恢复到以前的版本，并可以查看数据的更改细节早期版本控制使用的是CVS,后来SVN替代了CVS,随着android兴起，出现Git版本控制工具 1.1 SVN基本概念","text":"1.SVN介绍​ SVN是Subversion的简称，是一个自由开源的版本控制系统。 Subversion将文件存放在中心版本库里，这个版本库很像一个普通的文件服务器，不同的是，它可以记录每一次文 件和目录的修改情况，这样就可以借此将数据恢复到以前的版本，并可以查看数据的更改细节早期版本控制使用的是CVS,后来SVN替代了CVS,随着android兴起，出现Git版本控制工具 1.1 SVN基本概念 问题: 怎样让系统允许用户共享信息，而不会让他们因意外而互相干扰？ 复制-修改-合并方案(Subversion默认的模式) ​ 在这种模型里，每一个客户读取项目配置库建立一个私有工作副本——版本库中文件和目录的本地映射。用户并行工作，修改各自的工作副本，终，各个私有的复制合并在一起，成为终的版本，这种系统通常可以辅助合并操 作，但是终要靠人工去确定正误。 *锁定-修改-解锁方案 * 在这样的模型里，在一个时间段里配置库的一个文件只允许被一个人修改。 此模式不适合软件开发这种工作。 2.IDEA下SVN使用​ SVN是一种集中式管理代码的版本控制系统，原理就是把代码都保存到一个固定的位置（仓库），每次从这个位置 拷贝更新代码，进行编辑；再把修改后的代码提交到该目录中。多人协作开发也是如此。因此需要一个类似Oracle 或者Mysql的服务器用于保存和管理库文件（要保存的代码等文件）的服务端——VisualSVN Server。还需要一个 用户的操作端，用于提交更新检出代码，常用的有idea的Svn插件，以及TortoiseSVN（小乌龟）。SubVersion 官网：http://subversion.apache.org/ 2.1 IDEA下svn配置前提是我们的电脑上已经安装了TortoiseSVN. 1.Update Project 更新项目 2.Commit changes 提交项目上所有变化文件 3.Compare with the Same Repository Version 当前文件与服务器上该文件通版本的内容进行比较。如果当前编辑 的文件没有修改，则是灰色不可点击。 4.Show history 显示当前文件的历史记录 5.Revert 还原当前被修改的文件到违背修改的版本状态下 1.Local Changes 本地修改过的文件都会出现在这里 2.Repository svn仓库所有提交记录 3.Incoming 本地还没有更新的别人提交的代码 2.2 IDEA下SVN使用2.2.1 share project 2.2.2 checkout 2.2.3 add commit update 2.2.4 ignor 2.2.5 解决冲突3.SVN规范3.1 SVN目录规范在visualSVN中创建仓库时，可以选择svn目录结构 ​ Trunk 主干目录，此目录下的文件为基准文件 ​ Branches 用于开发的分支目录 Tags 用于发布的版本目录 ​ 假设有一个项目OA,我们完成了1.0版本，这时就可以打一个tags 后续我们在OA项目上添加一个新的模块(及时通讯),我们就可以开一个分支,又有一个公司需要在我们OA基础上添加 财务管理模块，我们又可以打一个分支.我们后续针对OA的1.0版本在升级，我们不需要原来附加功能,就可以在原来的主干上继续开发，形成OA2.0版本， 开发完成后就可以在打一个tags 3.2 分支与标记分支的定义规则: Project name+日期时间+功能点 Tags的定义规则 Project name+版本号 版本号定义为三段数字 编号 xxx.xxx.xxx 第一个:革命性的产品升级版 第二个:新功能版 第三个:修正bug Tags一般是只读，它代表的是发布的版本，所以我们不要进行改变。 3.3 主干与分支或标记的合并主干合并到分支 首先保证主干是新的(先update)，在分支这边进行操作 4.AdminLTE快速入门​ AdminLTE是一款建立在bootstrap和jquery之上的开源的模板主题工具，它提供了一系列响应的、 可重复使用的组件，并内置了多个模板页面；同时自适应多种屏幕分辨率，兼容PC和移动端。通 过AdminLTE，我们可以快速的创建一个响应式的Html5网站。AdminLTE框架在网页架构与设计 上，有很大的辅助作用，尤其是前端架构设计师，用好AdminLTE 不但美观，而且可以免去写很大 CSS与JS的工作量。 ​ 结构介绍 bower_components：存放了这个框架依赖的其他框架，如bootstrap，jquery、字体样式、图标样式等。 build： 编译前的源文件目录 dist：编译后的静态资源目录 pages：目录下是一些示例页面 plugins：目录存放依赖的插件 starter.html ：是 AdminLTE 建议用来作为起点的参考示例 index.html：是AdminLTE中比较完善的展示品，用于参考、借鉴。","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"SSM框架整合","slug":"SSM框架整合","date":"2021-05-08T13:19:59.182Z","updated":"2020-04-29T02:44:38.034Z","comments":true,"path":"10555/","link":"","permalink":"http://tonymua.top/10555/","excerpt":"1.SSM 整合1.1 环境准备1.1.1 导入坐标并建立依赖","text":"1.SSM 整合1.1 环境准备1.1.1 导入坐标并建立依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.9&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.9&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.1.2编写实体类1234567891011121314151617181920212223242526272829303132333435363738public class Account implements Serializable &#123; private Integer id; private String name; private Double money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; 1.1.3 编写业务层接口12345678public interface AccountService &#123; //查询所有账户 public List&lt;Account&gt; findAll(); //保存账户信息 public void saveAccount(Account account);&#125; 1.2 整合步骤springmvc.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--开启注解扫描，只扫描Controller注解--&gt; &lt;context:component-scan base-package=\"controller\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--配置视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"internalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--过滤静态资源--&gt; &lt;mvc:resources location=\"/css/\" mapping=\"/css/**\" /&gt; &lt;mvc:resources location=\"/images/\" mapping=\"/images/**\" /&gt; &lt;mvc:resources location=\"/js/\" mapping=\"/js/**\" /&gt; &lt;!--开启SpringMVC注解的支持--&gt; &lt;mvc:annotation-driven/&gt;&lt;/beans&gt; web.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--配置前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--加载springmvc.xml文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--启动服务器,创建该servlet--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--解决中文乱码的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!--设定编码集--&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置Spring的监听器,默认只加载WEB-INF目录下的applicationContext.xml配置文件--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--设置配置文件的路径--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; applicationContext.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--开启注解的扫描，希望处理service和dao，controller不需要Spring框架去处理--&gt; &lt;context:component-scan base-package=\"dao,service\"&gt; &lt;!--配置哪些注解不扫描--&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--spring整合MyBatis框架--&gt; &lt;!--配置连接池--&gt; &lt;bean class=\"com.mchange.v2.c3p0.ComboPooledDataSource\" id=\"dataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///ssm\"/&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"547717253\"/&gt; &lt;/bean&gt; &lt;!--配置SqlSessionFactory工厂--&gt; &lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置AccountDao接口所在的包--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\" id=\"mapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"dao\"/&gt; &lt;/bean&gt; &lt;!--配置Spring框架声明式事务管理--&gt; &lt;!--配置事务管理器--&gt; &lt;bean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务通知--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;tx:method name=\"*\" isolation=\"DEFAULT\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置AOP增强--&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(* service.impl.*ServiceImpl.*(..))\"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; AccountDao 123456789101112@Repositorypublic interface AccountDao &#123; //查询所有账户 @Select(\"select * from account\") public List&lt;Account&gt; findAll(); //保存账户信息 @Insert(\"insert into account(name,money) values(#&#123;name&#125;,#&#123;money&#125;)\") public void saveAccount(Account account);&#125; AccountServiceImpl 1234567891011121314151617@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public List&lt;Account&gt; findAll() &#123; System.out.println(\"业务层:查询所有账户...\"); return accountDao.findAll(); &#125; @Override public void saveAccount(Account account) &#123; System.out.println(\"业务层:保存账户...\"); accountDao.saveAccount(account); &#125;&#125; AccountController 12345678910111213141516171819202122@Controller@RequestMapping(\"/account\")public class AccountController &#123; @Autowired private AccountService accountService; @RequestMapping(\"/findAll\") public String findAll(Model model)&#123; System.out.println(\"表现层:查询所有账户...\"); //调用service的方法 List&lt;Account&gt; accounts = accountService.findAll(); model.addAttribute(\"accounts\",accounts); return \"list\"; &#125; @RequestMapping(\"/save\") public void save(Account account, HttpServletRequest request,HttpServletResponse response)throws Exception&#123; System.out.println(\"表现层:保存账户...\"); accountService.saveAccount(account); response.sendRedirect(request.getContextPath()+\"/account/findAll\"); return; &#125;&#125; index.jsp 12345678910111213141516&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;测试查询&lt;/h3&gt; &lt;a href=\"account/findAll\"&gt;findAll测试&lt;/a&gt; &lt;h3&gt;测试保存&lt;/h3&gt; &lt;form action=\"account/save\" method=\"post\"&gt; 姓名:&lt;input type=\"text\" name=\"name\"&gt;&lt;br&gt; 金额:&lt;input type=\"text\" name=\"money\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"保存\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; list.jsp 1234567891011121314&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;%@taglib prefix=\"c\" uri=\"http://java.sun.com/jsp/jstl/core\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;查询所有账户信息!&lt;/h3&gt; &lt;c:forEach items=\"$&#123;accounts&#125;\" var=\"account\"&gt; $&#123;account.name&#125; &lt;/c:forEach&gt;&lt;/body&gt;&lt;/html&gt;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SSM整合后台管理项目总结(二.SSM权限操作(用户与角色))","slug":"SSM整合后台管理项目总结(二.SSM权限操作(用户与角色))","date":"2021-05-08T13:19:59.180Z","updated":"2020-04-29T02:44:38.077Z","comments":true,"path":"60716/","link":"","permalink":"http://tonymua.top/60716/","excerpt":"1.Spring Security概述1.1 Spring Security介绍​ Spring Security 的前身是 Acegi Security ，是 Spring 项目组中用来提供安全认证服务的框架。 (https://projects.spring.io/spring-security/) Spring Security 为基于J2EE企业应用软件提供了全面安全服务。特别 是使用领先的J2EE解决方案-Spring框架开发的企业软件项目。人们使用Spring Security有很多种原因，不过通常吸 引他们的是在J2EE Servlet规范或EJB规范中找不到典型企业应用场景的解决方案。 特别要指出的是他们不能再 WAR 或 EAR 级别进行移植。这样，如果你更换服务器环境，就要，在新的目标环境进行大量的工作，对你的应用 系统进行重新配 置安全。使用Spring Security 解决了这些问题，也为你提供很多有用的，完全可以指定的其他安 全特性。 安全包括两个主要操作。 ​ “认证”，是为用户建立一个他所声明的主体。主题一般式指用户，设备或可以在你系 统中执行动作的其他系 统。 ​ “授权”指的是一个用户能否在你的应用中执行某个操作，在到达授权判断之前，身份的主题已经由 身份验证 过程建立了。","text":"1.Spring Security概述1.1 Spring Security介绍​ Spring Security 的前身是 Acegi Security ，是 Spring 项目组中用来提供安全认证服务的框架。 (https://projects.spring.io/spring-security/) Spring Security 为基于J2EE企业应用软件提供了全面安全服务。特别 是使用领先的J2EE解决方案-Spring框架开发的企业软件项目。人们使用Spring Security有很多种原因，不过通常吸 引他们的是在J2EE Servlet规范或EJB规范中找不到典型企业应用场景的解决方案。 特别要指出的是他们不能再 WAR 或 EAR 级别进行移植。这样，如果你更换服务器环境，就要，在新的目标环境进行大量的工作，对你的应用 系统进行重新配 置安全。使用Spring Security 解决了这些问题，也为你提供很多有用的，完全可以指定的其他安 全特性。 安全包括两个主要操作。 ​ “认证”，是为用户建立一个他所声明的主体。主题一般式指用户，设备或可以在你系 统中执行动作的其他系 统。 ​ “授权”指的是一个用户能否在你的应用中执行某个操作，在到达授权判断之前，身份的主题已经由 身份验证 过程建立了。 ​ 这些概念是通用的，不是Spring Security特有的。在身份验证层面，Spring Security广泛支持各种身份验证模式， 这些验证模型绝大多数都由第三方提供，或则正在开发的有关标准机构提供的，例如 Internet Engineering Task Force.作为补充，Spring Security 也提供了自己的一套验证功能。 ​ Spring Security 目前支持认证一体化如下认证技术： HTTP BASIC authentication headers (一个基于IEFT RFC 的 标准) HTTP Digest authentication headers (一个基于IEFT RFC 的标准) HTTP X.509 client certiﬁcate exchange (一个基于IEFT RFC 的标准) LDAP (一个非常常见的跨平台认证需要做法，特别是在大环境) Form-based authentication (提供简单用户接口的需求) OpenID authentication Computer Associates Siteminder JA-SIG Central Authentication Service (CAS，这是一个流行的开源单点登录系统) Transparent authentication context propagation for Remote Method Invocation and HttpInvoker (一个Spring远程调用协议) Maven依赖 1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-taglibs&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; 1.2 Spring Security使用数据库认证​ 在Spring Security中如果想要使用数据进行认证操作，有很多种操作方式，这里我们介绍使用UserDetails、 UserDetailsService来完成操作。 ​ UserDetails是一个接口，我们可以认为UserDetails作用是于封装当前进行认证的用户信息，但由于其是一个 接口，所以我们可以对其进行实现，也可以使用Spring Security提供的一个UserDetails的实现类User来完成 操作 2.用户管理2.1 用户登录web.xml 12345678910111213&lt;!-- 配置加载类路径的配置文件 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:applicationContext.xml,classpath*:spring-security.xml&lt;/param-value&gt; &lt;/context-param&gt;&lt;filter&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;springSecurityFilterChain&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; spring-security.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:security=\"http://www.springframework.org/schema/security\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/security http://www.springframework.org/schema/security/spring-security.xsd\"&gt; &lt;!-- 配置不拦截的资源 --&gt; &lt;security:http pattern=\"/login.jsp\" security=\"none\"/&gt; &lt;security:http pattern=\"/failer.jsp\" security=\"none\"/&gt; &lt;security:http pattern=\"/css/**\" security=\"none\"/&gt; &lt;security:http pattern=\"/img/**\" security=\"none\"/&gt; &lt;security:http pattern=\"/plugins/**\" security=\"none\"/&gt; &lt;!-- 配置具体的规则 auto-config=\"true\" 不用自己编写登录的页面，框架提供默认登录页面 use-expressions=\"false\" 是否使用SPEL表达式（没学习过） --&gt; &lt;security:http auto-config=\"true\" use-expressions=\"false\"&gt; &lt;!-- 配置具体的拦截的规则 pattern=\"请求路径的规则\" access=\"访问系统的人，必须有ROLE_USER的角色\" --&gt; &lt;security:intercept-url pattern=\"/**\" access=\"ROLE_USER,ROLE_ADMIN\"/&gt; &lt;!-- 定义跳转的具体的页面 --&gt; &lt;security:form-login login-page=\"/login.jsp\" login-processing-url=\"/login.do\" default-target-url=\"/index.jsp\" authentication-failure-url=\"/failer.jsp\" authentication-success-forward-url=\"/pages/main.jsp\" /&gt; &lt;!-- 关闭跨域请求 --&gt; &lt;security:csrf disabled=\"true\"/&gt; &lt;!-- 退出 --&gt; &lt;security:logout invalidate-session=\"true\" logout-url=\"/logout.do\" logout-success-url=\"/login.jsp\"/&gt; &lt;/security:http&gt; &lt;!-- 切换成数据库中的用户名和密码 --&gt; &lt;security:authentication-manager&gt; &lt;security:authentication-provider user-service-ref=\"userService\"&gt; &lt;!-- 配置加密的方式--&gt; &lt;security:password-encoder ref=\"passwordEncoder\"/&gt; &lt;/security:authentication-provider&gt; &lt;/security:authentication-manager&gt; &lt;!-- 配置加密类 --&gt; &lt;bean id=\"passwordEncoder\" class=\"org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder\"/&gt; &lt;!-- 提供了入门的方式，在内存中存入用户名和密码 &lt;security:authentication-manager&gt; &lt;security:authentication-provider&gt; &lt;security:user-service&gt; &lt;security:user name=\"admin\" password=\"&#123;noop&#125;admin\" authorities=\"ROLE_USER\"/&gt; &lt;/security:user-service&gt; &lt;/security:authentication-provider&gt; &lt;/security:authentication-manager&gt; --&gt;&lt;/beans&gt; UserServiceImpl 1234567891011121314151617181920@Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; UserInfo userInfo=null; try &#123; userInfo= userDao.findByUsername(username); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //处理自己的用户对象封装成UserDetails User user=new User(userInfo.getUsername(),userInfo.getPassword(),userInfo.getStatus()==0?false:true,true,true,true,getAuthority(userInfo.getRoles())); return user; &#125; //作用就是返回一个List集合，集合中装入的是角色描述 public List&lt;SimpleGrantedAuthority&gt; getAuthority(List&lt;Role&gt; roles)&#123; List&lt;SimpleGrantedAuthority&gt; list=new ArrayList&lt;SimpleGrantedAuthority&gt;(); for (Role role:roles)&#123; list.add(new SimpleGrantedAuthority(\"ROLE_\"+role.getRoleName())); &#125; return list; &#125; UserDao 1234567891011@Select(\"select * from users where username=#&#123;username&#125;\") @Results(&#123; @Result(id = true, property = \"id\", column = \"id\"), @Result(property = \"username\", column = \"username\"), @Result(property = \"email\", column = \"email\"), @Result(property = \"password\", column = \"password\"), @Result(property = \"phoneNum\",column = \"phoneNum\"), @Result(property = \"status\",column = \"status\"), @Result(property = \"roles\",column = \"id\",javaType = List.class,many = @Many(select = \"dao.RoleDao.findRoleByUserId\")) &#125;) public UserInfo findByUsername(String username) throws Exception; RoleDao.findRoleByUserId 12@Select(\"select * from role where id in(select roleId from users_role where userId=#&#123;userId&#125;)\") public List&lt;Role&gt; findRoleByUserId(String userId)throws Exception; 2.2 用户退出使用spring security完成用户退出，非常简单 spring-security.xml 12&lt;!-- 退出 --&gt; &lt;security:logout invalidate-session=\"true\" logout-url=\"/logout.do\" logout-success-url=\"/login.jsp\"/&gt; jsp 1&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/logout.do\" class=\"btn btn-default btn-flat\"&gt;注销&lt;/a&gt; 2.3 用户查询UserController 12345678@RequestMapping(\"/findAll.do\") public ModelAndView findAll()throws Exception&#123; ModelAndView modelAndView=new ModelAndView(); List&lt;UserInfo&gt; users=userService.findAll(); modelAndView.addObject(\"userList\",users); modelAndView.setViewName(\"user-list\"); return modelAndView; &#125; UserDao 12@Select(\"select * from users\") List&lt;UserInfo&gt; findAll()throws Exception; 2.4 用户添加UserController 12345@RequestMapping(\"/save.do\")public String save(UserInfo userInfo)throws Exception&#123; userService.save(userInfo); return \"redirect:findAll.do\";&#125; 添加用户时，我们需要对用户密码进行加密 spring-security.xml 12&lt;!-- 配置加密类 --&gt; &lt;bean id=\"passwordEncoder\" class=\"org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder\"/&gt; 加密以后的的登录问题 spring-security.xml 123456&lt;security:authentication-manager&gt; &lt;security:authentication-provider user-service-ref=\"userService\"&gt; &lt;!-- 配置加密的方式--&gt; &lt;security:password-encoder ref=\"passwordEncoder\"/&gt; &lt;/security:authentication-provider&gt;&lt;/security:authentication-manager&gt; UserServiceImpl 123456789101112131415@Service(\"userService\")@Transactionalpublic class UserServiceImpl implements UserService &#123; @Autowired private UserDao userDao; @Autowired private BCryptPasswordEncoder bCryptPasswordEncoder; @Override public void save(UserInfo userInfo) throws Exception &#123; //对密码进行加密处理 userInfo.setPassword(bCryptPasswordEncoder.encode(userInfo.getPassword())); userDao.save(userInfo); &#125;&#125; UserDao 12@Insert(\"insert into users(email,username,password,phoneNum,status) values(#&#123;email&#125;,#&#123;username&#125;,#&#123;password&#125;,#&#123;phoneNum&#125;,#&#123;status&#125;)\") void save(UserInfo userInfo)throws Exception; 2.5 用户详情UserController 12345678@RequestMapping(\"/findById.do\") public ModelAndView findById(String id)throws Exception&#123; ModelAndView modelAndView=new ModelAndView(); UserInfo userInfo=userService.findById(id); modelAndView.addObject(\"user\",userInfo); modelAndView.setViewName(\"user-show\"); return modelAndView; &#125; UserDao 12345678910@Select(\"select * from users where id=#&#123;id&#125;\")@Results(&#123; @Result(id = true, property = \"id\", column = \"id\"), @Result(property = \"username\", column = \"username\"), @Result(property = \"email\", column = \"email\"), @Result(property = \"password\", column = \"password\"), @Result(property = \"phoneNum\",column = \"phoneNum\"), @Result(property = \"status\",column = \"status\"), @Result(property = \"roles\",column = \"id\",javaType = List.class,many = @Many(select = \"dao.RoleDao.findRoleByUserId\"))&#125;)UserInfo findById(String id)throws Exception; RoleDao.findRoleByUserId 12345678@Select(\"select * from role where id in(select roleId from users_role where userId=#&#123;userId&#125;)\") @Results(&#123; @Result(id = true, property = \"id\", column = \"id\"), @Result(property = \"roleName\", column = \"roleName\"), @Result(property = \"roleDesc\", column = \"roleDesc\"), @Result(property = \"permissions\", column =\"id\",javaType = List.class,many =@Many(select =\"dao.PermissionDao.findPermissionByRoleId\" )) &#125;) public List&lt;Role&gt; findRoleByUserId(String userId) throws Exception; PermissionDao.findPermissionByRoleId 12@Select(\"select * from permission where id in(select permissionId from role_permission where roleId=#&#123;id&#125;)\")public List&lt;Permission&gt; findPermissionByRoleId(String id)throws Exception; ​ 角色管理(角色查询,角色添加)及资源权限管理(资源权限查询,资源权限添加)与上述流程大同小异就不再一一赘述了. 3.权限关联与控制3.1 用户角色关联UserController.findUserByIdAndAllRole 此方法用于查找要操作的用户及可以添加的角色，参数是要操作的用户id 123456789101112@RequestMapping(\"/findUserByIdAndAllRole.do\")public ModelAndView findUserByIdAndAllRole(@RequestParam(name = \"id\",required = true) String userId)throws Exception&#123; //1.根据用户id查询用户 UserInfo userInfo = userService.findById(userId); //2.根据用户id查询可以添加的角色 List&lt;Role&gt; otherRoles=userService.findOtherRoles(userId); ModelAndView modelAndView=new ModelAndView(); modelAndView.addObject(\"user\",userInfo); modelAndView.addObject(\"roleList\",otherRoles); modelAndView.setViewName(\"user-role-add\"); return modelAndView;&#125; UserController.addRoleToUser 此方法用于在用户与角色之间建立关系，参数userId代表要操作的用户id,参数ids代表的是角色id数组 123456//给用户添加角色@RequestMapping(\"/addRoleToUser.do\")public String addRoleToUser(@RequestParam(name = \"userId\",required = true)String userId,@RequestParam(name = \"ids\",required = true)String[] roleIds)throws Exception&#123; userService.addRoleToUser(userId,roleIds); return \"redirect:findAll.do\";&#125; UserServiceImpl 12345678910111213141516@Overridepublic UserInfo findById(String id) throws Exception &#123; return userDao.findById(id);&#125;@Overridepublic List&lt;Role&gt; findOtherRoles(String userId) throws Exception &#123; return userDao.findOtherRoles(userId);&#125;@Overridepublic void addRoleToUser(String userId, String[] roleIds) throws Exception &#123; for (String roleId:roleIds)&#123; userDao.addRoleToUser(userId,roleId); &#125;&#125; UserDao 12345678910111213141516@Select(\"select * from users where id=#&#123;id&#125;\")@Results(&#123; @Result(id = true, property = \"id\", column = \"id\"), @Result(property = \"username\", column = \"username\"), @Result(property = \"email\", column = \"email\"), @Result(property = \"password\", column = \"password\"), @Result(property = \"phoneNum\",column = \"phoneNum\"), @Result(property = \"status\",column = \"status\"), @Result(property = \"roles\",column = \"id\",javaType = List.class,many = @Many(select = \"dao.RoleDao.findRoleByUserId\"))&#125;)UserInfo findById(String id)throws Exception;@Select(\"select * from role where id not in(select roleId from users_role where userId=#&#123;userId&#125;)\")List&lt;Role&gt; findOtherRoles(String userId)throws Exception;@Insert(\"insert into users_role(userId,roleId)values(#&#123;userId&#125;,#&#123;roleId&#125;)\")void addRoleToUser(@Param(\"userId\") String userId, @Param(\"roleId\") String roleId)throws Exception; 3.2 角色权限关联 (与用户角色关联类似)3.3 服务器端方法级权限控制​ 在服务器端我们可以通过Spring security提供的注解对方法来进行权限控制。Spring Security在方法的权限控制上 支持三种类型的注解，JSR-250注解、@Secured注解和支持表达式的注解，这三种注解默认都是没有启用的，需要 单独通过global-method-security元素的对应属性进行启用 3.3.1 JSR-250注解 @RolesAllowed表示访问对应方法时所应该具有的角色 示例： @RolesAllowed({“USER”, “ADMIN”}) 该方法只要具有”USER”, “ADMIN”任意一种权限就可以访问。这里可以省 略前缀ROLE_，实际的权限可能是ROLE_ADMIN @PermitAll表示允许所有的角色进行访问，也就是说不进行权限控制 @DenyAll是和PermitAll相反的，表示无论什么角色都不能访问 3.3.2 支持表达式的注解 @PreAuthorize 在方法调用之前,基于表达式的计算结果来限制对方法的访问 示例： @PreAuthorize(“#userId == authentication.principal.userId or hasAuthority(‘ADMIN’)”) ​ void changePassword(@P(“userId”) long userId ){ } 这里表示在changePassword方法执行之前，判断方法参数userId的值是否等于principal中保存的当前用户的 userId，或者当前用户是否具有ROLE_ADMIN权限，两种符合其一，就可以访问该方法。 @PostAuthorize 允许方法调用,但是如果表达式计算结果为false,将抛出一个安全性异常 示例： @PostAuthorize ​ User getUser(“returnObject.userId == authentication.principal.userId or hasPermission(returnObject, ‘ADMIN’)”); @PostFilter 允许方法调用,但必须按照表达式来过滤方法的结果 @PreFilter 允许方法调用,但必须在进入方法之前过滤输入值 3.3.3 @Secured注解 @Secured注解标注的方法进行权限控制的支持，其值默认为disabled。 示例： @Secured(“IS_AUTHENTICATED_ANONYMOUSLY”) ​ public Account readAccount(Long id); ​ @Secured(“ROLE_TELLER”) 3.4 页面端标签控制权限3.4.1 导入maven导入 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-taglibs&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt;&lt;/dependency&gt; 页面导入 1&lt;%@taglib prefix=\"security\" uri=\"http://www.springframework.org/security/tags\" %&gt; 3.4.2.常用标签​ 在jsp中我们可以使用以下三种标签，其中authentication代表的是当前认证对象，可以获取当前认证对象信息，例 如用户名。其它两个标签我们可以用于权限控制 authentication 1&lt;security:authentication property=\"\" htmlEscape=\"\" scope=\"\" var=\"\"/&gt; property：只允许指定Authentication所拥有的属性，可以进行属性的级联获取，如“principal.username”， 不允许直接通过方法进行调用 htmlEscape：表示是否需要将html进行转义。默认为true。 scope：与var属性一起使用，用于指定存放获取的结果的属性名的作用范围，默认我pageContext。Jsp中拥 有的作用范围都进行进行指定 var：用于指定一个属性名，这样当获取到了authentication的相关信息后会将其以var指定的属性名进行存 放，默认是存放在pageConext中 1&lt;security:authentication property=\"principal.username\"/&gt; authorize authorize是用来判断普通权限的，通过判断用户是否具有对应的权限而控制其所包含内容的显示 1&lt;security:authorize access=\"\" method=\"\" url=\"\" var=\"\"&gt;&lt;/security:authorize&gt; access：需要使用表达式来判断权限，当表达式的返回结果为true时表示拥有对应的权限 method：method属性是配合url属性一起使用的，表示用户应当具有指定url指定method访问的权限， method的默认值为GET，可选值为http请求的7种方法 url：url表示如果用户拥有访问指定url的权限即表示可以显示authorize标签包含的内容 var：用于指定将权限鉴定的结果存放在pageContext的哪个属性中 123456&lt;security:authorize access=\"hasRole('ADMIN')\"&gt;&lt;li id=\"system-setting\"&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/user/findAll.do\"&gt; &lt;i class=\"fa fa-circle-o\"&gt;&lt;/i&gt; 用户管理&lt;/a&gt;&lt;/li&gt;&lt;/security:authorize&gt; 12345 &lt;security:http auto-config=\"true\" use-expressions=\"false\"&gt; &lt;!-- 配置具体的拦截的规则 pattern=\"请求路径的规则\" access=\"访问系统的人，必须有ROLE_USER的角色\" --&gt; &lt;security:intercept-url pattern=\"/**\" access=\"ROLE_USER,ROLE_ADMIN\"/&gt;....... &lt;/security:http&gt; 此时use-expression=”false”,若想在jsp页面使用表达式(hasRolr(‘ADMIN’)),需要在spring-security.xml中添加 1&lt;bean class=\"org.springframework.security.web.access.expression.DefaultWebSecurityExpressionHandler\" id=\"expressionHandler\"/&gt; accesscontrollist ​ accesscontrollist标签是用于鉴定ACL权限的。其一共定义了三个属性：hasPermission、domainObject和var， 其中前两个是必须指定的 1&lt;security:accesscontrollist hasPermission=\"\" domainObject=\"\" var=\"\"&gt;&lt;/security:accesscontrollist&gt; hasPermission：hasPermission属性用于指定以逗号分隔的权限列表 domainObject：domainObject用于指定对应的域对象 var：var则是用以将鉴定的结果以指定的属性名存入pageContext中，以供同一页面的其它地方使用","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"SSM整合后台管理项目总结(三.AOP日志)","slug":"SSM整合后台管理项目总结(三.AOP日志)","date":"2021-05-08T13:19:59.179Z","updated":"2020-04-29T02:44:37.937Z","comments":true,"path":"40021/","link":"","permalink":"http://tonymua.top/40021/","excerpt":"1.基于AOP日志处理创建切面类处理日志LogAop","text":"1.基于AOP日志处理创建切面类处理日志LogAop 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Component@Aspectpublic class LogAop &#123; @Autowired private HttpServletRequest request; @Autowired private SysLogService sysLogService; private Date visitTime; //开始时间 private Class aClass; //访问的类 private Method method; //访问的方法 //前置通知,获取开始时间,执行的是哪一个类,哪一个方法 @Before(\"execution(* controller.*.*(..))\") public void doBefore(JoinPoint joinPoint) throws NoSuchMethodException &#123; visitTime = new Date(); //访问时间 aClass = joinPoint.getTarget().getClass(); //获取访问的类 String methodName = joinPoint.getSignature().getName(); //获取访问的方法的名称 Object[] args = joinPoint.getArgs(); //获取访问的方法的参数 if (args == null || args.length == 0) &#123; method = aClass.getMethod(methodName); //只能获取无参数方法 &#125; else &#123; Class[] classArgs = new Class[args.length]; for (int i = 0; i &lt; args.length; i++) &#123; classArgs[i] = args[i].getClass(); //有参数，就将args中所有元素遍历，获取对应的Class,装入到一个Class[] &#125; aClass.getMethod(methodName, classArgs); //获取有参数方法 &#125; &#125; //后置通知 @After(\"execution(* controller.*.*(..))\") public void doAfter(JoinPoint joinPoint) throws Exception &#123; long time = new Date().getTime() - visitTime.getTime(); //获取访问时长 //获取url String url = \"\"; if (aClass != null &amp;&amp; method != null &amp;&amp; aClass != LogAop.class) &#123; //1.获取类上的@RequestMapping(\"/xxx\") Annotation classAnnotation = (RequestMapping) aClass.getAnnotation(RequestMapping.class); if (classAnnotation != null) &#123; String[] classValue = ((RequestMapping) classAnnotation).value(); //2.获取方法上的@RequestMapping(\"/xxx\") RequestMapping methodAnnotation = method.getAnnotation(RequestMapping.class); if (methodAnnotation != null) &#123; String[] methodValue = methodAnnotation.value(); url = classValue[0] + methodValue[0]; //获取ip String ip = request.getRemoteAddr(); //可以通过securityContext获取，也可以从request.getSession中获取 SecurityContext context = SecurityContextHolder.getContext(); //从上下文获取当前登录用户 User user = (User) context.getAuthentication().getPrincipal(); String username = user.getUsername(); //将日志相关信息封装到SysLog对象 SysLog sysLog = new SysLog(); sysLog.setExecutionTime(time); sysLog.setIp(ip); sysLog.setMethod(\"[类名] \" + aClass.getName() + \"[方法名] \" + method.getName()); sysLog.setUrl(url); sysLog.setUsername(username); sysLog.setVisitTime(visitTime); //调用Service，调用dao将sysLog insert数据库 sysLogService.save(sysLog); &#125; &#125; &#125; &#125;&#125; SysLogServiceImpl 1234567891011@Service@Transactionalpublic class SysLogServiceImpl implements SysLogService &#123; @Autowired private SysLogDao sysLogDao; @Override public void save(SysLog sysLog) throws Exception &#123; sysLogDao.save(sysLog); &#125;&#125; SysLogDao 12345@Repositorypublic interface SysLogDao &#123; @Insert(\"insert into syslog(visitTime,username,ip,url,executionTime,method) values(#&#123;visitTime&#125;,#&#123;username&#125;,#&#123;ip&#125;,#&#123;url&#125;,#&#123;executionTime&#125;,#&#123;method&#125;)\") public void save(SysLog sysLog)throws Exception;&#125; 2.查询AOP日志SysLogController123456789101112131415@Controller@RequestMapping(\"/sysLog\")public class SysLogController &#123; @Autowired private SysLogService sysLogService; @RequestMapping(\"/findAll.do\") public ModelAndView findAll()throws Exception&#123; ModelAndView modelAndView=new ModelAndView(); List&lt;SysLog&gt; sysLogs=sysLogService.findAll(); modelAndView.addObject(\"sysLogs\",sysLogs); modelAndView.setViewName(\"syslog-list\"); return modelAndView; &#125;&#125; SysLogServiceImpl 1234567891011@Service@Transactionalpublic class SysLogServiceImpl implements SysLogService &#123; @Autowired private SysLogDao sysLogDao; @Override public List&lt;SysLog&gt; findAll() throws Exception &#123; return sysLogDao.findAll(); &#125;&#125; SysLogDao 12345@Repositorypublic interface SysLogDao &#123; @Select(\"select * from syslog\") List&lt;SysLog&gt; findAll()throws Exception;&#125; 注意 ​ 查询出的页面所显示的访问时间需要进行转换 domain.SysLog 123456public String getVisitTimeStr() &#123; if (visitTime!=null)&#123; visitTimeStr= DateUtils.date2String(visitTime,\"yyyy-MM-dd HH:mm:ss\"); &#125; return visitTimeStr;&#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"SSM整合后台管理项目总结(一.产品操作与订单操作)","slug":"SSM整合后台管理项目总结(一.产品操作与订单操作)","date":"2021-05-08T13:19:59.178Z","updated":"2020-04-29T02:44:38.124Z","comments":true,"path":"50152/","link":"","permalink":"http://tonymua.top/50152/","excerpt":"SSM 环境搭建与产品操作1.环境准备1.1 数据库与表结构​ 数据库我们使用Oracle Oracle 为每个项目创建单独user，oracle数据表存放在表空间下，每个用户有独立表空间 ​ 对象权限是指针对于某一张表的操作权限,系统权限是指对表的CRUD操作权限, 角色权限是系统权限的集合,我们设置 时，一般是设置角色权限，设置resource与connect 1.2 maven工程搭建创建子模块 BM-ssm-web BM-ssm-domain BM-ssm-service BM-ssm-dao BM-ssm-utils 其中创建BM-ssm-web 时注意我们选择一个web工程","text":"SSM 环境搭建与产品操作1.环境准备1.1 数据库与表结构​ 数据库我们使用Oracle Oracle 为每个项目创建单独user，oracle数据表存放在表空间下，每个用户有独立表空间 ​ 对象权限是指针对于某一张表的操作权限,系统权限是指对表的CRUD操作权限, 角色权限是系统权限的集合,我们设置 时，一般是设置角色权限，设置resource与connect 1.2 maven工程搭建创建子模块 BM-ssm-web BM-ssm-domain BM-ssm-service BM-ssm-dao BM-ssm-utils 其中创建BM-ssm-web 时注意我们选择一个web工程 pom.xml(父工程BM_ssm) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;BM_ssm&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;BM_ssm_web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;BM_ssm_web Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;BM_ssm_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;BM_ssm_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;BM_ssm_web&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 实体类Product 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public class Product &#123; private String id; // 主键 private String productNum; // 编号 唯一 private String productName; // 名称 private String cityName; // 出发城市 @DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm\") private Date departureTime; // 出发时间 private String departureTimeStr; private double productPrice; // 产品价格 private String productDesc; // 产品描述 private Integer productStatus; // 状态 0 关闭 1 开启 private String productStatusStr; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getProductNum() &#123; return productNum; &#125; public void setProductNum(String productNum) &#123; this.productNum = productNum; &#125; public String getProductName() &#123; return productName; &#125; public void setProductName(String productName) &#123; this.productName = productName; &#125; public String getCityName() &#123; return cityName; &#125; public void setCityName(String cityName) &#123; this.cityName = cityName; &#125; public Date getDepartureTime() &#123; return departureTime; &#125; public void setDepartureTime(Date departureTime) &#123; this.departureTime = departureTime; &#125; public String getDepartureTimeStr() &#123; if (departureTime!=null)&#123; departureTimeStr= DateUtils.date2String(departureTime, \"yyyy-MM-dd HH:mm:ss\"); &#125; return departureTimeStr; &#125; public void setDepartureTimeStr(String departureTimeStr) &#123; this.departureTimeStr = departureTimeStr; &#125; public double getProductPrice() &#123; return productPrice; &#125; public void setProductPrice(double productPrice) &#123; this.productPrice = productPrice; &#125; public String getProductDesc() &#123; return productDesc; &#125; public void setProductDesc(String productDesc) &#123; this.productDesc = productDesc; &#125; public Integer getProductStatus() &#123; return productStatus; &#125; public void setProductStatus(Integer productStatus) &#123; this.productStatus = productStatus; &#125; public String getProductStatusStr() &#123; if (productStatus!=null)&#123; //状态:0 关闭 1 开启 if (productStatus==0) productStatusStr=\"关闭\"; if(productStatus==1) productStatusStr=\"开启\"; &#125; return productStatusStr; &#125; public void setProductStatusStr(String productStatusStr) &#123; this.productStatusStr = productStatusStr; &#125;&#125; 业务接口ProductDao 1234567891011@Repositorypublic interface ProductDao &#123; //查询所有的产品信息 @Select(\"select * from product\") public List&lt;Product&gt; findAll() throws Exception; //添加产品 @Insert(\"insert into product(productNum,productName,cityName,departureTime,productPrice,productDesc,productStatus) values(#&#123;productNum&#125;,#&#123;productName&#125;,#&#123;cityName&#125;,#&#123;departureTime&#125;,#&#123;productPrice&#125;,#&#123;productDesc&#125;,#&#123;productStatus&#125;)\") void save(Product product)throws Exception;&#125; *持久层接口ProductService * 1234567public interface ProductService &#123; //查询所有的产品信息 public List&lt;Product&gt; findAll() throws Exception; //保存产品 void save(Product product) throws Exception;&#125; 持久层接口实现类ProductServiceImpl 12345678910111213141516@Service@Transactionalpublic class ProductServiceImpl implements ProductService &#123; @Autowired private ProductDao productDao; @Override public List&lt;Product&gt; findAll() throws Exception &#123; return productDao.findAll(); &#125; @Override public void save(Product product) throws Exception &#123; productDao.save(product); &#125;&#125; 2.SSM整合与产品查询添加applicationContext.xml web.xml及springmvc.xml均放置在BM_ssm_web子模块中 applicationContext.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!-- 开启注解扫描，管理service和dao --&gt; &lt;context:component-scan base-package=\"service,dao\"/&gt; &lt;!-- 配置连接池 --&gt; &lt;context:property-placeholder location=\"classpath:db.properties\"/&gt; &lt;bean class=\"com.mchange.v2.c3p0.ComboPooledDataSource\" id=\"dataSource\"&gt; &lt;property name=\"driverClass\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"user\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;/bean&gt; &lt;!-- Spring管理 SqlSessionFactory --&gt; &lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!-- 扫描dao接口 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\" id=\"mapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"dao\"/&gt; &lt;/bean&gt; &lt;!-- 配置Spring的声明式事务管理 --&gt; &lt;!-- 配置事务管理器 --&gt; &lt;bean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt;&lt;/beans&gt; springmvc.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- 扫描controller的注解，别的不扫描 --&gt; &lt;context:component-scan base-package=\"controller\"/&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"viewResolver\"&gt; &lt;!-- JSP文件所在的目录 --&gt; &lt;property name=\"prefix\" value=\"/pages/\" /&gt; &lt;!-- 文件的后缀名 --&gt; &lt;property name=\"suffix\" value=\".jsp\" /&gt; &lt;/bean&gt; &lt;!-- 设置静态资源不过滤 --&gt; &lt;mvc:resources location=\"/css/\" mapping=\"/css/**\" /&gt; &lt;mvc:resources location=\"/img/\" mapping=\"/img/**\" /&gt; &lt;mvc:resources location=\"/js/\" mapping=\"/js/**\" /&gt; &lt;mvc:resources location=\"/plugins/\" mapping=\"/plugins/**\" /&gt; &lt;!-- 开启对SpringMVC注解的支持 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 支持AOP的注解支持，AOP底层使用代理技术 JDK动态代理，要求必须有接口 cglib代理，生成子类对象，proxy-target-class=\"true\" 默认使用cglib的方式 --&gt; &lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/&gt;&lt;/beans&gt; db.properties 1234jdbc.driver=oracle.jdbc.driver.OracleDriverjdbc.url=jdbc:oracle:thin:@192.168.17.130:1521:orcljdbc.username=ssmjdbc.password=547717253 web.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\"&gt; &lt;!-- 配置加载类路径的配置文件 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 配置监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置监听器，监听request域对象的创建和销毁的 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.request.RequestContextListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 前端控制器（加载classpath:springmvc.xml 服务器启动创建servlet） --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置初始化参数，创建完DispatcherServlet对象，加载springmvc.xml配置文件 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 服务器启动的时候，让DispatcherServlet对象创建 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 解决中文乱码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt;&lt;/web-app&gt; 注意点 ​ 产品列表页面产品状态显示 domain.Product 12345678910public String getProductStatusStr() &#123; if (productStatus!=null)&#123; //状态:0 关闭 1 开启 if (productStatus==0) productStatusStr=\"关闭\"; if(productStatus==1) productStatusStr=\"开启\"; &#125; return productStatusStr; &#125; ​ 产品列表出发时间(日期转字符串) ​ DateUtils 1234567891011121314public class DateUtils &#123; //日期转换成字符串 public static String date2String(Date date,String patt)&#123; SimpleDateFormat simpleDateFormat=new SimpleDateFormat(patt); String format = simpleDateFormat.format(date); return format; &#125; //字符串转换成日期 public static Date string2Date(String str,String patt) throws ParseException &#123; SimpleDateFormat simpleDateFormat=new SimpleDateFormat(); Date parse = simpleDateFormat.parse(str); return parse; &#125;&#125; domain.Product 123456public String getDepartureTimeStr() &#123; if (departureTime!=null)&#123; departureTimeStr= DateUtils.date2String(departureTime, \"yyyy-MM-dd HH:mm:ss\"); &#125; return departureTimeStr; &#125; 添加商品出发日期类型转换 ​ 实体类的属性上添加@DateTimeFormat注解 12@DateTimeFormat(pattern = \"yyyy-MM-dd HH:mm\") private Date departureTime; // 出发时间 3.产品的批量删除jsp关键代码 1234567891011121314151617181920212223242526&lt;button type=\"button\" class=\"btn btn-default\" title=\"删除\" id=\"deletebut\"&gt; &lt;i class=\"fa fa-trash-o\"&gt;&lt;/i&gt; 删除 &lt;/button&gt;&lt;c:forEach items=\"$&#123;productList&#125;\" var=\"product\" varStatus=\"stat\"&gt; &lt;tr&gt; &lt;td&gt;&lt;input name=\"ids\" type=\"checkbox\" value=\"$&#123;product.id &#125;\" id=\"box_$&#123;stat.index&#125;\"&gt;&lt;/td&gt; ... &lt;/c:forEach&gt;&lt;script&gt; $(\"#deletebut\").click(function () &#123; var boxs=$(\"input[type='checkbox'][id^='box_']\") var checkedBoxs=boxs.filter(\":checked\"); if (checkedBoxs.length&lt;1)&#123; confirm(\"请至少选择一个要删除的产品!\"); &#125;else&#123; var ids=checkedBoxs.map(function () &#123; return this.value; &#125;) if (!confirm(\"确认要删除吗?\")) &#123; return; &#125; window.location=\"$&#123;pageContext.request.contextPath&#125;/product/delete.do?ids=\"+ids.get(); &#125; &#125;) &lt;/script&gt; ProductController 12345678910@RequestMapping(\"/delete.do\") public String delete(String ids) throws Exception &#123; List&lt;String&gt; delList=new ArrayList&lt;String&gt;(); String[] strs = ids.split(\",\"); for (String str:strs) &#123; delList.add(str); &#125; productService.delete(delList); return \"redirect:findAll.do\"; &#125; ProductDao 1234567@Delete(&#123;\"&lt;script&gt;\" +\"delete from product where id in\" +\"&lt;foreach item='id' index='index' collection='list' open='(' separator=',' close=')'&gt;\" +\"#&#123;id&#125;\" +\"&lt;/foreach&gt;\" +\"&lt;/script&gt;\"&#125;) public void delete(List delList)throws Exception; 产品的批量开启(另一种写法) jsp关键代码 12345678910111213141516&lt;button type=\"button\" class=\"btn btn-default\" title=\"开启\" id=\"openbut\"&gt; &lt;i class=\"fa fa-check\"&gt;&lt;/i&gt; 开启 &lt;/button&gt;&lt;script&gt; $(\"#openbut\").click(function () &#123; var boxs=$(\"input[type='checkbox'][id^='box_']\") var checkedBoxs=boxs.filter(\":checked\"); var ids=checkedBoxs.map(function () &#123; return this.value; &#125;) if (!confirm(\"确认开启这些产品吗?\")) &#123; return; &#125; window.location=\"$&#123;pageContext.request.contextPath&#125;/product/open.do?ids=\"+ids.get(); &#125;) &lt;/script&gt; ProductController 12345678@RequestMapping(\"/open.do\") public String open(String ids) throws Exception &#123; String[] strs = ids.split(\",\"); for (String str:strs) &#123; productService.open(str); &#125; return \"redirect:findAll.do\"; &#125; ProductDao 12@Update(\"update product set productStatus=1 where id =#&#123;id&#125;\") void open(String id)throws Exception; 订单操作1.订单分页查询 1.1 PageHelper介绍​ PageHelper是国内非常优秀的一款开源的mybatis分页插件，它支持基本主流与常用的数据库，例如mysql、 oracle、mariaDB、DB2、SQLite、Hsqldb等。​ 本项目在 github 的项目地址：https://github.com/pagehelper/Mybatis-PageHelper ​ 本项目在 gitosc 的项目地址：http://git.oschina.net/free/Mybatis_PageHelper 1.2 PageHelper使用1.2.1.集成12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt;&lt;/dependency&gt; 1.2. 2.配置 在 MyBatis 配置 xml 中配置拦截器插件 12345678910111213&lt;!-- plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下: properties?, settings?, typeAliases?, typeHandlers?, objectFactory?,objectWrapperFactory?, plugins?, environments?, databaseIdProvider?, mappers? --&gt; &lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt; &lt;property name=\"param1\" value=\"value1\"/&gt; &lt;/plugin&gt; &lt;/plugins&gt; 在 Spring 配置文件中配置拦截器插件 1234567891011121314151617&lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!-- 传入PageHelper的插件 --&gt; &lt;property name=\"plugins\"&gt; &lt;array&gt; &lt;!-- 传入插件的对象 --&gt; &lt;bean class=\"com.github.pagehelper.PageInterceptor\"&gt; &lt;property name=\"properties\"&gt; &lt;props&gt; &lt;prop key=\"helperDialect\"&gt;oracle&lt;/prop&gt; &lt;prop key=\"reasonable\"&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 1.2.3 分页插件参数介绍 helperDialect ：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置 helperDialect 属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值： oracle , mysql , mariadb , sqlite , hsqldb , postgresql , db2 , sqlserver , informix , h2 , sqlserver201 2 , derby 特别注意：使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012 ，否则会使用 SqlServer2005 的 方式进行分页。 你也可以实现 AbstractHelperDialect ，然后配置该属性为实现类的全限定名称即可使用自定义的实现方 法。 offsetAsPageNum ：默认值为 false ，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分 页。 rowBoundsWithCount ：默认值为 false ，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置 为 true 时，使用 RowBounds 分页会进行 count 查询。 pageSizeZero ：默认值为 false ，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 reasonable ：分页合理化参数，默认值为 false 。当该参数设置为 true 时， pageNum&lt;=0 时会查询第一 页， pageNum&gt;pages （超过总数时），会查询最后一页。默认 false 时，直接根据参数进行查询。 params ：为了支持 startPage(Object params) 方法，增加了该参数来配置参数映射，用于从对象中根据属 性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable ，不配置映射的用默认值， 默认 值为 pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero 。 supportMethodsArguments ：支持通过 Mapper 接口参数来传递分页参数，默认值 false ，分页插件会从查 询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法 可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest 。 autoRuntimeDialect ：默认值为 false 。设置为 true 时，允许在运行时根据多数据源自动识别对应方言 的分页 （不支持自动选择 sqlserver2012 ，只能使用 sqlserver ），用法和注意事项参考下面的场景五。 closeConn ：默认值为 true 。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类 型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认 true 关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。 1.2.4.基本使用PageHelper.startPage 静态方法调用 ​ 在你需要进行分页的 MyBatis 查询方法前调用PageHelper.startPage 静态方法即可，紧 跟在这个方法后的第一个MyBatis 查询方法会被进行分页 OrdersServiceImpl 1234567@Override public List&lt;Orders&gt; findAll(int page,int size) throws Exception &#123; //参数pageNum是页码值 参数pageSize是每页显示条数 PageHelper.startPage(page,size); return ordersDao.findAll(); &#125; OrdersController 12345678910@RequestMapping(\"/findAll.do\") public ModelAndView findAll(@RequestParam(name = \"page\",required = true,defaultValue = \"1\")int page,@RequestParam(name = \"size\",required = true,defaultValue = \"5\")int size)throws Exception&#123; ModelAndView modelAndView=new ModelAndView(); List&lt;Orders&gt; orders = ordersService.findAll(page,size); //PageInfo就是一个分页Bean PageInfo pageInfo=new PageInfo(orders); modelAndView.addObject(\"pageInfo\",pageInfo); modelAndView.setViewName(\"orders-page-list\"); return modelAndView; &#125; OrdersDao 12345678910111213public interface OrdersDao &#123; @Select(\"select * from orders\") @Results(&#123; @Result(id = true,property = \"id\",column = \"id\"), @Result(property = \"orderNum\",column = \"orderNum\"), @Result(property = \"orderTime\",column = \"orderTime\"), @Result(property = \"peopleCount\",column = \"peopleCount\"), @Result(property = \"orderDesc\",column = \"orderDesc\"), @Result(property = \"payType\",column = \"payType\"), @Result(property = \"orderStatus\",column = \"orderStatus\"), @Result(property = \"product\",column = \"productId\",javaType = Product.class,one = @One(select =\"dao.ProductDao.findById\" )), &#125;) public List&lt;Orders&gt; findAll()throws Exception; ProductDao的ﬁndById方法 12@Select(\"select * from product where id=#&#123;id&#125;\") public Product findById(String id)throws Exception; jsp关键代码 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;div class=\"box-footer\"&gt; &lt;div class=\"pull-left\"&gt; &lt;div class=\"form-group form-inline\" &gt; 总共$&#123;pageInfo.pages&#125;页，共$&#123;pageInfo.total&#125;条数据。 每页 &lt;select class=\"form-control\" id=\"changePageSize\" onchange=\"changePageSize()\"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; 条 &lt;/div&gt; &lt;/div&gt; &lt;div class=\"box-tools pull-right\"&gt; &lt;ul class=\"pagination\"&gt; &lt;li&gt; &lt;a href=\"$&#123;pageContext.request.contextPath&#125;/orders/findAll.do?page=1&amp;size=$&#123;pageInfo.pageSize&#125;\" aria-label=\"Previous\"&gt;首页&lt;/a&gt; &lt;/li&gt; &lt;li&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/orders/findAll.do?page=$&#123;pageInfo.pageNum-1&#125;&amp;size=$&#123;pageInfo.pageSize&#125;\"&gt;上一页&lt;/a&gt;&lt;/li&gt; &lt;c:forEach begin=\"1\" end=\"$&#123;pageInfo.pages&#125;\" var=\"pageNum\"&gt; &lt;li&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/orders/findAll.do?page=$&#123;pageNum&#125;&amp;size=$&#123;pageInfo.pageSize&#125;\"&gt;$&#123;pageNum&#125;&lt;/a&gt;&lt;/li&gt; &lt;/c:forEach&gt; &lt;li&gt;&lt;a href=\"$&#123;pageContext.request.contextPath&#125;/orders/findAll.do?page=$&#123;pageInfo.pageNum+1&#125;&amp;size=$&#123;pageInfo.pageSize&#125;\"&gt;下一页&lt;/a&gt;&lt;/li&gt; &lt;li&gt; &lt;a href=\"$&#123;pageContext.request.contextPath&#125;/orders/findAll.do?page=$&#123;pageInfo.pages&#125;&amp;size=$&#123;pageInfo.pageSize&#125;\" aria-label=\"Next\"&gt;尾页&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&lt;script&gt; function changePageSize() &#123; //获取下拉框的值 var pageSize = $(\"#changePageSize\").val(); //向服务器发送请求，改变没页显示条数 location.href = \"$&#123;pageContext.request.contextPath&#125;/orders/findAll.do?page=1&amp;size=\" + pageSize; &#125; &lt;/script&gt; 2.订单详情在order-list.jsp页面上对”详情”添加链接 1&lt;button type=\"button\" class=\"btn bg-olive btn-xs\" onclick=\"location.href='$&#123;pageContext.request.contextPath&#125;/orders/findById.do?id=$&#123;orders.id&#125;'\"&gt;详情&lt;/button&gt; OrdersController 12345678@RequestMapping(\"/findById.do\") public ModelAndView findById(@RequestParam(name = \"id\",required = true)String ordersId)throws Exception&#123; ModelAndView modelAndView=new ModelAndView(); Orders orders=ordersService.findById(ordersId); modelAndView.addObject(\"orders\",orders); modelAndView.setViewName(\"orders-show\"); return modelAndView; &#125; OrdersDao 1234567891011121314@Select(\"select * from orders where id=#&#123;ordersId&#125;\") @Results(&#123; @Result(id = true,property = \"id\",column = \"id\"), @Result(property = \"orderNum\",column = \"orderNum\"), @Result(property = \"orderTime\",column = \"orderTime\"), @Result(property = \"peopleCount\",column = \"peopleCount\"), @Result(property = \"orderDesc\",column = \"orderDesc\"), @Result(property = \"payType\",column = \"payType\"), @Result(property = \"orderStatus\",column = \"orderStatus\"), @Result(property = \"product\",column = \"productId\",javaType = Product.class,one = @One(select =\"dao.ProductDao.findById\" )), @Result(property = \"member\",column = \"memberId\",javaType = Member.class,one =@One(select = \"dao.MemberDao.findById\")), @Result(property = \"travellers\",column =\"id\",javaType = List.class,many = @Many(select =\"dao.TravellerDao.findByOrdersId\" )) &#125;) public Orders findById(String ordersId)throws Exception; MemberDao的ﬁndById方法 12@Select(\"select * from member where id=#&#123;id&#125;\") public Member findById(String id)throws Exception; TravellerDao的ﬁndByOrdersId方法 12@Select(\"select * from traveller where id in(select travellerId from order_traveller where orderId=#&#123;ordersId&#125;)\") public List&lt;Traveller&gt; findByOrdersId(String ordersId)throws Exception; 注意:订单详情页面的显示问题 domain.Traveller 12345678910111213141516171819202122public String getCredentialsTypeStr() &#123; if (credentialsType != null) &#123; if (credentialsType == 0) &#123; credentialsTypeStr = \"身份证\"; &#125; else if (credentialsType == 1) &#123; credentialsTypeStr = \"护照\"; &#125; else if (credentialsType == 2) &#123; credentialsTypeStr = \"军官证\"; &#125; &#125; return credentialsTypeStr; &#125;public String getTravellerTypeStr() &#123; if (travellerType != null) &#123; if (travellerType == 0) &#123; travellerTypeStr = \"成人\"; &#125; else if (travellerType == 1) &#123; travellerTypeStr = \"儿童\"; &#125; &#125; return travellerTypeStr; &#125; domain.Orders 123456789101112131415161718192021222324public String getOrderTimeStr() &#123; if (orderTime!=null)&#123; orderTimeStr = DateUtils.date2String(orderTime, \"yyyy-MM-dd:mm\"); &#125; return orderTimeStr; &#125;public String getOrderStatusStr() &#123; if (orderStatus==0)&#123; orderStatusStr=\"未支付\"; &#125;else if (orderStatus==1)&#123; orderStatusStr=\"已支付\"; &#125; return orderStatusStr; &#125;public String getPayTypeStr() &#123; if (payType==0)&#123; payTypeStr=\"支付宝\"; &#125; else if (payType==1) &#123; payTypeStr=\"微信\"; &#125;else if (payType==2) &#123; payTypeStr=\"其它\"; &#125; return payTypeStr; &#125;","categories":[],"tags":[{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"}]},{"title":"SQL执行慢分析及SQL语句优化","slug":"SQL执行慢分析及SQL语句优化","date":"2021-05-08T13:19:59.176Z","updated":"2020-04-29T02:44:37.936Z","comments":true,"path":"31546/","link":"","permalink":"http://tonymua.top/31546/","excerpt":"1.SQL语句执行速度慢一个SQL语句执行的速度很慢, 分两种情况讨论: 大多数情况下很正常, 偶尔很慢, 则有如下原因: 数据库在刷新脏页 执行的时候, 遇到锁, 如表锁, 行锁 一直执行很慢, 则有如下原因","text":"1.SQL语句执行速度慢一个SQL语句执行的速度很慢, 分两种情况讨论: 大多数情况下很正常, 偶尔很慢, 则有如下原因: 数据库在刷新脏页 执行的时候, 遇到锁, 如表锁, 行锁 一直执行很慢, 则有如下原因 没有用上索引: 例如该字段没有索引, 由于对字段进行运算, 函数操作导致无法使用索引 数据库选错了索引 2.SQL语句的优化 设置合适的字段属性 字段的长度越小, 占用的内存越小, 性能就越好; 例如,中国的手机号码为11位, vachar的长度设置为11位即可 使用join语法 join语法分为内连接, 左(外)连接, 右(外)连接 尽量少使用select * select *会进行全表查询, 消耗的性能较大 在查找唯一一条数据的时候, 使用limit 1, 在查找到数据的时候会终止查找 使用limit分页 尽量少使用排序order by, order by DESC, order by ASC 避免进行类型转换 使用索引 优点: 加快索引速度 缺点: 创建索引和维护索引需要耗费时间和精力 ​ 索引需要占用空间 ​ 进行数据的增删改查时需要动态维护索引","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Spring相关面试题","slug":"Spring相关面试题","date":"2021-05-08T13:19:59.175Z","updated":"2020-04-29T02:44:38.037Z","comments":true,"path":"11294/","link":"","permalink":"http://tonymua.top/11294/","excerpt":"1.Spring与Spring MVC的区别Spring是IOC和AOP的容器框架，SpringMVC是基于Spring功能之上添加的Web框架，想用SpringMVC必须先依赖Spring。 为了简化开发者的使用，从而推出了Spring Boot, Spring Boot实现了自动配置，降低了项目搭建的复杂度。 2.IOC AOPIOC(控制反转):由Spring来负责控制对象的生命周期和对象间的关系","text":"1.Spring与Spring MVC的区别Spring是IOC和AOP的容器框架，SpringMVC是基于Spring功能之上添加的Web框架，想用SpringMVC必须先依赖Spring。 为了简化开发者的使用，从而推出了Spring Boot, Spring Boot实现了自动配置，降低了项目搭建的复杂度。 2.IOC AOPIOC(控制反转):由Spring来负责控制对象的生命周期和对象间的关系 IOC 实现的基础 IOC 是工厂模式与反射机制, 只需要在spring配置文件中配置相应的bean，以及设置相关的属性，让spring容器来生成类的实例对象以及管理对象。在spring容器启动的时候，spring会把你在配置文件中配置的bean都初始化好，然后在你需要调用的时候，就把它已经初始化好的那些bean分配给你需要调用这些bean的类。 AOP(面向切面编程):作为面向对象的一种补充, 用于处理系统中分布于各个模块的横切关注点, 比如事务管理, 日志, 缓存等等. ​ AOP的实现关键在于AOP框架自动创建的AOP代理, AOP代理主要分为静态代理和动态代理, 静态代理的代表为AspectJ; 而动态代理则以Spring AOP为代表. ​ 通常使用AspectJ的编译时增强实现AOP, AspectJ是静态代理的增强, 所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类, 因此也称为编译时增强. ​ Spring AOP中的动态代理主要有两种方式, JDK动态代理和CGLIB动态代理. JDK动态代理通过反射来接收被代理的类, 并要求被代理的类必须实现一个接口. JDK动态代理的核心是InvocationHandler接口和Proxy类. 如果目标类没有实现接口, 那么Spring AOP会选择使用CGLIB来动态代理目标类. CGLIB, 是一个代码生成的类库, 可以在运行时动态的生成某个类的子类, 注意, CGLIB是通过继承的方式做的动态代理, 因此如果某个类被标记为final, 那么它是无法使用CGLIB做动态代理的. 3.Spring支持的事务管理类型Spring支持如下两种方式的事务管理： 编程式事务管理:这意味着你可以通过编程的方式管理事务，这种方式带来了很大的灵活性, 允许你通过代码控制业务, 但很难维护。 声明式事务管理:这种方式意味着你可以将事务管理和业务代码分离。你只需要通过注解或者XML配置管理事务。 一般选择声明式事务管理，因为这种方式和应用程序的关联较少, 更加符合轻量级容器的概念。 4.DIDI叫做依赖注入, 是对IOC更简单的诠释. 控制反转是把传统上由程序代码直接操控的对象的调用权交给容器, 通过容器来实现对象组件的装配和管理, 由容器来创建对象命管理对象之间的依赖关系. DI是对IOC更准确的描述, 即组件之间的依赖关系，由容器在运行期决定. 形象的来说，既由容器动态的将某种依赖关系注入到组件之中. 依赖注入的三种方式: (1) 构造器注入：通过构造方法初始化 (2) setter方法注入：通过setter方法初始化 (3) 接口注入 5.Spring主要使用了哪些设计模式？ 工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 6.@RestController vs @Controller Controller 返回一个页面 单独使用 @Controller 不加 @ResponseBody的话一般使用在要返回一个视图的情况，这种情况属于比较传统的Spring MVC 的应用，对应于前后端不分离的情况。 @RestController 返回JSON 或 XML 形式数据 但@RestController只返回对象，对象数据直接以 JSON 或 XML 形式写入 HTTP 响应(Response)中，这种情况属于 RESTful Web服务，这也是目前日常开发所接触的最常用的情况（前后端分离）。 @Controller +@ResponseBody = @RestController 返回JSON 或 XML 形式数据 如果你需要在Spring4之前开发 RESTful Web服务的话，你需要使用@Controller 并结合@ResponseBody注解，也就是说@Controller +@ResponseBody= @RestController（Spring 4 之后新加的注解）。 @ResponseBody 注解的作用是将 Controller 的方法返回的对象通过适当的转换器转换为指定的格式之后，写入到HTTP 响应(Response)对象的 body 中，通常用来返回 JSON 或者 XML 数据，返回 JSON 数据的情况比较多。 7.Spring 中的 bean 的作用域有哪些? singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。 session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。 global-session： 全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话 8.Spring 中的单例 bean 的线程安全问题单例 bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。 常见的有两种解决办法： 在Bean对象中尽量避免定义可变的成员变量（不太现实）。 在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 9.@Component 和 @Bean 的区别 作用对象不同: @Component 注解作用于类，而@Bean注解作用于方法。 @Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了Spring这是某个类的示例，当我需要用它的时候还给我。 @Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。 10.SpringMVC 工作原理 流程说明（重要）： 客户端（浏览器）发送请求，直接请求到 DispatcherServlet。 DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。 解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。 HandlerAdapter 会根据 Handler来调用真正的处理器开处理请求，并处理相应的业务逻辑。 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。 ViewResolver 会根据逻辑 View 查找实际的 View。 DispaterServlet 把返回的 Model 传给 View（视图渲染）。 把 View 返回给请求者（浏览器） 11.Spring的优点 方便解耦，简化开发 通过 Spring提供的 IOC 容器，可以将对象间的依赖关系交由 Spring进行控制，避免硬编码所造 成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可 以更专注于上层的应用。 AOP编程的支持 通过 Spring的 AOP 功能，方便进行面向切面的编程，许多不容易用传统OOP 实现的功能可以通过 AOP 轻松应付。 声明式事务的支持 可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式方式灵活的进行事务的管理， 提高开发效率和质量。 方便程序的测试 可以用非容器依赖的编程方式进行几乎所有的测试工作，测试不再是昂贵的操作，而是随手可做的事情。 方便集成各种优秀框架 Spring可以降低各种框架的使用难度，提供了对各种优秀框架（Struts、Hibernate、Hessian、Quartz 等）的直接支持。 降低 JavaEE API的使用难度 Spring对 JavaEE API（如 JDBC、JavaMail、远程调用等）进行了薄薄的封装层，使这些 API 的 使用难度大为降低。 12.Spring 中的 bean 生命周期 Bean 容器找到配置文件中 Spring Bean 的定义。 Bean 容器利用 Java Reflection API 创建一个Bean的实例。 如果涉及到一些属性值 利用 set()方法设置一些属性值。 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入Bean的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。 如果Bean实现了 BeanFactoryAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoade r对象的实例。 与上面的类似，如果实现了其他 *.Aware接口，就调用相应的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 如果有和加载这个 Bean的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法 当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Spring框架(四)","slug":"Spring框架(四)","date":"2021-05-08T13:19:59.173Z","updated":"2020-04-29T02:44:38.107Z","comments":true,"path":"45219/","link":"","permalink":"http://tonymua.top/45219/","excerpt":"1.Spring中的 JdbcTemplate1.1 JdbcTemplate 概述​ 它是 spring 框架中提供的一个对象，是对原始 Jdbc API 对象的简单封装。spring 框架为我们提供了很多 的操作模板类。 操作关系型数据的： JdbcTemplate HibernateTemplate操作 nosql 数据库的： RedisTemplate操作消息队列的： JmsTemplate 我们今天的主角在 spring-jdbc-5.0.2.RELEASE.jar 中，我们在导包的时候，除了要导入这个 jar 包 外，还需要导入一个 spring-tx-5.0.2.RELEASE.jar（它是和事务相关的）。","text":"1.Spring中的 JdbcTemplate1.1 JdbcTemplate 概述​ 它是 spring 框架中提供的一个对象，是对原始 Jdbc API 对象的简单封装。spring 框架为我们提供了很多 的操作模板类。 操作关系型数据的： JdbcTemplate HibernateTemplate操作 nosql 数据库的： RedisTemplate操作消息队列的： JmsTemplate 我们今天的主角在 spring-jdbc-5.0.2.RELEASE.jar 中，我们在导包的时候，除了要导入这个 jar 包 外，还需要导入一个 spring-tx-5.0.2.RELEASE.jar（它是和事务相关的）。 1.2 JdbcTemplate 的增删改查操作 (dao)1.2.1 准备实体类Account 1234567891011121314151617181920212223242526272829303132333435363738public class Account implements Serializable &#123; private Integer id; private String name; private Float money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Float getMoney() &#123; return money; &#125; public void setMoney(Float money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; 1.2.2 第一种方式：在 dao 中定义 JdbcTemplateAccountDaoImpl 1234567891011121314151617181920212223242526272829@Repositorypublic class AccountDaoImpl implements AccountDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public Account findAccountById(Integer accountId) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where id =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountId); return accounts.isEmpty() ? null : accounts.get(0); &#125; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; jdbcTemplate.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; bean.xml 12345678910111213141516171819202122232425?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置jdbcTemplate--&gt; &lt;bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\"&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置账户持久层--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;!--注入jdbcTemplate--&gt; &lt;property name=\"jdbcTemplate\" ref=\"jdbcTemplate\"&gt;&lt;/property&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 存在的问题 ​ 有个小问题。就是我们的 dao 有很多时，每个 dao 都有一些重复性的代码。下面就是重复代码： 123private JdbcTemplate jdbcTemplate; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; 能不能把它抽取出来呢？ 1.2.3 第二种方式：让 dao 继承 JdbcDaoSupport​ JdbcDaoSupport 是spring 框架为我们提供的一个类，该类中定义了一个 JdbcTemplate 对象，我们可以 直接获取使用，但是要想创建该对象，需要为其提供一个数据源 AccountDaoImpl 123456789101112131415161718192021222324ublic class AccountDaoImpl extends JdbcDaoSupport implements AccountDao &#123; @Override public Account findAccountById(Integer accountId) &#123; List&lt;Account&gt; accounts = getJdbcTemplate().query(\"select * from account where id =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountId); return accounts.isEmpty() ? null : accounts.get(0); &#125; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = getJdbcTemplate().query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; getJdbcTemplate().update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; bean.xml 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置账户持久层--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 两版 Dao有什么区别呢？ 第一种在 Dao类中定义 JdbcTemplate 的方式，适用于所有配置方式（xml和注解都可以）。 第二种让 Dao继承 JdbcDaoSupport 的方式，只能用于基于 XML 的方式，注解用不了。 2.Spring中的事务控制2.1 Spring事务控制明确点第一：JavaEE 体系进行分层开发，事务处理位于业务层，Spring 提供了分层设计业务层的事务处理解决方 案。 第二：spring 框架为我们提供了一组事务控制的接口。这组接口是在 spring-tx-5.0.2.RELEASE.jar 中。 第三：spring 的事务控制都是基于 AOP 的，它既可以使用编程的方式实现，也可以使用配置的方式实现。我 们学习的重点是使用配置的方式实现 2.2 Spring中事务控制的 API介绍2.2.1 PlatformTransactionManager此接口是 spring 的事务管理器，它里面提供了我们常用的操作事务的方法，如下图： 我们在开发中都是使用它的实现类 真正管理事务的对象 org.springframework.jdbc.datasource.DataSourceTransactionManager 使用 Spring JDBC 或 iBatis 进行持久化数据时使用 org.springframework.orm.hibernate5.HibernateTransactionManager 使用 Hibernate 版本进行持久化数据时使用 2.2.2 TransactionDefinition它是事务的定义信息对象，里面有如下方法： 事务的隔离级别 *事务的传播行为 * REQUIRED:如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。一般的选 择（默认值） SUPPORTS:支持当前事务，如果当前没有事务，就以非事务方式执行（没有事务） MANDATORY：使用当前的事务，如果当前没有事务，就抛出异常 REQUERS_NEW:新建事务，如果当前在事务中，把当前事务挂起。 NOT_SUPPORTED:以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 NEVER:以非事务方式运行，如果当前存在事务，抛出异常 NESTED:如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行 REQUIRED 类似的操作。 超时时间 默认值是-1，没有超时限制。如果有，以秒为单位进行设置。 是否是只读事务 建议查询时设置为只读。 2.2.3 TransactionStatus此接口提供的是事务具体的运行状态，方法介绍如下图： 2.3 基于 XML 的声明式事务控制（配置方式）重点pom.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Account 1234567891011121314151617181920212223242526272829303132333435363738public class Account implements Serializable &#123; private Integer id; private String name; private Float money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Float getMoney() &#123; return money; &#125; public void setMoney(Float money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; AccountDao 1234567public interface AccountDao &#123; Account findAccountByName(String accountName); void updateAccount(Account account);&#125; AccountDaoImpl 123456789101112131415161718public class AccountDaoImpl extends JdbcDaoSupport implements AccountDao &#123; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = getJdbcTemplate().query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; getJdbcTemplate().update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; AccountService 1234public interface AccountService &#123; void transfer(String sourceName,String targetName,Float money);&#125; AccountServiceImpl 12345678910111213141516171819202122232425public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public void transfer(String sourceName, String targetName, Float money) &#123; //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125; AccountServiceTest 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:bean.xml\")public class AccountServiceTest &#123; @Autowired private AccountService accountService; @Test public void testTransfer()&#123; accountService.transfer(\"aaa\",\"bbb\",100f); &#125;&#125; bean.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!--配置账户持久层--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;!--注入jdbcTemplate--&gt; &lt;!--&lt;property name=\"jdbcTemplate\" ref=\"jdbcTemplate\"&gt;&lt;/property&gt;--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置业务层--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt; &lt;!--注入accountDao--&gt; &lt;property name=\"accountDao\" ref=\"accountDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- spring中基于XML的声明式事务控制配置步骤 1、配置事务管理器 2、配置事务的通知 此时我们需要导入事务的约束 tx名称空间和约束，同时也需要aop的 使用tx:advice标签配置事务通知 属性： id：给事务通知起一个唯一标识 transaction-manager：给事务通知提供一个事务管理器引用 3、配置AOP中的通用切入点表达式 4、建立事务通知和切入点表达式的对应关系 5、配置事务的属性 是在事务的通知tx:advice标签的内部 --&gt; &lt;!--1.配置事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!--注入dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--2.配置事务的通知--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;!--5.配置事务的属性 isolation：用于指定事务的隔离级别。默认值是DEFAULT，表示使用数据库的默认隔离级别。 propagation：用于指定事务的传播行为。默认值是REQUIRED，表示一定会有事务，增删改的选择。查询方法可以选择SUPPORTS。 read-only：用于指定事务是否只读。只有查询方法才能设置为true。默认值是false，表示读写。 timeout：用于指定事务的超时时间，默认值是-1，表示永不超时。如果指定了数值，以秒为单位。 rollback-for：用于指定一个异常，当产生该异常时，事务回滚，产生其他异常时，事务不回滚。没有默认值。表示任何异常都回滚。 no-rollback-for：用于指定一个异常，当产生该异常时，事务不回滚，产生其他异常时事务回滚。没有默认值。表示任何异常都回滚。 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"*\" propagation=\"REQUIRED\" read-only=\"false\"/&gt; &lt;tx:method name=\"find*\" propagation=\"SUPPORTS\" read-only=\"true\"&gt;&lt;/tx:method&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置AOP--&gt; &lt;aop:config&gt; &lt;!--3.配置AOP中的通用切入点表达式--&gt; &lt;aop:pointcut id=\"pt1\" expression=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:pointcut&gt; &lt;!--4、建立事务通知和切入点表达式的对应关系--&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"pt1\"&gt;&lt;/aop:advisor&gt; &lt;/aop:config&gt;&lt;/beans&gt; 2.4 基于注解的配置方式AccountDaoImpl 123456789101112131415161718192021@Repository(\"accountDao\")public class AccountDaoImpl implements AccountDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; jdbcTemplate.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; AccountServiceImpl 12345678910111213141516171819202122232425@Service(\"accountService\")@Transactionalpublic class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public void transfer(String sourceName, String targetName, Float money) &#123; //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125;&#125; bean.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--配置spring创建容器时要扫描的包--&gt; &lt;context:component-scan base-package=\"service,dao\"&gt;&lt;/context:component-scan&gt; &lt;!--配置JdbcTemplate--&gt; &lt;bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\"&gt; &lt;!--注入dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dateSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- spring中基于注解 的声明式事务控制配置步骤 1、配置事务管理器 2、开启spring对注解事务的支持 3、在需要事务支持的地方使用@Transactional注解 --&gt; &lt;!--1.配置事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!--注入dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dateSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--2.开启spring对注解事务的支持--&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"&gt;&lt;/tx:annotation-driven&gt;&lt;/beans&gt; 2.5 纯注解的配置方式jdbcConfig.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/springjdbc.username=rootjdbc.password=547717253 JdbcConfig 12345678910111213141516171819202122232425262728public class JdbcConfig &#123; @Value(\"$&#123;jdbc.driver&#125;\") private String driver; @Value(\"$&#123;jdbc.url&#125;\") private String url; @Value(\"$&#123;jdbc.username&#125;\") private String username; @Value(\"$&#123;jdbc.password&#125;\") private String password; @Bean(name =\"jdbcTemplate\" ) public JdbcTemplate createJdbcTemplate(DataSource dataSource)&#123; return new JdbcTemplate(dataSource); &#125; @Bean(name = \"dataSource\") public DataSource createDataSource()&#123; DriverManagerDataSource dataSource=new DriverManagerDataSource(); dataSource.setDriverClassName(driver); dataSource.setUrl(url); dataSource.setUsername(username); dataSource.setPassword(password); return dataSource; &#125;&#125; TransactionConfig 123456789public class TransactionConfig &#123;// 用于创建事务管理器对象 @Bean(name =\"transactionManager\" ) public PlatformTransactionManager createTransactionManager(DataSource dataSource)&#123; return new DataSourceTransactionManager(dataSource); &#125;&#125; SpringConfiguration 123456789//spring的配置类，相当于bean.xml@Configuration@ComponentScan(&#123;\"dao\",\"service\",\"config\"&#125;)@Import(&#123;JdbcConfig.class,TransactionConfig.class&#125;)@PropertySource(\"jdbcConfig.properties\")@EnableTransactionManagementpublic class SpringConfiguration &#123;&#125; AccountDaoImpl 123456789101112131415161718192021@Repository(\"accountDao\")public class AccountDaoImpl implements AccountDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public Account findAccountByName(String accountName) &#123; List&lt;Account&gt; accounts = jdbcTemplate.query(\"select * from account where name =?\", new BeanPropertyRowMapper&lt;Account&gt;(Account.class), accountName); if (accounts.isEmpty())&#123; return null; &#125;else if (accounts.size()&gt;1)&#123; throw new RuntimeException(\"查询结果不唯一\"); &#125; return accounts.get(0); &#125; @Override public void updateAccount(Account account) &#123; jdbcTemplate.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125;&#125; AccountService 12345678910111213141516171819202122232425@Service(\"accountService\")@Transactionalpublic class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public void transfer(String sourceName, String targetName, Float money) &#123; //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125;&#125; AccountServiceTest 12345678910111213141516/** * 使用Junit单元测试：测试我们的配置 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = SpringConfiguration.class)public class AccountServiceTest &#123; @Autowired private AccountService accountService; @Test public void testTransfer()&#123; accountService.transfer(\"aaa\",\"bbb\",100f); &#125;&#125; 3.Spring5的新特性3.1 与 JDK 相关的升级3.1.1 jdk 版本要求​ spring5.0 在 2017 年 9 月发布了它的 GA（通用）版本。该版本是基于 jdk8 编写的，所以 jdk8 以下版本 将无法使用。同时，可以兼容 jdk9 版本。 tomcat 版本要求 8.5 及以上。 注： 我们使用 jdk8 构建工程，可以降版编译。但是不能使用 jdk8 以下版本构建工程。 由于 jdk 和 tomcat 版本的更新，我们的 IDE 也需要同时更新。 3.1.2 利用 jdk8 版本更新的内容第一：基于 JDK8 的反射增强 第二：@NonNull 注解和@Nullable 注解的使用 用 @Nullable 和 @NotNull 注解来显示表明可为空的参数和以及返回值。这样就够在编译的时候处 理空值而不是在运行时抛出 NullPointerExceptions。 第三：日志记录方面 Spring Framework 5.0 带来了 Commons Logging 桥接模块的封装, 它被叫做 spring-jcl 而 不是标准的 Commons Logging。当然，无需任何额外的桥接，新版本也会对 Log4j 2.x, SLF4J, JUL ( java.util.logging) 进行自动检测。 3.2 核心容器的更新​ Spring Framework 5.0 现在支持候选组件索引作为类路径扫描的替代方案。该功能已经在类路径扫描器中 添加，以简化添加候选组件标识的步骤。 ​ 应用程序构建任务可以定义当前项目自己的 META-INF/spring.components 文件。在编译时，源模型是 自包含的，JPA 实体和 Spring 组件是已被标记的。 ​ 从索引读取实体而不是扫描类路径对于小于 200 个类的小型项目是没有明显差异。但对大型项目影响较大。 加载组件索引开销更低。因此，随着类数的增加，索引读取的启动时间将保持不变。 ​ 加载组件索引的耗费是廉价的。因此当类的数量不断增长，加上构建索引的启动时间仍然可以维持一个常数, 不过对于组件扫描而言，启动时间则会有明显的增长。 ​ 这个对于我们处于大型 Spring 项目的开发者所意味着的，是应用程序的启动时间将被大大缩减。虽然 20 或者 30 秒钟看似没什么，但如果每天要这样登上好几百次，加起来就够你受的了。使用了组件索引的话，就能帮助你每天过的更加高效。 你可以在 Spring 的 Jira 上了解更多关于组件索引的相关信息。 3.3 JetBrains Kotlin 语言支持​ Kolin概述：是一种支持函数式编程编程风格的面向对象语言。Kotlin 运行在 JVM 之上，但运行环境并不 限于 JVM。 3.4 响应式编程风格​ 此次 Spring 发行版本的一个激动人心的特性就是新的响应式堆栈 WEB 框架。这个堆栈完全的响应式且非 阻塞，适合于事件循环风格的处理，可以进行少量线程的扩展。 ​ Reactive Streams 是来自于 Netflix, Pivotal, Typesafe, Red Hat, Oracle, Twitter 以及 Spray.io 的工程师特地开发的一个 API。它为响应式编程实现的实现提供一个公共的 API，好实现 Hibernate 的 JPA。这里 JPA 就是这个 API, 而 Hibernate 就是实现。 ​ Reactive Streams API 是 Java 9 的官方版本的一部分。在 Java 8 中, 你会需要专门引入依赖来使 用 Reactive Streams API。 ​ Spring Framework 5.0 对于流式处理的支持依赖于 Project Reactor 来构建, 其专门实现了 Reactive Streams API。 ​ Spring Framework 5.0 拥有一个新的 spring-webflux 模块，支持响应式 HTTP 和 WebSocket 客 户端。 ​ Spring Framework 5.0 还提供了对于运行于服务器之上，包含了 REST, HTML, 以及 WebSocket 风 格交互的响应式网页应用程序的支持。 ​ 在 spring-webflux 中包含了两种独立的服务端编程模型： ​ 基于注解：使用到了@Controller 以及 Spring MVC 的其它一些注解； ​ 使用 Java 8 lambda 表达式的函数式风格的路由和处理。 ​ 有了 Spring Webflux, 你现在可以创建出 WebClient, 它是响应式且非阻塞的，可以作为 RestTemplate 的一个替代方案。 3.5 Junit5 支持​ 完全支持 JUnit 5 Jupiter，所以可以使用 JUnit 5 来编写测试以及扩展。此外还提供了一个编程以及 扩展模型，Jupiter 子项目提供了一个测试引擎来在 Spring 上运行基于 Jupiter 的测试。 ​ 另外，Spring Framework 5 还提供了在 Spring TestContext Framework 中进行并行测试的扩展。 ​ 针对响应式编程模型， spring-test 现在还引入了支持 Spring WebFlux 的 WebTestClient 集成测 试的支持，类似于 MockMvc，并不需要一个运行着的服务端。使用一个模拟的请求或者响应， WebTestClient 就可以直接绑定到 WebFlux 服务端设施。 ​ 你可以在这里找到这个激动人心的 TestContext 框架所带来的增强功能的完整列表。 ​ 当然， Spring Framework 5.0 仍然支持我们的老朋友 JUnit! 在我写这篇文章的时候， JUnit 5 还 只是发展到了 GA 版本。对于 JUnit4， Spring Framework 在未来还是要支持一段时间的。 3.6 依赖类库的更新终止支持的类库: Portlet. Velocity. JasperReports. XMLBeans. JDO. Guava. 支持的类库: Jackson 2.6+ EhCache 2.10+ / 3.0 GA Hibernate 5.0+ JDBC 4.0+ XmlUnit 2.x+ OkHttp 3.x+ Netty 4.1+","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring框架(二)","slug":"Spring框架(二)","date":"2021-05-08T13:19:59.172Z","updated":"2020-04-29T02:44:38.083Z","comments":true,"path":"46845/","link":"","permalink":"http://tonymua.top/46845/","excerpt":"1.使用 spring的 IoC的实现账户的 CRUD(xml)1.1 环境搭建1.1.1 环境配置1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbutils&lt;/groupId&gt; &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;","text":"1.使用 spring的 IoC的实现账户的 CRUD(xml)1.1 环境搭建1.1.1 环境配置1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbutils&lt;/groupId&gt; &lt;artifactId&gt;commons-dbutils&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 1.1.2 编写实体类Account 123456789101112131415161718192021222324252627282930313233343536373839public class Account implements Serializable &#123; private Integer id; private String name; private Float money; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Float getMoney() &#123; return money; &#125; public void setMoney(Float money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", money=\" + money + '&#125;'; &#125;&#125; 1.1.3 编写持久层代码AccountDao 1234567891011public interface AccountDao &#123; List&lt;Account&gt; findAllAccount(); Account findAccountById(Integer accountId); void saveAccount(Account account); void updateAccount(Account account); void deleteAccount(Integer accountId);&#125; AccountDaoImpl 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class AccountDaoImpl implements AccountDao &#123; private QueryRunner queryRunner; public void setQueryRunner(QueryRunner queryRunner) &#123; this.queryRunner = queryRunner; &#125; @Override public List&lt;Account&gt; findAllAccount() &#123; try &#123; return queryRunner.query(\"select * from account\",new BeanListHandler&lt;Account&gt;(Account.class)); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public Account findAccountById(Integer accountId) &#123; try &#123; return queryRunner.query(\"select * from account where id=?\",new BeanHandler&lt;Account&gt;(Account.class),accountId); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public void saveAccount(Account account) &#123; try &#123; queryRunner.update(\"insert into account(name,money)values(?,?)\",account.getName(),account.getMoney()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void updateAccount(Account account) &#123; try &#123; queryRunner.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void deleteAccount(Integer accountId) &#123; try &#123; queryRunner.update(\"delete from account where id=?\",accountId); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 1.1.4 编写业务层代码AccountService 1234567891011public interface AccountService &#123; List&lt;Account&gt; findAllAccount(); Account findAccountById(Integer accountId); void saveAccount(Account account); void updateAccount(Account account); void deleteAccount(Integer accountId);&#125; AccountServiceImpl 1234567891011121314151617181920212223242526272829303132public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public List&lt;Account&gt; findAllAccount() &#123; return accountDao.findAllAccount(); &#125; @Override public Account findAccountById(Integer accountId) &#123; return accountDao.findAccountById(accountId); &#125; @Override public void saveAccount(Account account) &#123; accountDao.saveAccount(account); &#125; @Override public void updateAccount(Account account) &#123; accountDao.updateAccount(account); &#125; @Override public void deleteAccount(Integer accountId) &#123; accountDao.deleteAccount(accountId); &#125;&#125; 1.2 配置对象bean.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置service--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt; &lt;!--注入dao--&gt; &lt;property name=\"accountDao\" ref=\"accountDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置Dao对象--&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt; &lt;!-- 注入QueryRunner --&gt; &lt;property name=\"queryRunner\" ref=\"queryRunner\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置QueryRunner--&gt; &lt;bean id=\"queryRunner\" class=\"org.apache.commons.dbutils.QueryRunner\" scope=\"prototype\"&gt; &lt;!--注入数据源--&gt; &lt;constructor-arg name=\"ds\" ref=\"dataSource\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!--连接数据库的必备信息--&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 1.3 测试案例AccountServiceTest 12345678910111213141516171819202122232425262728293031323334353637383940@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:bean.xml\")public class AccountServiceTest &#123; @Autowired private AccountService accountService; @Test public void testFindAll()&#123; List&lt;Account&gt; accounts = accountService.findAllAccount(); for (Account account:accounts)&#123; System.out.println(account); &#125; &#125; @Test public void testFindOne() &#123; Account account = accountService.findAccountById(1); System.out.println(account); &#125; @Test public void testSave() &#123; Account account=new Account(); account.setName(\"test\"); account.setMoney(2000f); accountService.saveAccount(account); &#125; @Test public void testUpdate() &#123; Account account=accountService.findAccountById(4); account.setMoney(3000f); accountService.updateAccount(account); &#125; @Test public void testDelete() &#123; accountService.deleteAccount(4); &#125;&#125; 2.基于注解的 IOC 配置2.1 常用注解2.1.1 用于创建对象的相当于： 1&lt;bean id=\"\" class=\"\"&gt; @Component 作用： 把资源让 spring 来管理。相当于在 xml 中配置一个 bean。 属性： value：指定 bean 的 id。如果不指定 value 属性，默认 bean 的 id 是当前类的类名。首字母小写。 @Controller @Service @Repository ​ 他们三个注解都是针对一个的衍生注解，他们的作用及属性都是一模一样的。 他们只不过是提供了更加明确的语义化。 @Controller：一般用于表现层的注解。 @Service：一般用于业务层的注解。 @Repository：一般用于持久层的注解。 细节：如果注解中有且只有一个属性要赋值时，且名称是 value，value在赋值是可以不写。 2.1.2 用于注入数据的 相当于： 12&lt;property name=\"\" ref=\"\"&gt; &lt;property name=\"\" value=\"\"&gt; @Autowired 作用： 自动按照类型注入。当使用注解注入属性时，set方法可以省略。它只能注入其他 bean 类型。当有多个 类型匹配时，使用要注入的对象变量名称作为 bean 的 id，在 spring 容器查找，找到了也可以注入成功。找不到 就报错。 @Qualifier 作用： 在自动按照类型注入的基础之上，再按照 Bean 的 id 注入。它在给字段注入时不能独立使用，必须和 @Autowire 一起使用；但是给方法参数注入时，可以独立使用。 属性： value：指定 bean 的 id。 *@Resource * 作用： 直接按照 Bean 的 id 注入。它也只能注入其他 bean 类型。 属性： name：指定 bean 的 id @Value 作用： 注入基本数据类型和 String 类型数据的 属性： value：用于指定值 2.1.3 用于改变作用范围的相当于： 1&lt;bean id=\"\" class=\"\" scope=\"\"&gt; @Scope 作用： 指定 bean 的作用范围。 属性： value：指定范围的值。 取值：singleton prototype request session globalsession 2.1.4 和生命周期相关的相当于： 1&lt;bean id=\"\" class=\"\" init-method=\"\" destroy-method=\"\" /&gt; @PostConstruct 作用： 用于指定初始化方法。 @PreDestroy 作用： 用于指定销毁方法。 2.2 spring的纯注解配置2.2.1 待改造的问题我们发现，之所以我们现在离不开 xml 配置文件，是因为我们有一句很关键的配置： 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 告知spring在创建容器时要扫描的包 --&gt; &lt;context:component-scan base-package=\"dao,service\"&gt;&lt;/context:component-scan&gt; &lt;!--配置QueryRunner--&gt; &lt;bean id=\"queryRunner\" class=\"org.apache.commons.dbutils.QueryRunner\" scope=\"prototype\"&gt; &lt;!--注入数据源--&gt; &lt;constructor-arg name=\"ds\" ref=\"dataSource\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 配置数据源 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!--连接数据库的必备信息--&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/spring\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"547717253\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 如果他要也能用注解配置，那么我们就离脱离 xml 文件又进了一步。 另外，数据源和 JdbcTemplate 的配置也需要靠注解来实现。 2.2.2 新注解说明@Configuration 作用： 用于指定当前类是一个 spring 配置类，当创建容器时会从该类上加载注解。获取容器时需要使用 AnnotationApplicationContext(有@Configuration 注解的类.class)。 属性： value:用于指定配置类的字节码 @ComponentScan 作用： 用于指定 spring 在初始化容器时要扫描的包。作用和在 spring 的 xml 配置文件中的： &lt;context:component-scan base-package=”com.itheima”/&gt;是一样的。 属性： basePackages：用于指定要扫描的包。和该注解中的 value 属性作用一样。 @Bean 作用： 该注解只能写在方法上，表明使用此方法创建一个对象，并且放入 spring 容器。 属性： name：给当前@Bean 注解方法创建的对象指定一个名称(即 bean 的 id）。 @PropertySource 作用： 用于加载.properties 文件中的配置。例如我们配置数据源时，可以把连接数据库的信息写到 properties 配置文件中，就可以使用此注解指定 properties 配置文件的位置。 属性： value[]：用于指定 properties 文件位置。如果是在类路径下，需要写上 classpath: @Import 作用： 用于导入其他配置类，在引入其他配置类时，可以不用再写@Configuration 注解。当然，写上也没问 题。 属性： value[]：用于指定其他配置类的字节码。 SpringConfiguration 1234567891011121314151617181920212223242526272829303132333435363738/** * 该类是一个配置类，它的作用和bean.xml是一样的 * spring中的新注解 * Configuration * 作用：指定当前类是一个配置类 * 细节：当配置类作为AnnotationConfigApplicationContext对象创建的参数时，该注解可以不写。 * ComponentScan * 作用：用于通过注解指定spring在创建容器时要扫描的包 * 属性： * value：它和basePackages的作用是一样的，都是用于指定创建容器时要扫描的包。 * 我们使用此注解就等同于在xml中配置了: * &lt;context:component-scan base-package=\"dao,service\"&gt;&lt;/context:component-scan&gt; * Bean * 作用：用于把当前方法的返回值作为bean对象存入spring的ioc容器中 * 属性: * name:用于指定bean的id。当不写时，默认值是当前方法的名称 * 细节： * 当我们使用注解配置方法时，如果方法有参数，spring框架会去容器中查找有没有可用的bean对象。 * 查找的方式和Autowired注解的作用是一样的 * Import * 作用：用于导入其他的配置类 * 属性： * value：用于指定其他配置类的字节码。 * 当我们使用Import的注解之后，有Import注解的类就父配置类，而导入的都是子配置类 * PropertySource * 作用：用于指定properties文件的位置 * 属性： * value：指定文件的名称和路径。 * 关键字：classpath，表示类路径下 */@Configuration//@ComponentScans(value = &#123;@ComponentScan(basePackages = \"dao\"),@ComponentScan(value = \"service\")&#125;)@ComponentScan(&#123;\"dao\",\"service\"&#125;)@Import(JdbcConfig.class)@PropertySource(\"classpath:jdbcConfig.properties\")public class SpringConfiguration &#123;&#125; JdbcConfig 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class JdbcConfig &#123; @Value(\"$&#123;jdbc.driver&#125;\") private String driver; @Value(\"$&#123;jdbc.url&#125;\") private String url; @Value(\"$&#123;jdbc.username&#125;\") private String username; @Value(\"$&#123;jdbc.password&#125;\") private String password; @Bean(name = \"queryRunner\") @Scope(\"prototype\") public QueryRunner createQueryRunner(@Qualifier(\"ds\") DataSource dataSource) &#123; return new QueryRunner(dataSource); &#125; @Bean(name = \"ds\") public DataSource createDataSource() &#123; try &#123; ComboPooledDataSource ds = new ComboPooledDataSource(); ds.setDriverClass(driver); ds.setJdbcUrl(url); ds.setUser(username); ds.setPassword(password); return ds; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; AccountDaoImpl 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Repository(\"accountDao\")public class AccountDaoImpl implements AccountDao &#123; @Autowired private QueryRunner queryRunner; @Override public List&lt;Account&gt; findAllAccount() &#123; try &#123; return queryRunner.query(\"select * from account\",new BeanListHandler&lt;Account&gt;(Account.class)); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public Account findAccountById(Integer accountId) &#123; try &#123; return queryRunner.query(\"select * from account where id=?\",new BeanHandler&lt;Account&gt;(Account.class),accountId); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; @Override public void saveAccount(Account account) &#123; try &#123; queryRunner.update(\"insert into account(name,money)values(?,?)\",account.getName(),account.getMoney()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void updateAccount(Account account) &#123; try &#123; queryRunner.update(\"update account set name=?,money=? where id=?\",account.getName(),account.getMoney(),account.getId()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void deleteAccount(Integer accountId) &#123; try &#123; queryRunner.update(\"delete from account where id=?\",accountId); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; AccountServiceImpl 12345678910111213141516171819202122232425262728293031@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Autowired private AccountDao accountDao; @Override public List&lt;Account&gt; findAllAccount() &#123; return accountDao.findAllAccount(); &#125; @Override public Account findAccountById(Integer accountId) &#123; return accountDao.findAccountById(accountId); &#125; @Override public void saveAccount(Account account) &#123; accountDao.saveAccount(account); &#125; @Override public void updateAccount(Account account) &#123; accountDao.updateAccount(account); &#125; @Override public void deleteAccount(Integer accountId) &#123; accountDao.deleteAccount(accountId); &#125;&#125; jdbcConfig.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/springjdbc.username=rootjdbc.password=547717253 3. Spring 整合 JunitAccountServiceTest 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 使用Junit单元测试：测试我们的配置 * Spring整合junit的配置 * 1、导入spring整合junit的jar(坐标) * 2、使用Junit提供的一个注解把原有的main方法替换了，替换成spring提供的 * @Runwith * 3、告知spring的运行器，spring和ioc创建是基于xml还是注解的，并且说明位置 * @ContextConfiguration * locations：指定xml文件的位置，加上classpath关键字，表示在类路径下 * classes：指定注解类所在地位置 * * 当我们使用spring 5.x版本的时候，要求junit的jar必须是4.12及以上 *///1.使用@RunWith 注解替换原有运行器 @RunWith(SpringJUnit4ClassRunner.class)//2.使用@ContextConfiguration 指定 spring 配置文件的位置 @ContextConfiguration(classes = SpringConfiguration.class)public class AccountServiceTest &#123; //3.使用@Autowired 给测试类中的变量注入数据 @Autowired private AccountService accountService; @Test public void testFindAll()&#123; List&lt;Account&gt; accounts = accountService.findAllAccount(); for (Account account:accounts)&#123; System.out.println(account); &#125; &#125; @Test public void testFindOne() &#123; Account account = accountService.findAccountById(1); System.out.println(account); &#125; @Test public void testSave() &#123; Account account=new Account(); account.setName(\"test\"); account.setMoney(2000f); accountService.saveAccount(account); &#125; @Test public void testUpdate() &#123; Account account=accountService.findAccountById(4); account.setMoney(3000f); accountService.updateAccount(account); &#125; @Test public void testDelete() &#123; accountService.deleteAccount(4); &#125;&#125; 为什么不把测试类配到 xml 中 在解释这个问题之前，先解除大家的疑虑，配到 XML 中能不能用呢？ ​ 答案是肯定的，没问题，可以使用。 那么为什么不采用配置到 xml 中的方式呢？ ​ 原因： 第一：当我们在 xml 中配置了一个 bean，spring 加载配置文件创建容器时，就会创建对象。 第二：测试类只是我们在测试功能时使用，而在项目中它并不参与程序逻辑，也不会解决需求上的问 题，所以创建完了，并没有使用。那么存在容器中就会造成资源的浪费。 所以，基于以上两点，我们不应该把测试配置到 xml 文件中。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring框架(三)","slug":"Spring框架(三)","date":"2021-05-08T13:19:59.170Z","updated":"2020-04-29T02:44:38.103Z","comments":true,"path":"9823/","link":"","permalink":"http://tonymua.top/9823/","excerpt":"1. AOP的相关概念1.1 AOP 概述1.1.1 什么是 AOPAOP：全称是 Aspect Oriented Programming 即：面向切面编程。 ​ 简单的说它就是把我们程序重复的代码抽取出来，在需要执行的时候，使用动态代理的技术，在不修改源码的基础上，对我们的已有方法进行增强。 1.1.2 AOP 的作用及优势","text":"1. AOP的相关概念1.1 AOP 概述1.1.1 什么是 AOPAOP：全称是 Aspect Oriented Programming 即：面向切面编程。 ​ 简单的说它就是把我们程序重复的代码抽取出来，在需要执行的时候，使用动态代理的技术，在不修改源码的基础上，对我们的已有方法进行增强。 1.1.2 AOP 的作用及优势 作用： 在程序运行期间，不修改源码对已有方法进行增强。 优势： 减少重复代码 提高开发效率 维护方便 1.1.3 AOP 的实现方式使用动态代理技术 1.2 AOP 的具体应用1.2.1 案例中问题1234567891011public class AccountServiceImpl implements IAccountService &#123; private IAccountDao accountDao; public void setAccountDao(IAccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public void saveAccount(Account account) throws SQLException &#123; accountDao.save(account); &#125; &#125; ​ 事务被自动控制了。换言之，我们使用了 connection 对象的 setAutoCommit(true) 此方式控制事务，如果我们每次都执行一条 sql 语句，没有问题，但是如果业务方法一次要执行多条 sql 语句，这种方式就无法实现功能了。 12345678910111213141516/** * 转账 */ void transfer(String sourceName,String targetName,Float money); @Override public void transfer(String sourceName, String targetName, Float money)&#123; //根据名称查询两个账户信息 Account source = accountDao.findByName(sourceName); Account target = accountDao.findByName(targetName); //转出账户减钱，转入账户加钱 source.setMoney(source.getMoney()-money); target.setMoney(target.getMoney()+money); //更新两个账户 accountDao.update(source); int i=1/0; //模拟转账异常 accountDao.update(target); &#125; ​ 当我们执行时，由于执行有异常，转账失败。但是因为我们是每次执行持久层方法都是独立事务，导致无法实现事务控制（不符合事务的一致性） 1.2.2 问题的解决解决办法：让业务层来控制事务的提交和回滚。 1.2.3 动态代理回顾动态代理的特点 ​ 字节码随用随创建，随用随加载。 它与静态代理的区别也在于此。因为静态代理是字节码一上来就创建好，并完成加载。 装饰者模式就是静态代理的一种体现 动态代理常用的有两种方式 基于接口的动态代理: ​ 提供者：JDK 官方的 Proxy 类。 要求：被代理类最少实现一个接口。 基于子类的动态代理: ​ 提供者：第三方的 CGLib，如果报 asmxxxx 异常，需要导入 asm.jar。 要求：被代理类不能用 final 修饰的类（最终类）。 使用 JDK 官方的 Proxy 类创建代理对象 IProducer 123456public interface IProducer &#123; void saleProduct(float money); void afterService(float money);&#125; Producer 123456789public class Producer implements IProducer&#123; public void saleProduct(float money)&#123; System.out.println(\"销售产品,并获得:\"+money); &#125; public void afterService(float money)&#123; System.out.println(\"提供售后服务,并获得:\"+money); &#125;&#125; Client 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class Client &#123; public static void main(String[] args) &#123; final Producer producer=new Producer(); /** * 动态代理： * 特点：字节码随用随创建，随用随加载 * 作用：不修改源码的基础上对方法增强 * 分类： * 基于接口的动态代理 * 基于子类的动态代理 * 基于接口的动态代理： * 涉及的类：Proxy * 提供者：JDK官方 * 如何创建代理对象： * 使用Proxy类中的newProxyInstance方法 * 创建代理对象的要求： * 被代理类最少实现一个接口，如果没有则不能使用 * newProxyInstance方法的参数： * ClassLoader：类加载器 * 它是用于加载代理对象字节码的。和被代理对象使用相同的类加载器。固定写法。 * Class[]：字节码数组 * 它是用于让代理对象和被代理对象有相同方法。固定写法。 * InvocationHandler：用于提供增强的代码 * 它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类，但不是必须的。 * 此接口的实现类都是谁用谁写。 */ IProducer proxyProducer = (IProducer) Proxy.newProxyInstance(producer.getClass().getClassLoader(), producer.getClass().getInterfaces(), new InvocationHandler() &#123; /** * 作用：执行被代理对象的任何接口方法都会经过该方法 * 方法参数的含义 * @param proxy 代理对象的引用 * @param method 当前执行的方法 * @param args 当前执行方法所需的参数 * @return 和被代理对象方法有相同的返回值 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //提供增强的代码 Object returnValue=null; //1.获取方法执行的参数 Float money = (Float) args[0]; //2.判断当前方法是不是销售 if (\"saleProduct\".equals(method.getName()))&#123; returnValue= method.invoke(producer,money*0.8f); &#125; return returnValue; &#125; &#125;); proxyProducer.saleProduct(5000f); &#125;&#125; 使用 CGLib 的 Enhancer 类创建代理对象 Producer 123456789public class Producer &#123; public void saleProduct(float money)&#123; System.out.println(\"销售产品,并获得:\"+money); &#125; public void afterService(float money)&#123; System.out.println(\"提供售后服务,并获得:\"+money); &#125;&#125; Client 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Client &#123; public static void main(String[] args) &#123; final Producer producer=new Producer(); /** * 动态代理： * 特点：字节码随用随创建，随用随加载 * 作用：不修改源码的基础上对方法增强 * 分类： * 基于接口的动态代理 * 基于子类的动态代理 * 基于子类的动态代理： * 涉及的类：Enhancer * 提供者：第三方cglib库 * 如何创建代理对象： * 使用Enhancer类中的create方法 * 创建代理对象的要求： * 被代理类不能是最终类 * create方法的参数： * Class：字节码 * 它是用于指定被代理对象的字节码。 * * Callback：用于提供增强的代码 * 它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类，但不是必须的。 * 此接口的实现类都是谁用谁写。 * 我们一般写的都是该接口的子接口实现类：MethodInterceptor */ Producer cglibProducer = (Producer) Enhancer.create(producer.getClass(), new MethodInterceptor() &#123; /** * 执行被代理对象的任何方法都会经过该方法 * @param proxy * @param method * @param args * 以上三个参数和基于接口的动态代理中invoke方法的参数是一样的 * @param methodProxy ：当前执行方法的代理对象 * @return * @throws Throwable */ @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float) args[0]; //2.判断当前方法是不是销售 if (\"saleProduct\".equals(method.getName())) &#123; returnValue = method.invoke(producer, money * 0.8f); &#125; return returnValue; &#125; &#125;); cglibProducer.saleProduct(5000f); &#125;&#125; 2. Spring中的 AOP2.1 Spring中 AOP 的细节AOP 相关术语 ​ Joinpoint(连接点): 所谓连接点是指那些被拦截到的点。在 spring 中,这些点指的是方法,因为 spring 只支持方法类型的 连接点。 ​ Pointcut(切入点): 所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义。 ​ Advice(通知/增强): 所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知。 通知的类型：前置通知,后置通知,异常通知,最终通知,环绕通知。 ​ Introduction(引介): 引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方 法或 Field。 ​ Target(目标对象): 代理的目标对象。 ​ Weaving(织入): 是指把增强应用到目标对象来创建新的代理对象的过程。 spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入。 ​ Proxy（代理）: 一个类被 AOP 织入增强后，就产生一个结果代理类。 ​ Aspect(切面): 是切入点和通知（引介）的结合。 2.2 基于 XML 的 AOP 配置123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; AccountService 123456789public interface AccountService &#123; //模拟保存账户 void saveAccount(); void updateAccount(int i); int deleteAccount();&#125; AccountServiceImpl 1234567891011121314151617public class AccountServiceImpl implements AccountService &#123; @Override public void saveAccount() &#123; System.out.println(\"保存......\"); &#125; @Override public void updateAccount(int i) &#123; System.out.println(\"更新......\"+i); &#125; @Override public int deleteAccount() &#123; System.out.println(\"删除......\"); return 0; &#125;&#125; Logger 1234567//用于记录日志的工具类，它里面提供了公共的代码public class Logger &#123;//用于打印日志：计划让其在切入点方法执行之前执行（切入点方法就是业务层方法） public void printLog()&#123; System.out.println(\"Logger类中的pringLog方法开始记录日志了。。。\"); &#125;&#125; bean.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- 配置srping的Ioc,把service对象配置进来--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;!--spring中基于XML的AOP配置步骤 1、把通知Bean也交给spring来管理 2、使用aop:config标签表明开始AOP的配置 3、使用aop:aspect标签表明配置切面 id属性：是给切面提供一个唯一标识 ref属性：是指定通知类bean的Id。 4、在aop:aspect标签的内部使用对应标签来配置通知的类型 我们现在示例是让printLog方法在切入点方法执行之前之前：所以是前置通知 aop:before：表示配置前置通知 method属性：用于指定Logger类中哪个方法是前置通知 pointcut属性：用于指定切入点表达式，该表达式的含义指的是对业务层中哪些方法增强 切入点表达式的写法： 关键字：execution(表达式) 表达式： 访问修饰符 返回值 包名.包名.包名...类名.方法名(参数列表) 标准的表达式写法： public void com.itheima.service.impl.AccountServiceImpl.saveAccount() 访问修饰符可以省略 void com.itheima.service.impl.AccountServiceImpl.saveAccount() 返回值可以使用通配符，表示任意返回值 * com.itheima.service.impl.AccountServiceImpl.saveAccount() 包名可以使用通配符，表示任意包。但是有几级包，就需要写几个*. * *.*.*.*.AccountServiceImpl.saveAccount()) 包名可以使用..表示当前包及其子包 * *..AccountServiceImpl.saveAccount() 类名和方法名都可以使用*来实现通配 * *..*.*() 参数列表： 可以直接写数据类型： 基本类型直接写名称 int 引用类型写包名.类名的方式 java.lang.String 可以使用通配符表示任意类型，但是必须有参数 可以使用..表示有无参数均可，有参数可以是任意类型 全通配写法： * *..*.*(..) 实际开发中切入点表达式的通常写法： 切到业务层实现类下的所有方法 * com.itheima.service.impl.*.*(..) --&gt; &lt;!--配置logger类--&gt; &lt;bean id=\"logger\" class=\"utils.Logger\"&gt;&lt;/bean&gt; &lt;!--配置AOP--&gt; &lt;aop:config&gt; &lt;!--配置切面--&gt; &lt;aop:aspect id=\"logAdvice\" ref=\"logger\"&gt; &lt;!-- 配置通知的类型，并且建立通知方法和切入点方法的关联--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(public void service.impl.AccountServiceImpl.saveAccount())\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(..))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(int))\"&gt;&lt;/aop:before&gt;--&gt; &lt;aop:before method=\"printLog\" pointcut=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:before&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; AOPTest 12345678910public class AOPTest &#123; public static void main(String[] args) &#123; //1.获取容器 ApplicationContext ac=new ClassPathXmlApplicationContext(\"bean.xml\"); //2.获取对象 AccountService accountService= (AccountService) ac.getBean(\"accountService\"); //3.执行方法 accountService.saveAccount(); &#125;&#125; 2.3 常用通知bean.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- 配置srping的Ioc,把service对象配置进来--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;!--配置logger类--&gt; &lt;bean id=\"logger\" class=\"utils.Logger\"&gt;&lt;/bean&gt; &lt;!--配置AOP--&gt; &lt;aop:config&gt; &lt;!-- 配置切入点表达式 id属性用于指定表达式的唯一标识。expression属性用于指定表达式内容 此标签写在aop:aspect标签内部只能当前切面使用。 它还可以写在aop:aspect外面，此时就变成了所有切面可用 --&gt; &lt;aop:pointcut id=\"pt1\" expression=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:pointcut&gt; &lt;!--配置切面--&gt; &lt;aop:aspect id=\"logAdvice\" ref=\"logger\"&gt; &lt;!-- 配置通知的类型，并且建立通知方法和切入点方法的关联--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(public void service.impl.AccountServiceImpl.saveAccount())\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(..))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--&lt;aop:before method=\"printLog\" pointcut=\"execution(* *..*.*(int))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--配置前置通知：在切入点方法执行之前执行--&gt; &lt;!--&lt;aop:before method=\"beforePrintLog\" pointcut=\"execution(* service.impl.*.*(..))\"&gt;&lt;/aop:before&gt;--&gt; &lt;!--配置后置通知：在切入点方法正常执行之后值。它和异常通知永远只能执行一个--&gt; &lt;!--&lt;aop:after-returning method=\"afterReturningPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:after-returning&gt;--&gt; &lt;!--配置异常通知：在切入点方法执行产生异常之后执行。它和后置通知永远只能执行一个--&gt; &lt;!--&lt;aop:after-throwing method=\"afterThrowingPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:after-throwing&gt;--&gt; &lt;!--配置最终通知：无论切入点方法是否正常执行它都会在其后面执行--&gt; &lt;!--&lt;aop:after method=\"afterPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:after&gt;--&gt; &lt;!-- 配置环绕通知 详细的注释请看Logger类中--&gt; &lt;aop:around method=\"arroundPrintLog\" pointcut-ref=\"pt1\"&gt;&lt;/aop:around&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; Logger 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Logger &#123; // 用于打印日志：计划让其在切入点方法执行之前执行（切入点方法就是业务层方法） //前置通知 public void beforePrintLog() &#123; System.out.println(\"Logger类中的beforPrintLog方法开始记录日志了。。。\"); &#125; //后置通知 public void afterReturningPrintLog() &#123; System.out.println(\"Logger类中的afterReturningPrintLog方法开始记录日志了。。。\"); &#125; //异常通知 public void afterThrowingPrintLog() &#123; System.out.println(\"Logger类中的afterThrowingPrintLog方法开始记录日志了。。。\"); &#125; //最终通知 public void afterPrintLog() &#123; System.out.println(\"Logger类中的afterPrintLog方法开始记录日志了。。。\"); &#125; /** * 环绕通知 * 问题： * 当我们配置了环绕通知之后，切入点方法没有执行，而通知方法执行了。 * 分析： * 通过对比动态代理中的环绕通知代码，发现动态代理的环绕通知有明确的切入点方法调用，而我们的代码中没有。 * 解决： * Spring框架为我们提供了一个接口：ProceedingJoinPoint。该接口有一个方法proceed()，此方法就相当于明确调用切入点方法。 * 该接口可以作为环绕通知的方法参数，在程序执行时，spring框架会为我们提供该接口的实现类供我们使用。 * &lt;p&gt; * spring中的环绕通知： * 它是spring框架为我们提供的一种可以在代码中手动控制增强方法何时执行的方式。 */ public Object arroundPrintLog(ProceedingJoinPoint pjp) &#123; Object returnValue = null; try &#123; Object[] args = pjp.getArgs();//得到方法执行所需的参数 System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。前置\"); returnValue = pjp.proceed(args);//明确调用业务层方法(切入点方法) System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。后置\"); return returnValue; &#125; catch (Throwable throwable) &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。异常\"); throw new RuntimeException(throwable); &#125; finally &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。最终\"); &#125; &#125;&#125; 2.4 基于注解的 AOP 配置AccountService 123456public interface AccountService &#123; //模拟保存账户 void saveAccount();&#125; AccountServiceImpl 12345678@Service(\"accountService\")public class AccountServiceImpl implements AccountService &#123; @Override public void saveAccount() &#123; System.out.println(\"保存......\");// int i=1/0; &#125;&#125; bean.xml 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 配置spring创建容器时要扫描的包--&gt; &lt;context:component-scan base-package=\"service,utils\"&gt;&lt;/context:component-scan&gt; &lt;!-- 配置spring开启注解AOP的支持 --&gt; &lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;&lt;/beans&gt; Logger 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Component(\"logger\")@Aspect//表示当前类是一个切面类public class Logger &#123; @Pointcut(\"execution(* service.impl.*.*(..))\") private void pt1()&#123; &#125; //前置通知 @Before(\"pt1()\") public void beforePrintLog() &#123; System.out.println(\"Logger类中的beforPrintLog方法开始记录日志了。。。\"); &#125; //后置通知 @AfterReturning(\"pt1()\") public void afterReturningPrintLog() &#123; System.out.println(\"Logger类中的afterReturningPrintLog方法开始记录日志了。。。\"); &#125; //异常通知 @AfterThrowing(\"pt1()\") public void afterThrowingPrintLog() &#123; System.out.println(\"Logger类中的afterThrowingPrintLog方法开始记录日志了。。。\"); &#125; //最终通知 @After(\"pt1()\") public void afterPrintLog() &#123; System.out.println(\"Logger类中的afterPrintLog方法开始记录日志了。。。\"); &#125; @Around(\"pt1()\") public Object arroundPrintLog(ProceedingJoinPoint pjp) &#123; Object returnValue = null; try &#123; Object[] args = pjp.getArgs();//得到方法执行所需的参数 System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。前置\"); returnValue = pjp.proceed(args);//明确调用业务层方法(切入点方法) System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。后置\"); return returnValue; &#125; catch (Throwable throwable) &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。异常\"); throw new RuntimeException(throwable); &#125; finally &#123; System.out.println(\"Logger类中的aroundPringLog方法开始记录日志了。。。最终\"); &#125; &#125;&#125; 不使用 XML的配置方式 123456@Configuration//@ComponentScans(value = &#123;@ComponentScan(basePackages = \"dao\"),@ComponentScan(value = \"service\")&#125;)@ComponentScan(&#123;\"dao\",\"service\"&#125;)@EnableAspectJAutoProxypublic class SpringConfiguration &#123;&#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring框架(一)","slug":"Spring框架(一)","date":"2021-05-08T13:19:59.168Z","updated":"2020-04-29T02:44:38.081Z","comments":true,"path":"30297/","link":"","permalink":"http://tonymua.top/30297/","excerpt":"1. Spring概述1.1 spring 是什么​ Spring是分层的 Java SE/EE应用 full-stack 轻量级开源框架，以 IoC（Inverse Of Control： 反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多 著名的第三方框架和类库，逐渐成为使用最多的Java EE 企业应用开源框架。 1.2 spring 的优势方便解耦，简化开发","text":"1. Spring概述1.1 spring 是什么​ Spring是分层的 Java SE/EE应用 full-stack 轻量级开源框架，以 IoC（Inverse Of Control： 反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多 著名的第三方框架和类库，逐渐成为使用最多的Java EE 企业应用开源框架。 1.2 spring 的优势方便解耦，简化开发 ​ 通过 Spring提供的 IoC容器，可以将对象间的依赖关系交由 Spring进行控制，避免硬编码所造 成的过度程序耦合。用户也不必再为单例模式类、属性文件解析等这些很底层的需求编写代码，可 以更专注于上层的应用。 AOP编程的支持 ​ 通过 Spring的 AOP 功能，方便进行面向切面的编程，许多不容易用传统OOP 实现的功能可以通过 AOP 轻松应付。 声明式事务的支持 ​ 可以将我们从单调烦闷的事务管理代码中解脱出来，通过声明式方式灵活的进行事务的管理， 提高开发效率和质量。 方便程序的测试 ​ 可以用非容器依赖的编程方式进行几乎所有的测试工作，测试不再是昂贵的操作，而是随手可 做的事情。 方便集成各种优秀框架 ​ Spring可以降低各种框架的使用难度，提供了对各种优秀框架（Struts、Hibernate、Hessian、Quartz 等）的直接支持。 降低 JavaEE API的使用难度 Spring对 JavaEE API（如 JDBC、JavaMail、远程调用等）进行了薄薄的封装层，使这些 API 的 使用难度大为降低。 Java源码是经典学习范例 ​ Spring的源代码设计精妙、结构清晰、匠心独用，处处体现着大师对Java 设计模式灵活运用以 及对 Java技术的高深造诣。它的源代码无意是 Java 技术的最佳实践的范例。 2. IoC 的概念和作用2.1 什么是程序的耦合​ 耦合性(Coupling)，也叫耦合度，是对模块间关联程度的度量。耦合的强弱取决于模块间接口的复杂性、调 用模块的方式以及通过界面传送数据的多少。模块间的耦合度是指模块之间的依赖关系，包括控制关系、调用关系、数据传递关系。模块间联系越多，其耦合性越强，同时表明其独立性越差( 降低耦合性，可以提高其独立 性)。耦合性存在于各个领域，而非软件设计中独有的，但是我们只讨论软件工程中的耦合。 ​ 在软件工程中，耦合指的就是就是对象之间的依赖性。对象之间的耦合越高，维护成本越高。因此对象的设计应使类和构件之间的耦合最小。软件设计中通常用耦合度和内聚度作为衡量模块独立程度的标准。划分模块的一个 准则就是高内聚低耦合。 它有如下分类： （1） 内容耦合。当一个模块直接修改或操作另一个模块的数据时，或一个模块不通过正常入口而转入另 一个模块时，这样的耦合被称为内容耦合。内容耦合是最高程度的耦合，应该避免使用之。 （2） 公共耦合。两个或两个以上的模块共同引用一个全局数据项，这种耦合被称为公共耦合。在具有大 量公共耦合的结构中，确定究竟是哪个模块给全局变量赋了一个特定的值是十分困难的。 （3） 外部耦合 。一组模块都访问同一全局简单变量而不是同一全局数据结构，而且不是通过参数表传 递该全局变量的信息，则称之为外部耦合。 （4） 控制耦合 。一个模块通过接口向另一个模块传递一个控制信号，接受信号的模块根据信号值而进 行适当的动作，这种耦合被称为控制耦合。 （5） 标记耦合 。若一个模块 A 通过接口向两个模块 B 和 C 传递一个公共参数，那么称模块 B 和 C 之间 存在一个标记耦合。 （6） 数据耦合。模块之间通过参数来传递数据，那么被称为数据耦合。数据耦合是最低的一种耦合形 式，系统中一般都存在这种类型的耦合，因为为了完成一些有意义的功能，往往需要将某些模块的输出数据作为另一些模块的输入数据。 （7） 非直接耦合 。两个模块之间没有直接关系，它们之间的联系完全是通过主模块的控制和调用来实 现的。 总结： 耦合是影响软件复杂程度和设计质量的一个重要因素，在设计上我们应采用以下原则：如果模块间必须 存在耦合，就尽量使用数据耦合，少用控制耦合，限制公共耦合的范围，尽量避免使用内容耦合。 内聚与耦合 内聚标志一个模块内各个元素彼此结合的紧密程度，它是信息隐蔽和局部化概念的自然扩展。内聚是从 功能角度来度量模块内的联系，一个好的内聚模块应当恰好做一件事。它描述的是模块内的功能联系。耦合是软件结构中各模块之间相互连接的一种度量，耦合强弱取决于模块间接口的复杂程度、进入或访问一个模块的点以及通过接口的数据。 程序讲究的是低耦合，高内聚。就是同一个模块内的各个元素之间要高度紧密，但是各个模块之 间的相互依存度却要不那么紧密。 ​ 内聚和耦合是密切相关的，同其他模块存在高耦合的模块意味着低内聚，而高内聚的模块意味着该模块同其他模块之间是低耦合。在进行软件设计时，应力争做到高内聚，低耦合。 ​ 我们在开发中，有些依赖关系是必须的，有些依赖关系可以通过优化代码来解除的。 请看下面的示例代码： 123public class AccountServiceImpl implements IAccountService &#123; private IAccountDao accountDao = new AccountDaoImpl(); &#125; ​ 上面的代码表示： 业务层调用持久层，并且此时业务层在依赖持久层的接口和实现类。如果此时没有持久层实现类，编译 将不能通过。这种编译期依赖关系，应该在我们开发中杜绝。我们需要优化代码解决。 ​ 再比如： 早期我们的 JDBC 操作，注册驱动时，我们为什么不使用 DriverManager 的 register 方法，而是采 用 Class.forName 的方式？ 12345678910public class JdbcDemo1 &#123; public static void main(String[] args) throws Exception &#123; //1.注册驱动 //DriverManager.registerDriver(new com.mysql.jdbc.Driver()); Class.forName(\"com.mysql.jdbc.Driver\"); //2.获取连接 //3.获取预处理 sql 语句对象 //4.获取结果集 //5.遍历结果集 &#125; &#125; ​ 原因就是： 我们的类依赖了数据库的具体驱动类（MySQL），如果这时候更换了数据库品牌（比如 Oracle），需要 修改源码来重新数据库驱动。这显然不是我们想要的. 2.2 解决程序耦合的思路​ 当是我们讲解 jdbc 时，是通过反射来注册驱动的，代码如下： 1Class.forName(\"com.mysql.jdbc.Driver\");//此处只是一个字符串 ​ 此时的好处是，我们的类中不再依赖具体的驱动类，此时就算删除 mysql 的驱动 jar 包，依然可以编译（运 行就不要想了，没有驱动不可能运行成功的）。 同时，也产生了一个新的问题，mysql 驱动的全限定类名字符串是在 java 类中写死的，一旦要改还是要修改 源码。 解决这个问题也很简单，使用配置文件配置。 2.3 工厂模式解耦​ 在实际开发中我们可以把三层的对象都使用配置文件配置起来，当启动服务器应用加载的时候，让一个类中的方法通过读取配置文件，把这些对象创建出来并存起来。在接下来的使用的时候，直接拿过来用就好了。 那么，这个读取配置文件，创建和获取三层对象的类就是工厂. 3.使用 spring的 IOC解决程序耦合3.1 案例的前期准​ 我们使用的案例是，账户的业务层和持久层的依赖关系解决。在开始 spring 的配置之前，我们要先准备 一下环境。由于我们是使用 spring 解决依赖关系，并不是真正的要做增删改查操作，所以此时我们没必要写实体 类。并且我们在此处使用的是 java 工程，不是 java web 工程。 3.1.1 准备 spring 的开发包pom.xml 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.1.2 创建业务层接口和实现类123456789public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao = new AccountDaoImpl(); // private AccountDao accountDao= (AccountDao) BeanFactory.getBean(\"accountDao\"); @Override public void saveAccount() &#123; accountDao.saveAccount(); &#125;&#125; 1234public interface AccountService &#123; //模拟保存账户 void saveAccount();&#125; 3.1.3 创建持久层接口和实现类123456public class AccountDaoImpl implements AccountDao &#123; @Override public void saveAccount() &#123; System.out.println(\"保存了账户\"); &#125;&#125; 123public interface AccountDao &#123; void saveAccount();&#125; 3.2 基于 XML 的配置(入门案例)3.2.1 第一步：在类的根路径下创建一个任意名称的 xml 文件（不能是中文）1234&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;/beans&gt; 3.2.2 第二步：让 spring 管理资源，在配置文件中配置 service 和 dao12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--把对象的创建交给spring来管理--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;bean id=\"accountDao\" class=\"dao.impl.AccountDaoImpl\"&gt;&lt;/bean&gt;&lt;/beans&gt; 3.2.3 测试配置是否成功1234567891011121314151617181920212223/*applicationContext的三个常用实现类： * ClassPathXmlApplicationContext：它可以加载类路径下的配置文件，要求配置文件必须在类路径下。不在的话，加载不了。(更常用) * FileSystemXmlApplicationContext：它可以加载磁盘任意路径下的配置文件(必须有访问权限） * AnnotationConfigApplicationContext：它是用于读取注解创建容器的 * * 核心容器的两个接口引发出的问题： * ApplicationContext: 单例对象适用 采用此接口 * 它在构建核心容器时，创建对象采取的策略是采用立即加载的方式。也就是说，只要一读取完配置文件马上就创建配置文件中配置的对象。 * * BeanFactory: 多例对象使用 * 它在构建核心容器时，创建对象采取的策略是采用延迟加载的方式。也就是说，什么时候根据id获取对象了，什么时候才真正的创建对象。*/public class Client &#123; public static void main(String[] args) &#123; //1.获取核心容器对象 ApplicationContext ac = new ClassPathXmlApplicationContext(\"bean.xml\");// ApplicationContext ac=new FileSystemXmlApplicationContext() //2.根据id获取Bean对象 AccountService as = (AccountService) ac.getBean(\"accountService\"); AccountDao ad=ac.getBean(\"accountDao\",AccountDao.class); as.saveAccount(); &#125;&#125; 3.3 Spring基于 XML 的 IOC 细节3.3.1 BeanFactory和 ApplicationContext 的区别BeanFactory 才是 Spring 容器中的顶层接口。ApplicationContext 是它的子接口。 BeanFactory 和 ApplicationContext 的区别： 创建对象的时间点不一样。 ApplicationContext：只要一读取配置文件，默认情况下就会创建对象。 BeanFactory：什么使用什么时候创建对象 3.3.2 ApplicationContext 接口的实现类ClassPathXmlApplicationContext： 它是从类的根路径下加载配置文件 推荐使用这种 FileSystemXmlApplicationContext： 它是从磁盘路径上加载配置文件，配置文件可以在磁盘的任意位置。 AnnotationConfigApplicationContext: 当我们使用注解配置容器对象时，需要使用此类来创建 spring 容器。它用来读取注解。 3.3.3 IOC 中 bean 标签和管理对象细节3.3.3.1 bean 标签作用： 用于配置对象让 spring 来创建的。 默认情况下它调用的是类中的无参构造函数。如果没有无参构造函数则不能创建成功。 属性： id：给对象在容器中提供一个唯一标识。用于获取对象。 class：指定类的全限定类名。用于反射创建对象。默认情况下调用无参构造函数。 scope：指定对象的作用范围。 ​ * singleton :默认值，单例的. * prototype :多例的. * request :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 request 域中. * session :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 session 域中. * global session :WEB 项目中,应用在 Portlet 环境.如果没有 Portlet 环境那么 globalSession 相当于 session. init-method：指定类中的初始化方法名称。 destroy-method：指定类中销毁方法名称。 3.3.3.2 bean 的作用范围和生命周期单例对象：scope=”singleton” 一个应用只有一个对象的实例。它的作用范围就是整个引用。 生命周期： 对象出生：当应用加载，创建容器时，对象就被创建了。 对象活着：只要容器在，对象一直活着。 对象死亡：当应用卸载，销毁容器时，对象就被销毁了。 多例对象：scope=”prototype” 每次访问对象时，都会重新创建对象实例。 ​ 生命周期： 对象出生：当使用对象时，创建新的对象实例。 对象活着：只要对象在使用中，就一直活着。 对象死亡：当对象长时间不用时，被 java 的垃圾回收器回收了。 3.3.3.3 实例化 Bean 的三种方式第一种方式：使用默认无参构造函数 12&lt;!--在默认情况下：它会根据默认无参构造函数来创建类对象。如果 bean 中没有默认无参构造函数，将会创建失败。 --&gt;&lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\" scope=\"singleton\"&gt;&lt;/bean&gt; 第二种方式：spring管理静态工厂-使用静态工厂的方法创建对象 1234567891011121314 /** 模拟一个静态工厂，创建业务层实现类 */ public class StaticFactory &#123; public static IAccountService createAccountService()&#123; return new AccountServiceImpl(); &#125; &#125; &lt;!-- 此种方式是: 使用 StaticFactory 类中的静态方法 createAccountService 创建对象，并存入 spring 容器 id 属性：指定 bean 的 id，用于从容器中获取 class 属性：指定静态工厂的全限定类名 factory-method 属性：指定生产对象的静态方法 --&gt; &lt;bean id=\"accountService\" class=\"factory.StaticFactory\" factory-method=\"createAccountService\"&gt;&lt;/bean&gt; 第三种方式：spring管理实例工厂-使用实例工厂的方法创建对象 1234567891011121314/** 模拟一个实例工厂，创建业务层实现类 * 此工厂创建对象，必须现有工厂实例对象，再调用方法 */ public class InstanceFactory &#123; public IAccountService createAccountService()&#123; return new AccountServiceImpl(); &#125; &#125; &lt;!-- 此种方式是： 先把工厂的创建交给 spring 来管理。然后在使用工厂的 bean 来调用里面的方法 factory-bean 属性：用于指定实例工厂 bean 的 id。 factory-method 属性：用于指定实例工厂中创建对象的方法。 --&gt; &lt;bean id=\"instancFactory\" class=\"com.itheima.factory.InstanceFactory\"&gt;&lt;/bean&gt; &lt;bean id=\"accountService\" factory-bean=\"instancFactory\" factory-method=\"createAccountService\"&gt;&lt;/bean&gt; 3.3.4 spring 的依赖注入3.3.4.1 依赖注入的概念依赖注入：Dependency Injection。 ​ 它是 spring 框架核心 ioc 的具体实现。 我们的程序在编写时，通过控制反转，把对象的创建交给了 spring，但是代码中不可能出现没有依赖的情况。 ioc 解耦只是降低他们的依赖关系，但不会消除。 例如：我们的业务层仍会调用持久层的方法。 那这种业务层和持久层的依赖关系，在使用 spring 之后，就让 spring 来维护了。 简单的说，就是坐等框架把持久层对象传入业务层，而不用我们自己去获取。 3.3.4.2 构造函数注入​ 顾名思义，就是使用类中的构造函数，给成员变量赋值。注意，赋值的操作不是我们自己做的，而是通过配置的方式，让 spring 框架来为我们注入。具体代码如下： 12345678910111213141516public class AccountServiceImpl implements AccountService &#123; //如果是经常变化的数据,并不适用注入的方式 private String name; private Integer age; private Date birthday; public AccountServiceImpl(String name,Integer age,Date birthday)&#123; this.name=name; this.age=age; this.birthday=birthday; &#125; @Override public void saveAccount() &#123; System.out.println(\"service中的saveAccount方法执行了\"+name+\"---\"+age+\"---\"+birthday); &#125;&#125; 123456789101112131415161718192021222324&lt;!--构造函数注入： 使用的标签:constructor-arg 标签出现的位置：bean标签的内部 标签中的属性 type：用于指定要注入的数据的数据类型，该数据类型也是构造函数中某个或某些参数的类型 index：用于指定要注入的数据给构造函数中指定索引位置的参数赋值。索引的位置是从0开始 name：用于指定给构造函数中指定名称的参数赋值 常用的 =============以上三个用于指定给构造函数中哪个参数赋值=============================== value：用于提供基本类型和String类型的数据 ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象 优势： 在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。 弊端： 改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据，也必须提供。--&gt; &lt;bean id=\"accountService\" class=\"service.impl.AccountServiceImpl\" scope=\"singleton\"&gt; &lt;constructor-arg name=\"name\" value=\"test\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"age\" value=\"18\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"birthday\" ref=\"now\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--配置一个日期对象--&gt; &lt;bean id=\"now\" class=\"java.util.Date\"&gt;&lt;/bean&gt; 3.3.4.3 set 方法注入​ 顾名思义，就是在类中提供需要注入成员的 set 方法。具体代码如下： 123456789101112public class AccountServiceImpl implements IAccountService &#123; private String name; private Integer age; private Date birthday; public void setName(String name) &#123; this.name = name; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; @Override public void saveAccount() &#123; System.out.println(name+\",\"+age+\",\"+birthday); &#125; &#125; 1234567891011121314151617&lt;!-- set方法注入 更常用的方式 涉及的标签：property 出现的位置：bean标签的内部 标签的属性 name：用于指定注入时所调用的set方法名称 value：用于提供基本类型和String类型的数据 ref：用于指定其他的bean类型数据。它指的就是在spring的Ioc核心容器中出现过的bean对象 优势： 创建对象时没有明确的限制，可以直接使用默认构造函数 弊端： 如果有某个成员必须有值，则获取对象是有可能set方法没有执行。 --&gt; &lt;bean id=\"accountService2\" class=\"service.impl.AccountServiceImpl2\" scope=\"singleton\"&gt; &lt;property name=\"name\" value=\"test2\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"18\"&gt;&lt;/property&gt; &lt;property name=\"birthday\" ref=\"now\"&gt;&lt;/property&gt; &lt;/bean&gt; 3.3.4.4 注入集合属性123456789101112131415161718192021222324252627282930313233343536public class AccountServiceImpl3 implements AccountService &#123; private String[] myStrs; private List&lt;String&gt; myList; private Set&lt;String&gt; mySet; private Map&lt;String,String&gt; myMap; private Properties myProps; public void setMyStrs(String[] myStrs) &#123; this.myStrs = myStrs; &#125; public void setMyList(List&lt;String&gt; myList) &#123; this.myList = myList; &#125; public void setMySet(Set&lt;String&gt; mySet) &#123; this.mySet = mySet; &#125; public void setMyMap(Map&lt;String, String&gt; myMap) &#123; this.myMap = myMap; &#125; public void setMyProps(Properties myProps) &#123; this.myProps = myProps; &#125; @Override public void saveAccount() &#123; System.out.println(Arrays.toString(myStrs)); System.out.println(myList); System.out.println(mySet); System.out.println(myMap); System.out.println(myProps); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!-- 复杂类型的注入/集合类型的注入 用于给List结构集合注入的标签： list array set 用于个Map结构集合注入的标签: map props 结构相同，标签可以互换 --&gt; &lt;bean id=\"accountService3\" class=\"service.impl.AccountServiceImpl3\"&gt; &lt;property name=\"myStrs\"&gt; &lt;array&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;ccc&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;property name=\"myList\"&gt; &lt;list&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;ccc&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=\"mySet\"&gt; &lt;set&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;ccc&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;property name=\"myProps\"&gt; &lt;props&gt; &lt;prop key=\"A\"&gt;aaa&lt;/prop&gt; &lt;prop key=\"b\"&gt;bbb&lt;/prop&gt; &lt;prop key=\"c\"&gt;ccc&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;property name=\"myMap\"&gt; &lt;map&gt; &lt;entry key=\"a\" value=\"aaa\"&gt;&lt;/entry&gt; &lt;entry key=\"b\"&gt; &lt;value&gt;bbb&lt;/value&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringMVC框架(二)","slug":"SpringMVC框架(二)","date":"2021-05-08T13:19:59.167Z","updated":"2020-04-29T02:44:38.101Z","comments":true,"path":"38896/","link":"","permalink":"http://tonymua.top/38896/","excerpt":"1. 响应数据和结果视图1.1 返回值分类1.1.1 字符串(String)​ controller 方法返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址。 1234567891011121314// 返回值类型为String @RequestMapping(\"/testString\") public String testString(Model model) &#123; System.out.println(\"testString方法执行了\"); //模拟从数据库中查询User对象 User user = new User(); user.setUsername(\"test\"); user.setPassword(\"123\"); user.setAge(12); model.addAttribute(\"user\", user); return \"success\"; &#125;","text":"1. 响应数据和结果视图1.1 返回值分类1.1.1 字符串(String)​ controller 方法返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址。 1234567891011121314// 返回值类型为String @RequestMapping(\"/testString\") public String testString(Model model) &#123; System.out.println(\"testString方法执行了\"); //模拟从数据库中查询User对象 User user = new User(); user.setUsername(\"test\"); user.setPassword(\"123\"); user.setAge(12); model.addAttribute(\"user\", user); return \"success\"; &#125; 1.1.2 void123456789101112131415 // 返回值类型为void @RequestMapping(\"/testVoid\") //如果没有返回值,默认请求testVoid.jsp public void testVoid(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; System.out.println(\"testVoid方法执行了\");// 编写请求转发的程序// 请求转发:一次请求,不用编写项目的名称// request.getRequestDispatcher(\"/WEB-INF/pages/success.jsp\").forward(request,response);// 重定向:两次请求// response.sendRedirect(request.getContextPath()+\"/index.jsp\");// 直接进行响应 response.setCharacterEncoding(\"UTF-8\"); response.setContentType(\"text/html;charset=UTF-8\"); response.getWriter().print(\"直接响应\"); return; &#125; 1.1.3 ModelAndView​ ModelAndView 是 SpringMVC 为我们提供的一个对象，该对象也可以用作控制器方法的返回值。 1234567891011121314151617 // 返回ModelAndView @RequestMapping(\"/testModelAndView\") public ModelAndView testModelAndView() &#123; System.out.println(\"testModelAndView方法执行了\"); //创建ModelAndView对象 ModelAndView modelAndView = new ModelAndView(); User user = new User(); user.setUsername(\"test\"); user.setPassword(\"123\"); user.setAge(12);// 把user对象存储到modelAndView对象中,也会把user对象存入到request对象 modelAndView.addObject(\"user\", user);// 跳转到哪个页面 modelAndView.setViewName(\"success\"); return modelAndView; &#125; 响应的 jsp代码： 123456789101112&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;成功!&lt;/h3&gt; $&#123;user.username&#125; $&#123;user.age&#125;&lt;/body&gt;&lt;/html&gt; ​ 我们在页面上上获取使用的是 requestScope.username 取的，所以返回 ModelAndView 类型时，浏览器跳转只能是请求转发。 1.2 转发和重定向​ controller 方法在提供了 String 类型的返回值之后，默认就是请求转发。需要注意的是，如果用了 formward：则路径必须写成实际视图 url，不能写逻辑视图。 它相当于“request.getRequestDispatcher(“url”).forward(request,response)”。使用请求 转发，既可以转发到 jsp，也可以转发到其他的控制器方法。 ​ contrller 方法提供了一个 String 类型返回值之后，它需要在返回值里使用:redirect:它相当于“response.sendRedirect(url)”。需要注意的是，如果是重定向到 jsp 页面，则 jsp 页面不 能写在 WEB-INF 目录中，否则无法找到。 123456789// 使用关键字的方式进行转发或者重定向 @RequestMapping(\"/testForwardOrRedirect\") public String testForwardOrRedirect() &#123; System.out.println(\"testForwardOrRedirect方法执行了\");// 请求转发// return \"forward:/WEB-INF/pages/success.jsp\";// 重定向 return \"redirect:/index.jsp\"; &#125; 1.3 ResponseBody 响应 json 数据1.3.1 使用说明作用：该注解用于将 Controller 的方法返回的对象，通过 HttpMessageConverter 接口转换为指定格式的 数据如：json,xml 等，通过 Response 响应给客户端 1.3.2 使用示例需求：使用@ResponseBody 注解实现将 controller 方法返回对象转换为 json 响应给客户端。 前置知识点：Springmvc 默认用 MappingJacksonHttpMessageConverter 对 json 数据进行转换，需要加入 jackson 的包。 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; 注意：2.7.0以下的版本用不了 jsp 中的代码： 123456789101112131415161718192021222324252627282930313233343536&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=\"js/jquery.min.js\"&gt;&lt;/script&gt; &lt;script&gt; // 页面加载，绑定单击事件 $(function()&#123; $(\"#btn\").click(function()&#123; // alert(\"hello btn\"); // 发送ajax请求 $.ajax(&#123; // 编写json格式，设置属性和值 url:\"user/testAjax\", contentType:\"application/json;charset=UTF-8\", data:'&#123;\"username\":\"hehe\",\"password\":\"123\",\"age\":30&#125;', dataType:\"json\", type:\"post\", success:function(data)&#123; // data:服务器端响应的json的数据，进行解析 alert(data); alert(data.username); alert(data.password); alert(data.age); &#125; &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;button id=\"btn\"&gt;发送ajax的请求&lt;/button&gt;&lt;/body&gt;&lt;/html&gt; 控制器中的代码： 12345678910111213// 模拟异步请求响应 @RequestMapping(\"/testAjax\") public @ResponseBody User testAjax(@RequestBody User user) &#123; System.out.println(\"testAjax方法执行了...\"); // 客户端发送ajax的请求，传的是json字符串，后端把json字符串封装到user对象中 System.out.println(user); // 做响应，模拟查询数据库 user.setUsername(\"haha\"); user.setAge(40); // 做响应 return user; &#125; 前端控制器: 1234&lt;!--前端控制器，哪些静态资源不拦截--&gt; &lt;mvc:resources location=\"/css/\" mapping=\"/css/**\"/&gt; &lt;mvc:resources location=\"/images/\" mapping=\"/images/**\"/&gt; &lt;mvc:resources location=\"/js/\" mapping=\"/js/**\"/&gt; 2.SpringMVC实现文件上传2.1 文件上传的回顾2.1.1 文件上传的必要前提A. form 表单的 enctype 取值必须是：multipart/form-data (默认值是:application/x-www-form-urlencoded) enctype:是表单请求正文的类型 B. method 属性取值必须是 Post C. 提供一个文件选择域 1&lt;input type=\"file\" /&gt; 2.1.2 文件上传的原理分析​ 当 form 表单的 enctype 取值不是默认值后，request.getParameter()将失效。 enctype=”application/x-www-form-urlencoded”时，form 表单的正文内容是： key=value&amp;key=value&amp;key=value​ 当 form 表单的 enctype 取值为 Mutilpart/form-data 时，请求正文内容就变成： 每一部分都是 MIME 类型描述的正文—————————–7de1a433602ac 分界符Content-Disposition: form-data; name=”userName” 协议头 aaa 协议的正文—————————–7de1a433602acContent-Disposition: form-data; name=”file”;filename=”C:\\Users\\zhy\\Desktop\\fileupload_demofile\\b.txt”Content-Type: text/plain 协议的类型（MIME 类型） bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb—————————–7de1a433602ac– 2.1.3 借助第三方组件实现文件上传​ 使用 Commons-fileupload 组件实现文件上传，需要导入该组件相应的支撑 jar 包：Commons-fileupload 和commons-io。commons-io 不属于文件上传组件的开发 jar 文件，但Commons-fileupload 组件从 1.1 版本开始，它工作时需要 commons-io 包的支持。 2.2 springmvc 传统方式的文件上传说明 ​ 传统方式的文件上传，指的是我们上传的文件和访问的应用存在于同一台服务器上。 并且上传完成之后，浏览器可能跳转。 配置文件上传的 jar 包到工程 1234567891011&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; jsp页面 1234567891011121314151617181920&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;传统方式文件上传&lt;/h3&gt; &lt;form action=\"user/fileUpload1\" method=\"post\" enctype=\"multipart/form-data\"&gt; 选择文件:&lt;input type=\"file\" name=\"upload\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"上传\"&gt;&lt;br&gt; &lt;/form&gt; &lt;h3&gt;SpringMVC方式文件上传&lt;/h3&gt; &lt;form action=\"user/fileUpload2\" method=\"post\" enctype=\"multipart/form-data\"&gt; 选择文件:&lt;input type=\"file\" name=\"upload\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"上传\"&gt;&lt;br&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 控制器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Controller@RequestMapping(\"/user\")public class UserController &#123; //传统方式文件上传 @RequestMapping(\"/fileUpload1\") public String fileUpload1(HttpServletRequest request) throws Exception&#123; System.out.println(\"传统方式文件上传...\");// 使用fileupload组件完成上传// 上传的位置 String Path = request.getSession().getServletContext().getRealPath(\"/uploads/\"); //判断该路径是否存在 File file = new File(Path); if (!file.exists())&#123; //创建该文件夹 file.mkdirs(); &#125; //解析request对象,获取上传文件项 DiskFileItemFactory fileItemFactory=new DiskFileItemFactory(); ServletFileUpload fileUpload=new ServletFileUpload(fileItemFactory); //解析request List&lt;FileItem&gt; fileItems = fileUpload.parseRequest(request); //遍历 for (FileItem fileItem:fileItems)&#123; //判断当前item对象是否是上传文件项 if (fileItem.isFormField())&#123; //普通表单项 &#125;else &#123; //上传文件项 //获取上传文件的名称 String fileItemName = fileItem.getName(); //把文件的名称设置唯一值,uuid String uuid = UUID.randomUUID().toString().replace(\"-\",\"\" ); fileItemName=uuid+\"_\"+fileItemName; //完成文件上传 fileItem.write(new File(Path,fileItemName)); //删除临时文件 fileItem.delete(); &#125; &#125; return \"success\"; &#125; //SpringMVC方式文件上传 @RequestMapping(\"/fileUpload2\") public String fileUpload2(HttpServletRequest request, MultipartFile upload) throws Exception&#123; System.out.println(\"SpringMVC方式文件上传...\"); String realPath = request.getSession().getServletContext().getRealPath(\"/uploads/\"); File file = new File(realPath); if (!file.exists())&#123; file.mkdirs(); &#125; String filename = upload.getOriginalFilename(); String uuid = UUID.randomUUID().toString().replace(\"-\", \"\"); filename=uuid+\"_\"+filename; upload.transferTo(new File(realPath,filename)); return \"success\"; &#125;&#125; 配置文件解析器 1234&lt;!--配置文件解析器--&gt; &lt;bean class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\" id=\"multipartResolver\"&gt; &lt;property name=\"maxUploadSize\" value=\"10485760\"/&gt; &lt;/bean&gt; 2.3 springmvc 跨服务器方式的文件上传2.3.1 分服务器的目的​ 在实际开发中，我们会有很多处理不同功能的服务器。例如： ​ 应用服务器：负责部署我们的应用 ​ 数据库服务器：运行我们的数据库 ​ 缓存和消息服务器：负责处理大并发访问的缓存和消息 ​ 文件服务器：负责存储用户上传文件的服务器。 (注意：此处说的不是服务器集群） ​ 分服务器处理的目的是让服务器各司其职，从而提高我们项目的运行效率。 2.3.2 准备两个 tomcat 服务器，并创建一个用于存放图片的 web 工程1.端口设置 HTTP port:9090 JMX port:1090 2.在webapp文件夹下创建文件夹images 3.web.xml中做如下配置: 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.catalina.servlets.DefaultServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;debug&lt;/param-name&gt; &lt;param-value&gt;0&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;readonly&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;listings&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 2.3.3 配置 jar包12345678910&lt;dependency&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-core&lt;/artifactId&gt; &lt;version&gt;1.18.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;version&gt;1.18.1&lt;/version&gt; &lt;/dependency&gt; 2.3.4 编写控制器实现上传图片1234567891011121314151617181920//SpringMVC跨服务器文件上传 @RequestMapping(\"/fileUpload3\") public String fileUpload3(MultipartFile upload) throws Exception &#123; System.out.println(\"跨服务器文件上传...\"); //定义上传文件服务器路径 String path = \"http://localhost:9090/uploads/\"; String filename = upload.getOriginalFilename(); String uuid = UUID.randomUUID().toString().replace(\"-\", \"\"); filename = uuid + \"_\" + filename; //完成文件上传,跨服务器上传 //创建客户端对象 Client client = Client.create(); //和图片服务器进行连接 WebResource webResource = client.resource(path + filename); //上传文件 webResource.put(upload.getBytes()); return \"success\"; &#125; 2.3.5 编写 jsp 页面12345h3&gt;SpringMVC跨服务器文件上传&lt;/h3&gt; &lt;form action=\"user/fileUpload3\" method=\"post\" enctype=\"multipart/form-data\"&gt; 选择文件:&lt;input type=\"file\" name=\"upload\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"上传\"&gt;&lt;br&gt; &lt;/form&gt; 2.3.6 配置解析器1234&lt;!--配置文件解析器--&gt; &lt;bean class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\" id=\"multipartResolver\"&gt; &lt;property name=\"maxUploadSize\" value=\"10485760\"/&gt; &lt;/bean&gt; 3.SpringMVC中的异常处理3.1 异常处理的思路​ 系统中异常包括两类：预期异常和运行时异常 RuntimeException，前者通过捕获异常从而获取异常信息， 后者主要通过规范代码开发、测试通过手段减少运行时异常的发生。 系统的 dao、service、controller 出现都通过 throws Exception 向上抛出，最后由 springmvc 前端 控制器交由异常处理器进行异常处理，如下图： 3.2 实现步骤3.2.1 编写异常类和错误页面123456789101112131415161718public class SysException extends Exception &#123; //存储信息 private String message; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125; public SysException(String message) &#123; this.message = message; &#125;&#125; error.jsp 123456789&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; $&#123;errorMsg&#125;&lt;/body&gt;&lt;/html&gt; 3.2.2 自定义异常处理器1234567891011121314151617public class SysExceptionResolver implements HandlerExceptionResolver &#123; @Override public ModelAndView resolveException(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) &#123; //获取异常对象 SysException exception = null; if (e instanceof SysException) &#123; exception = (SysException) e; &#125;else&#123; exception=new SysException(\"系统正在维护...\"); &#125; //创建ModelAndView对象 ModelAndView modelAndView=new ModelAndView(); modelAndView.addObject(\"errorMsg\",exception.getMessage()); modelAndView.setViewName(\"error\"); return modelAndView; &#125;&#125; 3.2.3 配置异常处理器123&lt;!--配置异常处理器--&gt; &lt;bean class=\"exception.SysExceptionResolver\" id=\"sysExceptionResolver\"/&gt; &lt;mvc:annotation-driven/&gt; 4. SpringMVC中的拦截器4.1 拦截器的作用​ Spring MVC 的处理器拦截器类似于 Servlet 开发中的过滤器 Filter，用于对处理器进行预处理和后处理。 用户可以自己定义一些拦截器来实现特定的功能。 ​ 谈到拦截器，还要向大家提一个词——拦截器链（Interceptor Chain）。拦截器链就是将拦截器按一定的顺 序联结成一条链。在访问被拦截的方法或字段时，拦截器链中的拦截器就会按其之前定义的顺序被调用。 ​ 说到这里，可能大家脑海中有了一个疑问，这不是我们之前学的过滤器吗？是的它和过滤器是有几分相似，但是也有区别，接下来我们就来说说他们的区别： ​ 过滤器是 servlet 规范中的一部分，任何 java web 工程都可以使用。 ​ 拦截器是 SpringMVC 框架自己的，只有使用了 SpringMVC 框架的工程才能用。 ​ 过滤器在 url-pattern 中配置了/*之后，可以对所有要访问的资源拦截。 ​ 拦截器它是只会拦截访问的控制器方法，如果访问的是 jsp，html,css,image 或者 js 是不会进行拦 截的。 它也是 AOP 思想的具体应用。 我们要想自定义拦截器， 要求必须实现：HandlerInterceptor 接口 4.2 自定义拦截器的步骤4.2.1 第一步：编写一个普通类实现 HandlerInterceptor 接口12345678910@Controller@RequestMapping(\"/user\")public class UserController &#123; @RequestMapping(\"/testInterceptor\") public String testInterceptor()&#123; System.out.println(\"testInterceptor方法执行了...\"); return \"success\"; &#125;&#125; 1234567891011121314151617181920212223242526public class MyInterceptor1 implements HandlerInterceptor &#123; /*预处理,controller方法执行前 return true:执行下一个拦截器,如果没有,执行controller中的方法 return false:不放行*/ @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println(\"MyInterceptor1方法执行了...前111\"); /*request.getRequestDispatcher(\"/WEB-INF/pages/error.jsp\").forward(request,response); return false;*/ return true; &#125;// 后处理方法，controller方法执行后，success.jsp执行之前 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; System.out.println(\"MyInterceptor1方法执行了...后111\"); &#125;// success.jsp页面执行后，该方法会执行 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; System.out.println(\"MyInterceptor1执行了...最后111\"); &#125;&#125; index.jsp 1234567891011&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;拦截器&lt;/h3&gt; &lt;a href=\"user/testInterceptor\"&gt;拦截器&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; success.jsp 12345678910&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;执行成功!&lt;/h3&gt; &lt;% System.out.println(\"success.jsp执行了..\");%&gt;&lt;/body&gt;&lt;/html&gt; error.jsp 123456789&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;错误页面!&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 4.2.2 第二步：配置拦截器123456789101112&lt;!--配置拦截器--&gt; &lt;mvc:interceptors&gt; &lt;!--配置拦截器--&gt; &lt;mvc:interceptor&gt; &lt;!--要拦截的具体方法--&gt; &lt;mvc:mapping path=\"/user/*\"/&gt; &lt;!--不要拦截的具体方法 &lt;mvc:exclude-mapping path=\"\"/&gt;--&gt; &lt;!--配置拦截器对象--&gt; &lt;bean class=\"interceptor.MyInterceptor1\"/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 4.3 拦截器的细节4.3.1 拦截器的放行​ 放行的含义是指，如果有下一个拦截器就执行下一个，如果该拦截器处于拦截器链的最后一个，则执行控制器中的方法。 4.3.2 拦截器中方法的说明1234567891011121314151617181920212223public interface HandlerInterceptor &#123; /** * 如何调用：按拦截器定义顺序调用 * 何时调用：只要配置了都会调用 * 有什么用：如果程序员决定该拦截器对请求进行拦截处理后还要调用其他的拦截器，或者是业务处理器去 进行处理，则返回 true。 如果程序员决定不需要再调用其他的组件去处理请求，则返回 false。 */ default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception &#123; return true; &#125; /** * 如何调用：按拦截器定义逆序调用 * 何时调用：在拦截器链内所有拦截器返成功调用 * 有什么用：在业务处理器处理完请求后，但是 DispatcherServlet 向客户端返回响应前被调用， 在该方法中对用户请求 request 进行处理。 */ default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,@Nullable ModelAndView modelAndView) throws Exception &#123; &#125; /** * 如何调用：按拦截器定义逆序调用 * 何时调用：只有 preHandle 返回 true 才调用 * 有什么用：在 DispatcherServlet 完全处理完请求后被调用， 可以在该方法中进行一些资源清理的操作。 */ default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123; &#125; &#125; 4.3.3 拦截器的作用路径1234567891011121314151617&lt;!--配置拦截器--&gt; &lt;mvc:interceptors&gt; &lt;!--配置拦截器--&gt; &lt;mvc:interceptor&gt; &lt;!--要拦截的具体方法--&gt; &lt;mvc:mapping path=\"/user/*\"/&gt; &lt;!--不要拦截的具体方法 &lt;mvc:exclude-mapping path=\"\"/&gt;--&gt; &lt;!--配置拦截器对象--&gt; &lt;bean class=\"interceptor.MyInterceptor1\"/&gt; &lt;/mvc:interceptor&gt; &lt;!--配置第二个拦截器--&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/**\"/&gt; &lt;bean class=\"interceptor.MyInterceptor2\"/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 4.3.4 多个拦截器的执行顺序 4.4 拦截器的简单案例（验证用户是否登录)4.4.1 实现思路1、有一个登录页面，需要写一个 controller 访问页面 2、登录页面有一提交表单的动作。需要在 controller 中处理。 ​ 2.1、判断用户名密码是否正确 ​ 2.2、如果正确 向 session 中写入用户信息 ​ 2.3、返回登录成功。 3、拦截用户请求，判断用户是否登录 ​ 3.1、如果用户已经登录。放行 ​ 3.2、如果用户未登录，跳转到登录页面 4.4.2 控制器代码1234567891011121314151617//登陆页面 @RequestMapping(\"/login\") public String login(Model model)throws Exception&#123; return \"login\"; &#125; //登陆提交 //userid：用户账号，pwd：密码 @RequestMapping(\"/loginsubmit\") public String loginsubmit(HttpSession session,String userid,String pwd)throws Exception&#123; //向 session 记录用户身份信息 session.setAttribute(\"activeUser\", userid); return \"redirect:/main.jsp\"; &#125; //退出@RequestMapping(\"/logout\") public String logout(HttpSession session)throws Exception&#123; //session 过期 session.invalidate(); return \"redirect:index.jsp\"; &#125; 4.4.3 拦截器代码123456789101112131415161718public class LoginInterceptor implements HandlerInterceptor&#123; @Override Public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //如果是登录页面则放行 if(request.getRequestURI().indexOf(\"login.action\")&gt;=0)&#123; return true; &#125; HttpSession session = request.getSession(); //如果用户已登录也放行 if(session.getAttribute(\"user\")!=null)&#123; return true; &#125; //用户没有登录挑战到登录页面 request.getRequestDispatcher(\"/WEB-INF/jsp/login.jsp\").forward(request, response); return false; &#125; &#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringMVC框架(一)","slug":"SpringMVC框架(一)","date":"2021-05-08T13:19:59.165Z","updated":"2020-04-29T02:44:38.126Z","comments":true,"path":"22356/","link":"","permalink":"http://tonymua.top/22356/","excerpt":"1.SpringMVC的基本概念1.1 关于三层架构和MVC1.1.1 三层架构​ 我们的开发架构一般都是基于两种形式，一种是 C/S 架构，也就是客户端/服务器，另一种是 B/S 架构，也就 是浏览器服务器。在 JavaEE 开发中，几乎全都是基于 B/S架构的开发。那么在 B/S架构中，系统标准的三层架构 包括：表现层、业务层、持久层。三层架构在我们的实际开发中使用的非常多，所以我们课程中的案例也都是基于三层架构设计的。 ​ 三层架构中，每一层各司其职，接下来我们就说说每层都负责哪些方面：","text":"1.SpringMVC的基本概念1.1 关于三层架构和MVC1.1.1 三层架构​ 我们的开发架构一般都是基于两种形式，一种是 C/S 架构，也就是客户端/服务器，另一种是 B/S 架构，也就 是浏览器服务器。在 JavaEE 开发中，几乎全都是基于 B/S架构的开发。那么在 B/S架构中，系统标准的三层架构 包括：表现层、业务层、持久层。三层架构在我们的实际开发中使用的非常多，所以我们课程中的案例也都是基于三层架构设计的。 ​ 三层架构中，每一层各司其职，接下来我们就说说每层都负责哪些方面： ​ 表现层：也就是我们常说的web层。它负责接收客户端请求，向客户端响应结果，通常客户端使用http协议请求 web 层，web 需要接收 http 请求，完成 http 响应。 表现层包括展示层和控制层：控制层负责接收请求，展示层负责结果的展示。 表现层依赖业务层，接收到客户端请求一般会调用业务层进行业务处理，并将处理结果响应给客户端。 表现层的设计一般都使用 MVC 模型。（MVC 是表现层的设计模型，和其他层没有关系 ​ 业务层：也就是我们常说的 service 层。它负责业务逻辑处理，和我们开发项目的需求息息相关。web 层依赖业 务层，但是业务层不依赖 web 层。 业务层在业务处理时可能会依赖持久层，如果要对数据持久化需要保证事务一致性。（也就是我们说的， 事务应该放到业务层来控制） ​ 持久层： 也就是我们是常说的 dao 层。负责数据持久化，包括数据层即数据库和数据访问层，数据库是对数据进 行持久化的载体，数据访问层是业务层和持久层交互的接口，业务层需要通过数据访问层将数据持久化到数据库中。通俗的讲，持久层就是和数据库交互，对数据库表进行曾删改查的。 1.1.2 MVC 模型MVC 全名是 Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写， 是一种用于设计创建 Web 应用程序表现层的模式。MVC 中每个部分各司其职： Model（模型）： 通常指的就是我们的数据模型。作用一般情况下用于封装数据。 ​ View（视图）：通常指的就是我们的 jsp 或者 html。作用一般就是展示数据的。 通常视图是依据模型数据创建的。 ​ Controller（控制器）：是应用程序中处理用户交互的部分。作用一般就是处理程序逻辑的。 它相对于前两个不是很好理解，这里举个例子： ​ 例如：我们要保存一个用户的信息，该用户信息中包含了姓名，性别，年龄等等。 这时候表单输入要求年龄必须是 1~100 之间的整数。姓名和性别不能为空。并且把数据填充 到模型之中。 此时除了 js 的校验之外，服务器端也应该有数据准确性的校验，那么校验就是控制器的该做 的。 ​ 当校验失败后，由控制器负责把错误页面展示给使用者。如果校验成功，也是控制器负责把数据填充到模型，并且调用业务层实现完整的业务需求 1.2 SpringMVC 概述1.2.1 SpringMVC 是什么​ SpringMVC 是一种基于 Java 的实现 MVC 设计模型的请求驱动类型的轻量级 Web 框架，属于 Spring FrameWork 的后续产品，已经融合在 Spring Web Flow 里面。Spring 框架提供了构建 Web 应用程序的全功 能 MVC 模块。使用 Spring 可插入的 MVC 架构，从而在使用 Spring 进行 WEB 开发时，可以选择使用 Spring 的 Spring MVC 框架或集成其他 MVC 开发框架，如 Struts1(现在一般不用)，Struts2 等。 ​ SpringMVC 已经成为目前最主流的 MVC 框架之一，并且随着 Spring3.0 的发布，全面超越 Struts2，成 为最优秀的 MVC 框架。 它通过一套注解，让一个简单的 Java 类成为处理请求的控制器，而无须实现任何接口。同时它还支持 RESTful 编程风格的请求。 1.2.2 SpringMVC 在三层架构的位置 1.2.3 SpringMVC 的优势​ 1、清晰的角色划分： 前端控制器（DispatcherServlet） ​ 请求到处理器映射（HandlerMapping） ​ 处理器适配器（HandlerAdapter） ​ 视图解析器（ViewResolver） ​ 处理器或页面控制器（Controller） ​ 验证器（ Validator） ​ 命令对象（Command 请求参数绑定到的对象就叫命令对象） ​ 表单对象（Form Object 提供给表单展示和提交到的对象就叫表单对象）。 ​ 2、分工明确，而且扩展点相当灵活，可以很容易扩展，虽然几乎不需要。 ​ 3、由于命令对象就是一个 POJO，无需继承框架特定 API，可以使用命令对象直接作为业务对象。 ​ 4、和 Spring 其他框架无缝集成，是其它 Web 框架所不具备的。 ​ 5、可适配，通过 HandlerAdapter 可以支持任意的类作为处理器。 ​ 6、可定制性，HandlerMapping、ViewResolver 等能够非常简单的定制。 ​ 7、功能强大的数据验证、格式化、绑定机制。 ​ 8、利用 Spring 提供的 Mock 对象能够非常简单的进行 Web 层单元测试。 ​ 9、本地化、主题的解析的支持，使我们更容易进行国际化和主题的切换。 ​ 10、强大的 JSP 标签库，使 JSP 编写更容易。 ​ ………………还有比如RESTful风格的支持、简单的文件上传、约定大于配置的契约式编程支持、基于注解的零配 置支持等等。 2.SpringMVC的入门2.1 SpringMVC入门案例配置pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;springmvc_start&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;springmvc_start Maven Webapp&lt;/name&gt; &lt;!-- FIXME change it to the project's website --&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.9&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.9&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;springmvc_start&lt;/finalName&gt; &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- see http://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_war_packaging --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; web.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!--前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置Servlet的初始化参数，读取springmvc的配置文件，创建spring容器 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 配置servlet启动时加载对象 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--配置解决中文乱码的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; springmvc.xml 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--开启注解扫描--&gt; &lt;context:component-scan base-package=\"controller\"/&gt; &lt;!--视图解析器对象--&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--文件所在目录--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;!--文件后缀名--&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--配置自定义类型转换器--&gt; &lt;bean id=\"conversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\"&gt; &lt;property name=\"converters\"&gt; &lt;set&gt; &lt;bean class=\"utils.StringToDateConverter\"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 开启SpringMVC框架注解的支持 --&gt; &lt;mvc:annotation-driven conversion-service=\"conversionService\"/&gt;&lt;/beans&gt; 2.2 SpringMVC入门案例jsp页面 index.jsp 123456789101112&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;入门程序&lt;/h3&gt; &lt;%-- &lt;a href=\"hello\"&gt;入门程序&lt;/a&gt;--%&gt; &lt;a href=\"testRequestMapping?username=test\"&gt;RequestMapping注解&lt;/a&gt; &lt;%--&lt;a href=\"user/testRequestMapping\"&gt;RequestMapping注解&lt;/a&gt;--%&gt;&lt;/body&gt;&lt;/html&gt; param.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%--请求参数绑定--%&gt; &lt;a href=\"param/testParam?username=test&amp;password=123\"&gt;请求参数绑定&lt;/a&gt; &lt;%--把数据封装到Account类中--%&gt; &lt;form action=\"param/saveAccount\" method=\"post\"&gt; 用户名:&lt;input type=\"text\" name=\"username\" /&gt;&lt;br/&gt; &lt;%--name和javaBean中的属性对应--%&gt; 密码:&lt;input type=\"text\" name=\"password\" /&gt;&lt;br/&gt; 金额:&lt;input type=\"text\" name=\"money\" /&gt;&lt;br/&gt; 用户姓名:&lt;input type=\"text\" name=\"user.uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"user.age\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;%--把数据封装到Account类中,类中存在list和map的集合--%&gt; &lt;form action=\"param/saveAccount\" method=\"post\"&gt; 用户名:&lt;input type=\"text\" name=\"username\" /&gt;&lt;br/&gt; &lt;%--name和javaBean中的属性对应--%&gt; 密码:&lt;input type=\"text\" name=\"password\" /&gt;&lt;br/&gt; 金额:&lt;input type=\"text\" name=\"money\" /&gt;&lt;br/&gt; 用户姓名:&lt;input type=\"text\" name=\"list[0].uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"list[0].age\" /&gt;&lt;br/&gt; 用户姓名:&lt;input type=\"text\" name=\"map['one'].uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"map['one']user.age\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;%--自定义类型转换器--%&gt; &lt;form action=\"param/saveUser\" method=\"post\"&gt; 用户姓名:&lt;input type=\"text\" name=\"uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"age\" /&gt;&lt;br/&gt; 用户生日:&lt;input type=\"text\" name=\"date\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;%--Servlet原生API--%&gt; &lt;a href=\"param/testServlet\"&gt;Servlet原生API&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; anno.jsp 123456789101112131415161718192021222324252627282930313233343536&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;%--常用的注解--%&gt; &lt;a href=\"anno/testRequestParam?name=哈哈\"&gt;RequestParam&lt;/a&gt;&lt;br&gt; &lt;form action=\"anno/testRequestBody\" method=\"post\"&gt; 用户姓名:&lt;input type=\"text\" name=\"uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"age\" /&gt;&lt;br/&gt; 用户生日:&lt;input type=\"text\" name=\"date\" /&gt;&lt;br/&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;a href=\"anno/testPathVariable/10\"&gt;PathVariable&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/testRequestHeader\"&gt;RequestHeader&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/testCookieValue\"&gt;CookieValue&lt;/a&gt;&lt;br&gt; &lt;form action=\"anno/testModelAttribute\" method=\"post\"&gt; 用户姓名:&lt;input type=\"text\" name=\"uname\" /&gt;&lt;br/&gt; 用户年龄:&lt;input type=\"text\" name=\"age\" /&gt;&lt;br/&gt; &lt;%--用户生日:&lt;input type=\"text\" name=\"date\" /&gt;&lt;br/&gt;--%&gt; &lt;input type=\"submit\" value=\"提交\" /&gt; &lt;/form&gt; &lt;a href=\"anno/testSessionAttributes\"&gt;SessionAttributes&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/getSessionAttributes\"&gt;getSessionAttributes&lt;/a&gt;&lt;br&gt; &lt;a href=\"anno/delSessionAttributes\"&gt;delSessionAttributes&lt;/a&gt;&lt;br&gt;&lt;/body&gt;&lt;/html&gt; success.jsp 1234567891011&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" isELIgnored=\"false\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;成功!&lt;/h3&gt; $&#123;msg&#125; $&#123;sessionScope&#125;&lt;/body&gt;&lt;/html&gt; 2.3 SpringMVC入门案例代码Account 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Account implements Serializable &#123; private String username; private String password; private Double money;// private User user; private List&lt;User&gt; list; private Map&lt;String,User&gt; map; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; /* public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125;*/ public List&lt;User&gt; getList() &#123; return list; &#125; public void setList(List&lt;User&gt; list) &#123; this.list = list; &#125; public Map&lt;String, User&gt; getMap() &#123; return map; &#125; public void setMap(Map&lt;String, User&gt; map) &#123; this.map = map; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"username='\" + username + '\\'' + \", password='\" + password + '\\'' + \", money=\" + money + \", list=\" + list + \", map=\" + map + '&#125;'; &#125;&#125; User 1234567891011121314151617181920212223242526272829303132333435363738public class User implements Serializable &#123; private String uname; private Integer age; private Date date; public String getUname() &#123; return uname; &#125; public void setUname(String uname) &#123; this.uname = uname; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public Date getDate() &#123; return date; &#125; public void setDate(Date date) &#123; this.date = date; &#125; @Override public String toString() &#123; return \"User&#123;\" + \"uname='\" + uname + '\\'' + \", age=\" + age + \", date=\" + date + '&#125;'; &#125;&#125; HelloController 123456789101112131415161718//控制器类@Controller//@RequestMapping(path = \"user\") 此时对应&lt;a href=\"user/testRequestMapping\"&gt;RequestMapping注解&lt;/a&gt;public class HelloController &#123; @RequestMapping(path = \"/hello\") public String sayHello()&#123; System.out.println(\"Hello SpringMVC\"); return \"success\"; &#125; @RequestMapping(path =\"/testRequestMapping\",method =&#123;RequestMethod.GET&#125;,params =&#123;\"username=test\"&#125;,headers =&#123;\"Accept\"&#125; )// @RequestMapping(value =\"/testRequestMapping\" ) public String testRequestMapping()&#123; System.out.println(\"测试RequestMapping注解...\"); return \"success\"; &#125;&#125; ParamController 1234567891011121314151617181920212223242526272829303132333435363738//请求参数绑定@Controller@RequestMapping(\"/param\")public class ParamController &#123; @RequestMapping(\"/testParam\") public String testParam(String username,String password)&#123; System.out.println(\"testParam执行了...\"); System.out.println(\"username:\"+username+\"---\"+\"password:\"+password); return \"success\"; &#125;// 请求参数绑定把数据封装到JavaBean的类中 @RequestMapping(\"/saveAccount\") public String saveAccount(Account account)&#123; System.out.println(\"saveAccount执行了...\"); System.out.println(account); return \"success\"; &#125;//自定义类型转换器 @RequestMapping(\"/saveUser\") public String saveUser(User user)&#123; System.out.println(\"saveUser执行了...\"); System.out.println(user); return \"success\"; &#125;// Servlet原生API @RequestMapping(\"/testServlet\") public String testServlet(HttpServletRequest request, HttpServletResponse response)&#123; System.out.println(\"testServlet执行了...\"); System.out.println(request); HttpSession session = request.getSession(); System.out.println(session); ServletContext servletContext = session.getServletContext(); System.out.println(servletContext); System.out.println(response); return \"success\"; &#125;&#125; AnnoController 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101//常用的注解@Controller@RequestMapping(\"/anno\")@SessionAttributes(value = &#123;\"msg\"&#125;) //把msg=test存入到session域对象中public class AnnoController &#123; @RequestMapping(\"/testRequestParam\") public String testRequestParam(@RequestParam(name = \"name\") String username) &#123; System.out.println(\"testRequestParam执行了...\"); System.out.println(username); return \"success\"; &#125; // 获取到请求体的内容 @RequestMapping(\"/testRequestBody\") public String testRequestBody(@RequestBody String body) &#123; System.out.println(\"testRequestParam执行了...\"); System.out.println(body); return \"success\"; &#125; // PathVariable注解 @RequestMapping(value = \"/testPathVariable/&#123;sid&#125;\", method = RequestMethod.PUT) public String testPathVariable(@PathVariable(name = \"sid\") String id) &#123; System.out.println(\"testPathVariable执行了...\"); System.out.println(\"id\" + id); return \"success\"; &#125; // RequestHeader注解,获取请求头的值 @RequestMapping(value = \"/testRequestHeader\") public String testRequestHeader(@RequestHeader(value = \"Accept\") String header) &#123; System.out.println(\"testPathVariable执行了...\"); System.out.println(\"header:\" + header); return \"success\"; &#125; // CookieValue注解,获取Cookie的值 @RequestMapping(value = \"/testCookieValue\") public String testCookieValue(@CookieValue(value = \"JSESSIONID\") String cookieValue) &#123; System.out.println(\"testCookieValue执行了...\"); System.out.println(\"cookieValue:\" + cookieValue); return \"success\"; &#125; // ModelAttribute注解 @RequestMapping(value = \"/testModelAttribute\") public String testModelAttribute(@ModelAttribute(\"test\") User user) &#123; System.out.println(\"testModelAttribute执行了...\"); System.out.println(user); return \"success\"; &#125;// 该方法会先执行 /*@ModelAttribute public User showUser(String uname)&#123; System.out.println(\"showUser执行了...\"); //通过用户查询数据库(模拟) User user=new User(); user.setUname(uname); user.setAge(20); user.setDate(new Date()); return user; &#125;*/ @ModelAttribute public void showUser(String uname, Map&lt;String, User&gt; map) &#123; System.out.println(\"showUser执行了...\"); //通过用户查询数据库(模拟) User user = new User(); user.setUname(uname); user.setAge(20); user.setDate(new Date()); map.put(\"test\", user); &#125; // SessionAttributes注解 @RequestMapping(value = \"/testSessionAttributes\") public String testSessionAttributes(Model model) &#123; System.out.println(\"testSessionAttributes执行了...\"); //底层会存储到request域对象中 model.addAttribute(\"msg\",\"test\"); return \"success\"; &#125; // 获取值 @RequestMapping(value = \"/getSessionAttributes\") public String getSessionAttributes(ModelMap modelMap) &#123; System.out.println(\"getSessionAttributes执行了...\"); String msg = (String) modelMap.get(\"msg\"); System.out.println(msg); return \"success\"; &#125; // 删除值 @RequestMapping(value = \"/delSessionAttributes\") public String delSessionAttributes(SessionStatus sessionStatus) &#123; System.out.println(\"delSessionAttributes执行了...\"); sessionStatus.setComplete(); return \"success\"; &#125;&#125; StringToDateConverter 123456789101112131415161718//把字符串转换日期public class StringToDateConverter implements Converter&lt;String, Date&gt; &#123; @Override public Date convert(String source) &#123; //判断 if (source==null)&#123; throw new RuntimeException(\"请您传入数据...\"); &#125; DateFormat dateFormat=new SimpleDateFormat(\"yyyy-MM-dd\"); try &#123; //把字符串转换成日期 return dateFormat.parse(source); &#125; catch (Exception e) &#123; throw new RuntimeException(\"数据类型转换出现错误\"); &#125; &#125;&#125; 2.4 入门案例中涉及的组件2.4.1 DispatcherServlet：前端控制器​ 用户请求到达前端控制器，它就相当于 mvc 模式中的 c，dispatcherServlet 是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet 的存在降低了组件之间的耦合性。 2.4.2 HandlerMapping：处理器映射器​ HandlerMapping 负责根据用户请求找到 Handler 即处理器，SpringMVC 提供了不同的映射器实现不同的 映射方式，例如：配置文件方式，实现接口方式，注解方式等。 2.4.3 Handler：处理器​ 它就是我们开发中要编写的具体业务控制器。由 DispatcherServlet 把用户请求转发到 Handler。由 Handler 对具体的用户请求进行处理。 2.4.4 HandlAdapter：处理器适配器​ 通过 HandlerAdapter 对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理 器进行执行。 2.4.5 View Resolver：视图解析器​ View Resolver 负责将处理结果生成 View 视图，View Resolver 首先根据逻辑视图名解析成物理视图名 即具体的页面地址，再生成 View 视图对象，最后对 View 进行渲染将处理结果通过页面展示给用户。 2.4.6 View：视图​ SpringMVC 框架提供了很多的 View 视图类型的支持，包括：jstlView、freemarkerView、pdfView 等。我们最常用的视图就是 jsp。 ​ 一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 2.3.7 mvc:annotation-driven说明​ 在 SpringMVC 的各个组件中，处理器映射器、处理器适配器、视图解析器称为 SpringMVC 的三大组件。 使用mvc:annotation-driven 自动加载 RequestMappingHandlerMapping （处理映射器）和 RequestMappingHandlerAdapter （ 处 理 适 配 器 ） ， 可 用 在 SpringMVC.xml 配 置 文 件 中 使 用 mvc:annotation-driven替代注解处理器和适配器的配置。 明确：我们只需要编写处理具体业务的控制器以及视图。 2.5 RequestMapping 注解作用： 用于建立请求 URL 和处理请求方法之间的对应关系。 出现位置： ​ 类上： 请求 URL 的第一级访问目录。此处不写的话，就相当于应用的根目录。写的话需要以/开头。 它出现的目的是为了使我们的 URL 可以按照模块化管理: 例如： 账户模块： /account/add /account/update /account/delete … 订单模块： /order/add /order/update /order/delete 红色的部分就是把 RequsetMappding 写在类上，使我们的 URL 更加精细。 ​ 方法上： 请求 URL 的第二级访问目录。 属性： value：用于指定请求的 URL。它和 path 属性的作用是一样的。 ​ method：用于指定请求的方式。 ​ params：用于指定限制请求参数的条件。它支持简单的表达式。要求请求参数的 key 和 value 必须和 配置的一模一样。 例如： params = {“accountName”}，表示请求参数必须有 accountName params = {“moeny!100”}，表示请求参数中 money 不能是 100。 ​ headers：用于指定限制请求消息头的条件。 注意： 以上四个属性只要出现 2 个或以上时，他们的关系是与的关系。 3.请求参数的绑定3.1 绑定说明3.1.1 绑定的机制​ 我们都知道，表单中请求参数都是基于 key=value 的。 SpringMVC 绑定请求参数的过程是通过把表单提交请求参数，作为控制器中方法参数进行绑定的。 3.1.2 支持的数据类型基本类型参数： ​ 包括基本类型和 String 类型 POJO 类型参数： ​ 包括实体类，以及关联的实体类 数组和集合类型参数： ​ 包括 List 结构和 Map 结构的集合（包括数组） ​ SpringMVC 绑定请求参数是自动实现的，但是要想使用，必须遵循使用要求。 3.1.3 使用要求如果是基本类型或者 String类型： ​ 要求我们的参数名称必须和控制器中方法的形参名称保持一致。(严格区分大小写) 如果是 POJO类型，或者它的关联对象： ​ 要求表单中参数名称和 POJO 类的属性名称保持一致。并且控制器方法的参数类型是 POJO 类型。 如果是集合类型,有两种方式： ​ 第一种： 要求集合类型的请求参数必须在 POJO 中。在表单中请求参数名称要和 POJO 中集合属性名称相同。给 List 集合中的元素赋值，使用下标。 给 Map 集合中的元素赋值，使用键值对。 ​ 第二种： 接收的请求参数是 json 格式数据。需要借助一个注解实现。 3.1.4 请求参数乱码问题post 请求方式：在 web.xml 中配置一个过滤器 12345678910111213&lt;!--配置解决中文乱码的过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; get 请求方式： tomacat 对 GET和 POST 请求处理方式是不同的，GET请求的编码问题，要改 tomcat 的 server.xml 配置文件，如下： 12345&lt;Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\"/&gt; 改为： &lt;Connector connectionTimeout=\"20000\" port=\"8080\" protocol=\"HTTP/1.1\" redirectPort=\"8443\" useBodyEncodingForURI=\"true\"/&gt; 如果遇到 ajax 请求仍然乱码，请把： useBodyEncodingForURI=\"true\"改为 URIEncoding=\"UTF-8\" 即可。 3.2 特殊情况3.2.1 自定义类型转换器12345678&lt;!--配置自定义类型转换器--&gt; &lt;bean id=\"conversionService\" class=\"org.springframework.context.support.ConversionServiceFactoryBean\"&gt; &lt;property name=\"converters\"&gt; &lt;set&gt; &lt;bean class=\"utils.StringToDateConverter\"/&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 3.2.2 使用原生ServletAPI 对象作为方法参数​ SpringMVC 还支持使用原始 ServletAPI 对象作为控制器方法的参数。支持原始 ServletAPI 对象有： HttpServletRequest HttpServletResponse HttpSession java.security.Principal Locale InputStream OutputStream Reader Writer 我们可以把上述对象，直接写在控制的方法参数中使用。 123456789101112// Servlet原生API @RequestMapping(\"/testServlet\") public String testServlet(HttpServletRequest request, HttpServletResponse response)&#123; System.out.println(\"testServlet执行了...\"); System.out.println(request); HttpSession session = request.getSession(); System.out.println(session); ServletContext servletContext = session.getServletContext(); System.out.println(servletContext); System.out.println(response); return \"success\"; &#125; 4.常用注解4.1 RequestParam作用：把请求中指定名称的参数给控制器中的形参赋值。 属性：value：请求参数中的名称。 required：请求参数中是否必须提供此参数。默认值：true。表示必须提供，如果不提供将报错。 4.2 RequestBody作用：用于获取请求体内容。直接使用得到是 key=value&amp;key=value…结构的数据。 get 请求方式不适用。 属性：required：是否必须有请求体。默认值是:true。当取值为 true 时,get 请求方式会报错。如果取值 为 false，get 请求得到是 null。 4.3 PathVaribale作用：用于绑定 url 中的占位符。例如：请求 url 中 /delete/{id}，这个{id}就是 url 占位符。 url 支持占位符是 spring3.0 之后加入的。是 springmvc 支持 rest 风格 URL 的一个重要标志。 属性：value：用于指定 url 中占位符名称。 required：是否必须提供占位符。 REST 风格 URL 什么是 rest： ​ REST（英文：Representational State Transfer，简称 REST）描述了一个架构样式的网络系统， 比如 web 应用程序。它首次出现在 2000 年 Roy Fielding 的博士论文中，他是 HTTP 规范的主要编写者之 一。在目前主流的三种 Web 服务交互方案中，REST 相比于 SOAP（Simple Object Access protocol，简单 对象访问协议）以及 XML-RPC 更加简单明了，无论是对 URL 的处理还是对 Payload 的编码，REST 都倾向于用更 加简单轻量的方法设计和实现。值得注意的是 REST 并没有一个明确的标准，而更像是一种设计的风格。 ​ 它本身并没有什么实用性，其核心价值在于如何设计出符合 REST 风格的网络接口。 restful 的优点 ​ 它结构清晰、符合标准、易于理解、扩展方便，所以正得到越来越多网站的采用。 restful 的特性： ​ 资源（Resources）：网络上的一个实体，或者说是网络上的一个具体信息。 它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的存在。可以用一个 URI（统一 资源定位符）指向它，每种资源对应一个特定的 URI 。要 获取这个资源，访问它的 URI 就可以，因此 URI 即为每一个资源的独一无二的识别符。 表现层（Representation）：把资源具体呈现出来的形式，叫做它的表现层 （Representation）。 比如，文本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现，甚至可以采用二进制格式。 状态转化（State Transfer）：每 发出一个请求，就代表了客户端和服务器的一次交互过程。 HTTP 协议，是一个无状态协议，即所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生“状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是 “表现层状态转化”。具体说，就是 HTTP 协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。 ​ restful 的示例： /account/1 HTTP GET ： 得到 id = 1 的 account ​ /account/1 HTTP DELETE： 删除 id = 1 的 account ​ /account/1 HTTP PUT： 更新 id = 1 的 account ​ /account HTTP POST： 新增 account 4.4 RequestHeader作用： 用于获取请求消息头。 属性： value：提供消息头名称 required：是否必须有此消息头 注： 在实际开发中一般不怎么用。 4.5 CookieValue作用： 用于把指定 cookie 名称的值传入控制器方法参数。 属性： value：指定 cookie 的名称。 required：是否必须有此 cookie。 4.6 ModelAttribute作用： 该注解是 SpringMVC4.3 版本以后新加入的。它可以用于修饰方法和参数。 出现在方法上，表示当前方法会在控制器的方法执行之前，先执行。它可以修饰没有返回值的方法，也可 以修饰有具体返回值的方法。 出现在参数上，获取指定的数据给参数赋值。 属性： value：用于获取数据的 key。key 可以是 POJO 的属性名称，也可以是 map 结构的 key。 应用场景： 当表单提交数据不是完整的实体类数据时，保证没有提交数据的字段使用数据库对象原来的数据。 例如： 我们在编辑一个用户时，用户有一个创建信息字段，该字段的值是不允许被修改的。在提交表单数 据是肯定没有此字段的内容，一旦更新会把该字段内容置为 null，此时就可以使用此注解解决问题。 4.7 SessionAttribute作用： 用于多次执行控制器方法间的参数共享。 属性： value：用于指定存入的属性名称 type：用于指定存入的数据类型。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringCloud框架(二)(微服务)","slug":"SpringCloud框架(二)(微服务)","date":"2021-05-08T13:19:59.164Z","updated":"2020-04-29T02:44:38.079Z","comments":true,"path":"50010/","link":"","permalink":"http://tonymua.top/50010/","excerpt":"1.Hystrix1.1 简介Hystrix是Netflix公司的一款组件。 主页：https://github.com/Netflix/Hystrix/ Hystix是Netflix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。 1.2 雪崩问题​ 微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路. 一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务。 ​ 如果此时，某个服务出现异常, 请求阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成雪崩效应。 Hystix解决雪崩问题的手段有两个：","text":"1.Hystrix1.1 简介Hystrix是Netflix公司的一款组件。 主页：https://github.com/Netflix/Hystrix/ Hystix是Netflix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。 1.2 雪崩问题​ 微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路. 一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务。 ​ 如果此时，某个服务出现异常, 请求阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成雪崩效应。 Hystix解决雪崩问题的手段有两个： 线程隔离 服务熔断 1.3 线程隔离，服务降级1.3.1 原理Hystrix为每个依赖服务调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队.加速失败判定时间。 用户的请求将不再直接访问服务，而是通过线程池中的空闲线程来访问服务，如果线程池已满，或者请求超时，则会进行降级处理，什么是服务降级？ 服务降级：优先保证核心服务，而非核心服务不可用或弱可用。 用户的请求故障时，不会被阻塞，更不会无休止的等待或者看到系统崩溃，至少可以看到一个执行结果（例如返回友好的提示信息） 。 服务降级虽然会导致请求失败，但是不会导致阻塞，而且最多会影响这个依赖服务对应的线程池中的资源，对其它服务没有响应。 触发Hystix服务降级的情况： 线程池已满 请求超时 1.3.2 动手实践首先在consumer_demo的pom.xml中引入Hystrix依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 开启熔断 在启动类中加注解@EnableCircuitBreaker 1234567891011121314@EnableCircuitBreaker@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; 可以看到，我们类上的注解越来越多，在微服务中，经常会引入上面的三个注解，于是Spring就提供了一个组合注解：@SpringCloudApplication 123456789101112@SpringCloudApplicationpublic class ConsumerApplication &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; 编写降级逻辑 我们改造consumer_demo，当目标服务的调用出现故障，我们希望快速失败，给用户一个友好提示。因此需要提前编写好失败时的降级处理逻辑，要使用HystixCommond来完成： 123456789101112131415161718192021222324252627@RestController@RequestMapping(\"consumer\")@DefaultProperties(defaultFallback =\"fallbackMethod\" )public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"&#123;id&#125;\") @HystrixCommand/* @HystrixCommand(commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\",value = \"2000\"), @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\",value = \"10\"), @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\",value = \"10000\"), @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\",value = \"60\") &#125;)*/ public String queryById(@PathVariable(\"id\")Integer id)&#123; String url = \"http://account-service/account/\"+id; return restTemplate.getForObject(url,String.class); &#125; /*熔断方法 * 返回值要和被熔断的方法的返回值一致 * 熔断方法不需要参数 * @return*/ public String fallbackMethod()&#123; return \"请求繁忙，请稍后再试！\"; &#125;&#125; 要注意，因为熔断的降级逻辑方法必须跟正常逻辑方法保证：相同的参数列表和返回值声明。失败逻辑中返回User对象没有太大意义，一般会返回友好提示。所以我们把queryById的方法改造为返回String，反正也是Json数据。这样失败逻辑中返回一个错误说明，会比较方便。 @DefaultProperties(defaultFallback = “defaultFallBack”)：在类上指明统一的失败降级方法 @HystrixCommand：在方法上直接使用该注解，使用默认的剪辑方法。 defaultFallback：默认降级方法，不用任何参数，以匹配更多方法，但是返回值一定一致 设置超时 在之前的案例中，请求在超过1秒后都会返回错误信息，这是因为Hystix的默认超时时长为1，我们可以通过配置修改这个值： 我们可以通过hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds来设置Hystrix超时时间。该配置没有提示。 1234567hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 # 设置hystrix的超时时间为2000ms 1.4 服务熔断1.4.1 熔断原理 熔断状态机3个状态： Closed：关闭状态，所有请求都正常访问。 Open：打开状态，所有请求都会被降级。Hystix会对请求情况计数，当一定时间内失败请求百分比达到阈值，则触发熔断，断路器会完全打开。默认失败比例的阈值是50%，请求次数最少不低于20次。 Half Open：半开状态，open状态不是永久的，打开后会进入休眠时间（默认是5S）。随后断路器会自动进入半开状态。此时会释放部分请求通过，若这些请求都是健康的，则会完全关闭断路器，否则继续保持打开，再次进行休眠计时 1.4.2 动手实践认的熔断触发要求较高，休眠时间窗较短，为了测试方便，我们可以通过配置修改熔断策略： 123circuitBreaker.requestVolumeThreshold=10circuitBreaker.sleepWindowInMilliseconds=10000circuitBreaker.errorThresholdPercentage=50 解读： requestVolumeThreshold：触发熔断的最小请求次数，默认20 errorThresholdPercentage：触发熔断的失败请求最小占比，默认50% sleepWindowInMilliseconds：休眠时长，默认是5000毫秒 2.Feign2.1 简介​ Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。 项目主页：https://github.com/OpenFeign/feign 2.2 快速入门导入依赖: 我们在启动类上，添加注解，开启Feign功能 1234567@SpringCloudApplication@EnableFeignClients //开启feign客户端public class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; 删除RestTemplate：feign已经自动集成了Ribbon负载均衡的RestTemplate。所以，此处不需要再注册RestTemplate。 Feign的客户端 在consumer_demo工程中，添加AccountClient接口： 12345@FeignClient(\"account-service\")public interface AccountClient &#123; @GetMapping(\"account/&#123;id&#125;\") Account queryById(@PathVariable(\"id\")Integer id);&#125; 首先这是一个接口，Feign会通过动态代理，帮我们生成实现类。这点跟mybatis的mapper很像 @FeignClient，声明这是一个Feign客户端，类似@Mapper注解。同时通过value属性指定服务名称 接口中的定义方法，完全采用SpringMVC的注解，Feign会根据注解帮我们生成URL，并访问获取结果 改造原来的调用逻辑，调用UserClient接口: 1234567891011@RestController@RequestMapping(\"consumer\")public class ConsumerController &#123; @Autowired private AccountClient accountClient; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; return accountClient.queryById(id); &#125;&#125; 2.3 负载均衡Feign中本身已经集成了Ribbon依赖和自动配置： 因此我们不需要额外引入依赖，也不需要再注册RestTemplate对象。 2.4 Hystrix支持Feign默认也有对Hystrix的集成： 只不过，默认情况下是关闭的。我们需要通过下面的参数来开启：(consumer_demo工程添加配置内容) 123feign: hystrix: enabled: true # 开启Feign的熔断功能 但是，Feign中的Fallback配置不像hystrix中那样简单了。 1）首先，我们要定义一个类AccountClientFallback，实现刚才编写的UserClient，作为fallback的处理类 123456789@Componentpublic class AccountClientFallback implements AccountClient&#123; @Override public Account queryById(Integer id) &#123; Account account=new Account(); account.setName(\"服务器繁忙，请稍后再试！\"); return account; &#125;&#125; 2）然后在AccountClient中，指定刚才编写的实现类 12345@FeignClient(value = \"account-service\",fallback = AccountClientFallback.class)public interface AccountClient &#123; @GetMapping(\"account/&#123;id&#125;\") Account queryById(@PathVariable(\"id\")Integer id);&#125; 2.5.请求压缩(了解)Spring Cloud Feign 支持对请求和响应进行GZIP压缩，以减少通信过程中的性能损耗。通过下面的参数即可开启请求与响应的压缩功能： 123456feign: compression: request: enabled: true # 开启请求压缩 response: enabled: true # 开启响应压缩 同时，我们也可以对请求的数据类型，以及触发压缩的大小下限进行设置： 123456feign: compression: request: enabled: true # 开启请求压缩 mime-types: text/html,application/xml,application/json # 设置压缩的数据类型 min-request-size: 2048 # 设置触发压缩的大小下限 注：上面的数据类型、压缩大小下限均为默认值。 2.6 日志级别(了解)3.Zuul网关​ 服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。 3.1 简介官网：https://github.com/Netflix/zuul 3.2 Zuul加入后的架构 ​ 不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都会经过Zuul这个网关，然后再由网关来实现 鉴权、动态路由等等操作。Zuul就是我们服务的统一入口。 3.3 快速入门新建一个module:gateway 引入依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 启动类GatewayApplication 1234567@SpringBootApplication@EnableZuulProxypublic class GatewayApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GatewayApplication.class); &#125;&#125; application.yaml 1234567891011121314151617server: port: 8084spring: application: name: gatewayeureka: client: service-url: defaultZone: http://localhost:8082/eurekazuul: routes: account-service: path: /account/** serviceId: account-service strip-prefix: false ignored-services: - consumer-service //忽略某些服务的配置 3.4 简化的路由配置在刚才的配置中，我们的规则是这样的： zuul.routes.&lt;route&gt;.path=/xxx/**： 来指定映射路径。&lt;route&gt;是自定义的路由名 zuul.routes.&lt;route&gt;.serviceId=service-provider：来指定服务名。 而大多数情况下，我们的&lt;route&gt;路由名称往往和服务名会写成一样的。因此Zuul就提供了一种简化的配置语法：zuul.routes.&lt;serviceId&gt;=&lt;path&gt; 比方说上面我们关于service-provider的配置可以简化为一条： 123zuul: routes: account-service: /account-service/** # 这里是映射路径 省去了对服务名称的配置。 3.5 默认的路由规则在使用Zuul的过程中，上面讲述的规则已经大大的简化了配置项。但是当服务较多时，配置也是比较繁琐的。因此Zuul就指定了默认的路由规则： 默认情况下，一切服务的映射路径就是服务名本身。例如服务名为：account-service，则默认的映射路径就 是：/account-service/** 也就是说，刚才的映射规则我们完全不配置也是OK的，不信就试试看。 3.6 路由前缀配置示例： 1234zuul: routes: account-service: /account-service/** prefix: /api # 添加路由前缀 我们通过zuul.prefix=/api来指定了路由的前缀，这样在发起请求时，路径就要以/api开头。 3.7 过滤器Zuul作为网关的其中一个重要功能，就是实现请求的鉴权。而这个动作我们往往是通过Zuul提供的过滤器来实现的。 3.7.1 ZuulFilterZuulFilter是过滤器的顶级父类。在这里我们看一下其中定义的4个最重要的方法： 12345678910public abstract ZuulFilter implements IZuulFilter&#123; abstract public String filterType(); abstract public int filterOrder(); boolean shouldFilter();// 来自IZuulFilter Object run() throws ZuulException;// IZuulFilter&#125; shouldFilter：返回一个Boolean值，判断该过滤器是否需要执行。返回true执行，返回false不执行。 run：过滤器的具体业务逻辑。 filterType：返回字符串，代表过滤器的类型。包含以下4种： pre：请求在被路由之前执行 route：在路由请求时调用 post：在route和errror过滤器之后调用 error：处理请求时发生错误调用 filterOrder：通过返回的int值来定义过滤器的执行顺序，数字越小优先级越高。 3.7.2 过滤器执行生命周期这张是Zuul官网提供的请求生命周期图，清晰的表现了一个请求在各个过滤器的执行顺序。 正常流程： 请求到达首先会经过pre类型过滤器，而后到达route类型，进行路由，请求就到达真正的服务提供者，执行请求，返回结果后，会到达post过滤器。而后返回响应。 异常流程： 整个过程中，pre或者route过滤器出现异常，都会直接进入error过滤器，在error处理完毕后，会将请求交给POST过滤器，最后返回给用户。 如果是error过滤器自己出现异常，最终也会进入POST过滤器，将最终结果返回给请求客户端。 如果是POST过滤器出现异常，会跳转到error过滤器，但是与pre和route不同的是，请求不会再到达POST过滤器了。 3.7.3 使用场景场景非常多： 请求鉴权：一般放在pre类型，如果发现没有访问权限，直接就拦截了 异常处理：一般会在error类型和post类型过滤器中结合来处理。 服务调用时长统计：pre和post结合使用。 3.8 自定义过滤器接下来我们来自定义一个过滤器，模拟一个登录的校验。基本逻辑：如果请求中有access-token参数，则认为请求有效，放行。 LoginFilter 1234567891011121314151617181920212223242526272829303132333435@Componentpublic class LoginFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return FilterConstants.PRE_TYPE; &#125; @Override public int filterOrder() &#123; return FilterConstants.PRE_DECORATION_FILTER_ORDER-1; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; //获取请求上下文 RequestContext ctx = RequestContext.getCurrentContext(); //获取Request HttpServletRequest request = ctx.getRequest(); //获取请求参数access-token String token = request.getParameter(\"access-token\"); //判断是否存在 if (StringUtils.isBlank(token))&#123; //不存在,则拦截 ctx.setSendZuulResponse(false); //设置响应状态码，403 ctx.setResponseStatusCode(HttpStatus.FORBIDDEN.value()); &#125; return null; &#125;&#125; 若使用StringUtils, 需要导入依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;&lt;/dependency&gt; 测试 3.9 负载均衡和熔断Zuul中默认就已经集成了Ribbon负载均衡和Hystix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议我们手动进行配置： 12345678910hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 4000 # 设置hystrix的超时时间为4000msribbon: ConnectionTimeOut: 500 ReadTimeOut: 1000 ribbon的超时时长, 真实值是(connect+read)*2, 需小于hystrix时长.","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringCloud框架(一)(微服务)","slug":"SpringCloud框架(一)(微服务)","date":"2021-05-08T13:19:59.162Z","updated":"2020-04-29T02:44:38.100Z","comments":true,"path":"52552/","link":"","permalink":"http://tonymua.top/52552/","excerpt":"1.系统架构演变​ 随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安一隅得过且过？ 其实生活不止眼前的苟且，还有诗和远方。所以我们今天就回顾历史，看一看系统架构演变的历程；把握现在，学习现在最火的技术架构；展望未来，争取成为一名优秀的Java工程师。 今天主要介绍的是微服务架构 微服务 ​ SOA，英文翻译过来是面向服务。微服务，似乎也是服务，都是对系统进行拆分。因此两者非常容易混淆，但其实却有一些差别：","text":"1.系统架构演变​ 随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安一隅得过且过？ 其实生活不止眼前的苟且，还有诗和远方。所以我们今天就回顾历史，看一看系统架构演变的历程；把握现在，学习现在最火的技术架构；展望未来，争取成为一名优秀的Java工程师。 今天主要介绍的是微服务架构 微服务 ​ SOA，英文翻译过来是面向服务。微服务，似乎也是服务，都是对系统进行拆分。因此两者非常容易混淆，但其实却有一些差别： 微服务的特点： 单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责 微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。 面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。 自治：自治是说服务间互相独立，互不干扰 团队独立：每个服务都是一个独立的开发团队，人数不能过多。 技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉 前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动段开发不同接口 数据库分离：每个服务都使用自己的数据源 部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护 微服务结构图： 2.远程调用方式无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？ 常见的远程调用方式有以下几种： RPC：Remote Produce Call远程过程调用，类似的还有RMI。自定义数据格式，基于原生TCP通信，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型 Http：http其实是一种网络传输协议，基于TCP，规定了数据传输的格式。现在客户端浏览器与服务端通信基本都是采用Http协议。也可以用来进行远程服务调用。缺点是消息封装臃肿。 现在热门的Rest风格，就可以通过http协议来实现。 2.1 认识RPCRPC，即 Remote Procedure Call（远程过程调用），是一个计算机通信协议。 该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。说得通俗一点就是：A计算机提供一个服务，B计算机可以像调用本地服务那样调用A计算机的服务。 通过上面的概念，我们可以知道，实现RPC主要是做到两点： 实现远程调用其他计算机的服务 要实现远程调用，肯定是通过网络传输数据。A程序提供服务，B程序通过网络将请求参数传递给A，A本地执行后得到结果，再将结果返回给B程序。这里需要关注的有两点： 1）采用何种网络通讯协议？ 现在比较流行的RPC框架，都会采用TCP作为底层传输协议 2）数据传输的格式怎样？ 两个程序进行通讯，必须约定好数据传输格式。就好比两个人聊天，要用同一种语言，否则无法沟通。所以，我们必须定义好请求和响应的格式。另外，数据在网路中传输需要进行序列化，所以还需要约定统一的序列化的方式。 像调用本地服务一样调用远程服务 如果仅仅是远程调用，还不算是RPC，因为RPC强调的是过程调用，调用的过程对用户而言是应该是透明的，用户不应该关心调用的细节，可以像调用本地服务一样调用远程服务。所以RPC一定要对调用的过程进行封装 RPC调用流程图： 2.2 认识HttpHttp协议：超文本传输协议，是一种应用层协议。规定了网络传输的请求格式、响应格式、资源定位和操作的方式等。但是底层采用什么网络传输协议，并没有规定，不过现在都是采用TCP协议作为底层传输协议。说到这里，大家可能觉得，Http与RPC的远程调用非常像，都是按照某种规定好的数据格式进行网络通信，有请求，有响应。没错，在这点来看，两者非常相似，但是还是有一些细微差别。 RPC并没有规定数据传输格式，这个格式可以任意指定，不同的RPC协议，数据格式不一定相同。 Http中还定义了资源定位的路径，RPC中并不需要 最重要的一点：RPC需要满足像调用本地服务一样调用远程服务，也就是对调用过程在API层面进行封装。Http协议没有这样的要求，因此请求、响应等细节需要我们自己去实现。 优点：RPC方式更加透明，对用户更方便。Http方式更灵活，没有规定API和语言，跨语言、跨平台 缺点：RPC方式需要在API层面进行封装，限制了开发的语言环境。 例如我们通过浏览器访问网站，就是通过Http协议。只不过浏览器把请求封装，发起请求以及接收响应，解析响应的事情都帮我们做了。如果是不通过浏览器，那么这些事情都需要自己去完成。 2.3 如何选择？既然两种方式都可以实现远程调用，我们该如何选择呢？ 速度来看，RPC要比http更快，虽然底层都是TCP，但是http协议的信息往往比较臃肿，不过可以采用gzip压缩。 难度来看，RPC实现较为复杂，http相对比较简单 灵活性来看，http更胜一筹，因为它不关心实现细节，跨平台、跨语言。 因此，两者都有不同的使用场景： 如果对效率要求更高，并且开发过程使用统一的技术栈，那么用RPC还是不错的。 如果需要更加灵活，跨语言、跨平台，显然http更合适 那么我们该怎么选择呢？ 微服务，更加强调的是独立、自治、灵活。而RPC方式的限制较多，因此微服务框架中，一般都会采用基于Http的Rest风格服务。 3.初始SpringCloud微服务是一种架构方式，最终肯定需要技术架构去实施。 微服务的实现方式很多，但是最火的莫过于Spring Cloud了。为什么？ 后台硬：作为Spring家族的一员，有整个Spring全家桶靠山，背景十分强大。 技术强：Spring作为Java领域的前辈，可以说是功力深厚。有强力的技术团队支撑，一般人还真比不了 群众基础好：可以说大多数程序员的成长都伴随着Spring框架，试问：现在有几家公司开发不用Spring？SpringCloud与Spring的各个框架无缝整合，对大家来说一切都是熟悉的配方，熟悉的味道。 使用方便：相信大家都体会到了SpringBoot给我们开发带来的便利，而SpringCloud完全支持SpringBoot的开发，用很少的配置就能完成微服务框架的搭建 SpringCloud是Spring旗下的项目之一，官网地址：http://projects.spring.io/spring-cloud/ Spring最擅长的就是集成，把世界上最好的框架拿过来，集成到自己的项目中。 SpringCloud也是一样，它将现在非常流行的一些技术整合到一起，实现了诸如：配置管理，服务发现，智能路由，负载均衡，熔断器，控制总线，集群状态等等功能。其主要涉及的组件包括： netflix Eureka：注册中心 Zuul：服务网关 Ribbon：负载均衡 Feign：服务调用 Hystix：熔断器 以上只是其中一部分，架构图： 4.微服务场景模拟首先，我们需要模拟一个服务调用的场景。方便后面学习微服务架构 4.1 父工程 配置依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;account_service&lt;/module&gt; &lt;module&gt;consumer_demo&lt;/module&gt; &lt;module&gt;eureka_server&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.SR1&lt;/spring-cloud.version&gt; &lt;demo.mapper.starter.version&gt;2.0.3&lt;/demo.mapper.starter.version&gt; &lt;mysql.version&gt;5.1.32&lt;/mysql.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;demo.mapper.starter.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 4.2 服务提供者首先, 我们需要模拟一个服务调用的场景。方便后面学习微服务架构 pom.xml 12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;account_service&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类AccountApplication 12345678@EnableDiscoveryClient@SpringBootApplication@MapperScan(\"lwy.mapper\")public class AccountApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AccountApplication.class); &#125;&#125; Account 1234567891011@Data@Table(name = \"account\")public class Account &#123; @Id @KeySql(useGeneratedKeys = true) private Integer id; private String name; private Double money;&#125; AccountMapper 12public interface AccountMapper extends Mapper&lt;Account&gt; &#123;&#125; AccountService 1234567891011121314@Servicepublic class AccountService &#123; @Autowired private AccountMapper accountMapper; public Account queryById(Integer id)&#123; return accountMapper.selectByPrimaryKey(id); &#125; @Transactional public void insert(Account account)&#123; accountMapper.insert(account); &#125;&#125; AccountController 1234567891011@RestController@RequestMapping(\"account\")public class AccountController &#123; @Autowired private AccountService accountService; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; return accountService.queryById(id); &#125;&#125; application.yaml 12345678910111213141516spring: application: name: account-service datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm?&amp;serverTimezone=UTC username: root password: 547717253server: port: 8081eureka: client: service-url: defaultZone: http://localhost:8082/eureka 4.3 服务调用者pom.xml 1234567891011121314151617181920212223&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;consumer_demo&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 启动类ConsumerApplication 123456789101112@EnableDiscoveryClient@SpringBootApplicationpublic class ConsumerApplication &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class); &#125;&#125; Account 12345678@Datapublic class Account &#123; private Integer id; private String name; private Double money;&#125; ConsumerController 123456789101112131415161718@RestController@RequestMapping(\"consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; //根据服务id获取实例 List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"account-service\"); //从实例中取出ip和端口 ServiceInstance instance = instances.get(0); String url = instance.getHost() + \":\" + instance.getPort()+\"/account/\"+id; return restTemplate.getForObject(url,Account.class); &#125;&#125; application.yaml 12345678eureka: client: service-url: defaultZone: http://localhost:8082/eurekaspring: application: name: consumer-server 4.4 Eureka注册中心 认识Eureka Eureka：就是服务注册中心（可以是一个集群），对外暴露自己的地址 提供者：启动后向Eureka注册自己信息（地址，提供什么服务） 消费者：向Eureka订阅服务，Eureka会将对应服务的所有提供者地址列表发送给消费者，并且定期更新 心跳(续约)：提供者定期通过http方式向Eureka刷新自己的状态 pom.xml 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud_demo&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;eureka_server&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; EureakServer 1234567@EnableEurekaServer@SpringBootApplicationpublic class EureakServer &#123; public static void main(String[] args) &#123; SpringApplication.run(EureakServer.class,args); &#125;&#125; application.yaml 1234567891011server: port: 8082eureka: client: service-url: defaultZone: http://localhost:8082/eurekaspring: application: name: eureka-server 5.Eureka详解接下来我们详细讲解Eureka的原理及配置。 5.1 基础架构Eureka架构中的三个核心角色： 服务注册中心 Eureka的服务端应用，提供服务注册和发现功能，就是刚刚我们建立的itcast-eureka。 服务提供者 提供服务的应用，可以是SpringBoot应用，也可以是其它任意技术实现，只要对外提供的是Rest风格服务即可。本例中就是我们实现的itcast-service-provider。 服务消费者 消费应用从注册中心获取服务列表，从而得知每个服务方的信息，知道去哪里调用服务方。本例中就是我们实现的itcast-service-consumer。 5.2 高可用的Eureka ServerEureka Server即服务的注册中心，在刚才的案例中，我们只有一个EurekaServer，事实上EurekaServer也可以是一个集群，形成高可用的Eureka中心。 服务同步 多个Eureka Server之间也会互相注册为服务，当服务提供者注册到Eureka Server集群中的某个节点时，该节点会把服务的信息同步给集群中的每个节点，从而实现数据同步。因此，无论客户端访问到Eureka Server集群中的任意一个节点，都可以获取到完整的服务列表信息。 5.3 服务提供者服务提供者要向EurekaServer注册服务，并且完成服务续约等工作。 服务注册 服务提供者在启动时，会检测配置属性中的：eureka.client.register-with-eureka=true参数是否正确，事实上默认就是true。如果值确实为true，则会向EurekaServer发起一个Rest请求，并携带自己的元数据信息，Eureka Server会把这些信息保存到一个双层Map结构中。 第一层Map的Key就是服务id，一般是配置中的spring.application.name属性 第二层Map的key是服务的实例id。一般host+ serviceId + port，例如：locahost:service-provider:8081 值则是服务的实例对象，也就是说一个服务，可以同时启动多个不同实例，形成集群。 服务续约 在注册服务完成以后，服务提供者会维持一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”。这个我们称为服务的续约（renew）； 有两个重要参数可以修改服务续约的行为： 1234eureka: instance: lease-expiration-duration-in-seconds: 90 lease-renewal-interval-in-seconds: 30 lease-renewal-interval-in-seconds：服务续约(renew)的间隔，默认为30秒 lease-expiration-duration-in-seconds：服务失效时间，默认值90秒 也就是说，默认情况下每个30秒服务会向注册中心发送一次心跳，证明自己还活着。如果超过90秒没有发送心跳，EurekaServer就会认为该服务宕机，会从服务列表中移除，这两个值在生产环境不要修改，默认即可。 但是在开发时，这个值有点太长了，经常我们关掉一个服务，会发现Eureka依然认为服务在活着。所以我们在开发阶段可以适当调小。 1234eureka: instance: lease-expiration-duration-in-seconds: 10 # 10秒即过期 lease-renewal-interval-in-seconds: 5 # 5秒一次心跳 5.4 服务消费者 获取服务列表 ​ 当服务消费者启动时，会检测eureka.client.fetch-registry=true参数的值，如果为true，则会拉取Eureka Server服务的列表只读备份，然后缓存在本地。并且每隔30秒会重新获取并更新数据。我们可以通过下面的参数来修改： 123eureka: client: registry-fetch-interval-seconds: 5 生产环境中，我们不需要修改这个值。 但是为了开发环境下，能够快速得到服务的最新状态，我们可以将其设置小一点。 5.5 失效剔除和自我保护 服务下线 ​ 当服务进行正常关闭操作时，它会触发一个服务下线的REST请求给Eureka Server，告诉服务注册中心：“我要下线了”。服务中心接受到请求之后，将该服务置为下线状态。 失效剔除 ​ 有些时候，我们的服务提供方并不一定会正常下线，可能因为内存溢出、网络故障等原因导致服务无法正常工作。Eureka Server需要将这样的服务剔除出服务列表。因此它会开启一个定时任务，每隔60秒对所有失效的服务（超过90秒未响应）进行剔除。 可以通过eureka.server.eviction-interval-timer-in-ms参数对其进行修改，单位是毫秒，生产环境不要修改。 自我保护 ​ 我们关停一个服务,触发了Eureka的自我保护机制。当一个服务未按时进行心跳续约时，Eureka会统计最近15分钟心跳失败的服务实例的比例是否超过了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务剔除列表并不妥当，因为服务可能没有宕机。Eureka就会把当前实例的注册信息保护起来，不予剔除。生产环境下这很有效，保证了大多数服务依然可用。 但是这给我们的开发带来了麻烦， 因此开发阶段我们都会关闭自我保护模式：（eureka） 1234eureka: server: enable-self-preservation: false # 关闭自我保护模式（缺省为打开） eviction-interval-timer-in-ms: 1000 # 扫描失效服务的间隔时间（缺省为60*1000ms） 6.负载均衡Ribbon什么是Ribbon： 6.1 开启负载均衡因为Eureka中已经集成了Ribbon，所以我们无需引入新的依赖，直接修改代码。 修改consumer_demo的引导类，在RestTemplate的配置方法上添加@LoadBalanced注解： 12345@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; 修改调用方式，不再手动获取ip和端口，而是直接通过服务名称调用： ConsumerController 1234567891011@RestController@RequestMapping(\"consumer\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @GetMapping(\"&#123;id&#125;\") public Account queryById(@PathVariable(\"id\")Integer id)&#123; String url = \"http://account-service/account/\"+id; return restTemplate.getForObject(url,Account.class); &#125;&#125; 6.2 负载均衡策略SpringBoot帮我们提供了修改负载均衡规则的配置入口，在consumer_demo的application.yml中添加如下配置： 123account-service: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 格式是：服务名称.ribbon.NFLoadBalancerRuleClassName，值就是IRule的实现类。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"SpringBoot框架","slug":"SpringBoot框架","date":"2021-05-08T13:19:59.161Z","updated":"2020-04-29T02:44:38.036Z","comments":true,"path":"58845/","link":"","permalink":"http://tonymua.top/58845/","excerpt":"1. 了解SpringBoot1.1 什么是SpringBoot​ 用一些固定的方式来构建生产级别的spring应用。Spring Boot 推崇约定大于配置的方式以便于你能够尽可能快速的启动并运行程序。 ​ 其实人们把Spring Boot 称为搭建程序的脚手架。其最主要作用就是帮我们快速的构建庞大的spring项目，并且尽可能的减少一切xml配置，做到开箱即用，迅速上手，让我们关注与业务而非配置。 1.2 为什么要学习SpringBoot​ Spring Boot 简化了基于Spring的应用开发，只需要“run”就能创建一个独立的、生产级别的Spring应用。Spring Boot为Spring平台及第三方库提供开箱即用的设置（提供默认设置，存放默认配置的包就是启动器），这样我们就可以简单的开始。多数Spring Boot应用只需要很少的Spring配置。 1.3 SpringBoot的特点Spring Boot 主要目标是：","text":"1. 了解SpringBoot1.1 什么是SpringBoot​ 用一些固定的方式来构建生产级别的spring应用。Spring Boot 推崇约定大于配置的方式以便于你能够尽可能快速的启动并运行程序。 ​ 其实人们把Spring Boot 称为搭建程序的脚手架。其最主要作用就是帮我们快速的构建庞大的spring项目，并且尽可能的减少一切xml配置，做到开箱即用，迅速上手，让我们关注与业务而非配置。 1.2 为什么要学习SpringBoot​ Spring Boot 简化了基于Spring的应用开发，只需要“run”就能创建一个独立的、生产级别的Spring应用。Spring Boot为Spring平台及第三方库提供开箱即用的设置（提供默认设置，存放默认配置的包就是启动器），这样我们就可以简单的开始。多数Spring Boot应用只需要很少的Spring配置。 1.3 SpringBoot的特点Spring Boot 主要目标是： 为所有 Spring 的开发者提供一个非常快速的、广泛接受的入门体验 开箱即用（启动器starter-其实就是SpringBoot提供的一个jar包），但通过自己设置参数（.properties），即可快速摆脱这种方式。 提供了一些大型项目中常见的非功能性特性，如内嵌服务器、安全、指标，健康检测、外部化配置等 绝对没有代码生成，也无需 XML 配置。 2.快速入门2.1 添加依赖​ 现在我们的项目与SpringBoot还没有什么关联。SpringBoot提供了一个名为spring-boot-starter-parent的工程，里面已经对各种常用依赖（并非全部）的版本进行了管理，我们的项目需要以这个项目为父工程，这样我们就不用操心依赖的版本问题了，需要什么依赖，直接引入坐标即可！ 添加父工程坐标 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;&lt;/parent&gt; 添加web启动器 ​ 为了让SpringBoot帮我们完成各种自动配置，我们必须引入SpringBoot提供的自动配置依赖，我们称为启动器。因为我们是web项目，这里我们引入web启动器： 123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 需要注意的是，我们并没有在这里指定版本信息。因为SpringBoot的父工程已经对版本进行了管理了。 2.2 启动类123456@SpringBootApplicationpublic class BootDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(BootDemoApplication.class,args); &#125;&#125; 2.3 编写controller接下来，我们就可以像以前那样开发SpringMVC的项目了！ 我们编写一个controller： 12345678@RestControllerpublic class HelloController &#123; @GetMapping(\"hello\") public String hello()&#123; return \"hello, spring boot!\"; &#125;&#125; 2.4 启动测试接下来，我们运行main函数 1）监听的端口是8080 2）SpringMVC的映射路径是：/ 3）/hello路径已经映射到了HelloController中的hello()方法 打开页面访问：http://localhost:8080/hello 3.Java配置在入门案例中，我们没有任何的配置，就可以实现一个SpringMVC的项目了，快速、高效！ 但是有同学会有疑问，如果没有任何的xml，那么我们如果要配置一个Bean该怎么办？比如我们要配置一个数据库连接池, 现在该怎么做呢？ 3.1 SpringBoot的属性注入首先引入Druid连接池依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.19&lt;/version&gt; &lt;/dependency&gt; 创建一个jdbc.properties文件，编写jdbc属性： 1234jdbc.driverClassName=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/ssmjdbc.username=rootjdbc.password=547717253 在SpringBoot中，提供了一种新的属性注入方式，支持各种java基本数据类型及复杂类型的注入。 1）我们新建一个类，用来进行属性注入： JdbcProperties 123456789@ConfigurationProperties(prefix = \"jdbc\")@Datapublic class JdbcProperties &#123; String driverClassName; String url; String username; String password;&#125; 此时使用@Data需要安装lombok插件并导入相关依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 2）在JdbcConfig中使用这个属性： 1234567891011121314@Configuration@EnableConfigurationProperties(JdbcProperties.class)public class JdbcConfig &#123; @Bean public DataSource dataSource(JdbcProperties jdbc) &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(jdbc.getUrl()); dataSource.setDriverClassName(jdbc.getDriverClassName()); dataSource.setUsername(jdbc.getUsername()); dataSource.setPassword(jdbc.getPassword()); return dataSource; &#125;&#125; 通过@EnableConfigurationProperties(JdbcProperties.class)来声明要使用JdbcProperties这个类的对象 然后你可以通过以下方式注入JdbcProperties： @Autowired注入 12@Autowiredprivate JdbcProperties prop; 构造函数注入 1234private JdbcProperties prop;public JdbcConfig(Jdbcproperties prop)&#123; this.prop = prop;&#125; 声明有@Bean的方法参数注入 1234@Beanpublic Datasource dataSource(JdbcProperties prop)&#123; // ...&#125; 本例中，我们采用第三种方式。 优势： Relaxed binding：松散绑定 不严格要求属性文件中的属性名与成员变量名一致。支持驼峰，中划线，下划线等等转换，甚至支持对象引导。比如：user.friend.name：代表的是user对象中的friend属性中的name属性，显然friend也是对象。@value注解就难以完成这样的注入方式。 meta-data support：元数据支持，帮助IDE生成属性提示（写开源框架会用到）。 3.2 更优雅的注入​ 事实上，如果一段属性只有一个Bean需要使用，我们无需将其注入到一个类（JdbcProperties）中。而是直接在需要的地方声明即可： JdbcConfig 123456789@Configuration@EnableConfigurationProperties(JdbcProperties.class)*/ @Bean // 声明要注入的属性前缀，SpringBoot会自动把相关属性通过set方法注入到DataSource中 @ConfigurationProperties(prefix = \"jdbc\") public DataSource dataSource() &#123; return new DruidDataSource(); &#125;&#125; ​ 我们直接把@ConfigurationProperties(prefix = &quot;jdbc&quot;)声明在需要使用的@Bean的方法上，然后SpringBoot就会自动调用这个Bean（此处是DataSource）的set方法，然后完成注入。使用的前提是：该类必须有对应属性的set方法！ 使用yaml代替properties application.yaml 12345jdbc: driverClassName: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm username: root password: 547717253 4.自动配置原理SpringBoot为我们提供了默认配置，而默认配置生效的条件一般有两个： 你引入了相关依赖 你自己没有配置 1）启动器 所以，我们如果不想配置，只需要引入依赖即可，而依赖版本我们也不用操心，因为只要引入了SpringBoot提供的stater（启动器），就会自动管理依赖及版本了。 因此，玩SpringBoot的第一件事情，就是找启动器，SpringBoot提供了大量的默认启动器. 2）全局配置 另外，SpringBoot的默认配置，都会读取默认属性，而这些属性可以通过自定义application.properties文件来进行覆盖。这样虽然使用的还是默认配置，但是配置中的值改成了我们自定义的。 因此，玩SpringBoot的第二件事情，就是通过application.properties来覆盖默认属性值，形成自定义配置。我们需要知道SpringBoot的默认属性key，非常多. 5.SpringBoot实践5.1.整合SpringMVC虽然默认配置已经可以使用SpringMVC了，不过我们有时候需要进行自定义配置。 5.1.1 修改端口查看SpringBoot的全局属性可知，端口通过以下方式在application.yaml中配置： 12server: port: 80 5.1.2 访问静态资源现在，我们的项目是一个jar工程，那么就没有webapp，我们的静态资源该放哪里呢？ 默认的静态资源路径为： classpath:/META-INF/resources/ classpath:/resources/ classpath:/static/ classpath:/public 只要静态资源放在这些目录中任何一个，SpringMVC都会帮我们处理。 我们习惯会把静态资源放在classpath:/static/目录下。即在resources目录下创建static目录，并且添加一些静态资源. 5.1.3 添加拦截器拦截器也是我们经常需要使用的，在SpringBoot中该如何配置呢？ 过实现WebMvcConfigurer并添加@Configuration注解来实现自定义部分SpringMvc配置。 首先我们定义一个拦截器： MyInterceptor 123456789101112131415161718@Slf4jpublic class MyInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; log.debug(\"preHandle method is running\"); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) &#123; log.debug(\"postHandle method is running\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; log.debug(\"afterCompletion method is running\"); &#125;&#125; 然后，我们定义配置类，添加拦截器： MvcConfig 12345678@Configurationpublic class MvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new MyInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; 接下来运行并查看日志： 你会发现日志中什么都没有，因为我们记录的log级别是debug，默认是显示info以上，我们需要进行配置。 SpringBoot通过logging.level.*=debug来配置日志级别，*填写包名 在application.yaml中配置： 123logging: level: demo: debug 5.2 整合连接池其实，在刚才引入jdbc启动器的时候，SpringBoot已经自动帮我们引入了一个连接池： ​ HikariCP应该是目前速度最快的连接池 因此，我们只需要指定连接池参数即可： ​ 在application.yaml中配置： 123456spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/ssm?&amp;serverTimezone=UTC username: root password: 547717253 5.3 通用mapper通用Mapper的作者为自己的插件编写了启动器，我们直接引入即可： 123456&lt;!--通用mapper--&gt;&lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt; 此时也不再需要mybatis启动器及jdbc的依赖 Account 1234567891011@Data@Table(name = \"account\")public class Account &#123; @Id @KeySql(useGeneratedKeys = true) private Integer id; private String name; private Double money;&#125; AccountMapper 123public interface AccountMapper extends Mapper&lt;Account&gt; &#123;&#125; AccountServiceImpl 1234567891011121314@Servicepublic class AccountServiceImpl &#123; @Autowired private AccountMapper accountMapper; public Account queryById(Integer id)&#123; return accountMapper.selectByPrimaryKey(id); &#125; @Transactional public void insert(Account account)&#123; accountMapper.insert(account); &#125;&#125; HelloController 12345678910111213@RestController@Slf4j@RequestMapping(\"account\")public class HelloController &#123; @Autowired private AccountServiceImpl accountService; @GetMapping(\"&#123;id&#125;\") public Account hello(@PathVariable(\"id\")Integer id)&#123; log.debug(\"hello method is running\"); return accountService.queryById(id); &#125;&#125; 启动测试 访问http://localhost:8080/account/5","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Spring AOP","slug":"Spring-AOP","date":"2021-05-08T13:19:59.159Z","updated":"2020-08-19T06:47:53.564Z","comments":true,"path":"spring_aop/","link":"","permalink":"http://tonymua.top/spring_aop/","excerpt":"1.AOP概述1.1 什么是AOP？AOP(Aspect Oriented Programming 面向切面编程)，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。常用于日志记录，性能统计，安全控制，事务处理，异常处理等等。","text":"1.AOP概述1.1 什么是AOP？AOP(Aspect Oriented Programming 面向切面编程)，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。常用于日志记录，性能统计，安全控制，事务处理，异常处理等等。 1.2 AOP术语切面(Aspect)：由横切关注点构成的特殊对象。连接点(Join Point)：连接点是指在程序执行过程中某个特定的点，比如某方法调用的时候或者处理异常的时候；通知(Advice)：指在切面的某个特定的连接点上执行的动作。Spring切面可以应用5种通知： 前置通知(Before):在目标方法或者说连接点被调用前执行的通知； 后置通知(After)：指在某个连接点完成后执行的通知； 返回通知(After-returning)：指在某个连接点成功执行之后执行的通知； 异常通知(After-throwing)：指在方法抛出异常后执行的通知； 环绕通知(Around)：指包围一个连接点通知，在被通知的方法调用之前和之后执行自定义的方法。 切点(Pointcut)：指匹配连接点的断言。通知与一个切入点表达式关联，并在满足这个切入的连接点上运行，例如：当执行某个特定的名称的方法。引入(Introduction)：引入也被称为内部类型声明，声明额外的方法或者某个类型的字段。目标对象(Target Object)：目标对象是被一个或者多个切面所通知的对象。AOP代理(AOP Proxy)：向目标对象应用通知之后创建的对象。织入(Wearving)：增强添加到目标类具体连接点上的过程。AOP有三种织入的方式：编译期织入、类装载期织入、动态代理织入(spring采用动态代理织入)。 1.3 通知执行顺序 正常情况@Around -&gt;@Before-&gt;主方法体-&gt;@Around中pjp.proceed()-&gt;@After-&gt;@AfterReturning 存在异常 异常在Around中pjp.proceed()之前@Around -&gt; @After -&gt; @AfterThrowing 异常在Around中pjp.proceed()之后@Around -&gt;@Before-&gt;主方法体-&gt;@Around中pjp.proceed()-&gt;@After-&gt;@AfterThrowing1.4 实现原理 JDK动态代理(JDK提供，只能代理接口) 使用动态代理可以为一个或多个接口在运行期动态生成实现对象，生成的对象中实现接口的方法时可以添加增强代码，从而实现AOP。缺点是只能针对接口进行代理，另外由于动态代理是通过反射实现的，有时可能要考虑反射调用的开销。 CGLib动态代理: (适用CGLib工具)采用动态的字节码生成技术，运行时动态生成指定类的一个子类对象，并覆盖其中特定方法，覆盖方法时可以添加增强代码，从而实现AOP 。1.5 Pointcut切入点的语法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 1、使用within表达式匹配 * 下面示例表示匹配com.example.controller包下所有的类的方法 */@Pointcut(\"within(com.example.controller..*)\")public void pointcutWithin()&#123;&#125;/** * 2、this匹配目标指定的方法，此处就是HelloController的方法 */@Pointcut(\"this(com.example.controller.HelloController)\")public void pointcutThis()&#123;&#125;/** * 3、target匹配实现UserInfoService接口的目标对象 */@Pointcut(\"target(com.leo.service.UserInfoService)\")public void pointcutTarge()&#123;&#125;/** * 4、bean匹配所有以Service结尾的bean里面的方法， * 注意：使用自动注入的时候默认实现类首字母小写为bean的id */@Pointcut(\"bean(*ServiceImpl)\")public void pointcutBean()&#123;&#125;/** * 5、args匹配第一个入参是String类型的方法 */@Pointcut(\"args(String, ..)\")public void pointcutArgs()&#123;&#125;/** * 6、@annotation匹配是@Controller类型的方法 */@Pointcut(\"@annotation(org.springframework.stereotype.Controller)\")public void pointcutAnnocation()&#123;&#125;/** * 7、@within匹配@Controller注解下的方法，要求注解的@Controller级别为@Retention(RetentionPolicy.CLASS) */@Pointcut(\"@within(org.springframework.stereotype.Controller)\")public void pointcutWithinAnno()&#123;&#125;/** * 8、@target匹配的是@Controller的类下面的方法，要求注解的@Controller级别为@Retention(RetentionPolicy.RUNTIME) */@Pointcut(\"@target(org.springframework.stereotype.Controller)\")public void pointcutTargetAnno()&#123;&#125;/** * 9、@args匹配参数中标注为@Sevice的注解的方法 */@Pointcut(\"@args(org.springframework.stereotype.Service)\")public void pointcutArgsAnno()&#123;&#125;/** * 10、使用excution表达式 * execution( * modifier-pattern? //用于匹配public、private等访问修饰符 * ret-type-pattern //用于匹配返回值类型，不可省略 * declaring-type-pattern? //用于匹配包类型 * name-pattern(param-pattern) //用于匹配类中的方法，不可省略 * throws-pattern? //用于匹配抛出异常的方法 * ) * * 下面的表达式解释为：匹配com.example.controller.HelloController类中以hello开头的修饰符为public返回类型任意的方法 */@Pointcut(value = \"execution(public * com.example.controller.HelloController.hello*(..))\")public void pointCut() &#123;&#125; 2.AOP实践2.1 HTTP接口鉴权需求： 可以定制地为某些指定的 HTTP RESTful api 提供权限验证功能。 当调用方的权限不符时, 返回错误。相关依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 2.1.1 自定义注解1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface AuthChecker &#123;&#125; AuthChecker 注解是一个方法注解，它用于注解 RequestMapping 方法。 2.1.2 aspect的实现12345678910111213141516171819202122232425262728293031323334353637@Component@Aspectpublic class HttpAopAdviseDefine &#123; //定义一个 Pointcut, 使用切点表达式函数来描述对哪些Join point使用advice. @Pointcut(\"@annotation(com.example.annotation.AuthChecker)\") public void pointcut()&#123; &#125; //定义advice @Around(\"pointcut()\") public Object checkAuth(ProceedingJoinPoint proceedingJoinPoint)&#123; HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); //检查用户所传递的 token 是否合法 String token = getToken(request); if (!token.equalsIgnoreCase(\"111\"))&#123; return \"token不合法！\"; &#125; try &#123; return proceedingJoinPoint.proceed(); &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); return null; &#125; &#125; private String getToken(HttpServletRequest request) &#123; Cookie[] cookies = request.getCookies(); if (cookies == null) &#123; return \"\"; &#125; for (Cookie cookie : cookies) &#123; if (cookie.getName().equalsIgnoreCase(\"token\")) &#123; return cookie.getValue(); &#125; &#125; return \"\"; &#125;&#125; 2.1.3 Controller12345678910111213@RestController@RequestMapping(\"/aop/http\")public class AopController &#123; @GetMapping(\"alive\") public String alive()&#123; return \"服务一切正常\"; &#125; @AuthChecker @GetMapping(\"login\") public String login()&#123; return \"登录成功！\"; &#125;&#125; 2.1.4 测试token缺失/不正确：token正确： 2.2 方法调用日志需求: 某个服务下的方法的调用需要有log记录调用的参数以及返回结果。 当方法调用出异常时，有特殊处理，例如打印异常 log，报警等。2.2.1 aspect 的实现123456789101112131415161718192021222324252627282930313233@Component@Aspectpublic class LogAopAdviseDefine &#123; private Logger logger = LoggerFactory.getLogger(getClass()); // 定义一个Pointcut, 使用切点表达式函数来描述对哪些 Join point 使用 advise. @Pointcut(\"within(com.example.service..*)\") public void poincut() &#123; &#125; // 定义advise @Before(\"poincut()\") public void logMethodInvokeParam(JoinPoint joinPoint) &#123; logger.info(\"---Before method &#123;&#125; invoke, param: &#123;&#125;---\", joinPoint.getSignature().toShortString(), joinPoint.getArgs()); &#125; @AfterReturning(pointcut = \"poincut()\",returning = \"message\") public void logMethodInvokeResult(JoinPoint joinPoint,Object message)&#123; logger.info(\"---After method &#123;&#125; invoke, result: &#123;&#125;---\", joinPoint.getSignature().toShortString(), joinPoint.getArgs()); &#125; @AfterThrowing(pointcut = \"poincut()\",throwing = \"exception\") public void logMethodInvokeException(JoinPoint joinPoint,Exception exception)&#123; logger.info(\"---method &#123;&#125; invoke exception: &#123;&#125;---\", joinPoint.getSignature().toShortString(), exception.getMessage()); &#125;&#125; 2.2.2 Service1234567891011121314151617@Servicepublic class LogServiceImpl implements LogService &#123; private Logger logger = LoggerFactory.getLogger(getClass()); private Random random = new Random(System.currentTimeMillis()); @Override public int LogMethod(String param) &#123; logger.info(\"---LogService: logMethod invoked, param: &#123;&#125;---\", param); return random.nextInt(); &#125; @Override public void exceptionMethod() throws Exception &#123; logger.info(\"---LogService: exceptionMethod invoked---\"); throw new Exception(\"Something bad happened!\"); &#125;&#125; 123456789@Servicepublic class NormalServiceImpl implements NormalService &#123; private Logger logger = LoggerFactory.getLogger(getClass()); @Override public void normalMethod() &#123; logger.info(\"---NormalService: someMethod invoked---\"); &#125;&#125; 2.2.3 测试123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTestpublic class LogAdviseTest &#123; @Autowired private LogService logService; @Autowired private NormalService normalService; @Test @PostConstruct public void testLogAdvise()&#123; logService.LogMethod(\"LogMethod Test!\"); try &#123; logService.exceptionMethod(); &#125;catch (Exception e)&#123; &#125; normalService.normalMethod(); &#125;&#125; 2.3 方法耗时统计需求: 为服务中的每个方法调用进行调用耗时记录. 将方法调用的时间戳, 方法名, 调用耗时上报到监控平台2.3.1 aspect 实现12345678910111213141516171819202122232425262728293031323334353637383940@Component@Aspectpublic class ExpiredAopAdviseDefine &#123; private Logger logger = LoggerFactory.getLogger(getClass()); @Pointcut(\"within(com.example.service.impl.ExpiredServiceImpl)\") public void pointcut() &#123; &#125; @Around(\"pointcut()\") public Object methodInvokeExpiredTime( ProceedingJoinPoint proceedingJoinPoint) &#123; try &#123; // StopWatch 任务执行时间监视器 StopWatch stopWatch = new StopWatch(); // 开始 stopWatch.start(); Object proceed = proceedingJoinPoint.proceed(); // 结束 stopWatch.stop(); // 上报到监控平台 reportToMonitorSystem( proceedingJoinPoint.getSignature().toShortString(), stopWatch.getTotalTimeMillis()); return proceed; &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); return null; &#125; &#125; public void reportToMonitorSystem(String methodName, long expiredTime) &#123; logger.info(\"---method &#123;&#125; invoked, expired time: &#123;&#125; ms---\", methodName, expiredTime); &#125;&#125; 2.3.2 Service123456789101112131415161718@Servicepublic class ExpiredServiceImpl implements ExpiredService &#123; private Logger logger = LoggerFactory.getLogger(getClass()); private Random random = new Random(System.currentTimeMillis()); @Override public void expiredTimeMethod() &#123; logger.info(\"---SomeService: someMethod invoked---\"); try &#123; //模拟耗时任务 Thread.sleep(random.nextInt(500)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2.3.3 测试123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class ExpiredAdviseTest &#123; @Autowired private ExpiredService expiredService; @Test @PostConstruct public void testExpiredTime() &#123; expiredService.expiredTimeMethod(); &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"http://tonymua.top/tags/AOP/"},{"name":"面向切面编程","slug":"面向切面编程","permalink":"http://tonymua.top/tags/面向切面编程/"}]},{"title":"Sping Cloud Alibaba","slug":"Sping-Cloud-Alibaba","date":"2021-05-08T13:19:59.157Z","updated":"2021-03-17T14:58:25.266Z","comments":true,"path":"SpringCloudAlibaba/","link":"","permalink":"http://tonymua.top/SpringCloudAlibaba/","excerpt":"1.主要功能 服务限流降级 服务注册与发现 分布式配置管理 消息驱动能力 分布式事务","text":"1.主要功能 服务限流降级 服务注册与发现 分布式配置管理 消息驱动能力 分布式事务 Spring Cloud Alibaba使用@GlobalTransactional注解，高效并且零入侵地解决分布式事务问题。 2.主要组件 SentinelSentinel把流量作为切入点，从流量控制、熔断降级、系统负载等多个维度保障服务的稳定性。Sentinel主要分为两部分，客户端在我们的程序中集成，控制台基于Spring Boot开发，打包后直接运行。利用Sertinel流量控制功能可以对网关、服务进行过载保护，另一个核心功能是熔断降级，与Hystrix一致。 NacosNacos是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。主要功能有注册中心和配置中心。Nacos可以代替Eureka和Apollo。 RocketMQ分布式消息系统，基于高可用分布式集群技术，提供低延时、高可靠的消息发布与订阅服务。使用消息队列可以让服务之间更加解耦，还可以进行流量削峰，还可以用事务消息来实现分布式事务。 DubboJava RPC框架，Spring Cloud Alibaba体系中，服务之间的通信可以使用Dubbo进行远程调用。Rest的优势：通用性强、无语言限制、调试方便，但一般都是JSON格式，报文较大，Dubbo是二进制传输，性能更好。Spring Cloud Alibaba中可以将Dubbo和Feign结合使用，即服务可以暴露Dubbo协议，也可以暴露Rest协议，调用方选择对应的协议进行调用，对于性能要求高的使用Dubbo，其它的使用Rest。 Seata分布式事务解决方案，提供了AT、TCC等事务模式。 3.技术选型推荐 服务注册与发现：Nacos 服务熔断限流：Sentinel 服务通信调用：Feign 配置中心：Nacos 服务网关：Spring Cloud Gateway 分布式事务：Seata 消息队列：RocketMQ 调用链监控：Sleuth+Zipkin 分布式任务调度：XXL-JOB","categories":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"}]},{"title":"Sping Cloud组件扩展","slug":"Sping Cloud组件扩展","date":"2021-05-08T13:19:59.156Z","updated":"2021-03-17T14:13:35.253Z","comments":true,"path":"SpringCloud_02/","link":"","permalink":"http://tonymua.top/SpringCloud_02/","excerpt":"1.Apollo统一管理配置信息，增强配置管理的服务能力。使用配置中心管理配置后，可以将配置信息从项目转移到配置中心，一般一个项目会有一个唯一的标识ID，通过这个ID从配置中心获取对应的配置内容。","text":"1.Apollo统一管理配置信息，增强配置管理的服务能力。使用配置中心管理配置后，可以将配置信息从项目转移到配置中心，一般一个项目会有一个唯一的标识ID，通过这个ID从配置中心获取对应的配置内容。 拉取项目在启动的时候通过配置中心拉取配置信息。 推送在配置中心修改配置后，可以实时地推送给客户端进行更新。 解决的问题：每个节点都要重启、格式不规范、容易被错改、没有历史记录、安全性不高 1.1 主要功能 统一管理不同环境、不同集群的配置 配置修改实时生效，即热发布功能 版本发布管理 灰度发布 权限管理、发布审核、操作审计 提供Java和.Net原生客户端，轻松集成、操作简单 提供开放平台API 部署简单 Apollo 和 Spring Cloud Config 对比 1.2 概念介绍 应用应用指项目，标识用appId来指定，Spring Boot项目中建议直接配置在application.yml中。 环境Apollo客户端在运行时除了需要知道项目当前的身份标识，还需要知道当前项目对应的环境，从而根据环境去配置中心获取对应的配置。可以通过Java System Property或配置文件指定，目前支持的环境有Local、DEV、FAT(测试环境)、UAT(集成环境)、PRO(生产环境)。 集群不同的集群可以有不同的配置文件，可以通过Java System Property或配置文件来指定。 命名空间可以用来对配置做分类，不同类型的配置存放在不同的命名空间中，如数据库配置文件、消息队列配置、业务相关配置等。命名空间还可以让多个项目共用一份配置，如Redis集群。 权限控制 1.3 架构设计 Config Service服务于Client对配置的操作，提供配置的查询、更新接口(基于Http long polling) Admin Service服务于后台Portal(Web管理端)，提供配置管理接口 Meta ServerMeta Server是对Eureka的一个封装，提供了HTTP接口获取Admin Service和Config Service的服务信息。部署时和Config Service是在一个JVM进程中的，所以IP、端口和Config Service一致。 Eureka用于提供服务注册和发现，Config Service和Admin Service都会向Eureka注册服务。Eureka在部署时和Config Service在一个JVM进程中，即Config Service包含了Meta Server和Eureka。 Portal后台Web界面管理配置，通过Meta Server获取Admin Service服务列表(IP+Port)进行配置的管理，客户端做负载均衡。 CilentApollo提供的客户端，用于项目中对配置的获取、更新。通过Meta Server获取Config Service服务列表(IP+Port)进行配置的管理，客户端内做负载均衡。 工作流程： 注册、续约、取消，也就是服务注册的操作，Config Service和Admin Service都会注册到Eureka中。 服务发现的逻辑，Client需要指定所有的Config Service，Portal需要知道所有的Admin Service，然后才能发起对应的操作。查找服务列表是通过负载进行转发到Meta Server. Meta Server去Eureka中获取对应的服务列表。 当获取到对应的服务信息后，就可以直接发起远程调用了。 推送设计：在Portal中进行配置的编辑和发布操作后，Portal会调用Admin Service提供的接口进行发布操作。Admin Service收到请求后，发送ReleaseMessage给各个Config Service，通知Config Service配置发生了变化。Config Service收到ReleaseMessage后，通知对应的客户端，基于HTTP长连接实现。 消息设计：ReleaseMessage消息是通过MySQL实现了一个简单的消息队列。Admin Service在配置发布后会往ReleaseMessage表插入一条消息记录，Config Service会启动一个线程定时扫描ReleaseMessage表，去查看是否有新的消息记录。Config Service发现有新的消息记录，那么就会通知所有的消息监听器，消息监听器得到配置发布的信息后，则会通知对应的客户端。 客户端设计：客户端和服务端保持了一个长连接，编译配置的实时更新推送。定时拉取配置是客户端本地的一个定时任务，默认5分钟1次，也可以通过在运行时指定System Property:apollo.refreshInterval来进行覆盖，单位是分钟，采用推送+定时拉取的方式就等于双保险。客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中。客户端会把从服务取到的配置在本地文件系统中缓存一份，当服务或网络不可用时可以使用本地配置，也就是本地开发模式env=Local。 2.分布式链路跟踪分布式链路跟踪的关键在于如何将请求经过的服务节点都关联起来。 2.1 核心概念 Span基本工作单元，如发送RPC请求是一个新的Span、发送HTTP请求是一个新的Span、内部方法调用也是一个新的Span。 Trace一次分布式调用的链路信息，每次调用链路信息都会在请求入口处生成一个TraceId。 Annotation用于记录事件的信息。在Annotation中会有CS、SR、SS、CR这些信息。 CSClient Sent，客户端发送一个请求，这个Annotation表示Span的开始。 SRServer Received，服务端获得请求并开始处理，用SR的时间减去CS的时间即网络延迟时间。 SSServer Sent，在请求处理完成时将响应发送回客户端，SR-SS，即服务端处理请求所需的时间。 CRClient Recevied，表示Span结束，客户端从服务端收到响应，CR-CS，即全部时间。 2.2 请求追踪过程分解 当一个请求访问SERVICE1时，此时没有Trace和Span，会生成Trace和Span，如图所示生成Trace ID是X，Span ID是A。 接着SERVICE1请求SERVICE2，这是一次远程请求，会生成一个新的Span，Span ID为B，Trace ID不变还是X。Span B处于CS状态，当请求到达SERVICE2后，SERVICE2有内部操作，生成了一个新的Span，Span ID为C，Trace ID不变。 SERVICE2处理完后向SERVICE3发起请求，生成新的Span，Span ID为D，Span D处于CS状态，SERVICE3接收请求后，Span D处于RS状态，同时SERVICE内部操作也会生成新的Span，Span ID为E。 SERVICE3处理完后，需要将结果响应给调用方，此时Span D处于SS状态，当SERVICE2收到响应后，Span D处于CR状态。 一次请求会经过多个服务，会产生多个Span，但Trace ID只有一个。 2.3 Spring Cloud Sleuth 可以添加链路信息到日志中 链路数据可直接上报给Zipkin 内置了很多框架的埋点，如Zuul、Feign、Hystrix 2.4 Zipkin收集数据、查询数据。 CollectorZipkin的数据收集器，进行数据验证、存储。 Storage存储组件，Zipkin默认在内存中存储数据，数据落地的话支持ElasticSearch和MySQL。 SearchZipkin的查询API，用于查找和检索数据，主要使用者为Web UI。 Web UI提供可视化的操作界面，直观的查询链路跟踪数据。 链路跟踪的信息会通过Transport传递给Zipkin的Collector，Transport支持的方式有HTTP和MQ进行传输。 2.5 Sleuth关联整个请求链路日志集成Spring Cloud Sleuth后，会在原始的日志加上一些链路的信息。 application name应用名称，即application.yml里的spring.application.name参数配置的属性。 traceId为请求分配的唯一请求号，用来标识一条请求链路。 spanId基本的工作单元，一个请求可以包含多个步骤，每个步骤有自己的Span ID，一次请求只有一个Trace ID和多个Span Id。 export布尔类型，表示是否将该信息输出到Zipkin进行收集和展示。 2.6 使用技巧 抽样采集数据spring.sleuth.sampler.probability=10请求次数：Zipkin数据条数=10：1 RabbitMQ代替HTTP发送调用链路数据删除配置spring.zipkin.base-url，在启动Zipkin服务时指定RabbitMQ信息： 1java -DRABBIT_ADDRESSES=192.168.10.124:5672 -DRABBIT_USER=admin -DRABBIT_PASSWORD=123456 -jar zipkin.jar ElasticSearch存储调用链数据启动Zipkin的时候指定存储类型为ES，指定ES的URL信息： 1java -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=http://localhost:9200 -jar zipkin.jar 手动埋点检测性能 Hystrix埋点分析 3.微服务安全认证3.1 常用的认证方式 session用户登陆后将信息存储在服务端，客户端通过cookie中的sessionId来标识对应的用户。 缺点： 服务端需要保存每个用户的登录信息，如果用户量非常的，服务端的存储压力也会增大。 多节点时，通过负载均衡器进行转发，session可能会丢失。 解决办法：session复制，Nginx可以设置黏性Cookie来保证一个用户的请求只访问同一个节点；session集中存储，如存储在Redis中。 HTTP Basic AuthenticationHTTP基本认证，客户端会在请求头中增加Authorization，Authorization是用户名和密码Base64加密后的内容，服务端获取Authorization Header中的用户名与密码进行验证。 Token与HTTP Basic Authentication类似，与session不同，session只是一个key，会话信息存储在服务端。而Token中会存储用户的信息，然后通过加密算法进行加密，只有服务端才能解密，服务端拿到Token后进行解密获取用户信息。 3.2 JWT认证简介：JWT(JSON Web Token)如用户登录时，基本思路就是用户提供用户名和密码给认证服务器，服务器验证用户提交信息的合法性；如果验证成功，会产生并返回一个Token，用户可以使用这个Token访问服务器上受保护的资源。 JWT由三部分构成：头部(Header)、消息体(Payload)、签名(Signature) 1token = encodeBase64(header) + '.' + encodeBase64(payload) + '.' + encodeBase64(signature) 头部信息：令牌类型、签名算法 1&#123; \"alg\": \"HS256\", \"typ\": \"JWT\" &#125; 消息体：应用需要的信息，如用户的id 1&#123;\"id\": \"1234567890\", \"name\": \"John Doe\"&#125; 签名：用来判断消息在传递的路径上是否被篡改 1HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) JWT认证流程：客户端需要调用服务端提供的认证接口来获取 Token。获取 Token 的流程如图所示，客户端会首先发起一个认证的请求到网关，网关会将请求转发到后端的用户服务中，在用户服务中验证身份后，就会根据用户的信息生成一个 Token 返回给客户端，这样客户端就获取了后面请求的通行证。然后，客户端会将获取的 Token 存储起来，在下次请求时带上这个 Token，一般会将 Token 放入请求头中进行传递。当请求到达网关后，会在网关中对 Token 进行校验，如果校验成功，则将该请求转发到后端的服务中，在转发时会将 Token 解析出的用户信息也一并带过去，这样在后端的服务中就不用再解析一遍 Token 获取的用户信息，这个操作统一在网关进行的。如果校验失败，那么就直接返回对应的结果给客户端，不会将请求进行转发。 在网关中，验证过滤器会对 /oauth/token 这个认证 API 进行放行，不进行验证。用户信息的全局传递扩展：不需要加参数，直接通过请求头进行传递，在服务内部通过ThreadLocal进行上下文传递。主要流程：从网关传递到后端服务，后端服务接受数据后存储到ThreadLocal中，服务会调用其它服务，如果用Feign调用可以利用Feign的拦截器传递数据，如果用RestTemplate的拦截器传递数据也一样。 3.3 Token的使用Token注销Token的有效期存储在Token本身中，只有解析出Token的信息，才能获取到Token的有效时间，不能修改。Token的有效期越短，安全性越高。还可以在用户退出登录时，进行Token的注销操作，如将注销的Token放入Redis中进行一层过滤，即在网关中验证Token有效性时先从Redis中判断Token是否存在，如果存在，直接拦截。Token放入Redis的过期时间一般会设置为Token剩余的有效时间。 使用建议 设置较短(合理)的过期时间 注销的Token及时清除(放入Redis中做一层过滤) 监控Token的使用频率 核心功能敏感操作可以使用动态验证(验证码) 网络环境、浏览器信息等识别 加密密钥支持动态修改 加密密钥支持动态修改 3.4 内部服务之间的认证 IP白名单如用户服务只能某些IP或IP段访问，IP白名单可以采用配置中心来存储，具备实时刷新的能力。 内部同样使用Token进行验证服务在启动时就可以在统一的认证服务中申请Token，申请需要的认证信息可以放在配置中心。这样服务启动时就有了能够访问其他服务的Token，在调用时带上Token，被调用的服务中进行Token的校验。对于Token的失效更新： 在请求时如果返回的Token已经失效，那么可以重新获取Token后再发起调用，这种在并发量大时需要加锁，不然会发生同时申请多个Token的情况。 定时更新，如Token有效期1个小时，那么定时任务可以50分钟更新一次。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"}]},{"title":"Sping Cloud相关组件了解","slug":"Sping Cloud相关组件了解","date":"2021-05-08T13:19:59.154Z","updated":"2021-03-15T02:09:38.855Z","comments":true,"path":"SpringCloud_01/","link":"","permalink":"http://tonymua.top/SpringCloud_01/","excerpt":"1.Eureka如果需要实现完整的服务注册与服务发现的功能，我们需要有注册中心来统一存储和管理服务信息，应用程序需要将自身的信息注册到注册中心，也就是服务提供者和服务消费者的信息。整个过程中包含的操作有注册、拉取、心跳、剔除等动作。","text":"1.Eureka如果需要实现完整的服务注册与服务发现的功能，我们需要有注册中心来统一存储和管理服务信息，应用程序需要将自身的信息注册到注册中心，也就是服务提供者和服务消费者的信息。整个过程中包含的操作有注册、拉取、心跳、剔除等动作。 注册中心：用来集中存储管理服务信息。 服务提供者：通过API供其他方调用服务。 服务消费者：需要调用其他方的API获取服务。 项目启动后Eureka Client会向Eureka Server发送请求，进行注册，并将自身信息发送给Eureka Server。注册成功后，每隔一定的时间，Eureka Client会向Eureka Server发送心跳来续约服务，汇报健康状态。如果客户端长时间没有续约，那么Eureka Server大约在90秒内从服务器注册表中清除客户端的信息。应用程序停止时Eureka Client会通知Eureka Server移除相关信息，信息移除成功后，对应的客户端会更新服务的信息，这样就不会调用已经下线的服务，但操作具有延迟，有可能会调到已经失效的服务，所以在客户端会开启失败重试功能来避免这个问题。Eureka Serve集群保证高可用，Eureka Server没有集成其它第三方存储，而是存储在内存中。所以Eureka Server之间会将注册信息复制到集群中的Eureka Serve的所有节点。这样数据才是共享状态，任何的Eureka Client都可以在任何一个Eureka Server节点查找到注册信息。 1.1 Eureka注册表Eureka的注册信息是存储在ConcurrentHashMap中的，Map的key是服务名称，value是一个Map。value的Map的key是服务实例的ID，value是Lease类，Lease中存储了实例的注册时间、上线时间等信息，还有具体的实例信息，如IP、端口、健康检查的地址等信息。 Eureka将注册的服务信息存储在内存中的原因：性能高；部署简单，不需要依赖于第三方存储。劣势：扩容难度高，每个Eureka Server都全量的存储一份注册表，假如存储空间不够了，需要扩容，那么所有的Eureka Server节点都必须扩容，必须采用的内存配置。 Eureka核心操作主要有注册、续约、下线、移除，接口为com.netflix.eureka.lease.LeaseManager，这些操作都是针对注册表的操作，也就是Map的操作。 1.2 自我保护机制自我保护机制是为了避免因网络分区故障而导致服务不可用的问题。自我保护机制带来的问题：若服务提供者B真的下线了，由于Eureka Serve自我保护机制打开，不会移除任务信息，当服务消费者对服务提供者B进行调用时，就会出错。出现某些有问题的实例没能及时移除掉的情况，服务消费者可以通过Ribbon来进行重试，保证调用能够成功。 自我保护开启的条件：AbstractInstanceRegistry中有两个字段，numberOfRenewsPerMinThreshold(期望最小每分钟能够续租的次数)、expectedNumberOfClientsSendingRenews(期望的服务实例数)。假如有10个实例，每个实例每分钟续约2次，那么10x2x0.85=17，即每分钟至少有17次续约才是正常的。 1.3 健康检查Eureka Client会定时发送心跳给Eureka Server来证明自己是否处于健康的状态。但某些场景下，服务处于存活状态，却已经不能对外提供服务，如数据库出问题了，但心跳正常，客户端在请求时还会请求到这个出问题的实例。可以在项目中集成Actuator，统一管理应用的健康状态，将这个状态反馈给Eureka Server。 2.Ribbon2.1 负载均衡负载均衡是一种基础的网络服务，它的核心原理是按照指定的负载均衡算法，将请求分配到后端服务集群上，从而为系统提供并行处理和高可用的能力。 集中式负载均衡：在消费者和提供者中间使用独立的代理方式进行负载，有硬件的负载均衡器，如F5，也有软件，如Nginx。客户端不需要关心对应服务实例的信息，只需要与负载均衡器进行交互，服务实例扩容或者缩容，客户端不需要修改任何代码。 客户端负载均衡：需要自己维护服务实例信息，然后通过某些负载均衡算法，从实例中选取一个实例，直接进行访问。区别：对服务实例信息的维护。集中式负载均衡的信息是集中进行维护的，如Nginx，都会在配置文件中进行指定。客户端负载均衡的信息是在客户端本地进行维护的，可以手动配置，最常见的是从注册中心拉取。 2.2 Ribbon使用方式： 原生API Ribbon+RestTemplate Ribbon+Feign通过给加了@LoadBalanced的RestTemplate添加拦截器，拦截器中通过Ribbon选取服务实例，然后将请求地址中的服务名称替换成Ribbon选取服务实例的IP和端口。 2.3 负载均衡策略 内置负载均衡策略 RoundRobinRule：轮询算法 RandomRule：随机算法 BestAvailableRule：选择一个最小的并发请求server，如果有A、B两个实例，当A有4个请求正在处理中，B有2个，下次请求会选择B，适用于服务所在机器配置相同的情况。 WeightedResponseTimeRule：根据请求的响应时间计算权重，如果响应时间越长，那么对应的权重越低，权重越低的服务器，被选择的可能性就越低。 自定义负载均衡算法 实现IRule接口或继承AbstractLoadBanlancerRule 实现choose方法 指定Ribbon的算法类使用场景： 定制与业务更匹配的策略。 灰度发布 多版本隔离 故障隔离 2.4 饥饿加载模式Ribbon在进行客户端负载均衡时并不是启动时就加载上下文，而是第一次请求时才去创建的，因此第一次调用会比较慢，有可能会引起调用超时。可以指定Ribbon客户端的名称，在启动时加载这些子应用程序上下文。 初始化后进行了缓存操作，getContext()方法中，如果在contexts中不存在才会创建，创建时会用synchronized加锁，并进行二次判断，防止并发下出现创建多次的问题，最后进行增加操作。如果有的话就直接从contexts获取返回。contexts就是一个ConcurrentHashMap。 3.Hystrix3.1 服务雪崩微服务架构下，会存在服务之间相互依赖调用的情况，当某个服务不可用时，很容易因为服务之间的依赖关系使故障扩大，甚至造成整个系统不可用，这种现象称为服务雪崩效应。 产生原因： 服务提供者代码的Bug问题，由于某些代码导致CPU飙升，将资源耗尽等；服务器出现问题，磁盘出问题，导致数据读写特别慢，拉高了响应时间；慢SQL语句问题；请求量太大，超出系统本身的承受能力。 服务消费者同步调用等待结果导致资源耗尽；自己既是服务消费者也是服务提供者。 解决方案： 服务提供者代码Bug问题：测试、Code Review等方式；慢SQL问题：数据库性能优化；服务器硬件故障问题：加大运维粒度，通过监控等手段提前预防；请求量超出承受能力：扩容或限流 服务消费者资源隔离、快速失败。 3.2 容错实现设计原则： 封装请求：将用户的操作进行统一封装，目的在于进行统一控制。 资源隔离：将对应的资源按照指定的类型进行隔离，如线程池和信号量。 失败回退：备用方案，当请求失败后，Hystrix会让用户自定义备用方案。 断路器：决定了请求是否需要真正的执行，如果断路器打开，那么所有的请求都将失败，执行回退逻辑。如果断路器关闭，那么请求将正常执行。 指标监控：对请求的生命周期进行监控。 工作原理： 构建一个HystrixCommand或者HystrixObservableCommand对象，将请求包装到Command对象中。 执行构建好的命令。 判断当前请求是否有缓存，如果有就直接返回缓存的内容。 判断断路器是否打开，如果打开，跳到第8步，获取fallback方法，执行fallback逻辑。如果没有打开，执行第5步。 如果是线程池隔离模式，判断线程池队列的容量；如果是信号量隔离模式，会判断信号量的值是否已经被使用完。如果线程池和信号量都已经满了，同样请求不被执行，直接跳到第8步。 执行HystrixObservableCommand.construct()或HystrixCommand.run()方法，正在执行的请求逻辑就封装在construct()或run()方法中。 请求过程中，若出现异常或者超时，会直接到第8步，执行成功就返回结果。执行结果会将数据上报给断路器，断路器会根据上报的数据来判断断路器是否打开 fallback 3.3 Hystrix使用 HystrixCommand注解方式 在Feign中使用 在Zuul中使用 Hystrix配置： 3.4 Hystrix隔离机制 线程池隔离：当用户请求A服务后，A服务需要调用其它服务，这个时候可以为不同的服务创建独立的线程池，假如A需要调用B和C，那么可以创建两个独立的线程池，将调用B服务的线程池丢入到一个线程池，将调用C服务的线程丢入另一个线程池，这样起隔离效果，就算其中某个线程池请求满了，无法处理请求了，对另一个线程池页没有影响。使用线程隔离。需要调整好线程池参数，否则和信号量一样，并发量大的时候性能上不去。设置最大线程数，默认为10，队列大小决定了能够堆积多少请求，但请求不能一直堆积，所有还需要设置一个阈值来进行拒绝。 信号量隔离：信号量就算一个计数器，如初始化是100，那么每次请求过来时信号量就会减1，当信号量计数为0时，请求就会被拒绝，等之前的请求处理完成后，信号量就会加1。起到了限流的作用，信号量隔离是在请求主线程中执行的。 线程池隔离的特点是Command运行在独立的线程池中，可以支持超时，是单独的线程，支持异步。信号量隔离运行在调用的主线程中，不支持超时，只能同步调用。 3.5 使用技巧 配置可以对接配置中心进行动态调整 回退逻辑中可以手动埋点或者通过输出日志进行告警 使用线程池隔离模式再用ThreadLocal会有坑被隔离的方法会包装成一个Command丢入到独立的线程中执行，这个时候就是从A线程切换到了B线程，ThreadLocal的数据就会丢失。 网关中尽量用信号隔离 插件机制可以实现很多扩展 Hystrix各种超时配置方式 commandKey、groupKey、threadPoolKey的使用在使用HystrixCommand注解时，会配置commandKey、groupKey、threadPoolKey。commandKey表示封装的command的名称，可以给指定的commandKey进行参数的设置。groupKey是将一组command进行分组，如果没有设置threadPoolKey的话，那么线程池的名称会用groupKey。threadPollKey是线程池的名称，多个command的threadPoolKey相同，那么会使用同一个线程池。 4.FeignFeign是一个声明式的REST客户端，Feign提供了HTTP请求的模板，通过编写简单的接口和插入注解，就可以定义好Http请求的参数、格式、地址等信息。Feign会完全代理HTTP请求，Spring Cloud对Feign进行了封装，使其支持SpringMVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡，与Hystrix组合使用，支持熔断回退。 4.1 重要组件 Contract 契约组件Contract允许用户自定义契约去解析注解信息，如在Spring Cloud中使用Feign，可以使用SpringMVC的注解来定义Feign的客户端。 Encoder 编码组件通过该组件可以将请求信息采用指定的编码方式来进行编码后传输。 Decoder 编码组件 Decoder将相应数据解码成对象。 ErrorDecoder 异常解码器当被调用方发生异常后，可以在ErrorDecoder中将响应的数据转换成具体的异常返回给调用方，适合内部服务之间调用，但不想通过指定的字段来判断是否成功的场景，直接用自定义异常代替。 Logger 日志记录Logger组件负责Feign中记录日志的，可以指定Logger的级别及自定义日志的输出。 Client 请求执行组件Client是负责HTTP请求执行的组件，Feign将请求信息封装好后会交由Client来执行，Feign中默认的Client是通过JDK的HttpURLConnection发起请求的，每次发起请求的适合，都会建立新的HttpURLConnection链接，性能很差。可以扩展该接口，使用Apache HttpClient等基于连接池的高性能HTTP客户端。 Retryer 重试组件Retryer是负责重试的组件，Feign内置了重试器，当HTTP请求出现IO异常时，Feign会限定最大重试次数来进行重试操作。 InvocationHandlerFactory 代理IncocationHandlerFactory采用JDK的动态代理方式生成代理对象，定义的Feign接口，当调用这个接口中定义的方法时，实际上是去调用远程的HTTP API，这里用了动态代理的方式，当调用某个方法时，会进入代理中正在的去调用远程HTTP API。 RequestInterceptor 请求拦截器可以为Feign添加多个拦截器，在请求执行前设置一些扩展的参数信息。 QueryMapEncoder 参数查询QueryMapEncoder是针对实体类参数查询的编码器，可以基于QueryMapEncoder将实体类生成对应的查询参数。 4.2 Feign执行过程定义对应的接口类，在接口类上使用Feign自带的注解来标识HTTP的参数信息，当调用接口对应的方法时，Feign内部会基于面向接口的动态代理方式生成实现类，将请求调用委托到动态代理实现类，负责动态代理的组件是InvocationHandlerFactory。根据Contract规则，解析接口类的注解信息，翻译成Feign内部能识别的信息。Spring Cloud OpenFeign中就扩展了SpringMVCContract。MethodHandler在执行的时候会生成Request对象，在构建Request对象的时候会为其设置拦截器，交由Client执行前记录一些日志，Client执行完成后也记录一些日志，然后使Decoder进行相应结果的解码操作，并返回结果。 4.3 使用技巧 继承特性将API的定义提取出来封装成一个单独的接口，给API的实现方和调用方共用。 拦截器添加自己的拦截器来实现某些场景下的需求，实现RequestInterceptor接口，在apply方法中编写自己的逻辑。 GET请求多参数传递一般超过3个以上的参数会封装在一个实体类中，在Spring Cloud Open Feign中要支持对象接收多个参数，需要增加@SpringQueryMap注解。 日志配置Feign日志级别： NONE：不输出日志 BASIC：只输出请求方法的URL和响应的状态码及执行的时间 HEADERS：将BASIC和请求头信息输出 FULL：会输出全部完整的请求信息 异常解码器 5.ZuulAPI网关是对外提供服务的一个入口，并且隐藏了内部架构的实现。可以为我们管理大量的API接口，负责对接用户、协议适配、安全认证、路由转发、流量限制、日志监控、防止爬虫、灰度发布等功能。 动态路由将客户端的请求路由到后端不同的服务上，如果没有网关去做统一的路由，那么客户端就要关注后端N个服务。 请求监控对整个系统的请求进行监控，详细的记录请求响应日志，可以实时的统计当前系统的访问量及监控状态。 认证鉴权统一对访问请求做认证，拒绝非法请求，保护后端的服务。 压力测试动态的将测试请求转发到后端服务的集群中，还可以识别测试流量和真实流量，用来做一些特殊的处理。 灰度发布当需要发布新版本时，通过测试请求对1.1版本的服务进行测试，若没发现问题，可以将正常的请求转发过来，若有问题，不影响用户使用的1.0版本。 5.1 过滤器过滤器可以对请求或响应结果进行处理，Zuul支持动态加载、编译、运行这些过滤器。 pre过滤器：可以在请求被路由器之前调用。适用于身份认证的场景，认证通过后再继续执行下个流程。 route过滤器：在路由请求时被调用。适用于灰度发布的场景，在将要路由的时候可以做一些自定义的逻辑。 post过滤器：在route和error过滤器之后被调用。将请求路由到达具体的服务之后执行，适用于添加响应头，记录响应日志等应用场景。 error过滤器：处理请求发生错误时被调用。在执行过程中发送错误时会进入error过滤器，可以用来统一记录错误信息。 自定义过滤器：继承ZuulFilter，然后重写ZuulFilter的四个方法shouldFilter方法决定了是否执行该过滤器，true为执行，false不执行，可以利用配置中心实现动态的开启或关闭过滤器。filterType方法是要返回过滤器的类型，可选择为pre、route、post、error四种类型。过滤器可以有多个，先后顺序可以通过filterOrder来指定过滤器的执行顺序，数字越小，优先级越高。业务逻辑写在run方法中。 5.2 请求生命周期请求先进入pre过滤器，在pre过滤器执行完后，进入routing过滤器，开始路由到具体的服务中，路由完成后，接着到了post过滤器，然后将请求结果返回给客户端。如果过程中出现异常，则会进入error过滤器。源码对应ZuulServlet。 5.3 Zuul容错与回退5.4 使用技巧 内置端点当@EnableZuulProxy与Spring Boot Actuator配合使用时，Zuul会暴露一个路由管理端点/routes。借助这个端点，可以直观的查看及管理Zuul的路由。还有一个/filters端点可以查看Zuul中所有过滤器的信息。 文件上传通过Zuul上传文件，超过1M的文件会上传失败，配置max-file-size和max-request-size，Zuul中需要配置，最终接受文件的服务也要配置。或在网关请求地址前面上加上/zuul，可以绕过Spring DispatcherServlet上传大文件。Zuul服务不用再配置，但接收文件的服务还是要配置文件上传大小。在上传大文件时，时间较长，可以设置Ribbon的ConnectTimeOut和ReadTimeOut。如果Zuul的Hystrix隔离模式为线程的话需要设置Hystrix的超时时间。 请求响应输出 Zuul Debug 跨域配置 关闭Zuul全局路由转发配置zuul.ignored-service=*关闭路由转发，配置zuui.ignoredPatterns忽略不想暴露的API。 动态过滤器定期扫描存放Groovy Filter文件的目录，如果发现有新Groovy Filter文件或者Groovy Filter源码有改动，那么就会对Groovy文件进行编译加载。首先在项目中增加Groovy的依赖，然后在项目启动后设置Groovy的动态加载任务，定时动态加载指定目录的Groovy文件。","categories":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"}]},{"title":"Redis五种数据类型的底层结构","slug":"Redis五种数据类型的底层结构","date":"2021-05-08T13:19:59.153Z","updated":"2021-04-24T15:10:14.121Z","comments":true,"path":"redisfive/","link":"","permalink":"http://tonymua.top/redisfive/","excerpt":"RedisObject: Redis 中只有一个 K，一个 V。其中 K 绝对是字符串对象，而 V 可以是 String、List、Hash、Set、ZSet 任意一种。","text":"RedisObject: Redis 中只有一个 K，一个 V。其中 K 绝对是字符串对象，而 V 可以是 String、List、Hash、Set、ZSet 任意一种。 123456789101112typedef struct redisObject &#123; // 类型 string list set hash zset等 4bit unsigned type:4; // 编码方式 4bit unsigned encoding:4; // LRU 时间 24bit unsigned lru:LRU_BITS; // 引用计数 4byte int refcount; // 指向对象的指针 8byte 指针指向具体的数据，如set test hello，ptr指向的就是存储hello的字符串。 void *ptr;&#125; robj; encoding： 1234567891011/** 对象编码*/#define REDIS_ENCODING_RAW 0 // 编码为字符串#define REDIS_ENCODING_INT 1 // 编码为整数#define REDIS_ENCODING_HT 2 // 编码为哈希表#define REDIS_ENCODING_ZIPMAP 3 // 编码为 zipmap(2.6 后不再使用)#define REDIS_ENCODING_LINKEDLIST 4 // 编码为双端链表#define REDIS_ENCODING_ZIPLIST 5 // 编码为压缩列表#define REDIS_ENCODING_INTSET 6 // 编码为整数集合#define REDIS_ENCODING_SKIPLIST 7 // 编码为跳跃表 lru 记录对象最后一次被命令程序访问的时间，通过lru时间和当前时间可以计算某个对象的空转时间；利用object idletiem命令可以显示空转时间(单位为秒)，且不会改变该对象的lru。 refcount 该对象被引用的次数，目前共享对象只支持整数值的字符串对象。 1.String三种编码方式： int：存储的字符串全是数字 embstr：存储的字符串长度小于44个字符 raw：存储的字符串长度大于44个字符 embstr类型，它的数据指针和SDS对象在内存地址是连在一起的；但对于raw类型，二者在内存地址不是连续的。 SDS封装char[]，一个SDS最大512M 12345struct sdshdr&#123; unsigned int len; // 标记char[]的长度 unsigned int free; //标记char[]中未使用的元素个数 char buf[]; // 存放元素的坑&#125; Redis底层对SDS做的优化 预空间分配 SDS长度(len的值)小于1MB，那么程序将分配和len属性同样大小的未使用空间，此时 free和len属性值相同。假如SDS的len将变成15字节，则程序也会分配15字节的未使用空间，SDS的buf数组的实际长度变为15+15+1=31字节(额外一个字节用户保存空字符串) SDS长度(len的值)大于等于1MB，程序会分配1MB的未使用空间。如进行修改之后，SDS的len变成30MB，那么它的实际长度为30MB+1MB+1byte 惰性释放空间 当执行sdstrim(截取字符串)之后，SDS不会立即释放多出来的空间，如果下次在进行字符串拼接操作，且拼接的没有刚才释放的大，就会使用刚才的空间，不需要再重新申请空间。 二进制安全 C语言通过是否存在空字符\\0来判断是否已经是字符串的结尾。某些情况下(如使用空格进行分割一段字符串、或图片、视频等二进制文件)时，就会出现问题。SDS通过len字段判断，因此具备二进制安全性。 2.ListquickList(快速列表，是zipList压缩列表和linkedList双端链表的组合)，最大长度2^32-1，自测两端插入和弹出，并可以获得指定位置(或范围)的元素，可以充当数组、队列和栈。 lpush+lpop 先进后出的栈 lpush+rpop 先进先出的队列 lpush+ltrim 有限集合 lpush+Brpop 消息队列 linkedList 1234567891011121314151617181920212223//定义链表节点的结构体 typedef struct listNode &#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value; &#125;typedef struct list&#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表包含节点的数量 unsigned long len; //节点复制函数，用于链表转移复制时对节点value拷贝的实现，一般情况下使用等号，某些特殊情况下给这个函数赋值NULL即表示使用等号进行节点转移 vode *(*dup) (void *ptr); //节点释放函数，用于释放一个节点所占用的内存空间，默认赋值NULL，即使用Redis自带的zfree函数进行内存空间释放 vode *(*free) (void *ptr); //节点对比函数，用于对比两个链表节点的value是否相等，相等返回1，不相等返回0 vode *(*match) (void *ptr,void *key);&#125; 获取前置节点、后置节点、表头节点和表尾节点的复杂度都是O(1)，获取节点数量也是O(1)。与双端链表相比，压缩列表可以节省空间，但进行修改或增删操作时，复杂度较高；因此节点数量较少时，可以使用压缩列表，但节点数量较多时，还是使用双端链表。 zipList 123456789101112131415161718192021typedf struct ziplist&lt;T&gt;&#123; //压缩列表占用字符数 int32 zlbytes; //最后一个元素距离起始位置的偏移量，用于快速定位最后一个节点 int32 zltail_offset; //元素个数 int16 zllength; //元素内容 T[] entries; //结束位 0xFF int8 zlend;&#125;ziplist typede struct entry&#123; //前一个entry的长度，倒序遍历可以通过这个参数定位到上一个entry的位置 int&lt;var&gt; prelen; //元素类型编码 int&lt;var&gt; encoding; //元素内容 optional byte[] content;&#125;entry zltail_offset这个参数可以快速定位到最后一个entry节点的位置，然后开始倒序遍历，即ziplist支持双向遍历。zipList遍历的时候，先根据zlbytes和zltail_offset定位到最后一个entry的位置，然后根据根据entry的prelen时确定前一个entry的位置。 zipList相比linkedList少了pre和next两个指针16个字节(64位系统1个指针就是8个字节)，linkedList每个节点内存都是单独分配，家具内存碎片化，zipList是由连续的内存组成的。 连锁更新 entry的prelen字段：前一个节点的长度小于254个字节时，prelen长度为1字节；前一个节点的长度大于254个字节时，prelen长度为5字节 假设现在有一组压缩列表，长度都在250~253字节之间，突然新增一个entry节点，这个entry节点长度大于等于254字节。由于新的entry节点大于等于254字节，这个entry节点的prelen为5个字节，随后会导致其余的所有entry节点的prelen增大为5字节；同样地，删除操作也会导致出现连锁更新这种情况。 zipList与linkedList的区别 当列表中元素的长度较小或数量较少时，通常采用zipList，当列表中元素长度较大或者数量较多时，使用linkedList 双向链表linkedList便于在列表的两端进行push和pop，插入节点复杂度很低，但内存开销比较大。(额外保存prev和next指针；内存碎片) zipList存储在一块连续的内存上，所以存储效率高，但插入和删除操作需要频繁的申请和释放内存。 3.2版本之后List使用quickList代替了zipList和linkedList，是zipList和linkedList的混合体。它将linkedList按段切分，每一段使用zipList来紧凑存储，多个zipList之间使用双向指针串接起来。 quickList内部默认单个zipList长度为8k字节，即redis.conf中list-max-ziplist-size的值为-2，超过这个阈值就会重新生成一个zipList来存储数据。当list-max-ziplist-size为正数n时，表示每个quicklist节点上的ziplist最多包含n个数据项。 压缩深度 quickList可以使用LZF算法对zipList进一步压缩，压缩后的zipList结构为 123456typedf struct ziplist_compressed&#123; //元素个数 int32 size; //元素内容 byte[] compressed_data&#125; 此时quicList为： redis.conf中list-compress-depth表示一个quickList两端不被压缩的节点的个数(指quickList双向链表节点个数，而不是zipList里数据项个数)，quickList默认压缩深度为0，即不开启压缩；当list-compress-depth为1，表示quickList的两端各有1个节点不进行压缩，中间节点进行压缩；当list-compress-dept为2，表示quickList的首尾各有2个节点不进行压缩，中间节点进行压缩；由此类推，对于quickList来说，首尾两个节点永远不会被压缩。 3.Hash dict 底层可以是zipList或hashtable(字典也叫哈希表)，hash中元素数量小于512个且所有键值对的键和值字符串长度都小于64字节时，才会使用zipList。 1234567typedf struct dict&#123; dictType *type;//类型特定函数，包括一些自定义函数，这些函数使得key和value能够存储 void *private;//私有数据 dictht ht[2];//两张hash表 int rehashidx;//rehash索引，字典没有进行rehash时，此值为-1 unsigned long iterators; //正在迭代的迭代器数量&#125;dict; type和private这两个属性是为了实现字典多态而设置的，当字典中存放着不同类型的值，对于的一些复制、比较函数也不一样。 rehashidx，这是一个辅助变量，用于记录rehash过程的进度，以及是否正在进行rehash等信息，等于-1时，表示dict此时没有rehash过程。 iterators，记录此时dict有几个迭代器正在进行遍历过程。 dictht dict本质上是对dicht的一个简单封装 123456typedf struct dictht&#123; dictEntry **table;//存储数据的dicEntry类型的数组 二维 unsigned long size;//数组的大小 unsigned long sizemask;//哈希表的大小的掩码，用于计算索引值，总是等于size-1 unsigned long used;//// 哈希表中中元素个数&#125;dictht; dicthtEntry 12345678910typedf struct dictEntry&#123; void *key;//键 union&#123; void val; unit64_t u64; int64_t s64; double d; &#125;v;//值 struct dictEntry *next；//指向下一个节点的指针&#125;dictEntry; 扩容与缩容 渐进式hash 假设当前数据在dictht[0]中，那么首先未dictht[1]分配足够的空间，如果是扩容，则dictht[1]的大小按照扩容规则进行扩容，如果是缩减，则dictht[1]的大小按照缩减规则进行缩减。 在字典dict中维护一个变量，rehashidx=0，表示rehash正式开始。 rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，还会顺带将dictht[0]哈希表在rehashidx索引上的所有键值对rehash到dichth[1]，当一次rehash工作完成之后，程序将rehashidx属性的值+1。同时在serverCron中调用rehash相关函数，在1ms的时间内，进行rehash处理，每次仅处理少量的转移任务(100个元素)。 当dichth[0]的所有键值对都会被rehash至dichth[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。 每次对字典执行增删改查才会触发rehash，万一某段时间没有任何命令请求命令呢？ Redis有一个定时器，会定时判断rehash是否完成，如果没有完成，则继续hash。 如果是添加操作，会将新的数据直接添加到dichth[1]上，而对于删除、更改、查询操作，会直接在dictht[0]上进行，当dictht[0]上查询不到时，会接着去dictht[1]上查找，如果再找不到，则表明不存在该K-V值。 优点：采用分而治之的思想，将rehash操作分散到每一次到hash表的操作上及定时函数上，避免了集中式hash带来的性能压力。 缺点：在rehash过程中，需要保存两个hash表，对内存的占用比较大，如果在Redis服务器本来内存满了的时候，突然进行rehash会造成大量的key被抛弃。 4.Set无序且存储元素不重复。当value是整数时，且数据量不大时使用inset存储，其他情况用字典dict来存储。 inset 12345678typedf struct inset&#123; uint32_t encoding;//编码方式 有三种 默认 INSET_ENC_INT16 会根据插入数据的大小选择不一样的类型来存储 uint32_t length;//集合元素个数 int8_t contents[];//实际存储元素的数组，元素类型并不一定是ini8_t类型，柔性数组不占intset结构体大小，并且数组中的元素从小到大排列&#125;inset;#define INTSET_ENC_INT16 (sizeof(int16_t)) //16位，2个字节，表示范围-32,768~32,767#define INTSET_ENC_INT32 (sizeof(int32_t)) //32位，4个字节，表示范围-2,147,483,648~2,147,483,647#define INTSET_ENC_INT64 (sizeof(int64_t)) //64位，8个字节，表示范围-9,223,372,036,854,775,808~9,223,372,036,854,775,807 inset升级过程 了解旧的存储格式，计算出目前已有元素占用大小，计算规则是length*encoding，如4 * 16=64 确定新的编码格式，当原有的编码格式不能存储下新增的数据时，此时就要选择新的合适的编码格式 根据新的编码格式计算出需要新增的内存大小，然后从尾部将数据插入 根据新的编码格式重置之前的值，此时contents存在两种编码格式的值，需要统一，从插入新数据的位置开始，从后向前将之前的数据按照新的编码格式进行移动和设置。从后往前是为了防止数据被覆盖。 优点：根据存入的数据选择合适的编码方式，且只在必要的时候进行升级操作，节省内存。 缺点：耗费系统资源，不支持降级。 5.SortedSet常用作排行榜等功能，以用户id为value，关注事件或者分数作为score进行排序。zipList和skipList两种不同的实现： zipList [score,value]键值对数量少于128个 每个元素的长度小于64字节 skipList 不满足以上两个条件时使用跳表、组合了hash和skipList，hash用来存储value到score的映射，这样就可以在O(1)时间内找到value对应的分数；skipList按照从小到大的顺序存储分数；skipList每个元素的值都是[score,value]对。 skipList 空间换时间 跳表一个节点最高可以达到64层，一个跳表中最多可以存储2^64个元素。跳表中，每个节点都是一个skipListNode，每个跳表的节点也都会维护一个score值，这个值在跳表中是按照从小到大的顺序排列好的。 12345678910typedf struct zskiplist&#123; //头节点 struct zskiplistNode *header; //尾节点 struct zskiplistNode *tail; //跳表中元素个数 unsigned long length; //目前表内节点的最大层数 int level;&#125;zskiplist; 123456789typedf struct zskiplistNode&#123; sds ele;// 具体的数据 每个节点所保存的数据是唯一的，但节点的分数可以是一样的。两个相同分数的节点是按照元素的字典序进行排列的； double score;// 分数 从小到大排序 struct zskiplistNode *backward;//后退指针，用于从表尾向表头遍历，每个节点只有一个，即每次只能后退一步 struct zskiplistLevel&#123; struct zskiplistNode *forward;//前进指针forward，指向下一个节点 unsigned int span;//跨度span用来计算当前节点在跳表中的一个排名 &#125;level[];//层级数组 最大32&#125;zskiplistNode;","categories":[{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/tags/Redis/"}]},{"title":"Redis","slug":"Redis","date":"2021-05-08T13:19:59.151Z","updated":"2020-04-29T02:44:38.032Z","comments":true,"path":"27273/","link":"","permalink":"http://tonymua.top/27273/","excerpt":"1.Redis概述redis是一款高性能的NOSQL系列的非关系型数据库 1.1 什么是NoSQL​ NoSQL(NoSQL = Not Only SQL)，意即“不仅仅是SQL”，是一项全新的数据库理念，泛指非关系型的数据库。​ 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集和多重数据种类带来的挑战，尤其是大数据应用难题。 1.1.1 NOSQL和关系型数据库比较","text":"1.Redis概述redis是一款高性能的NOSQL系列的非关系型数据库 1.1 什么是NoSQL​ NoSQL(NoSQL = Not Only SQL)，意即“不仅仅是SQL”，是一项全新的数据库理念，泛指非关系型的数据库。​ 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集和多重数据种类带来的挑战，尤其是大数据应用难题。 1.1.1 NOSQL和关系型数据库比较 优点： (1) 成本：nosql数据库简单易部署，基本都是开源软件，不需要像使用oracle那样花费大量成本购买使用，相比关系型数据库价格便宜。 (2) 查询速度：nosql数据库将数据存储于缓存之中，关系型数据库将数据存储在硬盘中，自然查询速度远不及nosql数据库。 (3) 存储数据的格式：nosql的存储格式是key,value形式、文档形式、图片形式等等，所以可以存储基础类型以及对象或者是集合等各种格式，而数据库则只支持基础类型。 (4) 扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。 缺点： (1) 维护的工具和资料有限，因为nosql是属于新的技术，不能和关系型数据库10几年的技术同日而语。 (2) 不提供对sql的支持，如果不支持sql这样的工业标准，将产生一定用户的学习和使用成本。 (3) 不提供关系型数据库对事务的处理。 1.1.2 非关系型数据库的优势​ (1) 性能NoSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。​ (2) 可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。 1.1.3 关系型数据库的优势​ (1) 复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。​ (2) 事务支持使得对于安全性能很高的数据访问要求得以实现。对于这两类数据库，对方的优势就是自己的弱势，反之亦然。 1.1.4 总结​ 关系型数据库与NoSQL数据库并非对立而是互补的关系，即通常情况下使用关系型数据库，在适合使用NoSQL的时候使用NoSQL数据库，让NoSQL数据库对关系型数据库的不足进行弥补。​ 一般会将数据存储在关系型数据库中，在nosql数据库中备份存储关系型数据库的数据 1.2 主流的产品常见的关系型数据库: Oracle、DB2、MySQL、[SQL Server](https://baike.baidu.com/item/Microsoft SQL Server/2947866) 常见的非关系型数据库: Redis、MongodDB、HBase、Neo4J (1) 键值(Key-Value)存储数据库 相关产品： Tokyo Cabinet/Tyrant、Redis、Voldemort、Berkeley DB 典型应用： 内容缓存，主要用于处理大量数据的高访问负载。 数据模型： 一系列键值对 优势： 快速查询 劣势： 存储的数据缺少结构化 (2) 列存储数据库 相关产品：Cassandra, HBase, Riak 典型应用：分布式的文件系统 数据模型：以列簇式存储，将同一列数据存在一起 优势：查找速度快，可扩展性强，更容易进行分布式扩展 劣势：功能相对局限 (3) 文档型数据库 相关产品：CouchDB、MongoDB 典型应用：Web应用（与Key-Value类似，Value是结构化的） 数据模型： 一系列键值对 优势：数据结构要求不严格 劣势： 查询性能不高，而且缺乏统一的查询语法 (4) 图形(Graph)数据库 相关数据库：Neo4J、InfoGrid、Infinite Graph 典型应用：社交网络 数据模型：图结构 优势：利用图结构相关算法。 劣势：需要对整个图做计算才能得出结果，不容易做分布式的集群方案。 1.3 什么是Redis​ Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库，官方提供测试数据，50个并发执行100000个请求,读的速度是110000次/s,写的速度是81000次/s ，且Redis通过提供多种键值数据类型来适应不同场景下的存储需求，目前为止Redis支持的键值数据类型如下：​ (1) 字符串类型 string​ (2) 哈希类型 hash​ (3) 列表类型 list​ (4) 集合类型 set​ (5) 有序集合类型 sortedset redis的应用场景 缓存（数据查询、短连接、新闻内容、商品内容等等） 聊天室的在线好友列表 任务队列（秒杀、抢购、12306等等） 应用排行榜 网站访问统计 数据过期处理（可以精确到毫秒 分布式集群架构中的session分离 2.常用命令操作2.1 redis的数据结构redis存储的是：key, value格式的数据，其中key都是字符串，value有5种不同的数据结构 value的数据结构： (1) 字符串类型 string (2) 哈希类型 hash ： map格式 (3) 列表类型 list ： linkedlist格式。支持重复元素 (4) 集合类型 set ： 不允许重复元素 (5) 有序集合类型 sortedset：不允许重复元素，且元素有顺序 字符串类型 string 123456789存储： set key value 127.0.0.1:6379&gt; set username zhangsan OK获取： get key 127.0.0.1:6379&gt; get username \"zhangsan\"删除： del key 127.0.0.1:6379&gt; del age (integer) 1 哈希类型 hash 1234567891011121314151617181920存储： hset key field value 127.0.0.1:6379&gt; hset myhash username lisi (integer) 1 127.0.0.1:6379&gt; hset myhash password 123 (integer) 1获取： hget key field: 获取指定的field对应的值 127.0.0.1:6379&gt; hget myhash username \"lisi\" hgetall key：获取所有的field和value 127.0.0.1:6379&gt; hgetall myhash 1) \"username\" 2) \"lisi\" 3) \"password\" 4) \"123\"删除： hdel key field 127.0.0.1:6379&gt; hdel myhash username (integer) 1 列表类型 list: 可以添加一个元素到列表的头部（左边）或者尾部（右边） 12345678910111213141516171819202122添加： lpush key value: 将元素加入列表左表 rpush key value：将元素加入列表右边 127.0.0.1:6379&gt; lpush myList a (integer) 1 127.0.0.1:6379&gt; lpush myList b (integer) 2 127.0.0.1:6379&gt; rpush myList c (integer) 3获取： lrange key start end ：范围获取 127.0.0.1:6379&gt; lrange myList 0 -1 (1) \"b\" (2) \"a\" (3) \"c\"删除： lpop key： 删除列表最左边的元素，并将元素返回 rpop key： 删除列表最右边的元素，并将元素返回 集合类型 set : 不允许重复元素 12345678910111213存储：sadd key value 127.0.0.1:6379&gt; sadd myset a (integer) 1 127.0.0.1:6379&gt; sadd myset a (integer) 0获取：smembers key:获取set集合中所有元素 127.0.0.1:6379&gt; smembers myset (1) \"a\"删除：srem key value:删除set集合中的某个元素 127.0.0.1:6379&gt; srem myset a (integer) 1 有序集合类型 sortedset：不允许重复元素，且元素有顺序.每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 123456789101112131415161718192021222324存储：zadd key score value 127.0.0.1:6379&gt; zadd mysort 60 zhangsan (integer) 1 127.0.0.1:6379&gt; zadd mysort 50 lisi (integer) 1 127.0.0.1:6379&gt; zadd mysort 80 wangwu (integer) 1获取：zrange key start end [withscores] 127.0.0.1:6379&gt; zrange mysort 0 -1 (1) \"lisi\" (2) \"zhangsan\" (3) \"wangwu\" 127.0.0.1:6379&gt; zrange mysort 0 -1 withscores (1) \"zhangsan\" (2) \"60\" (3) \"wangwu\" (4) \"80\" (5) \"lisi\" (6) \"500\"删除：zrem key value 127.0.0.1:6379&gt; zrem mysort lisi (integer) 1 2.2 通用命令1231. keys * : 查询所有的键2. type key ： 获取键对应的value的类型3. del key：删除指定的key value 3.Java客户端 Jedis3.1 Jedis操作各种redis中的数据结构123456//1. 获取连接 Jedis jedis = new Jedis(\"localhost\",6379); //2. 操作 jedis.set(\"username\",\"zhangsan\"); //3. 关闭连接 jedis.close(); 字符串类型 string 123456789101112//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 //存储 jedis.set(\"username\",\"zhangsan\"); //获取 String username = jedis.get(\"username\"); System.out.println(username); //可以使用setex()方法存储可以指定过期时间的 key value jedis.setex(\"activecode\",20,\"hehe\");//将activecode：hehe键值对存入redis，并且20秒后自动删除该键值对 //3. 关闭连接 jedis.close(); 哈希类型 hash: map格式 12345678910111213141516171819202122//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // 存储hash jedis.hset(\"user\",\"name\",\"lisi\"); jedis.hset(\"user\",\"age\",\"23\"); jedis.hset(\"user\",\"gender\",\"female\"); // 获取hash String name = jedis.hget(\"user\", \"name\"); System.out.println(name); // 获取hash的所有map中的数据 Map&lt;String, String&gt; user = jedis.hgetAll(\"user\"); // keyset Set&lt;String&gt; keySet = user.keySet(); for (String key : keySet) &#123; //获取value String value = user.get(key); System.out.println(key + \":\" + value); &#125; //3. 关闭连接 jedis.close(); 列表类型 list: linkedlist格式 支持重复元素 ​ lpush / rpush​ lpop / rpop​ lrange start end : 范围获取 123456789101112131415161718192021222324//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // list 存储 jedis.lpush(\"mylist\",\"a\",\"b\",\"c\");//从左边存 jedis.rpush(\"mylist\",\"a\",\"b\",\"c\");//从右边存 // list 范围获取 List&lt;String&gt; mylist = jedis.lrange(\"mylist\", 0, -1); System.out.println(mylist); // list 弹出 String element1 = jedis.lpop(\"mylist\");//c System.out.println(element1); String element2 = jedis.rpop(\"mylist\");//c System.out.println(element2); // list 范围获取 List&lt;String&gt; mylist2 = jedis.lrange(\"mylist\", 0, -1); System.out.println(mylist2); //3. 关闭连接 jedis.close(); 集合类型 set: 不允许重复元素 12345678910//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // set 存储 jedis.sadd(\"myset\",\"java\",\"php\",\"c++\"); // set 获取 Set&lt;String&gt; myset = jedis.smembers(\"myset\"); System.out.println(myset); //3. 关闭连接 jedis.close(); 有序集合类型 sortedset: 不允许重复元素，且元素有顺序 123456789101112//1. 获取连接 Jedis jedis = new Jedis();//如果使用空参构造，默认值 \"localhost\",6379端口 //2. 操作 // sortedset 存储 jedis.zadd(\"mysortedset\",3,\"亚瑟\"); jedis.zadd(\"mysortedset\",30,\"后裔\"); jedis.zadd(\"mysortedset\",55,\"孙悟空\"); // sortedset 获取 Set&lt;String&gt; mysortedset = jedis.zrange(\"mysortedset\", 0, -1); System.out.println(mysortedset); //3. 关闭连接 jedis.close(); 3.2 jedis连接池: JedisPool* 使用： 1. 创建JedisPool连接池对象 2. 调用方法 getResource()方法获取Jedis连接1234567891011121314//0.创建一个配置对象 JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(50); config.setMaxIdle(10); //1.创建Jedis连接池对象 JedisPool jedisPool = new JedisPool(config,\"localhost\",6379); //2.获取连接 Jedis jedis = jedisPool.getResource(); //3. 使用 jedis.set(\"hehe\",\"heihei\"); //4. 关闭 归还到连接池中 jedis.close(); 连接池工具类 12345678910111213141516171819202122232425262728public class JedisPoolUtils &#123; private static JedisPool jedisPool; static&#123; //读取配置文件 InputStream is = JedisPoolUtils.class.getClassLoader().getResourceAsStream(\"jedis.properties\"); //创建Properties对象 Properties pro = new Properties(); //关联文件 try &#123; pro.load(is); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; //获取数据，设置到JedisPoolConfig中 JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(Integer.parseInt(pro.getProperty(\"maxTotal\"))); config.setMaxIdle(Integer.parseInt(pro.getProperty(\"maxIdle\"))); //初始化JedisPool jedisPool = new JedisPool(config,pro.getProperty(\"host\"),Integer.parseInt(pro.getProperty(\"port\"))); &#125; /** * 获取连接方法 */ public static Jedis getJedis()&#123; return jedisPool.getResource(); &#125;&#125;","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Redis, Nginx常见面试题","slug":"Redis, Nginx常见面试题","date":"2021-05-08T13:19:59.150Z","updated":"2020-04-29T06:05:05.796Z","comments":true,"path":"35847/","link":"","permalink":"http://tonymua.top/35847/","excerpt":"1.Redis常见面试题1.1 为什么使用redis 性能: 我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 并发: 在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。 1.2 使用redis有什么缺点 缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存的并发竞争问题","text":"1.Redis常见面试题1.1 为什么使用redis 性能: 我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 并发: 在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。 1.2 使用redis有什么缺点 缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存的并发竞争问题 1.3 单线程的redis为什么这么快 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用机制 ​ redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 1.4 redis的数据类型，以及每种数据类型的使用场景 String hash ​ 这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。单点登录的时候，用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。 list ​ 使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。 set 因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。 sorted set sorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做排行榜应用，取TOP N操作。 1.5 redis的过期策略以及内存淘汰机制redis采用的是定期删除+惰性删除策略。 1.6 redis和数据库双写一致性问题​ 一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。 首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 1.7 如何应对缓存穿透和缓存雪崩问题 缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。 缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。 给缓存的失效时间，加上一个随机值，避免集体失效。 使用互斥锁，但是该方案吞吐量明显下降了。 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点: I 从缓存A读数据库，有则直接返回II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。III 更新线程同时更新缓存A和缓存B。 1.8 Redis如何做持久化的？​ bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。 1.9 Redis的同步机制了解么？​ Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 1.10 是否使用过Redis集群，集群的原理是什么？Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。 Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。 2.nginx常见面试题2.1 什么是Nginx？ Nginx是一个高性能的HTTP和反向代理服务器，及电子邮件（IMAP/POP3）代理服务器，同时也是一个非常高效的反向代理、负载平衡。 2.2 为什么要用Nginx？ 跨平台、配置简单 非阻塞、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发 内存消耗小：开启10个nginx才占150M内存，Nginx采取了分阶段资源分配技术 nginx处理静态文件好,耗费内存少 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。 节省宽带：支持GZIP压缩，可以添加浏览器本地缓存 稳定性高：宕机的概率非常小 master/worker结构：一个master进程，生成一个或者多个worker进程 接收用户请求是异步的：浏览器将请求发送到nginx服务器，它先将用户请求全部接收下来，再一次性发送给后端web服务器，极大减轻了web服务器的压力 一边接收web服务器的返回数据，一边发送给浏览器客户端 网络依赖性比较低，只要ping通就可以负载均衡 可以有多台nginx服务器 2.3 为什么Nginx性能这么高？ 得益于它的事件处理机制： 异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决 2.4 为什么不使用多线程？Apache: 创建多个进程或线程，而每个进程或线程都会为其分配cpu和内存（线程要比进程小的多，所以worker支持比perfork高的并发），并发过大会榨干服务器资源。 Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。所以才使得Nginx支持更高的并发。 2.5 正向代理与反向代理 正向代理一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器), 然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理 正向代理总结就一句话：代理端代理的是客户端 反向代理反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求，发给内部网络上的服务器, 并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器 反向代理总结就一句话：代理端代理的是服务端 2.6 动态资源、静态资源分离​ 动态资源、静态资源分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后, 我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路 动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离 2.7 为什么要做动、静分离？​ 在我们的软件开发中，有些请求是需要后台处理的（如：.jsp,.do等等），有些请求是不需要经过后台处理的（如：css、html、jpg、js等等文件, 这些不需要经过后台处理的文件称为静态文件，否则动态文件。因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗? 当然这是可以的，但是这样后台的请求次数就明显增多了。在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决, 动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问 这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中 2.8 负载均衡负载均衡即是代理服务器将接收的请求均衡的分发到各服务器中 负载均衡主要解决网络拥塞问题，提高服务器响应速度，服务就近提供，达到更好的访问质量，减少后台服务器大并发压力。","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Oracle(二)","slug":"Oracle(二)","date":"2021-05-08T13:19:59.148Z","updated":"2020-04-29T02:44:38.075Z","comments":true,"path":"25938/","link":"","permalink":"http://tonymua.top/25938/","excerpt":"1.视图视图就是封装了一条复杂查询的语句。语法 1.：CREATE VIEW 视图名称 AS 子查询 如果视图已经存在我们可以使用语法 2 来创建视图，这样已有的视图会被覆盖。 语法 2：CREATE OR REPLACE VIEW 视图名称 AS 子查询 我们可以设置视图为只读。语法 3：CREATE OR REPLACE VIEW 视图名称 AS 子查询 WITH READ ONLY","text":"1.视图视图就是封装了一条复杂查询的语句。语法 1.：CREATE VIEW 视图名称 AS 子查询 如果视图已经存在我们可以使用语法 2 来创建视图，这样已有的视图会被覆盖。 语法 2：CREATE OR REPLACE VIEW 视图名称 AS 子查询 我们可以设置视图为只读。语法 3：CREATE OR REPLACE VIEW 视图名称 AS 子查询 WITH READ ONLY 12345678910111213141516--视图:视图就是提供一个查询的窗口,所有数据来自于原表--查询语句创建表create table emp as select * from scott.emp;select * from emp;--创建视图(必须有dba权限)create view v_emp as select ename,job from emp;--查询视图select * from v_emp;--修改视图(不推荐)update v_emp set job=&apos;CLERK&apos; where ename=&apos;ALLEN&apos;;commit;--创建只读视图create view v_emp_readonly as select ename,job from emp with read only;--视图的作用--1.视图可以屏蔽掉一些敏感字段--2.保证总部和分布数据及时统一 2.索引​ 索引是用于加速数据存取的数据对象。合理的使用索引可以大大降低 i/o 次数,从而 提高数据访问性能。索引有很多种我们主要介绍常用的几种: ​ 为什么添加了索引之后，会加快查询速度呢？ ​ 图书馆：如果杂乱地放书的话检索起来就非常困难,所以将书分类，然后再建一个箱子，箱 子里面放卡片，卡片里面可以按类查询,按书名查或者类别查,这样的话速度会快很多很多， 这个就有点像索引。索引的好处就是提高你找到书的速度，但是正是因为你建了索引，就应该有人 专门来维护索引，维护索引是要有时间精力的开销的，也就是说索引是不能乱建的，所以建索引有 个原则：如果有一个字段如果不经常查询，就不要去建索引。现在把书变成我们的表，把卡片变成 我们的索引，就知道为什么索引会快，为什么会有开销。 创建索引的语法： 创建索引： 1．单列索引 单列索引是基于单个列所建立的索引，比如: ​ CREATE index 索引名 on 表名(列名) 2．复合索引 复合索引是基于两个列或多个列的索引。在同一张表上可以有多个索引，但是 要求列的组合必须不同,比如： ​ Create index emp_idx1 on emp(ename,job); ​ Create index emp_idx1 on emp(job,ename); 索引的使用原则：  在大表上建立索引才有意义  在 where子句后面或者是连接条件上的字段建立索引  表中数据修改频率高时不建议建立索引 12345678910111213141516--索引:索引就是在表的列上构建一个二叉树--达到大幅度提高查询效率的目的,但是索引会影响增删改的效率--单列索引--创建单列索引create index idx_ename on emp(ename);--单列索引触发规则,条件必须是索引列中的原始值--单行函数,模糊查询都会影响索引的触发select * from emp where ename=&apos;SCOTT&apos;;--复合索引--创建复合索引create index idx_enamejob on emp(ename,job);--复合索引中第一列为优先检索列--如果要触发复合索引,必须包含优先检索列中的原始值select * from emp where ename=&apos;SCOTT&apos; and job=&apos;xx&apos;;--触发复合索引select * from emp where ename=&apos;SCOTT&apos; or job=&apos;xx&apos;;--不触发索引select * from emp where ename=&apos;SCOTT&apos;;--触发单列索引 3.pl/sql基本语法什么是 PL/SQL? ​ PL/SQL（Procedure Language/SQL） PLSQL 是 Oracle 对sql 语言的过程化扩展，指在 SQL 命令语言中增加了过程处理语句（如分支、循 环等），使 SQL语言具有过程处理能力。把SQL 语言的数据操纵能力与过程语言的数据处理能力结合 起来，使得 PLSQL面向过程但比过程语言简单、高效、灵活和实用。 3.1 pl/sql程序语法程序语法： ​ declare 说明部分 （变量说明，游标申明，例外说明 ) ​ begin 语句序列 （DML 语句〕… ​ exception 例外处理语句 ​ End; 3.2 常量和变量定义​ 在程序的声明阶段可以来定义常量和变量。  变量的基本类型就是 oracle 中的建表时字段的变量如 char, varchar2, date, number, boolean, long ​ 定义语法： ​ varl char(15); ​ Psal number(9,2); ​ 说明变量名、数据类型和长度后用分号结束说明语句。 ​ 常量定义：married constant boolean:=true  引用变量 Myname emp.ename%type; ​ 引用型变量，即my_name 的类型与emp 表中 ename 列的类型一样 在 sql中使用 into 来赋值  记录型变量 Emprec emp%rowtype ​ 记录变量分量的引用 emp_rec.ename:=’ADAMS’; 1234567891011121314151617181920--pl/sql编程语言--pl/sql编程语言是对sql语言的扩展，使得sql语言具有过程化编程的特性--pl/sql编程语言比一般的过程化编程语言，更加灵活高效--pl/sql编程语言主要用来编写存储过程和存储函数等--声明方法--赋值操作可以使用:=也可以使用into查询语句赋值declare i number(2):=10; s varchar2(10):=&apos;小明&apos;; ename emp.ename%type;--引用型变量 emprow emp%rowtype;--记录型变量begin dbms_output.put_line(i); dbms_output.put_line(s); select ename into ename from emp where empno=7788; dbms_output.put_line(ename); select * into emprow from emp where empno=7788; dbms_output.put_line(emprow.ename||&apos;的工作为:&apos;||emprow.job);end; 3.3 if 分支语法 1： ​ IF 条件 THEN 语句 1; ​ 语句 2; ​ END IF; 语法 2： ​ IF 条件 THEN 语句序列 1； ​ ELSE 语句序列 2； ​ END IF； 语法 3： ​ IF 条件 THEN 语句; ​ ELSIF 语句 THEN 语句; ​ ELSE 语句; ​ END IF; 123456789101112131415--pl/sql中的if判断--输入小于18的数字，输出未成年--输入大于18小于40的数字，输出中年人--输入大于40的数字，输出老年人declare i number(3):=&amp;ii;begin if i&lt;18 then dbms_output.put_line(&apos;未成年&apos;); elsif i&lt;40 then dbms_output.put_line(&apos;中年人&apos;); else dbms_output.put_line(&apos;老年人&apos;); end if;end; 3.4 LOOP 循环语句语法 1： ​ WHILE total &lt;= 25000 LOOP ​ .. . ​ total : = total + salary; ​ END LOOP; 语法 2： ​ Loop ​ EXIT [when 条件]; ​ …… ​ End loop 语法 3： ​ FOR I IN 1 . . 3 LOOP ​ 语句序列 ; ​ END LOOP ; 1234567891011121314151617181920212223242526272829--pl/sql中的loop循环--用三种方式输出1到10是个数字--while循环declare i number(2):=1;begin while i&lt;11 loop dbms_output.put_line(i); i:=i+1; end loop;end;--exit循环declare i number(2):=1;begin loop exit when i&gt;10; dbms_output.put_line(i); i:=i+1; end loop;end;--for循环declarebegin for i in 1..10 loop dbms_output.put_line(i); end loop;end; 3.5 游标 Cursor​ 在写 java 程序中有集合的概念，那么在 pl/sql 中也会用到多条记录，这时候我们就要用到游标， 游标可以存储查询返回的多条数据。 语法： CURSOR 游标名 [ (参数名 数据类型,参数名 数据类型,…)] IS SELECT 语句; 游标的使用步骤： ​  打开游标： open c1; (打开游标执行查询) ​  取一行游标的值：fetch c1 into pjob; (取一行到变量中) ​  关闭游标： close c1;(关闭游标释放资源) ​  游标的结束方式 exit when c1%notfound ​  注意： 上面的 pjob 必须与 emp表中的 job 列类型一致： ​ 定义：pjob emp.empjob%type; 12345678910111213141516171819202122232425262728293031--游标：可以存放多个对象，多行记录--输出emp表中所有员工的姓名declare cursor c1 is select * from emp; emprow emp%rowtype;begin open c1; loop fetch c1 into emprow; exit when c1%notfound; dbms_output.put_line(emprow.ename); end loop; close c1;end;--给指定部门员工涨工资declare cursor c2(eno emp.deptno%type) is select empno from emp where deptno=eno; en emp.empno%type;begin open c2(10); loop fetch c2 into en; exit when c2%notfound; update emp set sal=sal+100 where empno=en; commit; end loop; close c2;end;--查询10号部门员工信息select * from emp where deptno = 10; 4. 存储过程​ 存储过程（Stored Procedure）是在大型数据库系统中，一组为了完成特定功能的 SQL 语句集，经 编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来 执行它。存储过程是数据库中的一个重要对象，任何一个设计良好的数据库应用程序都应该用到存储过程。 创建存储过程语法： ​ create [or replace] PROCEDURE 过程名[(参数名 in/out 数据类型)] ​ AS ​ begin ​ PLSQL子程序体； ​ End; 或者 ​ create [or replace] PROCEDURE 过程名[(参数名 in/out 数据类型)] ​ is ​ begin ​ PLSQL子程序体； ​ End 过程名; 1234567891011121314151617--存储过程：存储过程就是提前已经编译好的一段pl/sql语言，放置在数据库端--可以直接被调用。这一段pl/sql一般都是固定步骤的业务。--给指定员工涨100块钱create or replace procedure p1(eno emp.empno%type)isbegin update emp set sal=sal+100 where empno=eno; commit;end;select * from emp where empno=7788;--测试p1declarebegin p1(7788);end; 5.存储函数create or replace function 函数名(Name in type, Name in type, …) return 数据类型 is ​ 结果变量 数据类型; begin ​ return(结果变量); end函数名; 存储过程和存储函数的区别 ​ 一般来讲，过程和函数的区别在于函数可以有一个返回值；而过程没有返回值。 但过程和函数都可以通过 out 指定一个或多个输出参数。我们可以利用out 参数，在过程和函数中实 现返回多个值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768--通过存储函数实现计算指定员工的年薪--存储过程和存储函数的参数都不能带长度--存储函数的返回值类型不能带长度create or replace function f_yearsal(eno emp.empno%type)return numberis s number(10);begin select sal*12+nvl(comm,0)into s from emp where empno=eno; return s;end;--测试f_yearsal--存储函数在调用的时候，返回值需要接收declare s number(10);begin s:=f_yearsal(7788); dbms_output.put_line(s);end;--out类型参数如何使用--使用存储过程来算年薪create or replace procedure p_yearsal(eno emp.empno%type,yearsal out number)is s number(10); c emp.comm%type;begin select sal*12,nvl(comm,0)into s,c from emp where empno=eno; yearsal:=s+c;end;--测试p_yearsaldeclare yearsal number(10);begin p_yearsal(7788,yearsal); dbms_output.put_line(yearsal);end;--in和out类型参数的区别是什么？--凡是涉及到into查询语句赋值或者:=赋值操作的参数，都必须使用out来修饰--存储过程和存储函数的区别--语法区别：关键字不一样，--存储函数比存储过程多了两个return--本质区别：存储函数有返回值，而存储过程没有返回值。--如果存储过程想实现有返回值的业务，我们就必须使用out类型的参数--即便是存储过程使用了out类型的参数，起本质也不是真的有了返回值--而是在存储过程内部给out类型参数赋值，在执行完毕后，我们直接拿到输出类型参数的值--我们可以使用存储函数有返回值的特性，来自定义函数--而存储过程不能用来自定义函数--案例需求：查询出员工姓名，员工所在部门名称--案例准备工作：把scott用户下的dept表复制到当前用户下create table dept as select * from scott.dept;--使用传统方式来实现案例需求select e.ename,d.dnamefrom emp e,dept dwhere e.deptno=d.deptno;--使用存储函数来实现提供一个部门编号，输出一个部门名称create or replace function fdna(dno dept.deptno%type)return dept.dname%typeis dna dept.dname%type;begin select dname into dna from dept where deptno=dno; return dna;end;--使用fdna存储函数来实现案例需求：查询出员工姓名，员工所在部门名称select e.ename,fdna(e.deptno) from emp e; 6.触发器​ 数据库触发器是一个与表相关联的、存储的 PL/SQL 程序。每当一个特定的数据操作语句(Insert,update,delete)在指定的表上发出时，Oracle 自动地执行触发器中定义的语句序列。 触发器可用于 ​  数据确认 ​  实施复杂的安全性检查 ​  做审计，跟踪表上所做的数据操作等 ​  数据的备份和同步 *触发器的类型 * ​ 语句级触发器 ：在指定的操作语句操作之前或之后执行一次，不管这条语句影响了多少行 。 ​ 行级触发器（FOR EACH ROW） ：触发语句作用的每一条记录都被触发。在行级触 发器中使用 old 和 new伪记录变量, 识别值的状态。 语法： ​ CREATE [or REPLACE] TRIGGER 触发器名 ​ {BEFORE | AFTER} ​ {DELETE | INSERT | UPDATE [OF 列名]} ​ ON 表名 ​ [FOR EACH ROW [WHEN(条件) ] ] ​ begin ​ PLSQL 块 ​ End 触发器名 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--触发器:就是制定一个规则，在我们做增删改操作的时候，只要满足该规则，自动触发，无需调用--语句级触发器：不包含有for each row的触发器--行级触发器：包含有for each row的就是行级触发器--加for each row是为了使用:old或者:new对象或者一行记录--语句级触发器--插入一条记录，输出一个新员工入职create or replace trigger t1afterinsert on persondeclarebegin dbms_output.put_line(&apos;一个新员工入职&apos;);end;--触发t1insert into person values (1, &apos;小红&apos;);commit;select * from person;--行级别触发器--不能给员工降薪create or replace trigger t2beforeupdate on empfor each row declare begin if:old.sal&gt;:new.sal then raise_application_error(-20001,&apos;不能给员工降薪&apos;); end if; end;--触发t2select * from emp where empno = 7788;update emp set sal=sal-1 where empno = 7788;commit;--触发器实现主键自增。(行级触发器)--分析：在用户做插入操作的之前，拿到即将插入的数据，给该数据中的主键列赋值create or replace trigger autoidbeforeinsert on personfor each row declare begin select s_person.nextval into :new.pid from dual; end;--使用auid实现主键自增insert into person(pname) values(&apos;a&apos;);commit;--查询person表数据select * from person; 7.Java程序调用导入jar包 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.oracle&lt;/groupId&gt; &lt;artifactId&gt;ojdbc14&lt;/artifactId&gt; &lt;version&gt;10.2.0.4.0&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; OracleDemo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class OracleDemo &#123; @Test public void javaCallOracle()throws Exception&#123; //加载数据库驱动 Class.forName(\"oracle.jdbc.driver.OracleDriver\"); //得到Connection连接 Connection connection = DriverManager.getConnection(\"jdbc:oracle:thin:@192.168.17.130:1521:orcl\", \"test1\", \"test1\"); //得到预编译的ps对象 PreparedStatement ps = connection.prepareStatement(\"select * from emp where empno = ?\"); //给参数赋值 ps.setObject(1,7788); //执行数据库查询操作 ResultSet rs = ps.executeQuery(); //输出结果 while (rs.next())&#123; System.out.println(rs.getString(\"ename\")); &#125; //释放资源 rs.close(); ps.close(); connection.close(); &#125; /** * java调用存储过程 * &#123;?= call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储函数使用 * &#123;call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储过程使用 * @throws Exception */ @Test public void javaCallProcedure()throws Exception&#123; //加载数据库驱动 Class.forName(\"oracle.jdbc.driver.OracleDriver\"); //得到Connection连接 Connection connection = DriverManager.getConnection(\"jdbc:oracle:thin:@192.168.17.130:1521:orcl\", \"test1\", \"test1\"); //得到预编译对象 CallableStatement cs = connection.prepareCall(\"&#123;call p_yearsal(?,?)&#125;\"); //给参数赋值 cs.setObject(1,7788); cs.registerOutParameter(2, OracleTypes.NUMBER); //执行数据库查询操作 cs.execute(); //输出结果[第二个参数] System.out.println(cs.getObject(2)); //释放资源 cs.close(); connection.close(); &#125; /** * java调用存储函数 * &#123;?= call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储函数使用 * &#123;call &lt;procedure-name&gt;[(&lt;arg1&gt;,&lt;arg2&gt;, ...)]&#125; 调用存储过程使用 * @throws Exception */ @Test public void javaCallFunction() throws Exception &#123; //加载数据库驱动 Class.forName(\"oracle.jdbc.driver.OracleDriver\"); //得到Connection连接 Connection connection = DriverManager.getConnection(\"jdbc:oracle:thin:@192.168.17.130:1521:orcl\", \"test1\", \"test1\"); //得到预编译的Statement对象 CallableStatement cs = connection.prepareCall(\"&#123;?= call f_yearsal(?)&#125;\"); //给参数赋值 cs.setObject(2, 7788); cs.registerOutParameter(1, OracleTypes.NUMBER); //执行数据库查询操作 cs.execute(); //输出结果[第一个参数] System.out.println(cs.getObject(1)); //释放资源 cs.close(); connection.close(); &#125;&#125;","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"}]},{"title":"Oracle(一)","slug":"Oracle(一)","date":"2021-05-08T13:19:59.147Z","updated":"2020-04-29T02:44:38.074Z","comments":true,"path":"42486/","link":"","permalink":"http://tonymua.top/42486/","excerpt":"1.oracle介绍​ ORACLE 数据库系统是美国ORACLE 公司（甲骨文）提供的以分布式数据库为核心的一组软件产品，是目前最流行的客户/服务器(CLIENT/SERVER)或 B/S体系结构的数据库之一。比如SilverStream 就是基于数据库的一种中间件。ORACLE数据库是目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系数据库，它是一个完备关系的产品；作为分布式数据库它实现了分布式处理功能。但它的所有知识，只要在一种机型上学习了 ORACLE知识，便能在各种类型的机器上使用它。 2.Oracle体系结构","text":"1.oracle介绍​ ORACLE 数据库系统是美国ORACLE 公司（甲骨文）提供的以分布式数据库为核心的一组软件产品，是目前最流行的客户/服务器(CLIENT/SERVER)或 B/S体系结构的数据库之一。比如SilverStream 就是基于数据库的一种中间件。ORACLE数据库是目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系数据库，它是一个完备关系的产品；作为分布式数据库它实现了分布式处理功能。但它的所有知识，只要在一种机型上学习了 ORACLE知识，便能在各种类型的机器上使用它。 2.Oracle体系结构 2.1 数据库​ Oracle 数据库是数据的物理存储。这就包括（数据文件ORA或者 DBF、控制文件、联机日志、参数文件）。其实Oracle 数据库的概念和其它数据库不一样，这里的数据库是一个操作系统只有一个库。可以看作是Oracle 就只有一个大数据库。 2.2 实例​ 一个 Oracle 实例（Oracle Instance）有一系列的后台进程（Backguound Processes)和内存结构（Memory Structures)组成。一个数据库可以有 n 个实例。 2.3 用户​ 用户是在实例下建立的。不同实例可以建相同名字的用户。 2.4 表空间​ 表空间是 Oracle 对物理数据库上相关数据文件（ORA或者 DBF 文件）的逻辑映射。一个数据库在逻辑上被划分成一到若干个表空间，每个表空间包含了在逻辑上相关联的一组结构。每个数据库至少有一个表空间(称之为system表空间)。 ​ 每个表空间由同一磁盘上的一个或多个文件组成，这些文件叫数据文件(datafile)。一个数据文件只能属于一个表空间。 2.5 数据文件（dbf、ora）​ 数据文件是数据库的物理存储单位。数据库的数据是存储在表空间中的，真正是在某一个或者多个数据文件中。而一个表空间可以由一个或多个数据文件组成，一个数据文件只能属于一个表空间。一旦数据文件被加入到某个表空间后，就不能删除这个文件，如果要删除某个数据文件，只能删除其所属于的表空间才行。 ​ 注：表的数据，是有用户放入某一个表空间的，而这个表空间会随机把这些表数据放到一个或者多个数据文件中。 ​ 由于 oracle 的数据库不是普通的概念，oracle 是有用户和表空间对数据进行管理和存放的。但是表不是有表空间去查询的，而是由用户去查的。因为不同用户可以在同一个表空间建立同一个名字的表！这里区分就是用户了！ 3.创建表空间​ 表空间:ORACLE数据库的逻辑单元。 一个表空间可以与多个数据文件（物理结构）关联 一个数据库下可以建立多个表空间，一个表空间可以建立多个用户、一个用户下可以建立多个表。 123456-创建表空间create tablespace test1datafile &apos;c:\\test1.dbf&apos;size 100mautoextend onnext 10m; ​ test1 为表空间名称 datafile 指定表空间对应的数据文件 size 后定义的是表空间的初始大小 autoextend on 自动增长 ，当表空间存储都占满时，自动增长 next 后指定的是一次自动增长的大小。 12--删除表空间drop tablespace test1; 4. 用户4.1 创建用户1234--创建用户create user test1identified by test1default tablespace test1; identified by 后边是用户的密码 default tablespace 后边是表空间名称 oracle 数据库与其它数据库产品的区别在于，表和其它的数据库对象都是存储在用户下的。 4.2 用户赋权限新创建的用户没有任何权限，Oracle 中已存在三个重要的角色：connect 角色，resource角色，dba角色。 CONNECT 角色： –是授予最终用户的典型权利，最基本的 ALTER SESSION –修改会话 CREATE CLUSTER –建立聚簇 CREATE DATABASE LINK –建立数据库链接 CREATE SEQUENCE –建立序列 CREATE SESSION –建立会话 CREATE SYNONYM –建立同义词 CREATE VIEW –建立视图 RESOURCE 角色： –是授予开发人员的 CREATE CLUSTER –建立聚簇 CREATE PROCEDURE –建立过程 CREATE SEQUENCE –建立序列 CREATE TABLE –建表 CREATE TRIGGER –建立触发器 CREATE TYPE –建立类型 DBA角色：拥有全部特权，是系统最高权限，只有 DBA才可以创建数据库结构，并且系统权限也需要DBA授出，且 DBA用户可以操作全体用户的任意基表，包括删除 ​ 进入 system 用户下给用户赋予 dba 权限，否则无法正常登陆 1234567--给用户授权,否则无法登录--Oracle数据库中常用角色:connect--连接角色,基本角色resource--开发者角色dba--超级管理员角色--给test1用户授予dba角色grant dba to test1; 5.Oracle数据类型 6.表的管理6.1 建表语法： Create table 表名（ 字段 1 数据类型 [default 默认值], 字段 2 数据类型 [default 默认值], … 字段 n 数据类型 [default 默认值] ）; 12345--创建一个person表create table person( pid number(20), pname varchar(10)); 6.2 表的修改在 sql中使用 alter 可以修改表 添加语法：ALTER TABLE 表名称 ADD(列名 1 类型 [DEFAULT 默认值]，列名 1 类型 [DEFAULT 默认值]…) 修改语法：ALTER TABLE 表名称 MODIFY(列名 1 类型 [DEFAULT 默认值]，列名 1 类型 [DEFAULT 默认值]…) 修改列名: ALTER TABLE 表名称 RENAME 列名 1 TO 列名 2 123456789--修改表结构--添加一列alter table person add (gender number(1));--修改列类型alter table person modify gender char(1);--修改列名称alter table person rename column gender to sex;--删除一列alter table person drop column sex; 6.3 表删除123456789--三个删除--删除表中全部记录delete from person;--删除表结构drop table person;--先删除表,再次创建表结构.效果等同于删除表中全部记录--在数据量大的情况下,尤其在表中带有索引的情况下--索引可以提高查询效率,但是会影响增删改效率truncate table person; 6.4 表中数据的增删改INSERT（增加） 标准写法： INSERT INTO 表名[(列名 1，列名 2，…)]VALUES(值 1，值 2，…) 简单写法（不建议）: INSERT INTO 表名 VALUES(值 1，值 2，…) 注意：使用简单的写法必须按照表中的字段的顺序来插入值，而且如果有为空的字段使用 null *UPDATE（修改） * 全部修改：UPDATE 表名 SET 列名 1=值 1，列名 2=值 2，…. 局部修改：UPDATE 表名 SET 列名 1=值 1，列名 2=值 2，….WHERE 修改条件； *DELETE（删除） * 语法 : DELETE FROM 表名 WHERE 删除条件; ​ 在删除语句中如果不指定删除条件的话就会删除所有的数据 因为 oracle 的事务对数据库的变更的处理，我们必须做提交事务才能让数据真正的插入到数据库中，在同样在执行完数据库变更的操作后还可以把事务进行回滚，这样就不会插入到数据库。如果事务提交后则不可以再回滚。提交：commit回滚：rollback 12345678--查询表中记录select * from person;--添加一条记录insert into person (pid,pname) values(1,&apos;小明&apos;);commit;--修改一条记录update person set pname=&apos;小马&apos; where pid=1;commit; 6.5 序列​ 在很多数据库中都存在一个自动增长的列,如果现在要想在 oracle 中完成自动增长的功能, 则只能依靠序列完成,所有的自动增长操作,需要用户手工完成处理。 语法： CREATE SEQUENCE 序列名 [INCREMENT BY n] [START WITH n] [{MAXVALUE/ MINVALUE n|NOMAXVALUE}] [{CYCLE|NOCYCLE}] [{CACHE n|NOCACHE}]; 123456--序列不真的属于任何一张表,但是可以逻辑和表做绑定--序列:默认从1开始,依次递增,主要用来给主键赋值使用--dual:虚表,只是为了补全语法,没有任何意义create sequence s_person;select s_person.nextval from dual;select s_person.currval from dual; ​ 序列创建完成之后,所有的自动增长应该由用户自己处理,所以在序列中提供了以下的两种操作： nextval :取得序列的下一个内容 currval :取得序列的当前内容 ​ 在实际项目中每一张表会配一个序列，但是表和序列是没有必然的联系的，一个序列被哪一张表使用都可以，但是我们一般都是一张表用一个序列。 7.Scott用户123456--scott用户,密码tiger--解锁scott用户alter user scott account unlock;--解锁scott用户的密码(此句也可以用来重置密码)alter user scott identified by tiger;--切换到scott用户下 8.单行函数8.1 字符函数接收字符输入返回字符或者数值，dual是伪表 把小写的字符转换成大小的字符 把大写字符变成小写字符 1234--单行函数:作用于一行,返回一个值--字符函数select upper(&apos;yes&apos;) from dual;--YESselect lower(&apos;YES&apos;) from dual;--yes 8.2 数值函数四舍五入函数：ROUND() 默认情况下 ROUND 四舍五入取整，可以自己指定保留的位数。 1234--数值函数select round(26.18,1) from dual;--四舍五入,后面的参数保留的小数位数select trunc(26.18,1) from dual;--直接截取,不再看后面的数字是否大于5select mod(10,3) from dual;--求余数 8.3 日期函数​ Oracle 中提供了很多和日期相关的函数，包括日期的加减，在日期加减时有一些规律日期 – 数字 = 日期日期 + 数字 = 日期日期 – 日期 = 数字 1234567891011--日期函数--查询出emp表中所有员工入职距离现在几天select sysdate-e.hiredate from emp e;--算出明天此刻select sysdate+1 from dual;--查询出emp表中所有员工入职距离现在几月select months_between(sysdate,e.hiredate) from emp e;--查询出emp表中所有员工入职距离现在几年select months_between(sysdate,e.hiredate)/12 from emp e;--查询出emp表中所有员工入职距离现在几周select round(sysdate-e.hiredate)/7 from emp e; 8.4 转换函数 TO_CHAR:字符串转换函数 拆分时需要使用通配符 年：y, 年是四位使用 yyyy 月：m, 月是两位使用 mm 日：d, 日是两位使用 dd 时: h,时是两位使用 hh 24小时制:hh24 分：分是两位使用 mi 秒：秒是两位使用 ss 如果前面被补了前导零，可以使用 fm 去掉前导零 TO_DATE:日期转换函数 12345--转换函数--日期转字符串select to_char(sysdate,&apos;fm yyyy-mm-dd hh24:mi:ss&apos;) from dual;--字符串转日期select to_date(&apos; 2019-8-1 15:41:34&apos;,&apos;fm yyyy-mm-dd hh24:mi:ss&apos;) from dual; 8.5 通用函数1．空值处理nvl ​ 我们发现很多员工的年薪是空的，原因是很多员工的奖金是 null，null和任何数值计算都是null，这时我们可以使用 nvl来处理。 1234--通用函数--算出emp表中所有员工的年薪--奖金里面有null值，如果null值和任意数字做算术运算，结果都是nullselect e.sal*12+nvl(e.comm,0) from emp e; *2.Decode函数 * 该函数类似 if….else if…esle语法：DECODE(col/expression, [search1,result1],[search2, result2]….[default])Col/expression:列名或表达式Search1，search2…:用于比较的条件Result1, result2…:返回值如果 col/expression 和 Searchi匹配就返回 resulti,否则返回 default 的默认值 123456789--oracle中除了起别名，都用单引号。--oracle专用条件表达式select e.ename, decode(e.ename, &apos;SMITH&apos;,&apos;张三&apos;, &apos;ALLEN&apos;,&apos;李四&apos;, &apos;WARD&apos;,&apos;王二&apos;, &apos;无名&apos;)&quot;中文名&quot;from emp e; *3.case when * 12345678910111213141516171819--条件表达式--条件表达式的通用写法，mysql和oracle通用--给emp表中员工起中文名select e.ename, case e.ename when &apos;SMITH&apos; then &apos;张三&apos; when &apos;ALLEN&apos; then &apos;李四&apos; when &apos;WARD&apos; then &apos;王二&apos; --else &apos;无名&apos; endfrom emp e;--判断emp表中员工工资，如果高于3000显示高收入，如果高于1500低于3000显示中等收入，其余显示低收入select e.sal, case when e.sal&gt;3000 then &apos;高收入&apos; when e.sal&gt;1500 then &apos;中等收入&apos; else &apos;低收入&apos; endfrom emp e; 9.多行函数（聚合函数)123456--多行函数(聚合函数):作用于多行,返回一个值select count(1) from emp;--查询总数量select sum(sal) from emp;--工资总和select max(sal) from emp;--最大工资select min(sal) from emp;--最低工资select avg(sal) from emp;--平均工资 10. 分组统计分组统计需要使用 GROUP BY来分组 语法：SELECT * |列名 FROM 表名 {WEHRE 查询条件} {GROUP BY 分组字段} ORDER BY 列 名 1 ASC|DESC，列名 2…ASC|DESC 123456789101112131415161718192021222324252627282930--分组查询--查询出每个部门的平均工资--分组查询中，出现在group by后面的原始列，才能出现在select后面--没有出现在group by后面的列，想在select后面，必须加上聚合函数。--聚合函数有一个特性，可以把多行记录变成一个值。select e.deptno,avg(e.sal)from emp egroup by e.deptno;--查询出平均工资高于2000的部门信息select e.deptno,avg(e.sal) asalfrom emp egroup by e.deptnohaving avg(e.sal)&gt;2000;--所有条件都不能使用别名来判断--比如下面的条件语句也不能使用别名当条件select ename,sal s from where s&gt;1500;--查询出每个部门工资高于800的员工的平均工资----where是过滤分组前的数据，having是过滤分组后的数据---表现形式：where必须在group by之前，having是在group by之后select e.deptno,avg(e.sal) asalfrom emp ewhere e.sal&gt;800group by e.deptno;---查询出每个部门工资高于800的员工的平均工资---然后再查询出平均工资高于2000的部门select e.deptno,avg(e.sal) asalfrom emp ewhere e.sal&gt;800group by e.deptnohaving avg(e.sal)&gt;2000; 11.多表查询使用一张以上的表做查询就是多表查询 语法： SELECT {DISTINCT} *|列名.. FROM 表名 别名，表名 1 别名 ​ {WHERE 限制条件 ORDER BY 排序字段 ASC|DESC…} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647--多表查询中的一些概念--笛卡尔积select * from emp e,dept d;--等值连接(推荐使用)select * from emp e,dept d where e.deptno=d.deptno;--内连接select * from emp e inner join dept d on e.deptno=d.deptno;--查询所有部门,以及部门下的员工信息(外连接)select * from emp e right join dept d on e.deptno=d.deptno;--查询所有员工信息，以及员工所属部门select * from emp e left join dept d on e.deptno=d.deptno;--oracle中专用外连接:查询所有部门,以及部门下的员工信息select * from emp e,dept d where e.deptno(+)=d.deptno;--查询出员工姓名,员工领导姓名--自连接：自连接其实就是站在不同的角度把一张表看成多张表select e1.ename,e2.enamefrom emp e1,emp e2where e1.mgr=e2.empno;--查询出员工姓名，员工部门名称，员工领导姓名，员工领导部门名称select e1.ename,d1.dname,e2.ename,d2.dnamefrom emp e1,emp e2,dept d1,dept d2where e1.mgr=e2.empnoand e1.deptno=d1.deptnoand e2.deptno=d2.deptno;--查询出每个员工编号，姓名，部门名称，工资等级和他的上级领导的姓名，工资等级select e1.empno,e1.ename, (case s1.grade when 1 then &apos;一级&apos; when 2 then &apos;二级&apos; when 3 then &apos;三级&apos; when 4 then &apos;四级&apos; when 5 then &apos;五级&apos; end)&quot;grade&quot;,d1.dname,e2.empno,e2.ename, (case s2.grade when 1 then &apos;一级&apos; when 2 then &apos;二级&apos; when 3 then &apos;三级&apos; when 4 then &apos;四级&apos; when 5 then &apos;五级&apos; end)&quot;grade&quot; from emp e1,emp e2,dept d1,salgrade s1,salgrade s2where e1.mgr=e2.empnoand e1.deptno=d1.deptnoand e1.sal between s1.losal and s1.hisaland e2.sal between s2.losal and s2.hisal; 12.子查询子查询：在一个查询的内部还包括另一个查询，则此查询称为子查询。Sql的任何位置都可以加入子查询。 子查询在操作中有三类：单列子查询：返回的结果是一列的一个内容 单行子查询：返回多个列，有可能是一个完整的记录 多行子查询：返回多条记录 在返回多条记录的子查询可以把它的结果集当做一张表，给起个别名 1234567891011121314151617181920212223--子查询--子查询返回一个值--查询出工资和SCOTT一样的员工信息select * from emp where sal in(select sal from emp where ename=&apos;SCOTT&apos;);--子查询返回一个集合--查询出工资和10号部门任意员工一样的员工信息select * from emp where sal in(select sal from emp where deptno=10);--子查询返回一张表--查询出每个部门最低工资，和最低工资员工姓名，和该员工所在部门名称--1.先查询出每个部门最低工资select deptno,min(sal) msalfrom empgroup by deptno--2.三表联查，得到最终结果。select t.deptno,t.msal,e.ename,d.dnamefrom(select deptno,min(sal) msal from emp group by deptno) t,emp e,dept dwhere t.deptno=e.deptnoand t.msal=e.saland e.deptno=d.deptno; 13.Rownum与分页查询ROWNUM:表示行号，实际上此是一个列,但是这个列是一个伪列,此列可以在每张表中出现。 ​ 我们可以根据 rownum 来取结果集的前几行，比如前 5 行 ,但是我们不能取到中间几行，因为rownum不支持大于号，只支持小于号，如果想 实现我们的 需求怎么办呢？答案是使用子查询，也正是oracle分页的做法。 12345678910111213141516171819--oracle中的分页--rownum行号：当我们做select操作的时候，每查询出一行记录，就会在该行上加上一个行号，行号从1开始，依次递增，不能跳着走--排序操作会影响rownum的顺序select rownum,e.* from emp e order by e.sal desc;--如果涉及到排序，但是还要使用rownum的话，我们可以再次嵌套查询select rownum,t.* from(select rownum,e.* from emp e order by e.sal desc)t;--emp表工资倒叙排列后，每页五条记录，查询第二页--rownum行号不能写上大于一个正数select * from( select rownum rn,t.* from( select * from emp order by sal desc )t where rownum&lt;11)where rn&gt;5;--第二种写法： select * from ( select rownum rn ,emp.* from emp) t where t.rn &gt;5 and t.rn &lt;11","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"}]},{"title":"Mybatis框架(二)","slug":"Mybatis框架(二)","date":"2021-05-08T13:19:59.145Z","updated":"2020-04-29T02:44:38.072Z","comments":true,"path":"28604/","link":"","permalink":"http://tonymua.top/28604/","excerpt":"1.Mybatis 的输出结果封装1.1 resultType 配置结果类型​ resultType 属性可以指定结果集的类型，它支持基本类型和实体类类型。 我们在前面的 CRUD 案例中已经对此属性进行过应用了。 需要注意的是，它和 parameterType 一样，如果注册过类型别名的，可以直接使用别名。没有注册过的必须 使用全限定类名。例如：我们的实体类此时必须是全限定类名（今天最后一个章节会讲解如何配置实体类的别名） 同时，当是实体类名称是，还有一个要求，实体类中的属性名称必须和查询语句中的列名保持一致，否则无法 实现封装。 1.2 resultMap 结果类型​ resultMap 标签可以建立查询的列名和实体类的属性名称不一致时建立对应关系。从而实现封装。 在 select 标签中使用 resultMap 属性指定引用即可。同时 resultMap 可以实现将查询结果映射为复杂类 型的 pojo，比如在查询结果映射对象中包括 pojo 和 list 实现一对一查询和一对多查询。","text":"1.Mybatis 的输出结果封装1.1 resultType 配置结果类型​ resultType 属性可以指定结果集的类型，它支持基本类型和实体类类型。 我们在前面的 CRUD 案例中已经对此属性进行过应用了。 需要注意的是，它和 parameterType 一样，如果注册过类型别名的，可以直接使用别名。没有注册过的必须 使用全限定类名。例如：我们的实体类此时必须是全限定类名（今天最后一个章节会讲解如何配置实体类的别名） 同时，当是实体类名称是，还有一个要求，实体类中的属性名称必须和查询语句中的列名保持一致，否则无法 实现封装。 1.2 resultMap 结果类型​ resultMap 标签可以建立查询的列名和实体类的属性名称不一致时建立对应关系。从而实现封装。 在 select 标签中使用 resultMap 属性指定引用即可。同时 resultMap 可以实现将查询结果映射为复杂类 型的 pojo，比如在查询结果映射对象中包括 pojo 和 list 实现一对一查询和一对多查询。 定义 resultMap : 1234567891011121314&lt;!-- 建立 User 实体和数据库表的对应关系 type 属性：指定实体类的全限定类名 id 属性：给定一个唯一标识，是给查询 select 标签引用用的。 --&gt; &lt;resultMap type=\"com.itheima.domain.User\" id=\"userMap\"&gt; &lt;id column=\"id\" property=\"userId\"/&gt; &lt;result column=\"username\" property=\"userName\"/&gt; &lt;result column=\"sex\" property=\"userSex\"/&gt; &lt;result column=\"address\" property=\"userAddress\"/&gt; &lt;result column=\"birthday\" property=\"userBirthday\"/&gt; &lt;/resultMap&gt; id 标签：用于指定主键字段 result 标签：用于指定非主键字段 column 属性：用于指定数据库列名 property 属性：用于指定实体类属性名称 映射配置 : 1&lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultMap=\"userMap\"&gt; select * from user &lt;/select&gt; 2.SqlMapConfig.xml配置文件2.1 SqlMapConfig.xml 中配置的内容和顺序1234567891011121314151617-properties（属性） --property -settings（全局配置参数） --setting -typeAliases（类型别名） --typeAliase --package -typeHandlers（类型处理器） -objectFactory（对象工厂） -plugins（插件） -environments（环境集合属性对象） --environment（环境子属性对象） ---transactionManager（事务管理） ---dataSource（数据源） -mappers（映射器） --mapper --package 2.2 properties（属性） 在classpath 下定义 jdbcConfig.properties 文件 1234567jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/eesy_mybatis jdbc.username=root jdbc.password=547717253 properties 标签配置 : 123456&lt;!-- 配置连接数据库的信息 resource 属性：用于指定 properties 配置文件的位置，要求配置文件必须在类路径下 resource=\"jdbcConfig.properties\" url 属性： URL： Uniform Resource Locator 统一资源定位符 http://localhost:8080/mystroe/CategoryServlet URL 协议 主机 端口 URI URI：Uniform Resource Identifier 统一资源标识符 /mystroe/CategoryServlet 它是可以在 web 应用中唯一定位一个资源的路径 --&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; 此时我们的 dataSource 标签就变成了引用上面的配置: 123456&lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; 2.3 typeAliases（类型别名）自定义别名： 1234567在 SqlMapConfig.xml 中配置： &lt;typeAliases&gt; &lt;!-- 单个别名定义 --&gt; &lt;typeAlias alias=\"user\" type=\"com.itheima.domain.User\"/&gt; &lt;!-- 批量别名定义，扫描整个包下的类，别名为类名（首字母大写或小写都可以） --&gt; &lt;package name=\"com.itheima.domain\"/&gt; &lt;package name=\" 其它包 \"/&gt; &lt;/typeAliases&gt; 2.4 mappers（映射器） 使用相对于类路径的资源 如： 1&lt;mapper resource=\"com/itheima/dao/IUserDao.xml\" /&gt; 1使用 mapper 接口类路径 如：&lt;mapper class=\"com.itheima.dao.UserDao\"/&gt; 注意：此种方法要求 mapper 接口名称和 mapper 映射文件名称相同，且放在同一个目录中。 1注册指定包下的所有 mapper 接口 如：&lt;package name=\"cn.itcast.mybatis.mapper\"/&gt; 注意：此种方法要求 mapper 接口名称和 mapper 映射文件名称相同，且放在同一个目录中。 3.Mybatis 的连接池技术1234567891011数据源配置就是在 SqlMapConfig.xml 文件中，具体配置如下： &lt;!-- 配置数据源（连接池）信息 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; MyBatis 在初始化时，根据&lt;dataSource&gt;的 type 属性来创建相应类型的的数据源 DataSource，即： type=”POOLED”：MyBatis 会创建 PooledDataSource 实例 type=”UNPOOLED” ： MyBatis 会创建 UnpooledDataSource 实例 type=”JNDI”：MyBatis 会从 JNDI 服务上查找 DataSource 实例，然后返回使用 4.Mybatis 自动提交事务的设置123456789101112131415161718为什么 CUD 过程中必须使用 sqlSession.commit()提交事 务？主要原因就是在连接池中取出的连接，都会将调用 connection.setAutoCommit(false)方法，这样我们 就必须使用 sqlSession.commit()方法，相当于使用了 JDBC 中的 connection.commit()方法实现事务提 交。 明白这一点后，我们现在一起尝试不进行手动提交，一样实现 CUD 操作。 @Before//在测试方法执行之前执行 public void init()throws Exception &#123; //1.读取配置文件 in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); //2.创建构建者对象 SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); //3.创建 SqlSession 工厂对象 factory = builder.build(in); //4.创建 SqlSession 对象 session = factory.openSession(true); //5.创建 Dao 的代理对象 userDao = session.getMapper(IUserDao.class); &#125; @After//在测试方法执行完成之后执行 public void destroy() throws Exception&#123; //7.释放资源 session.close(); in.close(); &#125; 5.Mybatis 的动态 SQL 语句5.1 动态 SQL 之if标签12345/** * 根据用户信息，查询用户列表 * @param user * @return */ List&lt;User&gt; findByUser(User user); 12345678910&lt;select id=\"findByUser\" resultType=\"user\" parameterType=\"user\"&gt; select * from user where 1=1 &lt;if test=\"username!=null and username != '' \"&gt; and username like #&#123;username&#125; &lt;/if&gt; &lt;if test=\"address != null\"&gt; and address like #&#123;address&#125; &lt;/if&gt; &lt;/select&gt; 注意：&lt;if&gt;标签的 test 属性中写的是对象的属性名，如果是包装类的对象要使用 OGNL 表达式的写法。 另外要注意 where 1=1 的作用~！ 1234567891011@Test public void testFindByUser() &#123; User u = new User(); u.setUsername(\"%王%\"); u.setAddress(\"%顺义%\"); //6.执行操作 List&lt;User&gt; users = userDao.findByUser(u); for(User user : users) &#123; System.out.println(user); &#125; &#125; 5.2动态 SQL 之where标签为了简化上面 where 1=1 的条件拼装，我们可以采用标签来简化开发。 1234567891011&lt;!-- 根据用户信息查询 --&gt; &lt;select id=\"findByUser\" resultType=\"user\" parameterType=\"user\"&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; &lt;where&gt; &lt;if test=\"username!=null and username != '' \"&gt; and username like #&#123;username&#125; &lt;/if&gt; &lt;if test=\"address != null\"&gt; and address like #&#123;address&#125; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 5.3动态标签之foreach标签​ 传入多个 id 查询用户信息，用下边两个 sql 实现： SELECT * FROM USERS WHERE 1username LIKE '%张%' AND (id =10 OR id =89 OR id=16) SELECT * FROM USERS WHERE username LIKE '%张%' AND id IN (10,89,16) 这样我们在进行范围查询时，就要将一个集合中的值，作为参数动态添加进来。 在 QueryVo 中加入一个 List 集合用于封装参数: 123456789101112/** * * &lt;p&gt;Title: QueryVo&lt;/p&gt; * &lt;p&gt;Description: 查询的条件&lt;/p&gt; * &lt;p&gt;Company: http://www.itheima.com/ &lt;/p&gt; */ public class QueryVo implements Serializable &#123; private List&lt;Integer&gt; ids; public List&lt;Integer&gt; getIds() &#123; return ids; &#125; public void setIds(List&lt;Integer&gt; ids) &#123; this.ids = ids; &#125; &#125; 12345/** * 根据 id 集合查询用户 * @param vo * @return */ List&lt;User&gt; findInIds(QueryVo vo); 1234567891011121314151617181920&lt;!-- 查询所有用户在 id 的集合之中 --&gt; &lt;select id=\"findInIds\" resultType=\"user\" parameterType=\"queryvo\"&gt; &lt;!-- select * from user where id in (1,2,3,4,5); --&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; &lt;where&gt; &lt;if test=\"ids != null and ids.size() &gt; 0\"&gt; &lt;foreach collection=\"ids\" open=\"id in ( \" close=\")\" item=\"uid\" separator=\",\"&gt; #&#123;uid&#125; &lt;/foreach&gt; &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; SQL 语句： select 字段 from user where id in (?) &lt;foreach&gt;标签用于遍历集合，它的属性： collection:代表要遍历的集合元素，注意编写时不要写#&#123;&#125; open:代表语句的开始部分 close:代表结束部分 item:代表遍历集合的每个元素，生成的变量名 sperator:代表分隔符 12345678910111213141516@Test public void testFindInIds() &#123; QueryVo vo = new QueryVo(); List&lt;Integer&gt; ids = new ArrayList&lt;Integer&gt;(); ids.add(41); ids.add(42); ids.add(43); ids.add(46); ids.add(57); vo.setIds(ids); //6.执行操作 List&lt;User&gt; users = userDao.findInIds(vo); for(User user : users) &#123; System.out.println(user); &#125; &#125; 5.4 Mybatis 中简化编写的 SQL 片段Sql 中可将重复的 sql 提取出来，使用时用 include 引用即可，最终达到 sql 重用的目的。 定义代码片段 : 1234&lt;!-- 抽取重复的语句代码片段 --&gt; &lt;sql id=\"defaultSql\"&gt; select * from user &lt;/sql&gt; 引用代码片段 : 123456789&lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultType=\"user\"&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; &lt;/select&gt; &lt;!-- 根据 id 查询 --&gt; &lt;select id=\"findById\" resultType=\"UsEr\" parameterType=\"int\"&gt; &lt;include refid=\"defaultSql\"&gt;&lt;/include&gt; where id = #&#123;uid&#125; &lt;/select&gt; 6.Mybatis 延迟加载策略6.1 何为延迟加载?延迟加载： 就是在需要用到数据时才进行加载，不需要用到数据时就不加载数据。延迟加载也称懒加载. 好处：先从单表查询，需要时再从关联表去关联查询，大大提高数据库性能，因为查询单表要比关联查询多张表速 度要快。 坏处： 因为只有当需要用到数据时，才会进行数据库查询，这样在大批量数据查询时，因为查询工作也要消耗 时间，所以可能造成用户等待时间变长，造成用户体验下降。 6.2 实现需求需求：查询账户(Account)信息并且关联查询用户(User)信息。如果先查询账户(Account)信息即可满足要 求，当我们需要查询用户(User)信息时再查询用户(User)信息。把对用户(User)信息的按需去查询就是延迟加 载。 实现多表操作时，使用resultMap来实现一对一，一对多，多对多关系的操作。主要 是通过 association、collection 实现一对一及一对多映射。association、collection 具备延迟加载功 能。 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"dao.IAccountDao\"&gt; &lt;!-- 建立对应关系 --&gt; &lt;resultMap type=\"account\" id=\"accountMap\"&gt; &lt;id column=\"aid\" property=\"id\"/&gt; &lt;result column=\"uid\" property=\"uid\"/&gt; &lt;result column=\"money\" property=\"money\"/&gt; &lt;!-- 它是用于指定从表方的引用实体属性的 --&gt; &lt;association property=\"user\" javaType=\"user\" select=\"com.itheima.dao.IUserDao.findById\" column=\"uid\"&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id=\"findAll\" resultMap=\"accountMap\"&gt; select * from account &lt;/select&gt; &lt;/mapper&gt; select： 填写我们要调用的 select 映射的 id column ： 填写我们要传递给 select 映射的参数 6.3 使用 assocation 实现延迟加载123456我们需要在 Mybatis 的配置文件 SqlMapConfig.xml 文件中添加延迟加载的配置。 &lt;!-- 开启延迟加载的支持 --&gt; &lt;settings&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;setting name=\"aggressiveLazyLoading\" value=\"false\"/&gt; &lt;/settings&gt; 6.4 使用 Collection 实现延迟加载​ 同样我们也可以在一对多关系配置的结点中配置延迟加载策略。 结点中也有 select 属性，column 属性。 需求： 完成加载用户对象时，查询该用户所拥有的账户信息。 在 User 实体类中加入 List属性: 123private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; 编写用户持久层映射配置: 12345678910111213141516171819&lt;resultMap type=\"user\" id=\"userMap\"&gt; &lt;id column=\"id\" property=\"id\"&gt;&lt;/id&gt; &lt;result column=\"username\" property=\"username\"/&gt; &lt;result column=\"address\" property=\"address\"/&gt; &lt;result column=\"sex\" property=\"sex\"/&gt; &lt;result column=\"birthday\" property=\"birthday\"/&gt; &lt;!-- collection 是用于建立一对多中集合属性的对应关系 ofType 用于指定集合元素的数据类型 select 是用于指定查询账户的唯一标识（账户的 dao 全限定类名加上方法名称） column 是用于指定使用哪个字段的值作为条件查询 --&gt; &lt;collection property=\"accounts\" ofType=\"account\" select=\"com.itheima.dao.IAccountDao.findByUid\" column=\"id\"&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultMap=\"userMap\"&gt; select * from user &lt;/select&gt; &lt;collection&gt;标签： 主要用于加载关联的集合对象 select 属性： 用于指定查询 account 列表的 sql 语句，所以填写的是该 sql 映射的 id column 属性： 用于指定 select 属性的 sql 语句的参数来源，上面的参数来自于 user 的 id 列，所以就写成 id 这一 个字段名了 7.Mybatis 缓存7.1 Mybatis 一级缓存一级缓存是 SqlSession 级别的缓存，只要 SqlSession 没有 flush 或 close，它就存在。 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"dao.IUserDao\"&gt; &lt;!-- 根据 id 查询 --&gt; &lt;select id=\"findById\" resultType=\"UsEr\" parameterType=\"int\" useCache=\"true\"&gt; select * from user where id = #&#123;uid&#125; &lt;/select&gt; &lt;/mapper&gt; 一级缓存的分析 : ​ 一级缓存是 SqlSession 范围的缓存，当调用 SqlSession 的修改，添加，删除，commit()，close()等方法时，就会清空一级缓存。 ​ 第一次发起查询用户 id 为 1 的用户信息，先去找缓存中是否有 id 为 1 的用户信息，如果没有，从数据库查 询用户信息。 得到用户信息，将用户信息存储到一级缓存中。 如果 sqlSession 去执行 commit 操作（执行插入、更新、删除），清空 SqlSession 中的一级缓存，这样 做的目的为了让缓存中存储的是最新的信息，避免脏读。 第二次发起查询用户 id 为 1 的用户信息，先去找缓存中是否有 id 为 1 的用户信息，缓存中有，直接从缓存 中获取用户信息。 7.2 Mybatis 二级缓存​ 二级缓存是 mapper 映射级别的缓存，多个 SqlSession 去操作同一个 Mapper 映射的 sql 语句，多个 SqlSession 可以共用二级缓存，二级缓存是跨 SqlSession 的。 二级缓存的分析 : 首先开启 mybatis 的二级缓存。sqlSession1 去查询用户信息，查询到用户信息会将查询数据存储到二级缓存中。 如果 SqlSession3 去执行相同 mapper 映射下 sql，执行 commit 提交，将会清空该 mapper 映射下的二 级缓存区域的数据。sqlSession2 去查询与 sqlSession1 相同的用户信息，首先会去缓存中找是否存在数据，如果存在直接从 缓存中取出数据。 二级缓存的开启与关闭: 第一步：在 SqlMapConfig.xml 文件开启二级缓存 12345&lt;settings&gt; &lt;!-- 开启二级缓存的支持 --&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; 因为 cacheEnabled 的取值默认就为 true，所以这一步可以省略不配置。为 true 代表开启二级缓存；为 false 代表不开启二级缓存。 第二步：配置相关的 Mapper 映射文件 1234567&lt;cache&gt;标签表示当前这个 mapper 映射将使用二级缓存，区分的标准就看 mapper 的 namespace 值。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"dao.IUserDao\"&gt; &lt;!-- 开启二级缓存的支持 --&gt; &lt;cache&gt;&lt;/cache&gt; &lt;/mapper&gt; 第三步：配置 statement 上面的 useCache 属性 123456&lt;!-- 根据 id 查询 --&gt; &lt;select id=\"findById\" resultType=\"user\" parameterType=\"int\" useCache=\"true\"&gt; select * from user where id = #&#123;uid&#125; &lt;/select&gt; 将 UserDao.xml 映射文件中的&lt;select&gt;标签中设置 useCache=”true”代表当前这个 statement 要使用 二级缓存，如果不使用二级缓存可以设置为 false。 注意：针对每次查询都需要最新的数据 sql，要设置成 useCache=false，禁用二级缓存。 二级缓存注意事项 : 123456789101112当我们在使用二级缓存时，所缓存的类一定要实现 java.io.Serializable 接口，这种就可以使用序列化 方式来保存对象。 /** * * &lt;p&gt;Title: User&lt;/p&gt; * &lt;p&gt;Description: 用户的实体类&lt;/p&gt; */ public class User implements Serializable &#123; private Integer id; private String username; private Date birthday; private String sex; private String address; &#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Mybatis框架(三)","slug":"Mybatis框架(三)","date":"2021-05-08T13:19:59.144Z","updated":"2020-04-29T02:44:38.069Z","comments":true,"path":"65310/","link":"","permalink":"http://tonymua.top/65310/","excerpt":"1. Mybatis 注解开发1.1 mybatis 的常用注解说明@Insert:实现新增 @Update:实现更新 @Delete:实现删除 @Select:实现查询 @Result:实现结果集封装 @Results:可以与@Result 一起使用，封装多个结果集","text":"1. Mybatis 注解开发1.1 mybatis 的常用注解说明@Insert:实现新增 @Update:实现更新 @Delete:实现删除 @Select:实现查询 @Result:实现结果集封装 @Results:可以与@Result 一起使用，封装多个结果集 @ResultMap:实现引用@Results 定义的封装 @One:实现一对一结果集封装 @Many:实现一对多结果集封装 @SelectProvider: 实现动态 SQL 映射 @CacheNamespace:实现注解二级缓存的使用 1.2 使用 Mybatis 注解实现基本 CRUD1.2.1 编写实体类 1234567891011121314151617181920public class User implements Serializable &#123; private Integer userId; private String userName; private Date userBirthday; private String userSex; private String userAddress; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public Date getUserBirthday() &#123; return userBirthday; &#125; public void setUserBirthday(Date userBirthday) &#123; this.userBirthday = userBirthday; &#125; public String getUserSex() &#123; return userSex; &#125; public void setUserSex(String userSex) &#123; this.userSex = userSex; &#125; public String getUserAddress() &#123; return userAddress; &#125; public void setUserAddress(String userAddress) &#123; this.userAddress = userAddress; &#125; @Override public String toString() &#123; return \"User [userId=\" + userId + \", userName=\" + userName + \", userBirthday=\" + userBirthday + \", userSex=\" + userSex + \", userAddress=\" + userAddress + \"]\"; &#125; &#125; 注意： 此处我们故意和数据库表的列名不一致。 1.2.2 使用注解方式开发持久层接口 1234567891011121314151617181920212223242526272829303132333435363738394041public interface IUserDao &#123; /** * 查询所有用户 * @return */ @Select(\"select * from user\") @Results(id=\"userMap\", value= &#123; @Result(id=true,column=\"id\",property=\"userId\"), @Result(column=\"username\",property=\"userName\"), @Result(column=\"sex\",property=\"userSex\"), @Result(column=\"address\",property=\"userAddress\"), @Result(column=\"birthday\",property=\"userBirthday\") &#125;) List&lt;User&gt; findAll(); /** * 根据 id 查询一个用户 * @param userId * @return */ @Select(\"select * from user where id = #&#123;uid&#125; \") @ResultMap(\"userMap\") User findById(Integer userId); /** * 保存操作 * @param user * @return */ @Insert(\"insert into user(username,sex,birthday,address)values(#&#123;username&#125;,#&#123;sex&#125;,#&#123;birthday&#125;,#&#123;address&#125; )\") @SelectKey(keyColumn=\"id\",keyProperty=\"id\",resultType=Integer.class,before = false, statement = &#123; \"select last_insert_id()\" &#125;) int saveUser(User user); /** * 更新操作 * @param user * @return */ @Update(\"update user set username=#&#123;username&#125;,address=#&#123;address&#125;,sex=#&#123;sex&#125;,birthday=#&#123;birthday&#125; where id =#&#123;id&#125; \") int updateUser(User user); /** * 删除用户 * @param userId * @return */ @Delete(\"delete from user where id = #&#123;uid&#125; \") int deleteUser(Integer userId); /** * 查询使用聚合函数 * @return */ @Select(\"select count(*) from user \") int findTotal(); /** * 模糊查询 * @param name * @return */ @Select(\"select * from user where username like #&#123;username&#125; \") List&lt;User&gt; findByName(String name); &#125; 通过注解方式，我们就不需要再去编写 UserDao.xml 映射文件了。 1.2.3 编写 SqlMapConfig 配置文件 123456789101112131415161718192021222324252627 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;!-- 配置 properties 文件的位置 --&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; &lt;!-- 配置别名的注册 --&gt; &lt;typeAliases&gt; &lt;package name=\"domain\"/&gt; &lt;/typeAliases&gt; &lt;!-- 配置环境 --&gt; &lt;environments default=\"mysql\"&gt; &lt;!-- 配置 mysql 的环境 --&gt; &lt;environment id=\"mysql\"&gt; &lt;!-- 配置事务的类型是 JDBC --&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;!-- 配置数据源 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 配置映射信息 --&gt; &lt;mappers&gt; &lt;!-- 配置 dao 接口的位置，它有两种方式 第一种：使用 mapper 标签配置 class 属性 第二种：使用 package 标签，直接指定 dao 接口所在的包 --&gt; &lt;package name=\"com.itheima.dao\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 1.2.4 编写测试方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class AnnotationCRUDTest &#123; private InputStream in; private SqlSessionFactory factory; private SqlSession sqlSession; private UserDao userDao; @Before public void init() throws Exception &#123; in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); factory = new SqlSessionFactoryBuilder().build(in); sqlSession=factory.openSession(true); userDao=sqlSession.getMapper(UserDao.class); &#125; @After public void destroy() throws Exception &#123; sqlSession.close(); in.close(); &#125; @Test public void testSave()&#123; User user=new User(); user.setUsername(\"test\"); user.setSex(\"男\"); user.setBirthday(new Date()); user.setAddress(\"兰州\"); userDao.saveUser(user); &#125; @Test public void testUpdate()&#123; User user=new User(); user.setId(54); user.setUsername(\"testUpdate\"); user.setSex(\"女\"); user.setBirthday(new Date()); user.setAddress(\"西安\"); userDao.updateUser(user); &#125; @Test public void testDelete()&#123; userDao.deletUser(54); &#125; @Test public void testFindOne()&#123; User user =userDao.findById(48); System.out.println(user); &#125; @Test public void testFindByName()&#123;// List&lt;User&gt; users = userDao.findUserByName(\"%王%\"); List&lt;User&gt; users = userDao.findUserByName(\"王\"); for (User user:users)&#123; System.out.println(user); &#125; &#125; @Test public void testFindTotal()&#123; int totalUser = userDao.findTotalUser(); System.out.println(totalUser); &#125;&#125; 1.3 使用注解实现复杂关系映射开发​ 实现复杂关系映射之前我们可以在映射文件中通过配置来实现，在使用注解开发时我们需要借 助@Results 注解，@Result 注解，@One 注解，@Many 注解。 1.3.1 复杂关系映射的注解说明 @Results 注解 代替的是标签 该注解中可以使用单个@Result 注解，也可以使用@Result 集合 @Results（{@Result（），@Result（）}）或@Results（@Result（）） @Resutl 注解 代替了 标签和标签 @Result 中 属性介绍： id 是否是主键字段 column 数据库的列名 property 需要装配的属性名 one 需要使用的@One 注解（@Result（one=@One）（））） many 需要使用的@Many 注解（@Result（many=@many）（））） @One 注解（一对一） 代替了标签，是多表查询的关键，在注解中用来指定子查询返回单一对象。 @One 注解属性介绍： select 指定用来多表查询的 sqlmapper fetchType 会覆盖全局的配置参数 lazyLoadingEnabled。 使用格式： @Result(column=” “,property=””,one=@One(select=””)) @Many 注解（多对一） 代替了标签,是是多表查询的关键，在注解中用来指定子查询返回对象集合。 注意：聚集元素用来处理“一对多”的关系。需要指定映射的 Java 实体类的属性，属性的 javaType （一般为 ArrayList）但是注解中可以不定义； 使用格式： @Result(property=””,column=””,many=@Many(select=””)) 1.3.2 使用注解实现一对一复杂关系映射及延迟加载 需求： 加载账户信息时并且加载该账户的用户信息，根据情况可实现延迟加载。（注解方式实现） 添加 User 实体类及 Account 实体类: 1234//多对一关系映射：从表方应该包含一个主表方的对象引用 private User user; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; 添加账户的持久层接口并使用注解配置 : 12345678910111213public interface IAccountDao &#123; /** * 查询所有账户，采用延迟加载的方式查询账户的所属用户 * @return */ @Select(\"select * from account\") @Results(id=\"accountMap\", value= &#123; @Result(id=true,column=\"id\",property=\"id\"), @Result(column=\"uid\",property=\"uid\"), @Result(column=\"money\",property=\"money\"), @Result(column=\"uid\", property=\"user\", one=@One(select=\"com.itheima.dao.IUserDao.findById\", fetchType=FetchType.LAZY) ) &#125;) List&lt;Account&gt; findAll(); &#125; 添加用户的持久层接口并使用注解配置 : 123456789101112131415161718public interface IUserDao &#123; /** * 查询所有用户 * @return */ @Select(\"select * from user\") @Results(id=\"userMap\", value= &#123; @Result(id=true,column=\"id\",property=\"userId\"), @Result(column=\"username\",property=\"userName\"), @Result(column=\"sex\",property=\"userSex\"), @Result(column=\"address\",property=\"userAddress\"), @Result(column=\"birthday\",property=\"userBirthday\") &#125;) List&lt;User&gt; findAll(); /** * 根据 id 查询一个用户 * @param userId * @return */ @Select(\"select * from user where id = #&#123;uid&#125; \") @ResultMap(\"userMap\") User findById(Integer userId);&#125; 1.3.3 使用注解实现一对多复杂关系映射需求： 查询用户信息时，也要查询他的账户列表。使用注解方式实现。 分析： 一个用户具有多个账户信息，所以形成了用户(User)与账户(Account)之间的一对多关系。 User 实体类加入 List: 12345//一对多关系映射：主表方法应该包含一个从表方的集合引用 private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; 编写用户的持久层接口并使用注解配置 : 12345678910111213141516171819public interface IUserDao &#123; /** * 查询所有用户 * @return */ @Select(\"select * from user\") @Results(id=\"userMap\", value= &#123; @Result(id=true,column=\"id\",property=\"userId\"), @Result(column=\"username\",property=\"userName\"), @Result(column=\"sex\",property=\"userSex\"), @Result(column=\"address\",property=\"userAddress\"), @Result(column=\"birthday\",property=\"userBirthday\"), @Result(column=\"id\",property=\"accounts\", many=@Many( select=\"com.itheima.dao.IAccountDao.findByUid\", fetchType=FetchType.LAZY ) ) &#125;) List&lt;User&gt; findAll(); &#125; @Many: 相当于&lt;collection&gt;的配置 select 属性：代表将要执行的 sql 语句 fetchType 属性：代表加载方式，一般如果要延迟加载都设置为 LAZY 的值 编写账户的持久层接口并使用注解配置: 12345678public interface IAccountDao &#123; /** * 根据用户 id 查询用户下的所有账户 * @param userId * @return */ @Select(\"select * from account where uid = #&#123;uid&#125; \") List&lt;Account&gt; findByUid(Integer userId); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class AnnotationCRUDTest &#123; private InputStream in; private SqlSessionFactory factory; private SqlSession sqlSession; private UserDao userDao; @Before public void init() throws Exception &#123; in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); factory = new SqlSessionFactoryBuilder().build(in); sqlSession=factory.openSession(true); userDao=sqlSession.getMapper(UserDao.class); &#125; @After public void destroy() throws Exception &#123; sqlSession.close(); in.close(); &#125; @Test public void FindAll()&#123; List&lt;User&gt; users = userDao.findAll(); for (User user:users)&#123; System.out.println(\"------每个用户的信息------\"); System.out.println(user); System.out.println(user.getAccounts()); &#125; &#125; @Test public void testFindOne()&#123; User user =userDao.findById(48); System.out.println(user); &#125; @Test public void testFindByName()&#123;// List&lt;User&gt; users = userDao.findUserByName(\"%王%\"); List&lt;User&gt; users = userDao.findUserByName(\"王\"); for (User user:users)&#123; System.out.println(user); &#125; &#125;&#125; 2.mybatis 基于注解的二级缓存2.1 在 SqlMapConfig 中开启二级缓存支持1234&lt;!--配置开启二级缓存--&gt; &lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; 2.2 在持久层接口中使用注解配置二级缓存1@CacheNamespace(blocking = true)//开启二级缓存 3.Mybatis使用总结SqlMapConfig.xml 1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--配置外部文件--&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; &lt;!--配置开启二级缓存--&gt; &lt;settings&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; &lt;!--使用typeAliases配置别名，它只能配置domain中类的别名 --&gt; &lt;typeAliases&gt; &lt;package name=\"domain\"&gt;&lt;/package&gt; &lt;/typeAliases&gt; &lt;!--配置环境--&gt; &lt;environments default=\"mysql\"&gt; &lt;environment id=\"mysql\"&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"&gt;&lt;/property&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--指定带有注解的dao接口所在位置--&gt; &lt;mappers&gt; &lt;package name=\"dao\"&gt;&lt;/package&gt; &lt;/mappers&gt;&lt;/configuration&gt; jdbcConfig.properties 1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/eesy_mybatisjdbc.username=rootjdbc.password=547717253 User 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class User implements Serializable &#123; private Integer userId; private String userName; private String userSex; private Date userBirthday; private String userAddress; //一对多关系映射,一个用户对应多个账户 private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getUserSex() &#123; return userSex; &#125; public void setUserSex(String userSex) &#123; this.userSex = userSex; &#125; public Date getUserBirthday() &#123; return userBirthday; &#125; public void setUserBirthday(Date userBirthday) &#123; this.userBirthday = userBirthday; &#125; public String getUserAddress() &#123; return userAddress; &#125; public void setUserAddress(String userAddress) &#123; this.userAddress = userAddress; &#125; @Override public String toString() &#123; return \"User&#123;\" + \"userId=\" + userId + \", userName='\" + userName + '\\'' + \", userSex='\" + userSex + '\\'' + \", userBirthday=\" + userBirthday + \", userAddress='\" + userAddress + '\\'' + '&#125;'; &#125;&#125; Account 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Account implements Serializable &#123; private Integer id; private Integer uid; private Double money; //多对一(mybatis中称之一对一)的映射:一个账户只能对应一个用户 private User user; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public Integer getUid() &#123; return uid; &#125; public void setUid(Integer uid) &#123; this.uid = uid; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; @Override public String toString() &#123; return \"Account&#123;\" + \"id=\" + id + \", uid=\" + uid + \", money=\" + money + '&#125;'; &#125;&#125; UserDao 12345678910111213141516171819202122232425@CacheNamespace(blocking = true)//开启二级缓存public interface UserDao &#123; @Select(\"select * from user\") @Results(id = \"userMap\",value = &#123; @Result(id = true ,property = \"userId\",column = \"id\"), @Result(id = false,property = \"userName\",column =\"username\" ), @Result(id = false,property = \"userSex\",column = \"sex\"), @Result(id = false,property = \"userBirthday\",column = \"birthday\"), @Result(id = false,property = \"userAddress\",column = \"address\"), @Result(property = \"accounts\",column =\"id\",many = @Many(select = \"dao.AccountDao.findAccountByUid\",fetchType = FetchType.LAZY)) &#125;) List&lt;User&gt; findAll(); @Select(\"select * from user where id=#&#123;id&#125;\")// @ResultMap(value = &#123;\"userMap\"&#125;) @ResultMap(\"userMap\") User findById(Integer id);// @Select(\"select * from user where username like #&#123;username&#125;\") @Select(\"select * from user where username like '%$&#123;value&#125;%'\") @ResultMap(\"userMap\") List&lt;User&gt; findUserByName(String username);&#125; AccountDao 1234567891011121314public interface AccountDao &#123; @Select(\"select * from account\") @Results(id = \"accountMap\",value = &#123; @Result(id = true,property = \"id\",column = \"id\"), @Result(id = false,property = \"uid\",column = \"uid\"), @Result(id = false,property = \"money\",column = \"money\"), @Result(property =\"user\",column = \"uid\",one = @One(select = \"dao.UserDao.findById\",fetchType = FetchType.EAGER)) &#125;) List&lt;Account&gt; findAll(); @Select(\"select * from account where uid=#&#123;userId&#125;\") List&lt;Account&gt; findAccountByUid(Integer userId);&#125;","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"Mybatis框架(一)","slug":"Mybatis框架(一)","date":"2021-05-08T13:19:59.142Z","updated":"2020-04-29T02:44:38.022Z","comments":true,"path":"44824/","link":"","permalink":"http://tonymua.top/44824/","excerpt":"1.框架概述1.1 什么是框架​ 框架（Framework）是整个或部分系统的可重用设计，表现为一组抽象构件及构件实例间交互的方法;另一种 定义认为，框架是可被应用开发者定制的应用骨架。前者是从应用方面而后者是从目的方面给出的定义。 简而言之，框架其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别 人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。 1.2 框架要解决的问题​ 框架要解决的最重要的一个问题是技术整合的问题，在 J2EE 的 框架中，有着各种各样的技术，不同的 软件企业需要从 J2EE 中选择不同的技术，这就使得软件企业最终的应用依赖于这些技术，技术自身的复杂性和技 术的风险性将会直接对应用造成冲击。而应用是软件企业的核心，是竞争力的关键所在，因此应该将应用自身的设计和具体的实现技术解耦。这样，软件企业的研发将集中在应用的设计上，而不是具体的技术实现，技术实现是应 用的底层支撑，它不应该直接对应用产生影响。","text":"1.框架概述1.1 什么是框架​ 框架（Framework）是整个或部分系统的可重用设计，表现为一组抽象构件及构件实例间交互的方法;另一种 定义认为，框架是可被应用开发者定制的应用骨架。前者是从应用方面而后者是从目的方面给出的定义。 简而言之，框架其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别 人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。 1.2 框架要解决的问题​ 框架要解决的最重要的一个问题是技术整合的问题，在 J2EE 的 框架中，有着各种各样的技术，不同的 软件企业需要从 J2EE 中选择不同的技术，这就使得软件企业最终的应用依赖于这些技术，技术自身的复杂性和技 术的风险性将会直接对应用造成冲击。而应用是软件企业的核心，是竞争力的关键所在，因此应该将应用自身的设计和具体的实现技术解耦。这样，软件企业的研发将集中在应用的设计上，而不是具体的技术实现，技术实现是应 用的底层支撑，它不应该直接对应用产生影响。 ​ 框架一般处在低层应用平台（如 J2EE）和高层业务逻辑之间的中间层。 1.3 软件开发的分层重要性​ 框架的重要性在于它实现了部分功能，并且能够很好的将低层应用平台和高层业务逻辑进行了缓和。为了实现软件工程中的“高内聚、低耦合”。把问题划分开来各个解决，易于控制，易于延展，易于分配资源。我们常见的 MVC 软件设计思想就是很好的分层思想。 2.Mybatis 框架快速入门2.1 mybatis 环境搭建步骤​ 第一步：创建 maven 工程 ​ 第二步：导入坐标 ​ 第三步：编写必要代码（实体类和持久层接口） ​ 第四步：编写 SqlMapConfig.xml ​ 第五步：编写映射配置文件 ​ 第六步：编写测试类 2.2 创建 maven 工程1&lt;packaging&gt;jar&lt;/packaging&gt; 2.3 添加 Mybatis3.4.5 及相关的坐标12345678910111213141516171819202122&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.基于代理 Dao 实现 CRUD 操作3.1 SqlMapConfig.xml12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!--配置环境--&gt; &lt;environments default=\"mysql\"&gt; &lt;!--配置mysql的环境--&gt; &lt;environment id=\"mysql\"&gt; &lt;!--配置事务--&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;!--配置连接池--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/eesy_mybatis\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"547717253\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--配置映射文件的位置--&gt; &lt;mappers&gt; &lt;mapper resource=\"dao/UserDao.xml\"&gt;&lt;/mapper&gt; &lt;/mappers&gt;&lt;/configuration&gt; 3.2 在持久层Dao接口中添加方法12345678910111213141516171819202122232425public interface UserDao &#123; List&lt;User&gt; findAll(); void saveUser(User user); void updateUser(User user); void deleteUser(User user); User findById(Integer id); //模糊查询 List&lt;User&gt; findByName(String username); //查询总用户数 int findTotal();&#125;public interface UserDao &#123; List&lt;User&gt; findAll(); void saveUser(User user); void updateUser(User user); void deleteUser(User user);&#125; 3.3 在用户的映射配置文件中配置1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"dao.UserDao\"&gt; &lt;select id=\"findAll\" resultType=\"domain.User\"&gt; select * from user ; &lt;/select&gt; &lt;insert id=\"saveUser\" parameterType=\"domain.User\"&gt; insert into user (username,birthday,sex,address)values (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;); &lt;/insert&gt; &lt;update id=\"updateUser\" parameterType=\"domain.User\"&gt; update user set username=#&#123;username&#125;,birthday=#&#123;birthday&#125;,sex=#&#123;sex&#125;,address=#&#123;address&#125; where id=#&#123;id&#125;; &lt;/update&gt; &lt;delete id=\"deleteUser\" parameterType=\"domain.User\"&gt; delete from user where id=#&#123;id&#125;; &lt;/delete&gt; &lt;select id=\"findById\" parameterType=\"int\" resultType=\"domain.User\"&gt; select * from user where id =#&#123;id&#125;; &lt;/select&gt; &lt;select id=\"findByName\" parameterType=\"String\" resultType=\"domain.User\"&gt; &lt;!--select * from user where username like #&#123;username&#125;--&gt; &lt;!--以下方式比较常用--&gt; select * from user where username like '%$&#123;value&#125;%'; &lt;/select&gt; &lt;select id=\"findTotal\" resultType=\"int\"&gt; select count(id) from user ; &lt;/select&gt;&lt;/mapper&gt; 细节： ​ parameterType 属性： 代表参数的类型，因为我们要传入的是一个类的对象，所以类型就写类的全名称。 ​ sql 语句中使用#{}字符： 它代表占位符，相当于原来 jdbc 部分所学的?，都是用于执行语句时替换实际的数据。 具体的数据是由#{}里面的内容决定的。 ​ #{}中内容的写法： 由于我们保存方法的参数是 一个 User 对象，此处要写 User 对象中的属性名称。 它用的是 ognl 表达式。 ​ ognl 表达式： 它是 apache 提供的一种表达式语言，全称是： Object Graphic Navigation Language 对象图导航语言 它是按照一定的语法格式来获取数据的。 语法格式就是使用 #{对象.对象}的方式 ​ #{user.username}它会先去找 user 对象，然后在 user 对象中找到 username 属性，并调用 getUsername()方法把值取出来。但是我们在 parameterType 属性上指定了实体类名称，所以可以省略 user. 而直接写 username。 3.4添加测试类中的测试方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class MybatisTest &#123; private InputStream in; private SqlSessionFactory factory; private SqlSession sqlSession; private UserDao userDao; @Before//在测试方法执行之前执行 public void init() throws Exception &#123; //1.读取配置文件,生成字节输入流 in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); //2.获取SqlSessionFactory对象 factory = new SqlSessionFactoryBuilder().build(in); //3.获取SqlSession对象 sqlSession = factory.openSession(); //4.获取dao的代理对象 userDao = sqlSession.getMapper(UserDao.class); &#125; @After//在测试方法执行之后执行 public void destrory() throws Exception &#123; //提交事务 sqlSession.commit(); //6.释放资源 sqlSession.close(); in.close(); &#125; // 测试查询所有 @Test public void testfindAll() throws Exception &#123; //1.读取配置文件,生成字节输入流 InputStream in = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); //2.获取SqlSessionFactory对象 SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(in); //3.获取SqlSession对象 SqlSession sqlSession = factory.openSession(); //4.获取dao的代理对象 UserDao userDao = sqlSession.getMapper(UserDao.class); //5.执行查询所有方法 List&lt;User&gt; users = userDao.findAll(); for (User user : users) &#123; System.out.println(user); &#125; //6.释放资源 sqlSession.close(); in.close(); &#125; // 测试保存 @Test public void testSave() &#123; User user = new User(); user.setUsername(\"张三\"); user.setBirthday(new Date()); user.setSex(\"男\"); user.setAddress(\"上海\"); //执行保存方法 userDao.saveUser(user); &#125; @Test public void testUpdate() &#123; User user=new User(); user.setId(51); user.setUsername(\"李四\"); user.setBirthday(new Date()); user.setSex(\"女\"); user.setAddress(\"北京\"); userDao.updateUser(user); &#125; @Test public void testDelete()&#123; User user=new User(); user.setId(52); userDao.deleteUser(user); &#125; @Test public void testFindById()&#123; User user = userDao.findById(51); System.out.println(user); &#125; @Test public void testFindByName()&#123; // List&lt;User&gt; users = userDao.findByName(\"%王%\"); List&lt;User&gt; users = userDao.findByName(\"王\"); for (User user:users)&#123; System.out.println(user); &#125; &#125; @Test public void testFindTotal()&#123; int total = userDao.findTotal(); System.out.println(total); &#125;&#125; 模糊查询注意事项:第一步：修改 SQL 语句的配置，配置如下： 1&lt;!-- 根据名称模糊查询 --&gt; &lt;select id=\"findByName\" parameterType=\"string\" resultType=\"com.itheima.domain.User\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; 我们在上面将原来的#{}占位符，改成了${value}。注意如果用模糊查询的这种写法，那么${value}的写 法就是固定的，不能写成其它名字。 第二步：测试，如下： /** 12测试模糊查询操作 */ @Test public void testFindByName()&#123; //5.执行查询一个方法 List&lt;User&gt; users = userDao.findByName(\"王\"); for(User user : users)&#123; System.out.println(user); &#125; &#125; **#{}与${}的区别:** #{}表示一个占位符号 通过#{}可以实现 preparedStatement 向占位符中设置值，自动进行 java 类型和 jdbc 类型转换， #{}可以有效防止 sql 注入。 #{}可以接收简单类型值或 pojo 属性值。 如果 parameterType 传输单个简单类 型值，#{}括号中可以是 value 或其它名称。 ${}表示拼接 sql 串 通过${}可以将 parameterType 传入的内容拼接在 sql中且不进行 jdbc 类型转换， ${}可以接收简 单类型值或 pojo 属性值，如果 parameterType 传输单个简单类型值，${}括号中只能是 value。","categories":[],"tags":[{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"}]},{"title":"MyBatis是如何防止SQL注入的","slug":"MyBatis是如何防止SQL注入的","date":"2021-05-08T13:19:59.141Z","updated":"2020-04-29T02:44:37.934Z","comments":true,"path":"16852/","link":"","permalink":"http://tonymua.top/16852/","excerpt":"1.MyBatis概述​ MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Ordinary Java Object,普通的 Java对象)映射成数据库中的记录。 2.SQL 注入攻击概述","text":"1.MyBatis概述​ MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Ordinary Java Object,普通的 Java对象)映射成数据库中的记录。 2.SQL 注入攻击概述 ​ SQL注入攻击，简称SQL攻击或注入攻击，是发生于应用程序之数据库层的安全漏洞。简而言之，是在输入的字符串之中注入SQL指令，在设计不良的程序当中忽略了检查，那么这些注入进去的指令就会被数据库服务器误认为是正常的SQL指令而运行，因此遭到破坏或是入侵。 ​ 最常见的就是我们在应用程序中使用字符串联结方式组合 SQL 指令，有心之人就会写一些特殊的符号，恶意篡改原本的 SQL 语法的作用，达到注入攻击的目的。 举个例子: 比如验证用户登录需要 username 和 password，编写的 SQL 语句如下： 1select * from user where (name = '\"+ username +\"') and (pw = '\"+ password +\"'); username 和 password 字段被恶意填入 1username = \"1' OR '1'='1\"; 与 1password = \"1' OR '1'='1\"; 将导致原本的 SQL 字符串被填为： 1select * from user where (name = '1' or '1'='1') and (pw = '1' or '1'='1'); 实际上运行的 SQL 语句将变成： 1select * from user; 也就是不再需要 username 和 password 账密即达到登录的目的，结果不言而喻。 3.MyBatis 解决 SQL 注入问题#{}和${}的区别是什么？ (1）mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值。 （2）mybatis在处理${}时，就是把${}替换成变量的值。 （3）使用#{}可以有效的防止SQL注入，提高系统安全性。原因在于：预编译机制。预编译完成之后，SQL的结构已经固定，即便用户输入非法参数，也不会对SQL的结构产生影响，从而避免了潜在的安全风险。 （4）预编译是提前对SQL语句进行预编译，而其后注入的参数将不会再进行SQL编译。我们知道，SQL注入是发生在编译的过程中，因为恶意注入了某些特殊字符，最后被编译成了恶意的执行操作。而预编译机制则可以很好的防止SQL注入。 MyBatis框架作为一款半自动化的持久层框架，其SQL语句都要我们自己手动编写，这个时候当然需要防止SQL注入。其实，MyBatis的SQL是一个具有“输入+输出”的功能，类似于函数的结构，参考上面的两个例子。其中，parameterType表示了输入的参数类型，resultType表示了输出的参数类型。回应上文，如果我们想防止SQL注入，理所当然地要在输入参数上下功夫。上面代码中使用#的即输入参数在SQL中拼接的部分，传入参数后，打印出执行的SQL语句，会看到SQL是这样的： 1select id, username, password, role from user where username=? and password=? 不管输入什么参数，打印出的SQL都是这样的。这是因为MyBatis启用了预编译功能，在SQL执行前，会先将上面的SQL发送给数据库进行编译；执行时，直接使用编译好的SQL，替换占位符“?”就可以了。因为SQL注入只能对编译过程起作用，所以这样的方式就很好地避免了SQL注入的问题。 底层实现原理 ​ MyBatis是如何做到SQL预编译的呢？其实在框架底层，是JDBC中的PreparedStatement类在起作用，PreparedStatement是我们很熟悉的Statement的子类，它的对象包含了编译好的SQL语句。这种“准备好”的方式不仅能提高安全性，而且在多次执行同一个SQL时，能够提高效率。原因是SQL已编译好，再次执行时无需再编译。 在使用MyBatis框架时，有以下场景极易产生SQL注入 SQL语句中的一些部分，例如order by字段、表名等，是无法使用预编译语句的。这种场景极易产生SQL注入。推荐开发在Java层面做映射，设置一个字段/表名数组，仅允许用户传入索引值。这样保证传入的字段或者表名都在白名单里面(手动过滤，添加白名单)。 like参数注入。使用如下SQL语句可防止SQL注入 1like concat('%',#&#123;title&#125;, '%')， in之后参数的SQL注入。使用如下SQL语句可防止SQL注入 1234id in&lt;foreach collection=\"ids\" item=\"item\" open=\"(\"separator=\",\" close=\")\"&gt;#&#123;item&#125; &lt;/foreach&gt;","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Maven","slug":"Maven","date":"2021-05-08T13:19:59.139Z","updated":"2020-04-29T02:44:38.123Z","comments":true,"path":"38008/","link":"","permalink":"http://tonymua.top/38008/","excerpt":"1.maven 构建 SSM 工程1.1 需求实现 SSM 工程构建，规范依赖管理。场景：根据 id 展示商品信息 1.2 知识点准备什么是依赖传递 ? ​ 除了 spring-webmvc 以外的其他 jar。因为我们的项目依赖 spring-webmv.jar，而spring-webmv.jar 会依赖spring-beans.jar 等等，所以 spring-beans.jar 这些 jar 包也出现在了我们的 maven 工程中，这种现象我们称为依赖传递 *依赖冲突的解决 * 1.2.1依赖调解原则maven 自动按照下边的原则调解：","text":"1.maven 构建 SSM 工程1.1 需求实现 SSM 工程构建，规范依赖管理。场景：根据 id 展示商品信息 1.2 知识点准备什么是依赖传递 ? ​ 除了 spring-webmvc 以外的其他 jar。因为我们的项目依赖 spring-webmv.jar，而spring-webmv.jar 会依赖spring-beans.jar 等等，所以 spring-beans.jar 这些 jar 包也出现在了我们的 maven 工程中，这种现象我们称为依赖传递 *依赖冲突的解决 * 1.2.1依赖调解原则maven 自动按照下边的原则调解： 1、第一声明者优先原则 在 pom 文件定义依赖，先声明的依赖为准。测试： 如果将上边 spring-webmvc 和 spring-context 顺序颠倒，系统将导入 spring-beans-5.0.2。分析： 由于 spring-webmvc 在前边以 spring-webmvc 依赖的 spring-beans-5.0.2 为准，所以最终spring-beans-5.0.2 添加到了工程中。 2、路径近者优先原则 例如：还是上述情况，spring-contex 和 spring-webmvc 都会传递过来 spirng-beans，那如果直接把 spring-beans 的依赖直接写到 pom 文件中，那么项目就不会再使用其他依赖传递来的 spring-beans，因为自己直接在 pom 中定义 spring-beans要比其他依赖传递过来的路径要近。 ​ 在本工程中的 pom 中加入 spirng-beans-5.0.2 的依赖，根据路径近者优先原则，系统将导入spirng-beans-5.0.2 1.2.2 排除依赖​ 上边的问题也可以通过排除依赖方法辅助依赖调解，如下： 比如在依赖 spring-webmvc 的设置中添加排除依赖，排除 spring-beans,下边的配置表示：依赖 spring-webmvc，但排除 spring-webmvc 所依赖的 spring-beans。 1.2.3 锁定版本 (推荐)​ 面对众多的依赖，有一种方法不用考虑依赖路径、声明优化等因素可以采用直接锁定版本的方法确定依赖构件的版本，版本锁定后则不考虑依赖的声明顺序或依赖的路径，以锁定的版本的为准添加到工程中，此方法在企业开发中常用。 还可以把版本号提取出来，使用标签设置成变量。 注意：在工程中锁定依赖的版本并不代表在工程中添加了依赖，如果工程需要添加锁定版本的依赖则需要单独添加标签 1.3 定义 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;maven_1&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!--maven工程要导入jar包的坐标，就必须要考虑解决jar包冲突。 解决jar包冲突的方式一： 第一声明优先原则：哪个jar包的坐标在靠上的位置，这个jar包就是先声明的。 先声明的jar包坐标下的依赖包，可以优先进入项目中。 maven导入jar包中的一些概念： 直接依赖：项目中直接导入的jar包，就是该项目的直接依赖包。 传递依赖：项目中没有直接导入的jar包，可以通过项目直接依赖jar包传递到项目中去。 解决jar包冲突的方式二： 路径近者优先原则。直接依赖路径比传递依赖路径近，那么最终项目进入的jar包会是路径近的直接依赖包。 解决jar包冲突的方式三【推荐使用】： 直接排除法。 当我们要排除某个jar包下依赖包，在配置exclusions标签的时候，内部可以不写版本号。 因为此时依赖包使用的版本和默认和本jar包一样。--&gt; &lt;!-- 统一管理jar包版本 --&gt; &lt;properties&gt; &lt;spring.version&gt;5.0.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;shiro.version&gt;1.2.3&lt;/shiro.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;mybatis.version&gt;3.4.5&lt;/mybatis.version&gt; &lt;spring.security.version&gt;5.0.1.RELEASE&lt;/spring.security.version&gt; &lt;/properties&gt; &lt;!--maven工程是可以分父子依赖关系的。 凡是依赖别的项目后，拿到的别的项目的依赖包，都属于传递依赖。 比如：当前A项目，被B项目依赖。那么我们A项目中所有jar包都会传递到B项目中。 B项目开发者，如果再在B项目中导入一套ssm框架的jar包，对于B项目是直接依赖。 那么直接依赖的jar包就会把我们A项目传递过去的jar包覆盖掉。 为了防止以上情况的出现。我们可以把A项目中主要jar包的坐标锁住，那么其他依赖该项目的项目中， 即便是有同名jar包直接依赖，也无法覆盖。 --&gt; &lt;!-- 锁定jar包版本 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 项目依赖jar包 --&gt; &lt;dependencies&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.6.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-taglibs&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.security.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 添加tomcat7插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 1.4 案例实现Items 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Items implements Serializable &#123; private Integer id; private String name; private Double price; private String pic; private Date createtime; private String detail; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Double getPrice() &#123; return price; &#125; public void setPrice(Double price) &#123; this.price = price; &#125; public String getPic() &#123; return pic; &#125; public void setPic(String pic) &#123; this.pic = pic; &#125; public Date getCreatetime() &#123; return createtime; &#125; public void setCreatetime(Date createtime) &#123; this.createtime = createtime; &#125; public String getDetail() &#123; return detail; &#125; public void setDetail(String detail) &#123; this.detail = detail; &#125;&#125; ItemsDao 12345@Repositorypublic interface ItemsDao &#123; @Select(\"select * from items where id=#&#123;id&#125;\") public Items findById(Integer id);&#125; ItemsService 123public interface ItemsService &#123; public Items findById(Integer id);&#125; ItemsServiceImpl 12345678910@Servicepublic class ItemsServiceImpl implements ItemsService &#123; @Autowired private ItemsDao itemsDao; @Override public Items findById(Integer id) &#123; return itemsDao.findById(id); &#125;&#125; ItemsController 12345678910111213@Controller@RequestMapping(\"/items\")public class ItemsController &#123; @Autowired private ItemsService itemsService; @RequestMapping(\"/findDetail\") public String findDetail(Model model)&#123; Items items = itemsService.findById(1); model.addAttribute(\"item\",items); return \"itemDetail\"; &#125;&#125; applicationContext.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--开启注解的扫描，希望处理service和dao，controller不需要Spring框架去处理--&gt; &lt;context:component-scan base-package=\"dao,service\" &gt; &lt;!--配置哪些注解不扫描--&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\" /&gt; &lt;/context:component-scan&gt; &lt;!--配置AccountDao接口所在包--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\" id=\"mapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"dao\"/&gt; &lt;/bean&gt; &lt;!--配置连接池--&gt; &lt;bean class=\"com.alibaba.druid.pool.DruidDataSource\" id=\"dataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///maven\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"547717253\"/&gt; &lt;/bean&gt; &lt;!--配置SqlSessionFactory工厂--&gt; &lt;bean class=\"org.mybatis.spring.SqlSessionFactoryBean\" id=\"sqlSessionFactory\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--aop面向切面编程，切面就是切入点和通知的组合--&gt; &lt;!--配置事务管理器--&gt; &lt;bean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\" id=\"transactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务的通知--&gt; &lt;tx:advice id=\"advice\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"find*\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置切面--&gt; &lt;aop:config&gt; &lt;aop:pointcut id=\"pointcut\" expression=\"execution(* service.impl.*.*(..))\"/&gt; &lt;aop:advisor advice-ref=\"advice\" pointcut-ref=\"pointcut\"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; springmvc.xml 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!--组件扫描--&gt; &lt;context:component-scan base-package=\"contrler\"/&gt; &lt;!--处理器映射器，处理器适配器--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\" id=\"viewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!--释放静态资源--&gt; &lt;mvc:default-servlet-handler/&gt;&lt;/beans&gt; web.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE web-app PUBLIC \"-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\" \"http://java.sun.com/dtd/web-app_2_3.dtd\" &gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" version=\"3.0\"&gt; &lt;!--编码过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置spring核心监听器--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--重新指定spring配置文件的路径--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--springmvc的核心servlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; itemDetail.jsp 12345678910111213141516171819202122232425262728293031323334&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/fmt\" prefix=\"fmt\"%&gt; &lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form&gt; &lt;table width=\"100%\" border=1&gt; &lt;tr&gt; &lt;td&gt;商品名称&lt;/td&gt; &lt;td&gt; $&#123;item.name &#125; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;商品价格&lt;/td&gt; &lt;td&gt; $&#123;item.price &#125; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;生成日期&lt;/td&gt; &lt;td&gt; &lt;fmt:formatDate value=\"$&#123;item.createtime&#125;\" pattern=\"yyyy-MM-dd HH:mm:ss\"/&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;商品简介&lt;/td&gt; &lt;td&gt;$&#123;item.detail&#125; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 1.5 运行与调试12345678910&lt;!-- 添加tomcat7插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; *注意: *解决配置本地tomcat中文乱码问题:在VM options处添加-Dfile.enconding=UTF-8 2.分模块构建工程基于上边的三个工程分析继承：创建一个 parent 工程将所需的依赖都配置在 pom 中聚合：聚合多个模块运行 2.1 需求将 SSM 工程拆分为多个模块开发： maven_dao maven_service maven_web 理解继承和聚合 通常继承和聚合同时使用 何为继承？ ​ 继承是为了消除重复，如果将 dao、service、web 分开创建独立的工程则每个工程的 pom.xml文件中的内容存在重复，比如：设置编译版本、锁定 spring的版本的等，可以将这些重复的配置提取出来在父工程的 pom.xml 中定义。 何为聚合？ ​ 项目开发通常是分组分模块开发，每个模块开发完成要运行整个工程需要将每个模块聚合在一起运行，比如：dao、service、web 三个工程最终会打一个独立的war 运行。 2.2 案例实现2.2.1 创建父工程定义与原案例相同的pom.xml 2.2.2 创建 dao 子模块选中父工程右键-new-Module并命名为maven_dao 将原工程中的 domain实体类 dao接口拷贝到 src/main/java 中 maven_dao 模块的 pom.xml 文件中需要继承父模块 将applicationContext.xml拆分出一个applicationContext-dao.xml，此文件中只配置 dao 相关放到resources-spring文件夹中 2.2.3 创建service 子模块选中父工程右键-new-Module并命名为maven_service maven_service 模块的 pom.xml 文件中需要继承父模块，maven_service 依赖 maven_dao 模块 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;maven_parent&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;maven_service&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;maven_dao&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 将原工程中的service接口拷贝到 src/main/java中 创建 applicationContext-service.xml，此文件中定义的service放到resources-spring文件夹中 依赖范围对传递依赖的影响 ​ 是因为依赖会有依赖范围，依赖范围对传递依赖也有影响，例如有 A、B、C，A 依赖 B、B依赖 C，C可能是 A的传递依赖 ​ 遇到依赖没有传递过来的问题我们通常的解决方案是在本工程中直接添加依赖： 把依赖添加到 maven_service的工程中 2.2.4 创建 web 子模块​ 选择骨架创建web 子模块 maven_web 模块的 pom.xml 文件中需要继承父模块，maven_web 依赖 maven_service 模块 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;maven_parent&lt;/artifactId&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;maven_web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;tonymua&lt;/groupId&gt; &lt;artifactId&gt;maven_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 将原工程中的controller 代码拷贝到src/main/java 中 将原工程中的springmvc代码拷贝到sresources中,applicationContext.xml引入以上两个工程中的applicationContext.xml 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;import resource=\"classpath:spring/applicationContext-dao.xml\"/&gt; &lt;import resource=\"classpath:spring/applicationContext-service.xml\"/&gt;&lt;/beans&gt; 将原工程中的pages及web.xml拷贝到WEB-INF中 2.3 运行调试方法 1：在maven_web 工程的 pom.xml 中配置 tomcat 插件运行 ​ 运行 maven_web 工程它会从本地仓库下载依赖的 jar 包，所以当 maven_web 依赖的 jar 包内容修改了必须及时发布到本地仓库，比如：maven_web 依赖的 maven_service 修改了，需要及时将maven_service 发布到本地仓库。 方法 2：在父工程的 pom.xml 中配置 tomcat插件运行，自动聚合并执行 ​ 推荐方法2，如果子工程都在本地，采用方法2则不需要子工程修改就立即发布到本地仓库，父工程会自动聚合并使用最新代码执行。注意：如果子工程和父工程中都配置了tomcat 插件，运行的端口和路径以子工程为准。 3.maven 私服3.1 需求正式开发，不同的项目组开发不同的工程。maven_dao工程开发完毕，发布到私服。 maven_service 从私服下载 dao 3.2 分析​ 公司在自己的局域网内搭建自己的远程仓库服务器，称为私服，私服服务器即是公司内部的 maven 远程仓库，每个员工的电脑上安装 maven 软件并且连接私服服务器，员工将自己开发的项目打成 jar 并发布到私服服务器，其它项目组从私服服务器下载所依赖的构件（jar） 。​ 私服还充当一个代理服务器，当私服上没有 jar 包会从互联网中央仓库自动下载，如下图： 3.4 将项目发布到私服​ 企业中多个团队协作开发通常会将一些公用的组件、开发模块等发布到私服供其它团队或模块开发人员使用。​ 本例子假设多团队分别开发 maven_dao、maven_service、maven_web，某个团队开发完在maven_dao会将 maven_dao 发布到私服供 maven_service团队使用，本例子会将 maven_dao 工程打成jar 包发布到私服 *配置 * 第一步： ​ 需要在客户端即部署 maven_dao工程的电脑上配置 maven环境，并 修改 settings.xml 文件，配置连接私服的用户和密码 。​ 此用户名和密码用于私服校验，因为私服需要知道上传的账号和密码是否和私服中的账号和密码一致。 12345678910&lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; releases 连接发布版本项目仓库snapshots 连接测试版本项目仓库 第二步： 配置项目 pom.xml ​ 配置私服仓库的地址，本公司的自己的 jar 包会上传到私服的宿主仓库，根据工程的版本号决定上传到哪个宿主仓库，如果版本为 release 则上传到私服的 release 仓库，如果版本为snapshot 则上传到私服的 snapshot仓库 1234567&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;url&gt;http://localhost:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; *测试 * 将项目 dao 工程打成 jar 包发布到私服： 1、首先启动 nexus 2、对 maven_dao工程执行 deploy 命令 ​ 根据本项目pom.xml中version定义决定发布到哪个仓库，如果version定义为snapshot，执行deploy后查看nexus的snapshot仓库，如果 version定义为release则项目将发布到nexus的 release仓库，本项目将发布到 snapshot仓库 3.5 从私服下载 jar包​ 没有配置 nexus 之前，如果本地仓库没有，去中央仓库下载，通常在企业中会在局域网内部署一台私服服务器，有了私服本地项目首先去本地仓库找 jar，如果没有找到则连接私服从私服下载 jar 包，如果私服没有 jar 包私服同时作为代理服务器从中央仓库下载 jar 包，这样做的好处是一方面由私服对公司项目的依赖 jar 包统一管理，一方面提高下载速度，项目连接私服下载 jar 包的速度要比项目连接中央仓库的速度快的多。 ​ 本例子测试从私服下载 maven_dao 工程 jar 包 *管理仓库组 * ​ nexus中包括很多仓库，hosted中存放的是企业自己发布的jar包及第三方公司的jar包，proxy 中存放的是中央仓库的 jar，为了方便从私服下载 jar 包可以将多个仓库组成一个仓库组，每个工程需要连接私服的仓库组下载 jar 包。 在 setting.xml 中配置仓库 ​ 在客户端的 setting.xml 中配置私服的仓库，由于 setting.xml 中没有 repositories 的配置标签需要使用 profile 定义仓库。 1234567891011121314151617181920212223242526272829&lt;profile&gt; &lt;!--profile 的 id--&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!--仓库 id，repositories 可以配置多个仓库，保证 id 不重复--&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!--仓库地址，即 nexus 仓库组的地址--&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;!--是否下载 releases 构件--&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;!--是否下载 snapshots 构件--&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;!-- 插件仓库，maven 的运行依赖插件，也需要从私服下载插件 --&gt; &lt;pluginRepository&gt; &lt;!-- 插件仓库的 id 不允许重复，如果重复后边配置会覆盖前边 --&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repositories&lt;/name&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; 使用 profile 定义仓库需要激活才可生效 123&lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 测试从私服下载 jar 包 测试 1：局域网环境或本地网络即可 在maven_service 工程中添加以上配置后，添加 maven_dao 工程的依赖，删除本地仓库中 maven_dao工程，同时在 IDEA 中关闭 maven_dao工程。 观察控制台： 项目先从本地仓库找 maven_dao，找不到从私服找，由于之前执行 deploy 将 maven_dao 部署到私服中，所以成功从私服下载 maven_dao 并在本地仓库保存一份。 测试 2：需要互联网环境 在项目的 pom.xml 添加一个依赖，此依赖在本地仓库和私服都不存在，maven 会先从本地仓库找，本地仓库没有再从私服找，私服没有再去中央仓库下载，jar 包下载成功在私服、本地仓库分别存储一份。 4.把第三方 jar 包放入本地仓库或私服4.1 导入本地库​ 随便找一个jar包测试，可以先CMD进入到jar包所在位置，运行 ​ mvn install:install-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37 -Dfile= fastjson-1.1.37.jar -Dpackaging=jar 4.2 导入私服​ 需要在 maven 软件的核心配置文件 settings.xml 中配置第三方仓库的 server 信息 12345&lt;server&gt; &lt;id&gt;thirdparty&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; ​ 才能执行一下命令 mvn deploy:deploy-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37-Dpackaging=jar -Dfile=fastjson-1.1.37.jar-Durl=http://localhost:8081/nexus/content/repositories/thirdparty/-DrepositoryId=thirdparty 4.3 参数说明DgroupId 和 DartifactId 构成了该 jar 包在 pom.xml 的坐标，项目就是依靠这两个属性定位。自己起名字也行。Dfile 表示需要上传的 jar 包的绝对路径。Durl 私服上仓库的位置，打开 nexus——&gt;repositories菜单，可以看到该路径。DrepositoryId 服务器的表示 id，在 nexus 的configuration 可以看到。Dversion 表示版本信息，关于 jar 包准确的版本： 包的名字上一般会带版本号，如果没有那可以解压该包，会发现一个叫 MANIFEST.MF 的文件，这个文件就有描述该包的版本信息。 比如 Specification-Version: 2.2 可以知道该包的版本了。 上传成功后，在 nexus 界面点击3rd party 仓库可以看到这包。","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"JVM&垃圾回收","slug":"JVM&垃圾回收","date":"2021-05-08T13:19:59.138Z","updated":"2021-04-07T14:48:19.865Z","comments":true,"path":"jvmAndgc/","link":"","permalink":"http://tonymua.top/jvmAndgc/","excerpt":"1.JRE、JDK JRE：Java的运行时环境，JVM的标准加上实现的一大堆基础类库。 JDK：包含JRE，还提供了一些小工具，如Javac、Java、Jar。 2.JVM","text":"1.JRE、JDK JRE：Java的运行时环境，JVM的标准加上实现的一大堆基础类库。 JDK：包含JRE，还提供了一些小工具，如Javac、Java、Jar。 2.JVM 3.类的加载过程 加载将外部的.class文件加载到方法区。 验证不能将任何的.class文件都加载，不符合规范的将抛出java.lang.VerifyError错误。(如低版本的JVM无法加载一些高版本的类库) 准备为一些类变量分配内存，并将其初始化为默认值。此时，实例对象还没有分配内存，所以这些动作是在方法区上进行的。 123456789101112131415161718code-snippet 1： public class A &#123; //类变量 static int a ; public static void main(String[] args) &#123; System.out.println(a); &#125; &#125;a:0code-snippet 2： public class A &#123; public static void main(String[] args) &#123; //局部变量 int a ; System.out.println(a); &#125; &#125;编译错误 类变量有两次赋初始值的过程：1.准备阶段，赋予初始值(也可以是指定值) 2.初始化阶段，赋予程序员指定的值 局部变量不存在准备阶段，如果没有赋予初始值就不能使用 解析将符号引用替换成直接引用符号引用：一种定义，可以是任何字面上的含义直接引用：直接指向目标的指针、相对变量，直接引用的对象都存在于内存中 类或接口的解析 类方法的解析 接口方法的解析 字段解析 初始化初始化成员变量 123456789101112public class A &#123; static int a = 0 ; static &#123; a = 1; b = 1; &#125; static int b = 0; public static void main(String[] args) &#123; System.out.println(a); //a:1 System.out.println(b); //b:0 &#125; &#125; static语句块只能访问到定义在static语句块之前的变量 JVM会保证在子类的初始化方法执行之前，父类的初始化方法已经执行完毕 类初始化顺序 父类静态变量、静态代码块(只有第一次加载类时执行) 子类静态变量、静态代码块(只有第一次加载类时执行) 父类非静态代码块 父类构造器 子类非静态代码块 子类构造器 4.clinit和init123456789101112131415161718192021222324252627public class A &#123; static &#123; System.out.println(\"1\"); &#125; public A()&#123; System.out.println(\"2\"); &#125; &#125; public class B extends A &#123; static&#123; System.out.println(\"a\"); &#125; public B()&#123; System.out.println(\"b\"); &#125; public static void main(String[] args)&#123; A ab = new B(); ab = new B(); &#125; &#125;// 1// a// 2// b// 2// b static字段和static代码块属于类，在类的初始化阶段就被执行，类的信息存放在方法区，同一个类加载器只有一份，所以上面的static只会执行一次，对应clinit方法。 对象初始化，在new一个新对象时，会调用构造方法来初始化对象的属性，对应init，每次新建对象都会执行。 5.双亲委派机制除了顶层的启动类加载器以外，其余的类加载器，在加载之前，都会委派给其父加载器进行加载。这样一层层向上传递，直到祖先们都无法胜任，它才会真正的加载。 6.引用级别 强引用当内存空间不足时，JVM抛出OutOfMemoryError。即使程序异常终止，这种对象也不会被回收，是最普通最强硬的一种存在，只有在和GC Roots断绝关系时才会被消灭掉。 软引用用于维护一些可有可无的对象。在内存足够时，软引用对象不会被回收，内存不足时，系统会回收软引用对象。如果回收了软引用对象仍然没有足够的内存，才会抛出内存溢出异常。软引用可以和引用队列联合使用，如果软引用的对象被垃圾回收，JVM就会把这个软引用加入到与之关联的引用队列中。 弱引用垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象，它拥有更短的生命周期。 虚引用如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。虚引用必须和引用队列联合使用，当垃圾回收准备回收一个对象时，如果发现它还有虚引用，就会在回收对象之前，把这个虚引用加入到与之关联的引用队列中。 7.典型OOM场景除了程序计数器，其它区域都有可能会发生OOM，但最常见的还是发生在堆上。 内存容量太小了，需要扩容，或者需要调整堆的空间 错误的引用的方式，发生了内存泄漏。如线程池里的线程，在复用的情况下忘记清理ThreadLocal的内容。 接口没有进行范围校验，外部传参超出范围。比如数据库查询时的每页条数等。 对堆外内存无限制的使用。这种情况更加严重，会造成操作系统内存耗尽。 8.垃圾回收算法 标记清除 标记：从根集合扫描，对存活的对象进行标记 清除：从堆内粗从头到尾进行线性遍历，回收不可达对象内存 标记整理 标记：从根集合扫描，对存活的对象进行标记 整理：移动所有存活的对象，按照内存地址排序，内存地址以后的内存全部回收。 复制算法分对象面和空闲面，对象在对象面创建，回收时，存活的对象被从对象面复制到空闲面，后将对象面所有对象清除。 分代收集把死的快的对象所占区域，叫作年轻代。其他活的长的对象所占的区域，叫作老年代。 年轻代：使用复制算法年轻代分为：一个伊甸园空间(Eden)，两个幸存者空间(Survivor)当年轻代中的Eden区分配满的时候，就会触发年轻代的GC(Minoe GC)。 在Eden区执行了第一次GC之后，存活的对象会移动到其中一个Survivor区(from) Eden再次GC，这时会采用复制算法，将Eden和from区一起清理。存活的对象会被复制到to区，接下来清空from区就可以了。 Eden：from：to = 8：1：1 -XX:SurvivorRatio 默认为8 TLAB：JVM默认给每个线程开辟一个buffer区域来加速对象分配，这个buffer就放在Eden区。对象的分配优先在TLAB上分配，但通常TLAB很小，所以对象比较大时，会在Eden的共享区域进行分配。 老年代：使用标记清除、标记整理算法 9.对象如何进入老年代 提升每当发生一次Minor GC，存活下的对象年龄会加1，达到阈值(-XX:+MaxTenuringThreshold，最大值为15)，就会提升到老年代。 分配担保每次存活的对象，都会放入其中一个幸存区，默认比例为10%。但无法保证每次存活的对象小于10%，当Survivor空间不够，就需要依赖其他内存(老年代)进行分配担保。 大对象直接在老年代分配超过某个大小的对象将直接在老年代分配，-XX:PretenureSizeThreshold进行配置，默认为0。 动态对象年龄判定有的垃圾回收算法，并不需要年龄达到15，会使用一些动态的计算方法，如幸存区中相同年龄对象大小的和大于幸存区的一半，大于或等于age的对象将直接进入老年代 10.垃圾回收器 年轻代垃圾收集器 Serial垃圾收集器处理GC的只有一条线程，并且在垃圾回收过程中暂停一切用户线程。 ParNew垃圾收集器Serial的多线程版本，多条GC线程并行的进行垃圾清理，清理过程中依然要停止用户线程。 Parallel Scavenge垃圾收集器另一个多线程版本的垃圾回收器。与ParNew的主要区别： Parallel Scacenge：追求CPU吞吐量，适合没有交互的后台计算。弱交互强计算。 ParNew：追求降低用户停顿时间，适合交互式应用。强交互弱计算。 老年代垃圾收集器 Serial Old垃圾收集器与年轻代的Serial垃圾收集器对应，都是单线程版本，同样适用客户端使用。年轻代的Serial，使用复制算法，老年代的Serial Old，使用标记-整理算法。 Parallel OldParallel Scavenge的老年代版本，追求CPU吞吐量。 CMS垃圾收集器垃圾收集时用户线程和GC线程可以并发执行。 11.CMS回收过程Minor GC：发生在年轻代的GC Major GC：发生在老年代的GC Full GC：全堆垃圾回收，如Metaspace区引起年轻代和老年代的回收 CMS(主要并发标记清除收集器)，年轻代使用复制算法，老年代使用标记-清除算法 初始标记初始标记阶段，只标记直接关联GC root的对象，不用向下追溯。最耗时的就是tracing阶段，极大地缩短了初始标记阶段，所以该过程时间较短，这个过程是STW的。 并发标记在初始标记的基础上，进行并发标记。tracing，标记所有可达的对象。这个阶段会比较久，但却可以和用户线程并行。 有些对象，从新生代晋升到了老年代 有些对象，直接分配到了老年代 老年代或者新生代的对象引用发生了变化 并发预清理不需要STW，目的是缩短重新标记的时间。这个时候，老年代中被标记为dirty的卡页中的对象，就会被重新标记，然后清除掉dirty的状态。由于这个阶段也是可以并发的，有可能还会有处于dirty状态的卡页。 并发可取消的预清理重新标记阶段是STW的，所以会有很多次预清理动作。可以在满足某些条件时，可以终止，如迭代次数、有用工作量、消耗的系统时间等。 意图：避免回扫年轻代的大量对象；当满足重新标记时，自动退出。 重新标记CMS尝试在年轻代尽可能空的情况下运行重新标记，以免接连多次发生STW。这是CMS垃圾回收阶段的第二次STW阶段，目标是完成老年代中所有存活对象的标记。 并发清理用户线程被重新激活，目标时删掉不可达对象。 由于CMS并发清理阶段用户线程还在运行中，CMS无法在当次GC中处理它们，只好留在下一处GC时再清理掉，这一部分垃圾称为”浮动垃圾”。 并发重置与用户线程并发执行，重置CMS算法相关的内部数据，为下一次GC循环做准备。 12.内存碎片 CMS执行过程中，用户线程还在运行，如果老年代空间快满了，才开始回收，用户线程可能会产生”Concurrent Mode Failure”的错误，这时会临时启用Serial Old收集器来重新进行老年代垃圾收集，这样STW会很久。 CMS对老年代回收的时候，并没有内存的整理阶段。程序长时间运行后，碎片太多，如果你申请一个稍大的对象，就会引起分配失败。(1) UseCMSCompactAtFullCollection(默认开启)，在进行Full GC时，进行碎片整理。内存碎片整理是无法并发的，STW时间较长。(2)CMSFullGCsBeforeCompation(默认为0)，每隔多少次不压缩的Full GC后，执行一次带压缩的Full GC。 13.CMS优势： 低延迟，尤其对大堆来说。大部分垃圾回收过程并发执行。 劣势： 内存碎片问题。Full GC的整理阶段，会造成较长时间的停顿。 需要预留空间，用来收集”浮动垃圾”。 使用更多的CPU资源。 14.G1 G1也是有Eden区和Survivor区的概念的，但内存上不是连续的。小区域(Region)的大小是固定的，名字叫做小队区，小队区可以是Eden，也可以是Survivor，还可以是Old。Region大小（-XX:G1HeapRegionSize=M)一致，为1M-32M字节间的一个2的幂指数。如果对象太大，大小超过Region 50%的对象，将会分配在Humongous Region。垃圾最多的小堆区，会被优先收集。-XX:MaxGCPauseMills=10 15.卡表与RSet 卡表老年代被分成众多的卡页(一般是2的次幂)，卡表就是用于标记卡页状态的一个集合，每个卡表对应一个卡页。如果年轻代有对象分配，而且老年代有对象指向这个新对象，那么这个老年代对象所对应内存的卡页，就会标识为dirty，卡表只需要很小的存储空间就可以保留这些状态。垃圾回收时，就可以先读卡表，进行快速判断。 RSetRSet是一个空间换时间的数据结构。卡表是一种points-out(我引用了谁对象)的结构，而RSet是一种points-into(谁引用了我的对象)的结构。RSet类似一个Hash，key是引用的Region地址，value是引用它的对象的卡页集合 16.G1回收过程 年轻代回收JVM启动时，G1会先准备好Eden区，程序在运行时不断创建到Eden区，当所有的Eden区满了，启动一次年轻代垃圾回收过程。年轻代是一个STW过程，它的跨代引用使用RSet来追溯，会一次回收掉年轻代的所有Region。 并发标记当整个堆内存使用达到一定比例(-XX:InitatingHeapOccupancyPercent 默认45%)，启动并发标记阶段。为混合回收提供标记服务，类似CMS的垃圾回收过程。 混合回收通过并发标记阶段，已经统计了老年代的垃圾占比，在Minor GC之后，如果占比达到阈值(-XX:G1HeapWastePercent 默认是堆大小的5%，该参数可以调整Mixed GC的频率)，下次就会触发混合回收。参数G1MixedGCCountTarget：一次并发标记之后，最多执行Mixed GC的次数。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://tonymua.top/tags/垃圾回收/"},{"name":"GC","slug":"GC","permalink":"http://tonymua.top/tags/GC/"}]},{"title":"Java面试总结","slug":"Java面试总结","date":"2021-05-08T13:19:59.137Z","updated":"2020-04-29T02:44:38.133Z","comments":true,"path":"20365/","link":"","permalink":"http://tonymua.top/20365/","excerpt":"1.网络基础1.1 OSI七层模型: 物理层, 数据链路层, 网络层, 传输层, 会话层, 表示层, 应用层 ​ 【1】物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特。 【2】数据链路层：定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问，这一层通常还提供错误检测和纠正，以确保数据的可靠传输。","text":"1.网络基础1.1 OSI七层模型: 物理层, 数据链路层, 网络层, 传输层, 会话层, 表示层, 应用层 ​ 【1】物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流（就是由1、0转化为电流强弱来进行传输,到达目的地后在转化为1、0，也就是我们常说的数模转换与模数转换），这一层的数据叫做比特。 【2】数据链路层：定义了如何让格式化数据以进行传输，以及如何让控制对物理介质的访问，这一层通常还提供错误检测和纠正，以确保数据的可靠传输。 【3】网络层：在位于不同地理位置的网络中的两个主机系统之间提供连接和路径选择，Internet的发展使得从世界各站点访问信息的用户数大大增加，而网络层正是管理这种连接的层。 【4】传输层：定义了一些传输数据的协议和端口号（WWW端口80等），如：TCP（传输控制协议，传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这种方式传输的）， 主要是将从下层接收的数据进行分段和传输，到达目的地址后再进行重组，常常把这一层数据叫做段。 【5】会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路，主要在你的系统之间发起会话或者接受会话请求（设备之间需要互相认识可以是IP也可以是MAC或者是主机名）。 【6】表示层：可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。例如，PC程序与另一台计算机进行通信，其中一台计算机使用扩展二一十进制交换码（EBCDIC），而另一台则使用美国信息交换标准码（ASCII）来表示相同的字符。如有必要，表示层会通过使用一种通格式来实现多种数据格式之间的转换。 ​ 【7】应用层： 是最靠近用户的OSI层，这一层为用户的应用程序（例如电子邮件、文件传输和终端仿真）提供网络服务。 1.2 TCP三次握手 第一次握手：客户端发送SYN包（seq=x），进入SYN_SENT（同步发送）状态第二次握手：服务器收到SYN包，确认SYN并发送ACK包（ack=x+1），同时发送一个SYN包（seq=y），即SYN+ACK包，进入SYN_RECV（同步接收）状态第三次握手：客户端收到SYN+ACK包，发送确认包ACK(ack=y+1），发送完毕后，客户端和服务器进入ESTABLISHED（连接成功）状态 需要三次握手的原因:为了防止失效的连接请求报文突然又传送到服务器产生错误。 1.3 TCP四次挥手 第一次挥手：客户端发送一个FIN包（seq=x），进入FIN_WAIT（结束等待）状态第二次挥手：服务器收到FIN包，发回一个ACK包(ack=x+1)，进入CLOSE_WAIT（关闭等待）状态第三次挥手：服务器关闭客户端的连接，并发送一个FIN包(seq=y)，进入LAST_ACK（最后确认）状态第四次挥手：客户端发回ACK(ack=y+1)包确认，发送完毕后，连接断开 需要四次挥手的原因:确保数据能够完全传输。 1.4 TCP 和 UDP的区别 (1) TCP是一种面向连接的可靠传输协议，UDP是面向无连接的不可靠传输协议(2) TCP支持报文传输，还支持字节流的传输。而UDP协议只支持传输报文 TCP:20个字节 UDP:8个字节(3) TCP数据报格式比较复杂，传输过程数据不容易丢失和出错，而UDP数据报格式较为简单，容易丢失(4) TCP传输在接收端会进行重排，所以是有序的，UDP则不保证有序(5) TCP速度慢，UDP速度快(6) TCP有流量控制和拥塞控制，而UDP没有 1.5 Get与Post的区别 (1) GET请求一般用于获取服务器上的资源，是幂等的。POST请求一般用于对服务器上资源进行更新，非幂等的（幂等即每次请求返回结果一样）(2) GET请求没有请求体，请求参数跟是在URL后面的，所以使用GET请求时请求参数用户是可以直接看到的。POST请求有请求体，请求参数放在请求体，对用户是不可见的。相对来说POST请求比GET请求更安全(3) GET请求的参数长度有限制，最多只能有1024个字节, 这是因为URL长度有限导致的。POST请求的参数长度可以认为是无限制的 1.6 forward 和 redirect的区别 (1) forward为转发，进行forward操作后，请求URL不发生变化，并且会把请求的数据携带到下一个请求中。redirect是重定向，进行redirect操作后，请求URL是发生变化的(2) forward是服务器内部请求转发，不可以请求到其它站点，redirect是服务器通知客户端重新请求，可以请求到其它站点(3) forward速度快，redirect速度慢 1.7 cookie 和 session的区别 (1) cookie由于把信息保存在客户端中。session把信息保存在服务器中(2) cookie性能更高一点，速度较快，用户的信息存在各自的浏览器中，可以分担服务器的一部分存储工作。session速度较慢，所有用户的信息都存在服务器中，在高并发时必然影响服务器性能(3) cookie有限制大小，在4K以内。session没有限制(4) cookie对用户是透明的，安全性低，不重要的或者可以公开的信息保存在cookie。session对用户是不可见的，安全性高，重要信息应该保存在session 1.8 Http与Https的区别 (1) https协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 (2) http是超文本传输协议，信息是明文传输，https则是具有安全性的SSL加密传输协议。 (3) http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 (4) http的连接很简单，是无状态的。Https协议是由SSL+Http协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。(无状态的意思是其数据包的发送、传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。) 1.9 在浏览器地址键入URL, 按下回车之后经历的流程 (1) DNS解析(查询缓存) (2) TCP连接(三次握手) (3) 发送Http请求 (4) 服务器处理请求并返回Http报文 (5) 浏览器解析渲染页面 (6) 连接结束(四次挥手) 1.10 Http请求常见状态码 (1) 200 OK，请求成功(2) 404 Not Found，对应的URL上不存在资源(3) 405 Method Not Allowed，请求不被允许，即请求方式错误(4) 500 Internal Server Error，服务器内部错误，发现严重BUG，要及时修复 2.数据库2.1 索引的作用？和它的优点缺点是什么？ ​ 索引就一种特殊的查询表，数据库的搜索可以利用它加速对数据的检索。它很类似与现实生活中书的目录，不需要查询整本书内容就可以找到想要的数据。索引可以是唯一的，创建索引允许指定单个列或者是多个列。缺点是它减慢了数据录入的速度，同时也增加了数据库的尺寸大小。 2.2 什么样的字段适合建索引? (1) 经常被查询的字段 (2) 不为空且字段值不重复 (3) 字段的值不经常被修改 2.3 Hash索引与B+树索引 时间复杂度分别为O(1)和O(logN) (1) 这和业务场景有关。只选一个数据，hash更快（o(1)）。数据库中经常会选择N条如果使用hash索引那就是o(n)，这时候由于B+树索引有序(o(logn))，且叶子节点上有链表相连，它的查询效率比hash就快很多了 (2) 索引存储在硬盘上，一般来说索引本身很大，不能一次性全部存在内存中，B+树的设计可以允许数据分批加载，同时树的高度较低，查找效率高 (3) 大家都知道硬盘的I/O速度相比内存来说非常慢，而索引是用于加快查询速度的，需要减少I/O操作 2.4 密集索引与稀疏索引的区别 (1) 密集索引文件中的每个搜索码值都对应一个索引值 (2) 稀疏索引文件只为索引码的某些值建立索引项 MyISAM:不管是主键索引，唯一键索引还是普通索引都是稀疏索引 InnoDB:若一个主键被定义, 该主键则作为密集索引; 若没有主键被定义, 该表的第一个唯一非空索引则作为密集索引; 若不满足以上条件, InnoDB内部会生成一个隐藏主键(密集索引); 若主键索引存储相关键位和其对应的主键值, 包含两次查找 2.5 数据库优化方法 (1) 选取最适用的字段属性 (2) 使用连接(JOIN)的方式来代替子查询 (3) 使用联合(UNION)来代替手动创建的临时表 (4) 事务 2.6 数据库ACID的特性 原子性:指事务是一个不可分割的工作单位, 事务的操作要么都发生, 要么都不发生 一致性:指事务前后数据的完整性必须保持一致 隔离性:指多个用户并发访问数据库时, 一个用户的事务不能被其他用户的事务所干扰, 多个并发事务之间数据要相互隔离 持久性:指一个事务一旦提交, 它对数据库中数据的改变就是永久性的, 即便数据库发生故障也不应该对其有任何影响 2.7 悲观锁与乐观锁 悲观锁:当我们要对一个数据库中的一条数据进行修改的时候，为了避免同时被其他人修改，最好的办法就是直接对该数据进行加锁以防止并发。这种借助数据库锁机制，在修改数据之前先锁定，再修改的方式被称之为悲观并发控制。 乐观锁:乐观锁是相对悲观锁而言的，乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息，让用户决定如何去做。 2.8 数据库的三范式 第一范式:强调的是列的原子性, 即列不能够再分成其他几列 第二范式:首先是1NF, 另外包含两部分内容, 一是表必须有一个主键; 二是没有包含在主键中的列必须完全依赖于主键, 而不能只依赖于主键的一部分 在1NF基础上, 任何非主属性不依赖与其它非主属性(在2NF基础上消除传递依赖) 第三范式:第三范式是第二范式的一个子集, 即满足第三范式必须满足第二范式 首先是2NF, 另外非主键必须直接依赖于主键, 直接依赖于主键, 不能存在传递依赖. 即不能存在: 非主键列A依赖于非主键列B, 非主键列B依赖于主键的情况 2.9 什么是内联接、左外联接、右外联接？ (1) 内联接（Inner Join）：匹配2张表中相关联的记录。(2) 左外联接（Left Outer Join）：除了匹配2张表中相关联的记录外，还会匹配左表中剩余的记录，右表中未匹配到的字段用NULL表示。(3) 右外联接（Right Outer Join）：除了匹配2张表中相关联的记录外，还会匹配右表中剩余的记录，左表中未匹配到的字段用NULL表示。 2.10 数据库隔离级别 脏读（Read out of invalid data)：指事务A读到了事务B还没有提交的数据，但事务B又进行了回滚，产生了脏数据，事务A读取到的数据就是脏数据，依据脏数据所做的操作可能是不正确的。 不可重复读（Unrepeatable Read)：指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据，即原始读取不可重复。这是由于在查询间隔，被另一个事务修改并提交了。与脏读的区别在于，脏读读取到另一个事务未提交的数据，而不可重复读是读取了前一事务提交的数据。 幻读（Phantom Read)：指在一个事务的两次查询中数据笔数不一致，例如有一个事务A查询了几列(Row)数据，而另一个事务B却在此时插入了新的几列数据，先前的事务A在接下来的查询中，就会发现有几列数据是它先前所没有的，就好像发生幻觉一样。 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（读未提交） 可能 可能 可能 Read committed（读提交） 不可能 可能 可能 Repeatable read（可重复读） 不可能 不可能 可能 Serializable（序列化 ） 不可能 不可能 不可能 2.11 MyISAM 和 InnoDB的区别是什么? (1) MyIASM是非事务安全的，而InnoDB是事务安全的 (2) MyIASM锁的粒度是表级的，而InnoDB支持行级锁也支持表级锁 (3) MyIASM支持全文类型索引，而InnoDB不支持全文索引 (4) MyIASM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyIASM (5) MyIASM表保存成文件形式，跨平台使用更加方便 MyISAM适用场景:频繁执行全表count语句; 对数据进行增删改的频率不高, 查询非常频繁; 没有事务 InnoDB适用场景:数据库增删改查都相当频繁; 可靠性要求比较高，要求支持事务 2.12 InnoDB可重复读隔离级别下如何避免幻读 表象：快照读（非阻塞读）—伪MVCC 内在：next-key锁（行锁+gap锁） 对主键索引或者唯一索引会用Gap锁吗 如果where条件全部命中，则不会用Gap锁，只会加记录锁 如果where条件部分命中或者全不命中，则会加Gap锁 2.13 关键语法 (1) group by:满足”select子句中的列名必须为分组列或列函数”; 列函数对于group by 子句定义的每个组各返回一个结果 12345678910select student_id,count(course_id),sum(score),course_id from score group by student_idselect s.student_id,stu.name,count(s.course_id),sum(s.score)from score s, student stuwhere s.student_id=stu.student_idgroup by s.student_id (2) having:通常与group by子句一起使用; where过滤行, having过滤组; 出现在同一sql的顺序: where&gt;group by&gt;having 123456789101112select student_id,avg(score) from scoregroup by student_idhaving avg(score)&gt;60select stu.student_id,stu.namefrom student stu, score s where stu.student_id=s.student_idgroup by s.student_idhaving count(*)&lt;(select count(*) from course) 3.Redis3.1 Memcache与Redis的区别 Memcache:代码层次类似hash, 支持简单数据类型, 不支持数据持久化存储, 不支持主从, 不支持分片 Redis:数据类型丰富, 支持数据磁盘持久化存储, 支持主从, 支持分片 3.2 为什么Redis能这么快 (1) 完全基于内存, 绝大部分请求是纯粹的内存操作, 执行效率高 (2) 数据结构简单, 对数据操作也简单 (3) 采用单线程, 避免了频繁的上下文切换. 单线程也能处理高并发请求, 想多核也可以启动多实例 (4) 采用了非阻塞I/O多路复用机制 3.3 Redis的数据类型 String:最基本的数据类型, 二进制安全 Hash:String元素组成的字典, 适用于存储对象 List:列表, 按照String元素插入顺序排序 Set:String元素组成的无序集合, 通过哈希表实现, 不允许重复 ZSet(Sorted Set):通过分数来为集合中的成员进行从小到大的排序 3.4 从海量数据里查询某一固定前缀的key 注意:摸清数据规模, 即问清楚数据边界 KEYS pattern：查找所有符合给定模式pattern的key 缺点： KEYS指令一次性返回所有匹配的key； 键的数量过大会使得服务卡顿； SCAN cursor [MATCH pattern] [COUNT count] 基于游标的迭代器，需要基于上一次的游标延续之前的迭代过程； 以0作为游标开始一次新的迭代，直到命令返回游标0完成一次遍历； 不保证每次执行都返回某个给定数量的元素，支持模糊查询； 对于增量式迭代命令，一次返回的数量不可控，只能是大概率符合count参数； 3.5 何通过Redis实现分布式锁 set key value[EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置键的过期时间为second（秒） PX milliseconds：设置键的过期时间为millisecond（毫秒） NX：只在键不存在的时候，才对键进行设置操作，效果等同于setnx XX：只在键已存在的时候，才对键进行设置操作 SET操作成功完成时，返回OK，否则则返回nil 代码实现例如： 1234567RedisService redisService = SpringUtils.getBean(RedisService.class);String result = redisService.set(lockKey,requestId,SET_IF_NOT_EXIST, SET_WITH_WITH_EXPIRE_TIME,expireTime);if(\"OK\".equals(result))&#123; //执行独占资源逻辑 doOcuppiedWork();&#125; 3.6 如何应对缓存穿透和缓存雪崩问题 缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。 (1) 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 (2) 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 (3) 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。 缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。 (1) 给缓存的失效时间，加上一个随机值，避免集体失效。 (2) 使用互斥锁，但是该方案吞吐量明显下降了。 (3) 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。 3.7 Redis和数据库双写一致性问题 ​ 一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 3.8 如何使用Redis做异步队列 (1) 使用List作为队列，RPUSH生产消息，LPOP消费消息。 缺点：没有等待队列中有值就直接消费； 弥补：可以在应用层引入Sleep机制去调用LPOP重试 (2) BLPOP key [key …] timeout：阻塞直到队列有消息就能够返回或超时 缺点：只能供一个消费者消费 (3) pub/sub：主题发布-订阅模式 ​ 发送者（publish）发送消息，订阅者（subscribe）接收消息；订阅者可以订阅任意数量的频道（Topic）； 缺点：消息的发布是无状态的，无法保证可达性，即发送完该消息无法保证该消息被接收到。若想解决该问题需要使用专业的消息队列，例如Kafka等。 3.9 Redis如何做持久化 (1) RDB(快照)持久化:保存某个时间点的全量数据快照 (2) AOF(Append-Only-File)持久化：保持写状态 RDB和AOF的优缺点： 类别 优点 缺点 RDB 全量数据快照，文件小，恢复快 无法保存最近一次快照之后的数据，会丢失这部分的数据 AOF 可读性高，适合保存增量数据，数据不易丢失 文件体积大，恢复时间长 (3) RDB-AOF混合持久化方式 ​ 在Redis 4.0之后推出了混合持久化方式，而且作为默认的配置方式。先以RDB方式从管道写全量数据再使用AOF方式从管道追加。AOF文件先半段是RDB形式的全量数据，后半段是Redis命令形式的增量数据。 ​ BGSAVE做镜像全量持久化，AOF做增量持久化。因为BGSAVE需要耗费大量的时间，不够实时，在停机的时候会造成大量数据丢失，这时需要AOF配合使用。在Redis实例重启的时候，会使用BGSAVE持久化文件重新构建内容，再使用AOF重放近期的操作指令，来实现完整恢复重启之前的状态。 3.10 使用Pineline的好处 (1) Pineline和Linux的管道类似； (2) Redis基于请求/响应模型，单个请求处理需要一一应答； (3) Pineline批量执行指令，节省了多次I/O往返的时间； (4) 有顺序依赖的指令建议分批发送； 3.11Redis的同步机制 Redis使用主从同步 (1) 第一阶段:与master建立连接 (2) 第二阶段:向master发送同步请求(SYNC) (3) 第三阶段:接受master发来的RDB数据 (4) 第四阶段:载入RDB文件 4.Java底层知识: JVM4.1 Java平台无关性如何实现? ​ Java源码首先被编译成字节码, 再由不同平台进行解析, Java语言在不同的平台上运行时不需要进行重新编译, Java虚拟机在执行字节码的时候, 把字节码转换成具体平台上的机器指令 4.2 JVM整体组成 类加载器(ClassLoader):依据特定格式, 加载class文件到内存 执行引擎(Execution Engine):对命令进行解析 本地库接口(Native Interface):融合不同开发语言的原生库为Java所用 运行时数据区(Runtime Data Area):JVM内存空间结构模型 4.3 类从编译到执行的过程 (1) 编译器将Hello.java源文件编译成Hello.class字节码文件 (2) ClassLoder将字节码文件转为JVM中的Class对象 (3) JVM利用Class对象实例化为Hello对象 4.4 反射的实现与作用 ​ Java语言编译之后会生成一个.class文件, 反射就是通过字节码文件找到某一个类, 类中的方法以及属性等. 反射的实现主要借助以下四个类: Class: 类的对象, Constructor:类的构造方法, Field:类中的属性对象, Method:类中的方法对象 作用:反射机制指的是程序在运行时能获取自身的信息. 在Java中, 只要给定类的名字, 那么就可以通过反射机制来获取类的所有信息 4.5 类的装载过程 (1) 加载:通过ClassLoader加载class文件字节码, 生成Class对象 (2) 链接: 校验:检查加载的class的正确性和安全性 ​ 准备:为类变量分配存储空间并设置类变量初始值 ​ 解析:JVM将常量池内的符号引用转换为直接引用 (3) 初始化:执行类变量赋值和静态代码块 4.6 loadClass() 和 forName() 的区别 类的装载方式有两种:(1) 隐式装载: 程序在运行过程中当碰到通过new等方式生成对象时, 隐式调用类装载器加载对应的类到JVM中; (2) 显式装载: 通过class.forname()等方法, 显示加载需要的类 使用 loadClass() 方法获得的 Class 对象只完成了类加载过程中的第一步：加载，后续的操作均未进行。 使用 Class.forName() 方法获得 Class 对象是已经执行完初始化的了 4.7 JVM运行时数据区组成(Java内存模型) 程序计数器(Program Counter Register):当前线程所执行的行号指示器。是 JVM 内存区域最小的一块区域。执行字节码工作时就是利用程序计数器来选取下一条需要执行的字节码指令。 虚拟机栈(JVM Stacks):Java 方法执行的内存模型：存储局部变量表，操作数栈，动态链接，方法出口等信息。生命周期与线程相同。 本地方法栈(Native Method Stack):作用与虚拟机栈类似，不同点本地方法栈为 native 方法执行服务，虚拟机栈为虚拟机执行的 Java 方法服务。 堆(Heap):存放对象实例，所有的对象和数组都要在堆上分配。 是 JVM 所管理的内存中最大的一块区域。 方法区(Methed Area):用于存储虚拟机加载的类信息，常量，静态变量等数据。 线程私有的:程序计数器, 虚拟机栈, 本地方法栈 线程共享的:方法区, 堆, 直接内存 4.8 元空间(MetaSpace) 相比永久代(PermGen)的优势 JDK8后去除了永久代 区别:元空间使用本地内存, 而永久代使用的是JVM的内存 字符串常量池存放在永久代中, 容易出现性能问题和内存溢出 类和方法的信息大小难以确定, 给永久代的大小指定带来困难 永久代会为GC带来不必要的复杂性 方便HotSpot与其它JVM如Jrockit的集成 4.9 JVM三大性能调优参数-Xms -Xmx -Xss的含义 -Xss:规定了每个线程虚拟机栈(堆栈)的大小 -Xms:堆的初始值 -Xmx:堆能达到的最大值 4.10 Java内存模型中堆和栈的区别 静态存储:编译时确定每个数据目标在运行时的存储空间需求 栈式存储:数据区需求在编译时未知, 运行时模块入口前确定 堆式存储:编译时或运行时模块入口都无法确定, 动态分配 联系:引用对象, 数组时, 栈定义变量保存堆中目标的首地址 区别:(1) 管理方式: 栈自动释放, 堆需要GC ​ (2) 空间大小: 栈比堆小 ​ (3) 碎片相关: 栈产生的碎片远小于堆 ​ (4) 分配方式: 栈支持静态和动态分配, 而堆仅支持动态分配 ​ (5) 效率: 栈的效率比堆高 5.Java底层知识: GC相关5.1 垃圾回收算法 标记-清除算法 标记:从根集合进行扫描, 对存活的对象进行标记 清除:对堆内存从头到尾进行线性遍历, 回收不可达对象内存 复制算法 分为对象面和空闲面, 对象在对象面上创建, 存活的对象被从对象面复制到空闲面, 将对象面所有对象内存清除 特点:解决碎片化问题; 顺序分配内存, 简单高效; 适用于对象存活率低的场景 标记-整理算法 标记:从根集合进行扫描, 对存活的对象进行标记 清除:移动所有存活的对象, 且按照内存地址次序依次排列, 然后将末端内存地址以后的内存全部回收 特点:避免内存的不连续性; 不用设置两块内存互换; 适用于存活率高的场景 分代收集算法 垃圾回收算法的组合拳; 按照对象生命周期的不同划分区域以采用不同的垃圾回收算法 目的:提高JVM的回收效率 年轻代:尽可能快速的收集掉那些声明周期短的对象 对象如何晋升到老年代: (1) 经历一定Minor次数依然存活的对象 (2) Survivor区中存放不下的对象 (3) 新生成的大对象(-XX:+PretenuerSizeThreshold) 常用的调优参数:-XX:SurvivorRatio:Eden和Survivor的比值, 默认8:1 -XX:NewRatio:老年代和年轻代内存大小比例 -XX:MaxTenuringThreshoid:对象从年轻代晋升到老年代经过GC次数的最大阈值 老年代:存放生命周期较长的对象; 标记-清理算法, 标记-整理算法 Full GC比Minor GC慢, 但执行频率低 触发Full GC的条件:老年代空间不足; 永久代空间不足(JDK8之前);CMS GC时出现promotion failed, concurrent mode failure;Minor GC晋升到老年代的平均大小大于老年代的剩余空间;调用System.gc();使用RMI来进行RPC或管理JDK应用, 每小时执行一次Full GC 5.2 常见垃圾收集器 年轻代常见的垃圾收集器 (1) Serial收集器(-XX:+UseSerialGC, 复制算法):单线程收集, 进行垃圾收集时, 必须暂停所有工作线程; 简单高效, Client模式下默认的年轻代收集器 (2) ParNew收集器(-XX:UseParNewGC, 复制算法):多线程收集, 特点和Serial收集器一样; 单核执行效率不如Serial, 在多核下执行才有优势 (3) Parallel Scavenge收集器(-XX:+UseParallelGC, 复制算法):比起关注用户线程停顿时间, 更关注系统的吞吐量; 在多核下执行才有优势, Server模式下默认的年轻代收集器 老年代常见的垃圾收集器 (1) Serial Old收集器(-XX:+UseSerialOldGC, 标记-整理算法):单线程收集, 进行垃圾收集时, 必须暂停所有工作线程; 简单高效, Client模式下默认的老年代收集器 (2) Parallel Old收集器(-XX:+UseParallelOldGC, 标记-整理算法):多线程, 吞吐量优先 (3) CMS收集器(-XX:+UseConcMarkSweepGC, 标记-清除算法):初始标记:stop-the-world; 并发标记:并发追溯标记, 程序不会停顿; 并发预清理:查找执行并发标记阶段从年轻代晋升到老年代的对象; 重新标记:暂停虚拟机, 扫描CMS堆中的剩余对象; 并发清理:清理垃圾对象, 程序不会停顿; 并发重置:重置CMS收集器的数据结构 G1收集器(-XX:+UseG1GC, 复制+标记-整理算法) 将整个Java堆内存划分成多个大小相等的Region; 年轻代和老年代不再物理隔离 特点:并行和并发; 分代收集; 空间整合; 可预测的停顿 ​ 注:相互连线表示可以共存 5.3 Object的finalize()方法的作用是否与C++的析构函数是否相同 (1) 与C++的析构函数不同, 析构函数调用确定, 而它的是不确定的 (2) 将未被引用的对象放置于F-Queue队列 (3) 方法执行随时可能终止 (4) 给予对象最后一次重生的机会 5.4 Java中的各种引用有什么用 强引用:最普遍的引用: Oject obj=new Object(); 抛出OutOfMemoryError终止程序也不会回收具有强引用的对象; 通过将对象设置为null来弱化引用, 使其被回收 软引用:对象处于有用但非必须的状态; 只要当内存空间不足时, GC会回收该引用的对象的内存; 可以用来实现高速缓存 12String str= new String(\"abc\"); //强引用SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str); //软引用 弱引用:非必须的对象, 比软引用更弱一些; GC时会被回收; 被回收的概率也不大,因为GC线程优先级比较低; 适用于引用偶尔被使用且不影响垃圾收集的对象 12String str=new String(\"abc\");WeakReference&lt;String&gt; weakRef=new WeakReference&lt;String&gt;(str); 虚引用:不会决定对象的生命周期; 任何时候都可能被垃圾收集器回收; 跟踪对象被垃圾收集器回收的活动, 起哨兵作用; 必须和引用队列ReferenceQueue联合使用 123String str=new String(\"abc\");ReferenceQueue queue=new ReferenceQueue();PhantomReference ref=new PhantomReference(str,queue); 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会 对象的一般状态 JVM停止运行时终止 软引用 在内存不足时 对象缓存 内存不足时终止 弱引用 在垃圾回收时 对象缓存 GC运行后终止 虚引用 Unknown 标记, 哨兵 Unknown 引用队列:无实际存储结构, 存储逻辑依赖于内部节点之间的关系来表达; 存储关联的且被GC的软引用, 弱引用以及虚引用 6.多线程与并发6.1 进程和线程的区别 (1) 线程不能看做独立应用, 而进程可看作独立应用 (2) 进程有独立的地址空间, 相互不影响, 线程只是进程的不同执行路径 (3) 线程没有独立的地址空间, 多进程的程序比多线程程序健壮 (4) 进程的切换比线程的切换开销大 进程是执行着的应用程序, 而线程是进程内部的一个执行序列. 一个进程可以有多个线程, 线程又叫做轻量级进程 6.2 Java进程和线程的关系 (1) Java对操作系统提供的功能进行封装, 包括进程和线程 (2) 运行一个程序会产生一个进程, 进程包含至少一个线程 (3) 每个进程对应一个JVM实例, 多个线程共享JVM里的堆 (4) Java采用单线程编程模型, 程序会自动创建主线程 (5) 主线程可以创建子线程, 原则上要后于子线程 6.3 Thread中的start和run方法的区别 调用start()方法会创建一个新的子线程并启动, run()方法只是Thread的一个普通方法的调用 6.4 Thread和Runable是什么关系 Thread是实现了Runnable接口的类, 使得run支持多线程; 因类的单一继承, 推荐多使用Runnable接口 6.5 如何给run()方法传参 (1) 构造函数传参 (2) 成员变量传参 (3) 回调函数传参 6.6 如何实现处理线程的返回值 (1) 主线程等待法 (2) 使用Thread类的join()阻塞当前线程以等待子线程处理完毕 (3) 通过Callable接口实现: 通过FutureTask或者线程池获取 6.7 线程的状态 新建(New):创建后尚未启动的线程的状态 运行(Runnable):包含Running和Ready 无限期等待(Waiting):不会被分配CPU执行时间, 需要显式的被唤醒 限期等待(Timed Waiting):在一定时间后会由系统自动的唤醒 阻塞(Blocked):等待获取排它锁 结束(Terminated):已终止线程的状态, 线程已经结束执行 6.8 sleep() 和 wait() 有什么区别 基本差别 sleep是Thread类的方法, wait是Object类中定义的方法 sleep()方法可以在任何地方使用, wait()方法只能在synchornized方法或synchronized块中使用 最主要的本质区别 sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 6.9 notify()与notifyAll()的区别 notifyAll会让所有等待池的线程全部进入锁池去竞争获取锁的机会; notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会 6.10 sleep()和yield()有什么区别 (1) sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会 (2) 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态 (3) sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常 (4) sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性 6.11 如何中断线程 调用interupt(), 通知线程应该中断了(需要被调用的线程配合中断) (1) 如果线程处于被阻塞状态, 那么线程将立即退出被阻塞状态, 并抛出一个InterruptedException异常(在正常运行任务时, 经常检查本线程的中断标志位, 如果被设置了中断标志就自行停止线程) (2) 如果线程处于正常活动状态, 那么会将该线程的中断标志设置为true. 被设置中断标志的线程将继续正常运行, 不受影响 6.12 线程安全问题 主要诱因:存在共享资源(也称临界资源); 存在多条线程共同操作这些共享数据 解决方法:同一时刻有且只要一个线程在操作共享数据, 其他线程必须等到该线程处理完数据后再对共享数据进行操作 6.13 如何保证线程安全？ (1) 通过合理的时间调度，避开共享资源的存取冲突 (2) 在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源 6.14 如何确保N个线程可以访问N个资源同时又不导致死锁 指定获取锁的顺序, 并强制线程按照指定的顺序获取锁 6.15 synchronized和ReentrantLock(再入锁)的区别 (1) synchronized是关键字, ReentrantLock是类 (2) ReentrantLock可以对获取锁的等待时间进行设置, 避免死锁 (3) ReentrantLock可以获取各种锁的信息 (4) ReentrantLock可以灵活的实现多路通知 主要相同点:Lock能完成synchronized所实现的所有功能 主要不同点:Lock有比synchronized更精确的线程语义和更好的性能(竞争激烈的情况下); synchronized会自动释放锁, Lock需要手动在finally从句中释放 6.16 volatile和synchronized的区别 (1) volatile本质是在告诉JVM当前变量在寄存器(工作内存)中的值是不确定的, 需要从主内存中读取; synchronized则是锁定当前变量, 只有当前线程可以访问该变量, 其它线程被阻塞住直到该线程完成变量操作为止 (2) volatile仅能使用在变量级别; synchronized则可以使用在变量, 方法和类级别 (3) volatile仅能实现变量的修改可见性, 不能保证原子性; 而synchronized则可以保证变量修改的可见性和原子性 (4) volatile不会造成线程的阻塞; synchronized可能会造成线程阻塞 (5)volatile标记的变量不会被编译器优化; synchronized标记的变量可以被编译器优化 6.17 为什么使用线程池 (1) 降低资源消耗 (2) 提高响应速度 (3) 提高线程的可管理性 6.18 Java线程池 ThreadPoolExecutor的构造函数 corePoolSize: 核心线程数量 maximumPoolSize: 线程不够用时能够创建的最大线程数 workQueue: 任务等待队列 keepAliveTime: 抢占的顺序不一定, 随机 threadFactory: 创建线程, Executeors.defaultThreadFactory() 线程池的状态 RUNNING: 能接受新提交的任务, 并且也能处理阻塞队列中的任务 SHUTDOWN: 不再接受新提交的任务, 但可以处理存量任务 STOP: 不再接受新提交的任务, 也不处理存量任务 TIDYING: 所有的任务都已终止 TERMINATED: terminated()方法执行完后进入该状态 线程池的大小如何选定 CPU密集型: 线程数=核数或核数+1 I/O密集型: 线程数=CPU核数*(1+平均等待时间/平均工作时间) 6.19 Java中有几种线程池 newFixedThreadPool创建一个指定工作线程数量的线程池, 每当提交一个任务就创建一个工作线程, 如果工作线程数量达到线程池初始的最大数, 则将提交的任务存入到池队列中 newCachedThreadPool创建一个可缓存的线程池. 特点:(1) 工作线程的创建数量几乎没有限制(其实也是有限制的, 数目为Interger.MAX_VALUE), 这样可灵活的往线程池中添加线程 (2) 如果长时间没有往线程中提交任务, 即如果工作线程空闲了指定的时间(默认1分钟), 则改工作线程将自动终止. 终止后, 如果你又提交了新的任务, 则线程池重新创建一个工作线程 newSingleThreadExecutor创建一个单线程化的Executor, 即只创建唯一的工作者线程来执行任务, 如果这个线程异常结束, 会有另一个来取代它, 保证顺序执行 newScheduThreadPool创建一个定长的线程池, 而且支持定时的以及周期性的任务执行, 类似于Timer 7.异常与常用类库7.1 Error和Exception的区别 Error:程序无法处理的系统错误, 编译器不做检查; Exception:程序可以处理的异常, 捕获后可能恢复 前者是程序无法处理的错误, 后者是可以处理的异常 RuntimeException:不可预知的, 程序应当自行避免; 非RuntimeException:可预知的, 从编译器校验的异常 7.2 常见Error以及Exception RuntimeException:(1) NullPointerException-空指针引用异常 (2) ClassCastException-类型强制转换异常 (3) IllegalArgumentException-传递非法参数异常 (4) IndexOutOfBoundsException-下标越界异常 (5) NumberFormatException-数字格式异常 非RuntimeException:(1) ClassNotFoundException-找不到指定class的异常 (2) IOException-IO操作异常 Error:(1) NoClassDefFoundError-找不到class定义的异常 (2)StackoverflowError-深递归导致栈被耗尽而抛出的异常 (3)OutOfMemoryError-内存溢出异常 7.3 Java异常的处理原则 具体明确: 抛出的异常应能通过异常类名和message准确说明异常的类型和产生异常的原因 提早抛出: 应尽可能早的发现并抛出异常, 便于精确定位问题 延迟捕获: 异常的捕获和处理应尽可能延迟, 让掌握更多信息的作用域来处理异常 7.4 Collection体系","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"Java并发编程","slug":"Java并发编程","date":"2021-05-08T13:19:59.135Z","updated":"2021-05-23T10:44:33.078Z","comments":true,"path":"multithreading/","link":"","permalink":"http://tonymua.top/multithreading/","excerpt":"1.多线程基础1.1 实现多线程的方法 实现Runnable接口 123456public class Test_01 implements Runnable&#123; @Override public void run() &#123; System.out.println(\"实现Runnable接口实现多线程\"); &#125;&#125;","text":"1.多线程基础1.1 实现多线程的方法 实现Runnable接口 123456public class Test_01 implements Runnable&#123; @Override public void run() &#123; System.out.println(\"实现Runnable接口实现多线程\"); &#125;&#125; 123456public class Test_02 extends Thread &#123; @Override public void run() &#123; System.out.println(\"继承Thread类实现多线程\"); &#125;&#125; 线程池创建线程 1234567891011121314151617181920212223242526static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 对于线程池而言，本质上是通过线程工厂创建线程的，默认采用DefaultThreadFactory，它会给线程池创建的线程设置一些默认值，如：线程的名字、是否守护线程，以及线程的优先级等。但无论怎么设置这些这些属性，最终还是通过new Thread()创建线程的，只不过这里的构造函数传入的参数要多一些，本质还是通过new Thread()实现的。 实现有返回值的Callable创建线程 12345678910111213141516public class Test_03 implements Callable &#123; @Override public Integer call() throws Exception &#123; int i = new Random().nextInt(); System.out.println(Thread.currentThread().getName() +\" : \"+ i); return i; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 100; i++) &#123; Future&lt;Integer&gt; future = executorService.submit(new Test_03()); &#125; executorService.shutdown(); &#125;&#125; Runnable创建线程是无返回值的，而Callable和与之相关的Future、FutureTask，它们可以把线程执行的结果作为返回值返回。 …… 实现线程只有一种方式 启动线程需要调用start()方法，而start方法最终会调用run()方法，分析run()方法 123456@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; target实际上就是一个Runnable，即使用Runnable接口实现线程时传给Thread类的对象。第二种，继承Thread方式，继承Thread之后，会把run()方法重写，最终还是会调用thread.start()方法启动线程，而start()方法最终也会调用这个已经被重写的run()方法来执行任务。创建线程本质就是构造一个Thread类，不同点在于实现线程运行内容的方式不同，可以通过实现Runnable接口，或继承Thread类重写run()方法。 1.2 实现Runnable接口比继承Thread类实现线程更好？ Java不支持多继承，一旦继承了Thread类，就无法再继承其它类，限制了代码的可扩展性。 Runnable里只有一个run()方法，定义了需要执行的内容，实现了Runnable与Thread类的解耦，Thread类负责线程启动和属性设置，权责分明。 1.3 如何正确停止线程？对于Java而言，最正确的停止线程的方式是使用interrupt，但interrupt仅仅起到通知被停止线程的作用，而对于被停止的线程而言，它拥有完全的自主权，即可以选择立即停止，也可以一段时间后停止，也可以不停止。Java希望程序间可以相互通知、相互协作的管理线程，如果贸然停止线程可能会造成一些安全性问题，为了避免造成问题就需要给对方一定的时间来整理收尾工作。 123while (!Thread.currentThread().isInterrupted() &amp;&amp; more work to do) &#123; do more work&#125; 一旦调用某个线程的interrupt后，该线程的中断标记位就会被设置成true，每个线程都有这样的标记位，当线程执行时应定期检查这个标记位。上面代码可以看到，while循环判断语句中，先通过Thread.currentThread().isInterrupt()判断是否被中断，随后检查是否还有工作要做。 1.4 sleep期间能否感受到中断？如果sleep、wait等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，线程是可以感受到中断信号的，并会抛出InterruptedException，同时清除中短信号，将中断标记位设为false。 处理方式： 方法签名抛异常，run()强制try/catch 123void subTask() throws InterruptedException &#123; Thread.sleep(1000);&#125; 要求每一个方法的调用方有义务去处理异常。调用方要不使用try/catch并在catch中正确处理异常，要不将异常声明到方法签名中。如果每层逻辑都遵守规范，便可以将中断信号传递到顶层，最终让run()方法可以捕获到异常。而对于run()方法而言，它本身没有抛出checkedException的能力，只能通过try/catch来处理异常。层层传递异常保障了异常不会被遗漏，而对于run()方法，就可以根据不同的业务逻辑来进行相应的处理。 再次中断 12345678private void reInterrupt() &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); e.printStackTrace(); &#125;&#125; 在catch语句中再次中断线程。如果线程在休眠期间被中断，那么会自动清除中断信号。如果这时手动添加中断信号，中断信号依然可以被捕捉到。 1.5 为什么用volatile标记位的停止方法是错误的？stop()会直接把线程停止，会导致出现数据完整性等问题。suspend()和resume()并不会释放锁，就开始进入休眠，但此时有可能仍持有锁，容易导致死锁问题。 volatile修饰标记位适用的场景 123456789101112131415161718192021222324252627public class VolatileCanStop implements Runnable &#123; private volatile boolean canceled = false; @Override public void run() &#123; int num = 0; while (!canceled &amp;&amp; num &lt; 1000000) &#123; if (num % 10 == 0) &#123; System.out.println(Thread.currentThread().getName() + \":\" + num + \"是10的倍数\"); &#125; num++; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; VolatileCanStop canStop = new VolatileCanStop(); Thread thread = new Thread(canStop); thread.start(); Thread.sleep(3000); canStop.canceled = true; &#125;&#125; 启动线程，经过3s，把volatile修饰的标记位设置为true，那么下一次while循环中判断出canceled的值为true，就跳出while循环，线程停止。 volatile修饰标记位不适用的场景 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class VolatileCanNotStop &#123; public static void main(String[] args) throws InterruptedException &#123; ArrayBlockingQueue storage = new ArrayBlockingQueue(8); Producer producer = new Producer(storage); Thread producerThread = new Thread(producer); producerThread.start(); Thread.sleep(500); Consumer consumer = new Consumer(storage); while (consumer.needMoreNums()) &#123; System.out.println(consumer.storage.take() + \"被消费了\"); Thread.sleep(100); &#125; System.out.println(\"消费者不需要更多数据了。\"); // 一旦消费不需要更多数据了，我们应该让生产者也停下来，但是实际情况却停不下来 producer.canceled = true; System.out.println(producer.canceled); &#125;&#125;class Producer implements Runnable &#123; public volatile boolean canceled = false; BlockingQueue storage; public Producer(BlockingQueue storage) &#123; this.storage = storage; &#125; @Override public void run() &#123; int num = 0; try &#123; while (!canceled &amp;&amp; num &lt;= 10000) &#123; if (num % 50 == 0) &#123; storage.put(num); System.out.println(Thread.currentThread().getName() + \":\" + num + \"是50的倍数，被放到仓库中了\"); &#125; num++; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"生产者结束运行\"); &#125; &#125;&#125;class Consumer &#123; BlockingQueue storage; public Consumer(BlockingQueue storage) &#123; this.storage = storage; &#125; public boolean needMoreNums() &#123; if (Math.random() &gt; 0.97) &#123; return false; &#125; return true; &#125;&#125; 线程被长时间阻塞的情况，就无法及时感受中断：尽管已经把canceled的标记位设置为true，但生产者仍然没有被停止，是因为生产者在执行storage.put(num)时发生阻塞，在它被叫醒之前是没有办法进入下次循环判断canceled的值的，这种情况下volatile没有办法让生产者停下来的，如果用interrupt语句来中断，即使生产者处于阻塞状态，仍然能够感受到中断信号，并做相应处理。 1.6 线程是如何在6种状态之间转换的？线程的6种状态 New(新建) Runnable(可运行) Blocked(被阻塞) Waiting(等待) Timed Waiting(计时等待) Terminated(被终止) New 新建New表示线程被创建但尚未启动的状态：new Thread()新建一个线程时，如果线程没有开始运行start()方法，所以也没有开始执行run()方法里面的代码，此时它的状态就是New。一旦线程调用了start()，就变成Runnable。 Runnable 可运行Java中的Runnable状态对应操作系统线程状态中的两种状态，分别是Running和Ready，即Java中处于Runnable状态的线程有可能正在执行，也有可能没有正在执行，正在等待被分配CPU资源。所以，如果一个正在运行的线程是Runnable状态，当它运行到任务的一半时，执行该线程的CPU被调度去做其他事情，导致该线程暂时不运行，它的状态仍为Runnable，因为它有可能随时被调度回来继续执行任务。 Blocked 被阻塞从Runnable状态进入Blocked状态只有一种可能，就是进入synchronized保护的代码块/方法时没有抢到monitor锁，Blocked仅仅针对synchronized monitor锁。 Waiting 等待线程进入Waiting 没有设置Timeout参数的Object.wait()方法 没有设置Timeout参数的Thread.join()方法 LockSupport.park()方法 Blocked与Waiting的区别是Blocked在等待其它线程释放monitor锁，而Waiting则是在等待某个条件，比如join的线程执行完毕，或者是notify()/notifyAll()。 Timed Waiting 限期等待Waiting和Time Waiting区别：有没有时间限制，Timed Waiting会等待超时，由系统自动唤醒，或者在超时前被唤醒信号唤醒。 线程进入Timed Waiting 设置了时间参数的Thread.sleep(long millis)方法 设置了时间参数的Object.wait(long timeout)方法 设置了时间参数的Thread.join(long millis)方法 设置了时间参数的LockSupport.parkNanos(long nanos)方法和LockSupport.parkUntil(long deadline)方法 Blocked—&gt;Runnable：线程获取monitor锁 Waiting—&gt;Runnable：执行了LockSupport.unpark()，或join的线程运行结束，或者被中断。 Waiting—&gt;Blocked：其它线程调用notify()或notifyAll()，因为唤醒Waiting线程的线程如果调用notify()或notifyAll()，必须首先持有该monitor锁，所以处于Waiting状态的线程被唤醒时拿不到该锁，就会进入Blocked状态，直到执行notify()/notifyAll()的唤醒线程执行完毕并释放monitor锁，才可能轮到它去抢夺这把锁，抢到就会从Blocked状态回到Runnable状态。 TimedWaiting类似，但如果它的超时时间到了且能直接获取到锁/join的线程运行结束/被中断/调用了LockSupport.unpark()，会直接恢复到Runnable状态。 Terminated线程进入Terminated run()方法执行完毕，线程正常退出。 出现一个没有捕获的异常，终止了run()方法，最终导致意外终止。 Tips 线程的状态是按照箭头方向走的，如线程从New不可以进入Blocked，它需要经历Runnable。 线程的生命周期不可逆：一旦进入Runnable就不能回到New状态；一旦被终止就不可能有任何状态的变化。所以一个线程只有一次New和Terminated状态，只有处于中间状态才可以相互转换。 1.7 为什么wait必须在synchronized保护的同步代码中使用？1.8 为什么wait/notify/notifyAll方法被定义在Object类中，而sleep定义在Thread类中？ Java中每个对象都有一把称之为monitor监视器的锁，由于每个对象都可以上锁，这就要求在对象头中有一个用来保存锁信息的位置。这个锁是对象级别的，而非线程级别的，wait/notify/notifyAll也都是锁级别的操作，它们的锁属于对象，所以把它们定义在Object类，因为Object类是所有对象的父类。 如果把wait/notify/notifyAll方法定义在Thread类中，会带有很大的局限性，如一个线程可能持有多个锁。如何明确当前线程等待的是哪把锁呢？既然是让当前线程去等待某个对象的锁，自然应该通过操作对象来实现。 1.9 wait/notify和sleep方法的异同相同点 都可以让线程阻塞 都可以响应interrupt中断：在等待的过程中如果收到中断信号，都可以进行响应，并抛出InterruptedException 不同点 wait方法必须在synchronized保护的代码中使用，而sleep方法并没这个要求。 在同步代码块中执行sleep方法，并不会释放monitor锁，但执行wait方法时会主动释放monitor锁。 sleep方法必须定义一个时间，时间到期后会主动会恢复，而对于没有参数的wait方法而言，意味着永久等待，直到被中断或被唤醒才能恢复，它并不主动恢复。 wait/notify是Object类的方法，而sleep是Thread类的方法。 2.线程安全如果某个对象是线程安全的，即使用时就不需要考虑方法间的协调问题。 2.1 3种典型的线程安全问题 运行结果错误 12345678910111213141516171819202122public class WrongResult &#123; volatile static int i; public static void main(String[] args) throws InterruptedException &#123; Runnable r = new Runnable() &#123; @Override public void run() &#123; for (int j = 0; j &lt; 10000; j++) &#123; i++; &#125; &#125; &#125;; Thread thread1 = new Thread(r); thread1.start(); Thread thread2 = new Thread(r); thread2.start(); thread1.join(); thread2.join(); System.out.println(i); &#125;&#125; i++并不是一个原子操作 发布或初始化导致线程安全问题 12345678910111213141516171819202122232425public class WrongInit &#123; private Map&lt;Integer, String&gt; students; public WrongInit() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; students = new HashMap&lt;&gt;(); students.put(1, \"王小美\"); students.put(2, \"钱二宝\"); students.put(3, \"周三\"); students.put(4, \"赵四\"); &#125; &#125;).start(); &#125; public Map&lt;Integer, String&gt; getStudents() &#123; return students; &#125; public static void main(String[] args) &#123; WrongInit wrongInit = new WrongInit(); System.out.println(wrongInit.getStudents().get(1)); &#125;&#125; students 这个成员变量是在构造函数中新建的线程中进行的初始化和赋值操作，而线程的启动需要一定的时间，但是我们的 main 函数并没有进行等待就直接获取数据，导致 getStudents 获取的结果为 null，这就是在错误的时间或地点发布或初始化造成的线程安全问题。 活跃性问题 分别为死锁、活锁和饥饿 死锁：两个线程之间相互等待对方资源，但同时又互不相让，都想自己先执行，如代码所示。 12345678910111213141516171819202122232425262728293031323334353637383940public class MayDeadLock &#123; Object lock1 = new Object(); Object lock2 = new Object(); public void thread1() throws InterruptedException &#123; synchronized (lock1)&#123; Thread.sleep(500); synchronized (lock2)&#123; System.out.println(\"线程1成功拿到两把锁\"); &#125; &#125; &#125; public void thread2() throws InterruptedException &#123; synchronized (lock2)&#123; Thread.sleep(500); synchronized (lock1)&#123; System.out.println(\"线程2成功拿到两把锁\"); &#125; &#125; &#125; public static void main(String[] args) &#123; MayDeadLock deadLock = new MayDeadLock(); new Thread(new Runnable() &#123; @SneakyThrows @Override public void run() &#123; deadLock.thread1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @SneakyThrows @Override public void run() &#123; deadLock.thread2(); &#125; &#125;).start(); &#125;&#125; 活锁：与死锁类似，不过活锁是活的，因为正在运行的线程并没有阻塞，它始终在运行，缺一直得不到结果。假设有一个消息队列里放着需要被处理的消息，而某个消息由于自身的错误无法被正确处理，同时队列的重试机制会把它放在队列头进行优先重试处理。 饥饿：线程需要某些资源始终得不到，尤其是CPU资源，就会导致线程一直不能运行。 在Java中有1-10的线程优先级，1最低，10最高。如果某个线程的优先级为1，该线程就有可能始终分配不到CPU资源，而导致长时间无法运行。 或者是某个线程始终持有某个文件的锁，其他线程想要修改文件必须先获取锁，这时想要修改文件的线程就会陷入饥饿。2.2 需要额外注意线程安全的场景 访问共享变量和资源 如访问共享对象的属性、访问static静态变量、访问共享的缓存等。 依赖时序的操作 123if (map.containsKey(key)) &#123; map.remove(obj)&#125; 不同数据之间存在绑定关系 不同的数据之间是成组出现的，存在着相互对应或绑定的关系，最典型的就是IP和端口号。 对方没有声明自己是线程安全的 2.3 为什么多线程会带来性能问题单线程是独立工作的，不需要与其他线程进行交互，但多线程之间则需要调度以及协作，调度与协作就会带来性能开销从而产生性能问题。 调度开销 上下文切换：线程数往往大于CPU核心数，操作系统会按照一定的调度算法，给每个线程分配时间片。而在进行调度时就会引起上下文切换，上下文切换会挂起当前正在执行的线程并保存当前的状态，然后寻找下一处即将恢复执行的代码，唤醒下一个线程。 缓存失效：进行了线程调度，切换到其他线程，CPU就会去执行不同的代码，原有的缓存就很有可能失效了，需要重新缓存新的数据。 给被调度到的线程设置最小执行时间，即只有执行完这段时间后，才可能进行下一次的调度，由此减少上下文切换的次数。 协作开销 为了避免共享数据错乱、保证线程安全，就有可能禁止编译器和CPU对其进行重排序等优化，也可能出于同步的目的，反复把线程工作内存的数据flush到主内存，然后再从主内存refresh到其他线程的工作内存中。 2.4 使用线程池的好处 线程池可以解决线程生命周期的系统开销问题，线程池里的线程可以复用，消除了线程创建带来的延迟，从而提高响应速度。 线程池可以统筹内存和CPU的使用，避免资源的使用不当。 线程池可以统一管理资源。 2.5 线程池各参数的含义 线程池的特点： 线程池希望保持较少的线程数，只有在负载变的很大时才增加线程。 线程池只有在任务队列满时才会创建多于corePoolSize的线程，如果使用的是无界队列(如LinkedBlockingQueue)，线程数不会超过corePoolSize。 设置corePoolSize和maxPoolSize为相同的值，可以创建固定大小的线程池。 2.6 线程池有哪几种拒绝策略？ AbortPolicy：拒绝任务时直接抛出一个类型为RejectedExecutionException的RuntimeException，可以感知到任务被拒绝了，可以根据业务逻辑选择重试或放弃提交等。 DiscardPolicy：当新任务被提交后直接被丢弃掉，不会有任何通知。 DiscardOldestOlicy：丢弃任务队列的头节点，通常是存活时间最长的任务，也不会有任何通知。 CallerRunsPolicy：把任务交给提交任务的线程执行，即谁提交任务，谁就负责执行任务。 提交的任务不会被丢弃 提交任务的线程负责执行任务，提交任务的线程被占用，不会再提交新的任务，线程池中的线程也可以利用这段时间执行掉一部分任务，相当于是给了线程池一定的缓冲期。 2.7 有哪6种常见的线程池？什么是Java8的ForkJoinPool? FixedThreadPool 核心线程数和最大线程数是一样的，可以看作是固定线程数的线程池，没有可用的线程的时候，任务会放在队列中等待，任务的长度无限制(LinkedBlockingQueue) CachedThreadPool 线程数几乎可以无限增加(Integer.MAX_VALUE，2^31-1)，该线程池的线程数量不固定，不够使用时自动增加，闲置时自动回收。队列为SynchronousQueue，队列容量为0，实际不存储任务，只对任务进行中转和传递。 ScheduledThreadPool 支持定时或周期的执行任务。 1234567ScheduledExecutorService service = Executors.newScheduledThreadPool(10);//延迟指定时间后执行一次任务，10秒执行一次service.schedule(new Task(), 10, TimeUnit.SECONDS);//以固定的频率执行任务service.scheduleAtFixedRate(new Task(), 10, 10, TimeUnit.SECONDS);//与第二种类似，不过scheduledAtFixedRate以开始时间为起点，时间到就开始第二次，而scheduledWithFixedDelay以任务结束时间为下一次循环的时间起点开始计算service.scheduleWithFixedDelay(new Task(), 10, 10, TimeUnit.SECONDS); SingleThreadExecutor 原理与FixedThreadPool一样，线程只有一个，如果线程在执行过程中发生异常，线程池也会重新创建一个线程来执行后续的任务。适合用于任务需要按被提交的顺序依次执行的场景。 SingleThreadScheduledExecutor 于ScheduledThreadPool类似，如源码所示：只是将ScheduledThreadPool的核心线程数设置为1 1new ScheduledThreadPoolExecutor(1) ForkJoinPool 2.8 线程池常用的阻塞队列 LinkedBlockingQueue 对于FixedThreadPool和SingleThreadExector，它们使用的是容量为Integer.MAX_VALUE的LinkedBlockingQueue，可以任务是无界队列。 SynchronousQueue 对于CachedThreadPool，最大线程数为Integer.MAX_VALUE，所以不需要任务队列来存储任务，一旦有任务提交就直接转发给线程或创建新线程来执行。 DelayedWorkQueue 对于ScheduledThreadPool和SingleThreadScheduledExecutor，DelayedWorkQueue内部元素并不是按照放入的时间排序，而是按照延迟的时间长短对任务进行排序，内部采用的是”堆”的数据结构。 2.9 为什么不应该自动创建线程池？ FixedThreadPool、SingleThreadPool 使用的队列是没有上限的LinkedBlockingQueue，如果处理任务过慢，队列中堆积的任务会越来越多，占用大量内存，导致OOM。 CachedThreadPool 不限制线程的数量，任务特别多时，有可能会创建非常多的线程，最终导致超过了操作系统的上限而无法创建线程，或导致内存不足。 ScheduledThreadPool、SingleThreadScheduledExecutor DelayedWorkQueue也是一个无界队列。 2.10 合适的线程数是多少？ CPU密集型任务 如加密、解密、压缩、计算等大量耗费CPU资源的任务，线程数为CPU核心数的1-2倍。 耗时IO型任务 如数据库、文件的读写、网络通信等并不消耗CPU资源的任务，线程数=CPU核心数*(1+平均等待时间/平均工工作时间) 线程的平均工作时间所占比例越高，就需要越少的线程。线程的平均等待时间所占比例越高，就需要越多的线程。 2.11 如何正确关闭线程？ shutdown() 安全的关闭的一个线程池，调用shutdown()之后，如果还有新任务被提交，线程池会根据拒绝策略直接拒绝后续提交的任务，执行完正在执行的任务和队列中等待的任务后关闭。 isShutdown() 判断线程是否已经开始了关闭工作，即是否执行了shutdown()或shutdownNow() isTerminated() 检测线程池是否真正”终结”了，即线程池已关闭，同时线程池中的所有任务都执行完毕了。 awaitTermination() 判断线程池状态，如给awaitTermination方法传入的参数为10秒，那么它会陷入10秒等待，直到 等待期间(包括进入等待之前)，线程池已关闭并所有任务都执行完毕，相当于线程池”终结”了，方法便返回true。 等待超时时间到后，线程池始终未”终结”，返回false。 等待期间线程被中断，方法抛出InterruptedException异常。 即调用awaitTermination方法后当前线程池会尝试等待一定指定的时间，如果在等待时间内，线程池已关闭并任务都执行完毕，方法返回true，否则返回false。 shutdownNow() 立刻关闭，执行shutdownNow()方法之后，首先会给线程池中的线程发送interrupt中断信号，尝试中断这些任务的执行，然后会将等待的所有任务转移到一个List中并返回。 3.各种各样的”锁”3.1 你知道哪几种锁？分别有什么特点？ 偏向锁/轻量级锁/重量级锁 特指synchronized锁的状态，通过在对象头中的mark word来表明锁的状态。 偏向锁 如果，这把锁一直不存在竞争，就没必要上锁，只需打个标记就行。对象被初始化，还没有线程来获取它的锁时，那么它就是可偏向的，当有第一个线程来访问它并尝试获取锁的时候，它就将这个线程记录下来，以后如果尝试获取锁的线程正是偏向锁的拥有者，就可以直接获取锁，开销很小，性能最好。 轻量级锁 synchronized中的代码是被多个线程交替执行的，并不存在实际的竞争、或只有短时间的竞争，用CAS就可以解决。轻量级锁是指当锁原来是偏向锁时，被另一个线程访问，说明存在竞争，那么偏向锁就会升级为轻量级锁，线程会通过自旋的形式获取锁，而不会陷入阻塞。 重量级锁 重量级锁是互斥锁，它是利用操作系统的同步机制实现的，开销相对较大。当多个线程直接实际竞争，且锁竞争时间长的时候，锁就会膨胀为重量级锁。重量级锁会让其它申请缺拿不到锁的线程进入到阻塞状态。 偏向锁性能最好，可以避免执行CAS操作。而轻量级锁利用自旋和CAS避免了重量级锁带来的线程阻塞和唤醒，性能中等。重量级锁则会把获取不到锁的线程阻塞，性能最差。 可重入锁/不可重入锁 可重入锁指的是线程当前已经持有这把锁了，能在不释放这个锁的情况下，再次获取这把锁。不可重入锁指的是虽然当前持有了这把锁，但如果想再次获取此锁，也必须先要释放锁后才能再次尝试获取。 共享锁/独占锁 共享锁指同一把锁可以被多个线程同时获得，而独占锁指这个锁只能同时被一个线程获得。如读写锁中的读锁是共享锁，而写锁是独占锁。 公平锁/非公平锁 公平锁 如果线程现在拿不到这把锁，那么线程都会进入等待，开始排队，在等待队列等待时间长的线程会优先拿到这把锁，先来先得。 非公平锁 在一定情况下，忽略掉已经在排队的线程，发生插队现象。 悲观锁/乐观锁 悲观锁 在获取资源之前，必须先拿到锁，以便达到”独占”的状态。 乐观锁 并不要求在获取资源前拿到锁，也不会锁住资源，利用CAS理念，在不独占资源的情况下，完成对资源的修改。 自旋锁/非自旋锁 自旋锁 如果线程现在拿不到锁，并不直接陷入阻塞或者释放CPU资源，而是开始利用循环，不停的尝试获取锁。 非自旋锁 拿不到锁就直接放弃，或者进行其它的处理逻辑，如阻塞、排队等。 可中断锁/不可中断锁 synchronized关键字修饰的锁代表的是不可中断锁，一旦线程申请了锁，就没有回头路，只能等拿到锁以后才能进行其它的逻辑处理。 ReentrantLock是一种典型的可中断锁，如使用lockInterruptibly方法在获取锁的过程中，突然不想获取了，可以在中断之后去做其它的事。 3.2 悲观锁与乐观锁 悲观锁 为了确保结果的正确性，会在每次获取并修改数据时，都把数据锁住，让其他线程无法访问。 线程A拿到了锁，并且正在操作同步资源，那么此时线程B就必须进行等待。 当线程A执行完毕后，CPU才会唤醒正在等待这把锁的线程B再次尝试获取锁 如果线程B获取到了锁，才可以对同步资源进行自己的操作。 乐观锁 认为自己在操作资源的时候不会有其他线程干扰，所以并不会锁住被操作对象。为了确保数据正确性，在更新之前，会去对比在修改数据期间，数据有没有被其他线程修改过。 例子： 悲观锁：synchronized关键字和Lock接口 以Lock接口为例，如Lock的实现类ReentrantLock，类中的lock()等方法就是执行加锁，而unlock()方法就是执行解锁()。处理资源之前必须要先加锁并拿到锁，等到处理完之后再解开锁。 乐观锁：原子类 如AtomicInteger在更新数据时，多个线程可以同时操作同一个原子变量。 两种锁各自的使用场景： 悲观锁适合于并发写入多、临界区代码复杂、竞争激烈等场景，此时悲观锁可以避免大量的无用的反复尝试等消耗。 乐观锁适用于读取多，修改少的场景，也适合虽然读写都很多，但是并发不激烈的场景。 3.3 synchronized背后的monitor锁获取和释放monitor锁的时机：线程在进入synchronized保护的代码块之前，会自动获取锁；并且无论是正常退出，还是抛出异常退出，在退出的时候都会自动释放锁。 查看反汇编命令：javac SynTest.java javap -verbose SynTest.class 同步代码块 123456789101112 ......3: monitorenter 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String lagou 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit ...... monitorenter可以理解为加锁，monitorexit理解为释放锁，每个对象维护着一个记录着被锁次数的计数器。未锁定的对象的该计数器未0。 monitorenter 如果该monitor的计数为0，则线程获得该monitor并将其计数设置为1，该线程就是这个monitor的所有者。 如果线程已经拥有了这个monitor，则它将重新进入，并且累加计数。 如果其他线程已经拥有了这个monitor，那么这个线程就会被阻塞，直到这个monitor的计数器变为0，代表这个monitor已经被释放了，于是当前这个线程就会再次尝试获取这个monitor。 monitorexit 作用：将monitor的计数器减1，直到减为0为止。代表这个monitor已经被释放了，已经没有任何线程拥有它了，也就代表着解锁。其他正在等待这个monitor的线程，此时可以再次尝试获取这个monitor的所有权。 同步方法 123456 public synchronized void synMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=0, locals=1, args_size=1...... 被synchronized修饰的方法会有一个ACC_SYNCHRONIZED标志，当某个线程要访问某个方法时，会首先检查方法是否有ACC_SYNCHRONIZED标志，如果有则需要先获得monitor锁，方法执行之后再释放monitor锁。3.4 synchronized与Lock 相同点 synchronized和Lock都是用来保护资源线程安全的 都可以保证可见性 synchronized和ReentrantLock(Lock的一个实现类)都拥有可重入的特点 不同点 用法区别 synchronized关键字可以加在方法上，不需要指定锁对象(此时的锁对象为this)；也可以修饰同步代码块并且自定义monitor对象。而Lock锁对象必须显示的开始加锁lock()和解锁unlock()，并且一般会在finally块中确保用unlock()来解锁，以防止发生死锁。 加解锁顺序不同 对于Lock而言如果有多把Lock锁，Lock可以不完全按照加锁的反序解锁 12345lock1.lock();lock2.lock();...lock1.unlock();lock2.unlock(); synchronized解锁的顺序和加锁的顺序必须完全相反，obj2先解锁，obj1后解锁。 12345synchronized(obj1)&#123; synchronized(obj2)&#123; ... &#125;&#125; synchronized锁不够灵活 一旦synchronized锁已经被某个线程获得了，此时其他线程如果还想获得，那么它只能被阻塞，直到持有锁的线程运行完毕或发生异常从而释放这个锁。Lock类在等待锁的过程中，如果使用的时lockInterruptibly方法，如果等待时间太长，可以中断退出，也可以使用tryLock()等方法尝试获取锁，如果获取不到可以执行其他逻辑。 synchronized锁只能同时被一个线程拥有，但Lock锁没有这个限制。 如在读写锁中的读锁，是可以被多个线程同时拥有的，但synchronized不行。 原理区别 synchronized是内置锁，由JVM实现获取锁和解锁，还分为偏向锁、轻量级锁、重量级锁。Lock根据实现不同，原理也不同，如ReentrantLock内部是通过AQS来获取和释放锁的。 是否可以设置公平/非公平 ReentrantLock可以根据需求来设置公平或非公平，synchronized则不能设置。 如何选择： 最好既不使用Lock也不使用synchronized，尽量使用java.util.concurrent包中的机制。 尽量使用synchronized，避免忘记在finally里忘记unlock。 需要Lock的特殊功能时，如尝试获取锁、可中断、超时功能等，才使用Lock。 3.5 Lock的常用方法 lock() 在线程获取锁时如果锁已被其他线程获取 12345678Lock lock = ...;lock.lock();try&#123; //获取到了被本锁保护的资源，处理任务 //捕获异常&#125;finally&#123; lock.unlock(); //释放锁&#125; tryLock() 用来尝试获取锁，如果当前锁没有被其他线程占用，则获取成功，返回true，否则返回false，代表获取锁失败，可以根据是否能获取到锁来决定后续程序行为。 12345678910Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则做其他事情&#125; tryLock(long time, TimeUnit unit) 和tryLock()类似，tryLock(long time, TimeUnit unit)会有一个超时时间，在拿不到锁时会等待一定的时间，时间期限结束后，还获取不到锁，就会返回false，如果在最开始或等待期间内获取到锁就返回true。 lockInterruptibly() 除非当前线程在获取锁期间被中断，否则会一直尝试获取直到获取到为止。相当于超时时间无限长的tryLock(long time, TimeUnit unit)。 123456789101112 public void lockInterruptibly() &#123; try &#123; lock.lockInterruptibly(); try &#123; System.out.println(\"操作资源\"); &#125; finally &#123; lock.unlock(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; unlock() 用于解锁，对ReentrantLock而言，执行unlock()的时候，内部会把锁的”被持有计数器”减1，直到减到0就代表当前这把锁已经完全释放了，如果减1后计数器不为0，说明这把锁之前被”重入”了，那么锁并没有真正释放，仅仅是减少了持有的次数。 3.6 公平锁与非公平锁公平锁：按照线程请求顺序来分配锁 非公平锁：不完全按照请求的顺序，在一定情况下，可以允许插队。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class FairAndUnfair &#123; static class PrintQueue &#123; private final Lock queueLock = new ReentrantLock(false);//false:非公平锁 true:公平锁 默认false public void printJob(Object document) &#123; queueLock.lock(); try &#123; Long duration = (long)(Math.random() * 10000); System.out.printf(\"%s: PrintQueue: Printing a Job during %d seconds\\n\", Thread.currentThread().getName(), (duration / 1000)); Thread.sleep(duration); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; queueLock.unlock(); &#125; queueLock.lock(); try &#123; Long duration = (long)(Math.random() * 10000); System.out.printf(\"%s: PrintQueue: Printing a Job during %d seconds\\n\", Thread.currentThread().getName(), (duration / 1000)); Thread.sleep(duration); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; queueLock.unlock(); &#125; &#125; &#125; static class Job implements Runnable &#123; private PrintQueue printQueue; public Job(PrintQueue printQueue) &#123; this.printQueue = printQueue; &#125; @Override public void run() &#123; System.out.printf(\"%s: Going to print a job\\n\", Thread.currentThread().getName()); printQueue.printJob(new Object()); System.out.println(); System.out.printf(\"%s: The document has been printed\\n\", Thread.currentThread().getName()); &#125; &#125; public static void main(String[] args) &#123; PrintQueue printQueue = new PrintQueue(); Thread thread[] = new Thread[10]; for (int i = 0; i &lt; 10; i++) &#123; thread[i] = new Thread(new Job(printQueue), \"Thread \" + i); &#125; for (int i = 0; i &lt; 10; i++) &#123; thread[i].start(); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 非公平情况下，存在抢锁”插队”现象，如Thread 0 在释放锁后又能优先获取到锁，虽然此时在等待队列中已经有Thread 1~Thread 9在排队了。 各自的优缺点 源码分析 ReentrantLock中包含一个Sync类，这个类继承自AQS(AbstractQueuedSynchronizer) 1234public class ReentrantLock implements Lock, java.io.Serializable &#123;private static final long serialVersionUID = 7373984872572414699L;/** Synchronizer providing all implementation mechanics */private final Sync sync; Sync有公平锁FairSync和非公平锁NonfairSync两个子类 12static final class NonfairSync extends Sync &#123;...&#125;static final class FairSync extends Sync &#123;...&#125; 公平锁与非公平获取锁的lock()方法唯一区别就在于公平锁在获取锁时多了一个限制条件：hasQueuedPredecessors()为false，这个方法就是在判断在等待队列中是否已经有线程在排队了。公平锁，一旦有线程在排队，当前线程就不再尝试获取锁了；对于非公平锁，无论是否有线程在排队，都会尝试获取一下锁，获取不到的话，再去排队。 tryLock()，一旦有线程释放了锁，那么正在tryLock的线程就能获取到锁，即使设置的是公平锁模式，即使在它之前已经有其他正在等待队列中等待的线程，即tryLock可以插队。调用的是nonfairTryAcquire()，表明是不公平的，和锁本身是否公平锁无关。 123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 3.7 读写锁保证多个线程同时读的效率，同时可以保证有写入操作时的线程安全。 读写锁的获取规则 如果一个线程已经占用了读锁，则此时其他线程如果要申请读锁，可以申请成功。 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁，因为读写不能同时操作。 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或读锁，都必须等待之前的线程释放锁，因为读写、写写不能同时操作。 要么是一个或多个线程同时有读锁，要么是一个线程有写锁，但是两者不会同时出现。即读读共享，其他都互斥。 1234567891011121314151617181920212223242526272829303132333435363738public class ReadWriteLockDemo &#123; private static final ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(false); private static final ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock.readLock(); private static final ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock.writeLock(); private static void read() &#123; readLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到读锁，正在读取\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放读锁\"); readLock.unlock(); &#125; &#125; private static void write() &#123; writeLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到写锁，正在写入\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放写锁\"); writeLock.unlock(); &#125; &#125; public static void main(String[] args) &#123; new Thread(() -&gt; read()).start(); new Thread(() -&gt; read()).start(); new Thread(() -&gt; write()).start(); new Thread(() -&gt; write()).start(); &#125;&#125; 运行结果： 12345678Thread-0得到读锁，正在读取Thread-1得到读锁，正在读取Thread-0释放读锁Thread-1释放读锁Thread-2得到写锁，正在写入Thread-2释放写锁Thread-3得到写锁，正在写入Thread-3释放写锁 读写锁适用于读多写少的情况 3.8 读锁应该插队么？什么是读写锁的升降级？ 公平锁 只要等待队列中有线程在等待，即hasQueueedPredecessors()返回true的时候，那么write和reader都会block，即不允许插队。 非公平锁 1234567final boolean writerShouldBlock() &#123; return false; // writers can always barge&#125;final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive();&#125; 写锁：随时可以插队 读锁： 允许插队 有可能导致需要拿到写锁的线程会陷入”饥饿”状态，它将在长时间内得不到执行。 不允许插队 即使是非公平锁，只要等待队列的头结点是尝试获取写锁的线程，那么读锁依然不能插队，目的是避免”饥饿”。 1234567891011121314151617181920212223242526272829303132333435363738public class ReadLockJumpQueue &#123; private static final ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); private static final ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock.readLock(); private static final ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock.writeLock(); private static void read() &#123; readLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到读锁，正在读取\"); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放读锁\"); readLock.unlock(); &#125; &#125; private static void write() &#123; writeLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到写锁，正在写入\"); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放写锁\"); writeLock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; read(), \"Thread-2\").start(); new Thread(() -&gt; read(), \"Thread-4\").start(); new Thread(() -&gt; write(), \"Thread-3\").start(); new Thread(() -&gt; read(), \"Thread-5\").start(); &#125;&#125; 运行结果： 12345678Thread-2得到读锁，正在读取Thread-4得到读锁，正在读取Thread-2释放读锁Thread-4释放读锁Thread-3得到写锁，正在写入Thread-3释放写锁Thread-5得到读锁，正在读取Thread-5释放读锁 锁的升降级 1234567891011121314151617181920212223242526272829303132public class CachedData &#123; Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; //在获取写锁之前，必须首先释放读锁。 rwl.readLock().unlock(); rwl.writeLock().lock(); try &#123; //这里需要再次判断数据的有效性,因为在我们释放读锁和获取写锁的空隙之内，可能有其他线程修改了数据。 if (!cacheValid) &#123; data = new Object(); cacheValid = true; &#125; //在不释放写锁的情况下，直接获取读锁，这就是读写锁的降级。 rwl.readLock().lock(); &#125; finally &#123; //释放了写锁，但是依然持有读锁 rwl.writeLock().unlock(); &#125; &#125; try &#123; System.out.println(data); &#125; finally &#123; //释放读锁 rwl.readLock().unlock(); &#125; &#125;&#125; 只有一处修改数据的代码，后面都是读取，如果一直使用写锁的话，就不能让多个线程同时来读取了，这个时候利用锁的降级，可以提高整体性能。 支持锁的降级，不支持升级 ReentrantReadWriteLock不支持读锁升级到写锁。 不可能有读锁和写锁同时持有的情况，升级写锁的过程中，需要等到所有的读锁都释放才能升级。另一种特殊情况，线程A、B都想升级到写锁，对于A而言，它需要等待其他线程(包括B)释放读锁，而线程B也是如此，则会发生死锁。 3.9 自旋锁 非自旋锁和自旋锁最大的区别，如果它遇到拿不到锁的情况，它会把线程阻塞，直到被唤醒；而自旋锁会不停地尝试。 自旋锁的好处 自旋锁用循环去不停地尝试获取锁，让线程始终处于Runnable状态，节省了线程切换带来的开销。 自己实现可重入的自旋锁： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ReentrantSpinLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); // 重入次数 private int count = 0; public void lock() &#123; Thread currentThread = Thread.currentThread(); if (currentThread == owner.get()) &#123; ++count; return; &#125; // 自旋获取锁 while (!owner.compareAndSet(null, currentThread)) &#123; System.out.println(\"自旋了！\"); &#125; &#125; public void unlock() &#123; Thread currentThread = Thread.currentThread(); // 只有持有锁的线程才能解锁 if (currentThread == owner.get()) &#123; if (count &gt; 0) &#123; --count; &#125; else &#123; // 此处无需CAS操作，因为没有竞争，因为只有线程持有者才能解锁 owner.set(null); &#125; &#125; &#125; public static void main(String[] args) &#123; ReentrantSpinLock spinLock = new ReentrantSpinLock(); Runnable runnable = new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \"开始尝试获取自旋锁\"); spinLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"获取到了自旋锁\"); Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; spinLock.unlock(); System.out.println(Thread.currentThread().getName() + \"释放了了自旋锁\"); &#125; &#125; &#125;; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); &#125;&#125; 运行结果： 123456789101112Thread-1开始尝试获取自旋锁Thread-0开始尝试获取自旋锁Thread-1获取到了自旋锁自旋了！自旋了！自旋了！......自旋了！自旋了！Thread-0获取到了自旋锁Thread-1释放了了自旋锁Thread-0释放了了自旋锁 缺点 虽然避免了线程切换的开销，但带来了新的开销，因为它需要不停地去尝试获取锁。 适用场景 自旋锁适用于并发度不是特别高，以及临界区比较短小的情况，这样可以避免线程切换来提高效率。可是如果临界区很大，线程一旦拿到锁，很久才会释放的话，那就不适合自旋锁，因为自旋会一直占用CPU却无法拿到锁，白白消耗资源。 3.10 JVM对锁的优化 自适应的自旋锁 自旋的缺点在于如果自旋时间过长，那么性能开销很大，浪费CPU资源。自适应意味着自旋的时间不再固定，而是根据最近自旋尝试的成功率、失败率，以及当前锁的拥有者的状态等多种因素来共同决定。如：最近尝试自旋获取某一把锁成功了，那么下次可能还会继续使用自旋，并且允许自旋更长时间；但如果最近自旋获取某一把锁失败了，那么可能会省略掉自旋的过程，以便减少无用的自旋，提高效率。 锁消除 123456@Overridepublic synchronized StringBuffer append(Object obj) &#123; toStringCache = null; super.append(String.valueOf(obj)); return this;&#125; 这个方法是被synchronized修饰的同步方法，因为它可能会被多个线程同时使用。但在大多数情况下，它只会在一个线程内使用，如果编译器能确定这个StringBuffer只会在一个线程内使用，那么编译器便会做出优化，把synchronized消除，省去加锁和解锁，以便增加整体的效率。 锁粗化 如果释放了锁，紧接着什么都没做，又重新获取锁，如： 12345678public void lockCoarsening() &#123; synchronized (this) &#123; //do something &#125; synchronized (this) &#123; //do something &#125;&#125; 可以把同步区域扩大，即最开始加一次锁，并且在最后直接解锁，减少性能开销。 如果在循环中也这样做，会导致其他线程长时间无法获得锁。锁粗化的功能默认打开，用-XX:-EliminateLocks可以关闭该功能。 12345for (int i = 0; i &lt; 1000; i++) &#123; synchronized (this) &#123; //do something &#125;&#125; 偏向锁/轻量级锁/重量级锁 这三种锁是特指synchronized锁的状态的，通过对象头中的mark word来表明锁的状态。 偏向锁 这把锁自始至终不存在竞争，那么没必要上锁，只要打个标记就行了。一个对象被初始化后，如果还没有任何线程来获取它的锁，它就是可偏向的，当第一个线程来访问它尝试获取锁的时候，它就记录下来这个线程，如果后面尝试获取锁的线程正是这个偏向锁的拥有者，就可以直接获取锁，开销小。 轻量级锁 synchronized中的代码块是被多个线程交替执行的，也就是不存在实际的竞争，或者只有短时间的竞争，用CAS就可以解决。轻量级锁指当锁原来是偏向锁的时候，被另一线程所访问，说明存在竞争，那么偏向锁升级为轻量级锁，线程会通过自旋的方式尝试获取锁，不会阻塞。 重量级锁 当多个线程直接有实际竞争，并且锁竞争时间比较长的时候，此时偏向锁和轻量级锁都不能满足需求，锁就会膨胀为重量级锁，会让其他申请却拿不到锁的线程进入阻塞状态。 3.10 HashMap为什么是线程不安全的？ 扩容期间取出的值不准确 HashMap扩容期间，会新建一个新的空数组，并用旧的项填充到这个新的数组中。如果这个填充的过程中，如果有线程取值，很可能会取到null值。 同时put碰撞导致数据丢失 如果有多个线程同时put，而且恰好两个put的key是一样的，它们发生了碰撞，也就是根据hash值计算出来的bucket位置一样，并且两个线程又同时判断该位置是空的，可以写入，所以这两个线程的两个不同的value便会添加到数组的同一位置，就丢失了一个数据。 可见性问题 线程1给某个key放入了一个新值，那么线程2在获取对应的key的值的时候，它的可见性是无法保证的。 死循环造成CPU100% 在扩容的时候，也就是内部新建新的HashMap的时候，扩容的逻辑会反转散列桶中的节点顺序，当多个线程同时进行扩容的时候，如果两个线程同时反转的话，便可能形成一个循环，并且这种循环是链表的循环，相当于A节点指向B节点，B节点又指回A节点，在下一次想要获取该key所对应的value的时候，便会在遍历链表的时候发生永远无法遍历结束的情况。 3.11 为什么Map桶中超过8个才转为红黑树？最开始的Map是空的，因为里面没有任何元素，往里放元素时会计算hash值，计算之后，第1个个value会占用一个桶(也称为槽点)位置，后续经过计算键值key计算hash值得到插入的数组索引i相同，那么会使用链表的形式往后延长，俗称拉链法。当链表长度大于或等于阈值(默认为8)，且数组长度大于或等于MIN_TREEIFY_CAPACITY(默认64)时，就会把链表转为红黑树。当红黑树的节点小于或等于6个以后，又会恢复为链表形态。 链表查找时间复杂度：O(n) 红黑树查找时间复杂度：O(log(n)) 单个TreeNode需要占用的空间大约是Node的两倍 时间与空间的平衡 如果hash计算结果离散的好，各个值都均匀分配，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为8时，概率仅为0.00000006，小于千万分之一概率，通常情况下并不会发生链表向红黑树的转换。 链表长度为8转为红黑树的设计，为了防止自定义实现了不好的hash算法导致链表长度过长，从而导致查询效率低。 3.12 Hashtable与ConcurrentHashMap的区别 出现版本不同 Hashtable在JDK1.0就存在了，并在JDK1.2实现了Map接口；ConcurrentHashMap在JDK1.5中才出现。 实现线程安全的方式不同 Hashtable通过synchronized关键字实现线程安全；ConcurrentHashMap利用了CAS+synchronized+Node(volatile)。 性能不同 随着线程数量的增加，Hashtable性能会急剧下降，每一次修改会锁住整个对象，而其他线程在此期间不能操作，还会带来额外的上下文切换；ConcurrentHashMap只会对一部分上锁而不是全部都上锁。 迭代时的修改不同 Hashtable(包括HashMap)不允许在迭代期间修改内容，否则会抛出ConcurrentModificationException异常，ConcurrentHashMap不会。 3.13 CopyOnWriteArrayListArrayList LinkedList 线程安全：Vector Collections.synchronized() Vector内部使用synchronized来保证线程安全，并且锁的粒度比较大，都是方法级别的锁，在并发高的时候，很容易发生竞争，并发效率相对较低。 适用场景： 读操作可以尽可能的快，而写即使慢一些也没关系 读多写少 读写规则： 读写锁的思想是：读读共享，其他都互斥，因为读操作不会修改原有的数据，因此并发读不会有安全问题；而写操作发生时，不允许读和写操作加入。CopyOnWriteArrayList读取是完全不用加锁的，并且写入也不会阻塞读取操作，也就是说可以在写入的同时进行读取，只有写入和写入之间需要进行同步，也就是不允许多个写入同时发生，但可以在写入时允许读取发生。 特点： CopyOnWrite 当容器需要被修改的时候，不直接修改当前容器，而是先将当前容器进行Copy，复制出一个新容器，然后修改新的容器，完成修改之后，再将容器的引用指向新的容器。读写分离的思想，读和写使用不同的容器。 迭代期间允许修改集合内容 ArrayList源码里的ListItr的next()方法中有一个checkForComodification()方法： 1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; modCount是保存修改次数，每次调用add、remove时都会增加，expectedComodification是迭代器的变量，创建迭代器时会初始化并记录当时的modCount，后面迭代期间如果发现modCount和expectedModCount不一致，就会抛出异常。CopyOnWriteArrayList的迭代器在迭代时，迭代器使用的依然是原数组，只不过迭代器的内容可能已经过时了。CopyOnWrite的迭代器一旦被建立，如果往之前的CopyOnWriteArrayList对象中去新增元素，在迭代器中既不会显示出元素的变更情况，同时也不会报错。 缺点： 内存占用问题 在元素较多或者复杂的情况下，复制的开销很大 数据一致性问题 由于CopyOnWrite容器的修改是先修改副本，所以这次修改对于其他线程来说，并不是实时能看到的，只有在修改完之后才能体现出来。 源码分析： 数据结构 1234567891011121314151617181920212223/** 可重入锁对象 */final transient ReentrantLock lock = new ReentrantLock();/** CopyOnWriteArrayList底层由数组实现，volatile修饰，保证数组的可见性 */private transient volatile Object[] array;/*** 得到数组*/final Object[] getArray() &#123; return array;&#125;/*** 设置数组*/final void setArray(Object[] a) &#123; array = a;&#125; /*** 初始化CopyOnWriteArrayList相当于初始化数组*/public CopyOnWriteArrayList() &#123; setArray(new Object[0]);&#125; add()方法 12345678910111213141516171819public boolean add(E e) &#123; // 加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; // 得到原数组的长度和元素 Object[] elements = getArray(); int len = elements.length; // 复制出一个新数组 Object[] newElements = Arrays.copyOf(elements, len + 1); // 添加时，将新元素添加到新数组中 newElements[len] = e; // 将volatile Object[] array 的指向替换成新数组 setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 在添加的时候首先上锁，并复制一个新数组，增加操作在新数组上完成，然后将array指向到新数组，最后解锁。上面的步骤实现了CopyOnWrite的思想：写操作是在原来容器的拷贝上进行的，并且在读取数据的时候不会锁住list。如果对容器拷贝操作的过程中有新的读线程进来，那么读到的还是旧的数据，因为那个时候对象的引用还没有被更改。 迭代器 COWIterator 类 1234private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements;&#125; snapshot：数组的快照，即创建迭代器那个时刻的数组情况 cursor：迭代器的游标 迭代器在被构建的时候，会把当时的elements赋值给snapshot，而之后的迭代器所有的操作都基于snapshot数组进行的，比如： 12345public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++];&#125; 可以看到，返回的内容是snapshot对象，所以，后续就算原数组被修改，这样snapshot既不会感知到，也不会受影响，执行迭代操作不需要加锁，也不会因此抛出异常。迭代器返回的结果，和创建迭代器的时候内容一致。 4.阻塞队列4.1 什么是阻塞队列？BlockingQueue，是一个接口，继承了Queue接口，是队列的一种，是线程安全的。 主要并发队列关系图 阻塞队列典型代表就是BlockingQueue接口的实现类，分别是ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、DelayQueue、PriorityBlockingQueue和LinkedTransferQueue。非阻塞队列的典型代表是ConcurrentLinkedQueue，这个类不会让线程阻塞，利用CAS保证线程安全。 Deque为双端队列，它从头和尾都能添加和删除元素；而普通的Queue只能从一端进入，另一端出去。 特点 阻塞功能使得生产者和消费者两端的能力得以平衡，当有任何一端速度过快时，阻塞队列便会把过快的速度给降下来。 take方法 获取并移除队列的头结点，在队列里有数据时可以正常移除，一旦执行take方法的时候，队列无数据，则阻塞，直到队列有数据。 put方法 put方法插入元素时，如果队列已满，那么就无法继续插入，则阻塞，直到队列有了空闲空间。 是否有界(容量有多大)无界队列意味着里面可以容纳非常多的元素，如LinkedBlockingQueue的上限是Integer.MAX_VALUE，约为2^31。有些阻塞队列是有界的，如ArrayBlockingQueue如果容量满了，也不会扩容，所以一旦满了，就无法再往里面放数据了。 4.2 阻塞队列常用方法第一组：无法正常执行的情况下抛出异常；第二组：在无法正常执行的情况下不抛出异常，但会用返回值提示运行失败；第三组：在遇到特殊情况时让线程阻塞，等到可以运行再继续执行。 带有超时时间的offer和poll 1offer(E e, long timeout, TimeUnit unit) 插入不成功时会等待指定的超时时间，时间到了依然没有插入成功，就会返回false 1poll(long timeout, TimeUnit unit) 如果移除时，如果队列是空的就会进行等待，超时时间到了，如果队列中依然没有元素可供移除，则会返回null为提示 4.3 几种常见的阻塞队列 ArrayBlockingQueue 有界队列，其内部是用数组存储元素的，利用ReentrantLock实现线程安全，在创建它的时候就需要指定它的容量，之后不可以再扩容了，可以在构造函数中指定是否公平。 非公平：存在插队的可能；公平：等待最长时间的线程会被优先处理 LinkedBlockingQueue 内部用链表实现，不指定容量时默认为Integer.MAX_VALUE，被称为无界队列。 SynchronousQueue 容量为0，所以没有地方来暂存元素，导致每次取数据都要先阻塞，直到有数据被放入；同理，每次放数据也会阻塞，直到有消费者来取。Synchronous的容量不是1而是0，它不需要去持有元素，它所做的就是直接传递。 PriorityBlockingQueue 支持优先级的无界阻塞队列，可以通过自定义类实现compareTo()方法来指定元素排序规则，或者初始化时通过构造器参数Comparator来指定排序规则。同时插入的对象必须是可比较大小的，即Comparable的，否则会抛出ClassCastException。 DelayQueue 具有”延迟”的功能，可以设定让队列中的任务延迟多久之后执行，如”30 分钟后未付款自动取消订单”。它是无界队列，放入的元素必须实现Delayed接口，而Delayed接口又继承了Comparable接口，拥有了比较和排序的能力。元素会根据延迟时间的长短放到队列的不同位置，越靠近头队列代表越早过期。 4.4 阻塞队列和非阻塞队列的并发安全原理 ArrayBlockingQueue 12345678// 用于存放元素的数组final Object[] items;// 下一次读取操作的位置int takeIndex;// 下一次写入操作的位置int putIndex;// 队列中的元素数量int count; 1234// 以下3个是控制并发用的工具final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull; 这三个变量非常关键，第一个是ReentrantLock，下面两个Condition是由ReentrantLock产生出来的。读操作和写操作都需要先获取到ReentrantLock独占锁才能进行下一步操作。进行读操作时如果队列为空，线程就会进入到读线程专属的noEmpty的Condition的队列中去排队，等待写线程写入新的元素；同理如果队列已满，写操作的线程会进入到写线程专属的notFull队列中去排队，等待读线程将队列元素移除并腾出空间。 put方法： 123456789101112public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; LinkedBlockingQueue的内部有两把锁，分别锁住队列的头和尾，比共用一把锁的效率高。 非阻塞队列ConcurrentLinkedQueue offer方法： 12345678910111213141516171819202122232425262728public boolean offer(E e) &#123; checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; // p is last node if (p.casNext(null, newNode)) &#123; // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become \"live\". if (p != t) // hop two nodes at a time casTail(t, newNode); // Failure is OK. return true; &#125; // Lost CAS race to another thread; re-read next &#125; else if (p == q) // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; else // Check for tail updates after two hops. p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 整个是以一个大的for循环，p.casNext()方法 123boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);&#125; 这里运用了UNSAFE.compareAndSwapObject方法来完成CAS操作，而compareAndSwapObject是一个native方法，最终会利用CPU的CAS指令保证其不可中断。非阻塞队列ConcurrentLinkedQueue使用CAS非阻塞算法+不停重试，来实现线程安全，适合用在不需要阻塞功能，且并发不是特别剧烈的场景。 4.5 如何选择合适的阻塞队列？ 线程池对于阻塞队列的选择 从以下5个角度考虑，来选择合适的阻塞队列。 功能 是否需要阻塞队列来排序，如优先级排序、优先执行等。 容量 是否需要有存储要求，还是只需要”直接传递”。 能否扩容 业务可能有高峰期、低谷期，如果需要动态扩容，就不能选择ArrayBlockingQueue。 内存结构 如ArrayBlockingQueue的内部结构是”数组”的形式，LinkedBlockingQueue的内部是链表实现的，ArrayBlockingQueue没有链表所需要的”节点”，空间链表利用率更高。 性能 如LinkedBlockingQueue拥有两把锁，操作粒度更细，并发程度高的时候，相对于只有一把锁的ArrayBlockingQueue性能会更好。SynchronousQueue性能往往优于其他实现，因为它只需要”直接传递”，而不需要存储的过程。 5.原子类5.1 原子类如何利用CAS保证线程安全？原子类的作用和锁有类似之处，都是为了保证并发情况下线程安全。 粒度更细：原子变量可以把竞争范围缩小到变量级别，通常情况下，锁的粒度都要大于原子变量的粒度。 效率更高：除高度竞争的情况下，原子类的效率通常比使用同步互斥锁的效率更高，因为原子类利用了CAS操作，不会阻塞线程。 6类原子类纵览 类型 具体类 特点 Atomic* 基本类型原子类 AtomicInteger、AtomicLong、AtomicBoolean Atomic*Array 数组类型原子类 AtomicIntegerArray(整形数组原子类)、AtomicLongArray(长整形数组原子类)、AtomicReferenceArray(引用类型数组原子类) Atomic*Reference 引用类型原子类 AtomicReference、AtomicStampedReference(对AtomicReference的升级，在此基础上还加了时间戳，用于解决CAS的ABA问题)、AtomicMarkableReference(和AtomicReference类似，多了一个绑定的布尔值，可以用于表示该对象已删除等场景) AtomicInteger可以让一个整数保证原子形，AtomicReference可以让一个对象保证原子性。 Atomic*FieldUpdater升级类型原子类 AtomicIntegerFieldUpdater(原子更新整形的更新器)、AtomicLongFieldUpdater(原子更新长整形的更新器)、AtomicReferenceFieldUpdater(原子更新引用的更新器) 可以把已经声明的变量进行升级，使其拥有CAS操作的能力。 Adder累加器 LongAdder、DoubleAdder Accumulator积累器 LongAccumulator、DoubleAccumulator 12345678910111213141516171819202122232425262728293031public class AtomicIntegerFieldUpdaterDemo implements Runnable &#123; public static class Score &#123; volatile int score; &#125; static Score math; static Score computer; static AtomicIntegerFieldUpdater&lt;Score&gt; scoreUpdater = AtomicIntegerFieldUpdater.newUpdater(Score.class, \"score\"); @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; computer.score++; scoreUpdater.getAndIncrement(math); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; math = new Score(); computer = new Score(); AtomicIntegerFieldUpdaterDemo updaterDemo = new AtomicIntegerFieldUpdaterDemo(); Thread thread1 = new Thread(updaterDemo); Thread thread2 = new Thread(updaterDemo); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(\"普通变量的结果：\"+ computer.score); System.out.println(\"升级后的结果：\"+ math.score); &#125;&#125; 以AtomicInteger为例，分析其如何利用CAS实现原子操作？ getAndAdd()方法 1234//JDK 1.8实现public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; Unsafe类 Unsafe类是CAS的核心类。Java无法直接访问底层操作系统，而需要通过native方法实现。在JDK中有一个Unsafe类，提供了硬件级别的原子操作，可以利用它直接操作内存数据。 1234567891011121314public class AtomicInteger extends Number implements java.io.Serializable &#123; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; public final int get() &#123;return value;&#125; ...&#125; static代码块会在类加载的时候执行，执行时会调用Unsafe的objectFieldOffset方法，从而得到当前这个原子类的value的偏移量(在内存中的偏移地址)，并且赋给valueOffset变量，并且赋值给valueOffset变量，Unsafe根据内存偏移地址获取数据的原值，这样就可以通过Unsafe来实现CAS了。 value是用volatile修饰的，它就是我们原子类存储的值的变量，由于它被volatile修饰，我们就可以保证在多线程之间看到的value是同一份，保证了可见性。 Unsafe的getAndAddInt方法： 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2);//获取var1中的var2偏移处的值 var1:当前原子类 var2:最开始获取到的offset &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//var1:object 当前原子类对象 var2:offset 即偏移量，借助它就可以获取到value的数值 var3:expectedValue 代表\"期望值\"，传入的是刚才获取到的var5 var5+var4:newValue 是希望修改的数值，等于之前取到的数值var5+var4，var4是希望原子类所改变的数值，如+1或-1。 return var5;&#125; compareAndSwapInt方法的作用：判断如果现在原子类里的value的值和之前获取到的var5相等的话，那么就把计算出来的var5+var4给更新上去。一旦CAS操作成功，就会退出这个while循环，但也有可能操作失败。如果操作失败就意味着在获取到var之后，并在CAS操作之前，value的数值已经发生变化了，证明有其他线程修改过这个变量。会再次执行循环体里面的代码，重新获取var5，即获取最新的原子变量的数值，并再次利用CAS尝试更新，直到更新成功。 5.2 AtomicInteger在高并发下性能不好，如何解决？为什么？123456789101112131415161718192021222324252627282930public class AtomicLongDemo &#123; static class Task implements Runnable &#123; private final AtomicLong counter; public Task(AtomicLong counter) &#123; this.counter = counter; &#125; @Override public void run() &#123; counter.incrementAndGet(); System.out.println(Thread.currentThread().getName()+\"...\"+counter.get()); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AtomicLong counter = new AtomicLong(0); ExecutorService poolExecutor = new ThreadPoolExecutor(20, 40, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); StopWatch stopWatch = new StopWatch(); stopWatch.start(); for (int i = 0; i &lt; 100; i++) &#123; poolExecutor.submit(new Task(counter)); &#125; Thread.sleep(2000); System.out.println(\"result:\"+counter.get()); stopWatch.stop(); System.out.println(stopWatch.getTotalTimeMillis()); &#125;&#125; 每一个线程是运行在自己的core中的，并且它们都有一个本地内存是自己独用的。在本地内存下方有两个CPU核心共用的共享内存。对于AtomicLong内部的value属性而言，它是被volatile修饰的，需要保证自身可见性。每次它的数值变化的时候，都需要进行flush到共享内存和refresh到本地内存。 flush和refresh操作耗费了很多资源，而且CAS也会经常失败。 LongAdder LongAdder引入了分段累加的概念，内部一共有两个参数参与计数： base，是一个变量，用在竞争不激烈的情况下，可以直接把来家结果改到base变量上。 Cell[]，是一个数组，一旦竞争激烈，各个线程会分散累加到自己所对应的那个Cell[]数组的某一个对象中，而大家不会共用同一个。 竞争激烈的时候，LongAdder会通过计算出每个线程的hash值来给线程分配到不同的Cell上去，每个Cell相当于是一个独立的计数器，Cell之间并不存在竞争，所以自加过程中，大大减少了flush和refresh，以及降低了冲突的概率。空间换时间。 1234567891011public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 如何选择 如何仅仅是需要用到加和减操作的场景，那么可以直接使用LongAdder。 如果需要利用CAS比如compareAndSet等操作的话，就需要使用AtomicLong来完成。 5.3 原子类与volatile 线程1和线程2分别在不同的CPU核心，每一个核心都有自己的本地内存，并且在下方也有它们的共享内存。在变量加上volatile关键字，线程1的更改会被flush到共享内存，然后又被refresh到线程2的本地内存，保证了可见性。 但对于value++这种，即使用volatile修饰value也是不能保证线程安全的，无法保证其原子性。此时可以使用原子类。 原子类和volatile的使用场景 通常情况下，volatile可以用来修饰boolean类型的标记位，对于标记位来讲，直接的赋值操作本身就具有原子性，再加上volatile保证了可见性，那么就是线程安全的了。而对于会被多个线程同时操作的计数器counter的场景，即不仅仅是赋值操作，还需要读取当前值，然后在此基础上进行一定的修改，再把它给赋值回去，此时需要使用原子类保证线程安全。 5.4 Adder与Accumlator的区别高并发场景下AtomicLong CAS冲突概率大，会导致经常自旋。而LongAdder引入了分段锁的概念，竞争不激烈的时候，所有线程都是通过CAS对同一个Base变量进行修改，但竞争激烈的时候，LongAdder会把不同线程对应到不同的Cell上进行修改，降低了冲突的概率。 LongAccumulator就是个更通用版本的Adder，提供了自定义的函数操作。 12345678910111213public class LongAccumulatorDemo &#123; public static void main(String[] args) throws InterruptedException &#123; LongAccumulator accumulator = new LongAccumulator((x, y) -&gt; x + y, 0); ExecutorService executorService = new ThreadPoolExecutor(8, 16, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); IntStream.range(1,10).forEach(i-&gt;executorService.submit(()-&gt;&#123; accumulator.accumulate(i); System.out.println(Thread.currentThread().getName()+\"...\"+accumulator.get()); &#125;)); Thread.sleep(2000); System.out.println(accumulator.getThenReset()); &#125;&#125; 自定义函数： 1234LongAccumulator counter = new LongAccumulator((x, y) -&gt; x + y, 0);LongAccumulator result = new LongAccumulator((x, y) -&gt; x * y, 0);LongAccumulator min = new LongAccumulator((x, y) -&gt; Math.min(x, y), 0);LongAccumulator max = new LongAccumulator((x, y) -&gt; Math.max(x, y), 0); 适用场景 需要大量的计算，并且当需要并行计算的时候。 计算的执行顺序并不关键。 6.ThreadLocal6.1 ThreadLocal适用场景 场景1 保存每个线程独享的对象，为每个线程都创建一个副本，这样每个线程都可以修改自己拥有的副本，而不会影响其他线程的副本，确保了线程安全。 这种场景下，每个Thread内都有自己的实例副本，且该副本只能由当前Thread访问到并使用，相当于每个线程内部的本地变量。因为每个线程独享副本，而不是共用的，所以不存在多线程间共享的问题。 这种场景通常用于保存线程不安全的工具类，如SimpleDateFormat。 1234567891011121314151617181920212223242526public class ThreadLocalDemo05 &#123; static ThreadLocal&lt;SimpleDateFormat&gt; formatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;()&#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(\"mm:ss\"); &#125; &#125;; public static ExecutorService executorService = new ThreadPoolExecutor(16, 32, 10, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); public String date(int seconds) &#123; Date date = new Date(1000 * seconds); SimpleDateFormat simpleDateFormat = formatThreadLocal.get(); return simpleDateFormat.format(date); &#125; public static void main(String[] args) throws InterruptedException &#123; IntStream.range(1, 1000).forEach(i -&gt; executorService.submit(() -&gt; &#123; String date = new ThreadLocalDemo05().date(i); System.out.println(Thread.currentThread().getName() + \":\" + date); &#125;)); Thread.sleep(2000); executorService.shutdown(); &#125;&#125; 场景2 每个线程内需要独立保存信息，以便其他方法更方便的获取该信息的场景。每个线程获取到的信息可能都是不一样的，前面执行的方法保存了信息之后，后续方法可以通过ThreadLocal直接获取到，避免了传参，类似于全局变量的概念。 每个线程内需要保存类似于全局变量的信息(列如拦截器中获取的用户信息)，可以让不同方法直接使用，避免参数传递的麻烦却不想被多线程共享(因为不同线程获取到的用户信息不一样)。 例如，用ThreadLocal保存一些业务内容(用户权限信息)，这些信息在同一个线程内相同，但在不同的线程使用的业务内容是不相同的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ThreadLocalDemo07 &#123; public static void main(String[] args) &#123; new Service1().service1(); &#125;&#125;class User &#123; String username; public User() &#123;&#125; public User(String username) &#123; this.username = username; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125;&#125;class userContextHolder &#123; public static ThreadLocal&lt;User&gt; holder = new ThreadLocal&lt;&gt;();&#125;class Service1 &#123; public void service1() &#123; User user = new User(\"张三\"); userContextHolder.holder.set(user); new Service2().service2(); &#125;&#125;class Service2 &#123; public void service2() &#123; User user = userContextHolder.holder.get(); System.out.println(\"Service2拿到用户名：\" + user.getUsername()); new Service3().service3(); &#125;&#125;class Service3 &#123; public void service3() &#123; User user = userContextHolder.holder.get(); System.out.println(\"Service3拿到用户名：\" + user.getUsername()); userContextHolder.holder.remove(); &#125;&#125; 6.2 ThreadLocal是用来解决共享资源的多线程访问的问题吗？不是，虽然ThreadLocal是用于解决多线程情况下的线程安全问题，但其资源并不是共享的，而是每个线程独占的。 如果把放到ThreadLocal中的资源用static修饰，让它变为一个共享资源的话，那么即便使用ThreadLocal，同样有线程安全问题。 ThreadLocal和synchronized是什么关系？ ThreadLocal是通过让每个线程独享自己的副本，避免了资源的竞争。 synchronized主要用于临界资源的分配，在同一时刻限制最多只有一个线程能够访问该资源 相比于ThreadLocal而言，synchronized的效率会更低一些，但花费的内存也更少。但对于ThreadLocal而言，它还有不同的使用场景。比如避免传参。 6.3 ThreadLocal的结构Thread、ThreadLocal及ThreadLocalMap三者之间的关系 每个Thread对象中都持有一个ThreadLocalMap类型的成员变量，这个ThreadLocalMap自身类似一个Map，里面会有一个个key-value形式的，key就是ThreadLocal的引用，value就是希望ThreadLocal存储的内容。 get方法 1234567891011121314151617public T get() &#123; //获取到当前线程 Thread t = Thread.currentThread(); //获取到当前线程内的ThreadLocalMap对象，每个线程内都有一个ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) &#123; //获取ThreadLocalMap中的Entry对象并拿到value，每个线程内都有一个ThreadLocalMap对象 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; //如果线程内之前没创建过ThreadLocalMap，就创建 return setInitialValue();&#125; getMap方法 12345 ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125;ThreadLocal.ThreadLocalMap threadLocals = null; set方法 1234567891011public void set(T value) &#123; //获取到当前线程 Thread t = Thread.currentThread(); //获取当前线程内的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) //第一个参数this：当前ThreadLocal的引用，key的类型则是ThreadLocal；第二个参数即为所传入的value map.set(this, value); else createMap(t, value);&#125; ThreadLocalMap类，即Thread.threadLocals 123456789101112131415static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private static final int INITIAL_CAPACITY = 16; private Entry[] table; ......&#125; 在ThreadLocalMap中会有一个Entry类型的数组，名字叫table。可以理解为一个map，其键值对为： 键，当前的ThreadLocal 值，实际需要存储的变量，比如user用户对象或者simpleDateFormat对象 HashMap在面对hash冲突的时候，采用的是拉链法，它会先把对象hash到一个对应的格子中，如果有冲突就用链表的形式往下链；但ThreadLocalMap采用的是线性探测法，如果发生冲突，并不会用链表的形式往下链，而是会继续寻找下一个空的格子。 6.4 为何每次用完 ThreadLocal 都要调用 remove()？内存泄漏：当某一个对象不再有用的时候，占用的内存却不能被回收。 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry是extends WeakReference。弱引用的特点：如果这个对象只被弱引用关联，而没有任何强引用关联，那么这个对象就可以被回收，所以弱引用不会阻止GC。 但是这个Entry包含了一个对value的强引用。value=v这行代码就代表了强引用的发生。 Thread Ref → Current Thread → ThreadLocalMap → Entry → Value → 可能泄漏的value实例。 这条链路是随着线程的存在而一直存在，如果线程迟迟不会终止，那么当垃圾回收进行可达性分析的时候，这个value就是可达的，所以不会被回收。但与此同时可能已经完成了业务逻辑处理，不再需要这个value了，此时就发生了内存泄漏。 在执行ThreadLocal的set、remove、rehash等方法时，都会扫描key为null的Entry，如果发现某个Entry的key为null，则代表它所对应的value也没有作用了，所以就会把对应的value设置为null，这样，value对象就可以被正常回收了。但假设ThreadLocal已经不被使用了，那么实际上set、remove、rehash方法也不会被调用。 如何避免内存泄漏 调用 ThreadLocal 的 remove 方法。调用这个方法就可以删除对应的 value 对象，可以避免内存泄漏。 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 7.Future7.1 Callable和Runnable的不同 Runnable的不足 不能返回一个返回值 不能抛出checked Exception 123456789101112131415161718192021222324public class RunThrowException &#123; /** * 普通方法内可以 throw 异常，并在方法签名上声明 throws */ public void normalMethod() throws Exception &#123; throw new IOException(); &#125; Runnable runnable = new Runnable() &#123; /** * run方法上无法声明 throws 异常，且run方法内无法 throw 出 checked Exception，除非使用try catch进行处理 */ @Override public void run() &#123; try &#123; throw new IOException(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Runnable规定了run()方法的返回类型是void，而且没有声明抛出任何异常。所以，当实现并重写这个方法的时候，既不能改变返回值类型，也不能更改对于异常抛出的描述。 123public interface Runnable &#123; public abstract void run();&#125; Callable接口 call方法已经声明了throws Exception，前面还有一个V泛型的返回值。 123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; Callable和Runnable的不同之处 方法名：Callable规定的执行方法是call()，而Runnable规定的执行方法是run() 返回值：Callable的任务执行后有返回值，而Runnable的任务执行后是没有返回值的 抛出异常：call()方法可抛出异常，而run方法是不能抛出检查异常的 和Callable配合使用的Future类，通过Future可以了解任务的执行情况，或者取消任务的执行，还可获取任务的执行结果等。 7.2 Future的主要功能Future的作用 比如当做一定较耗时的任务时，可以把任务放到子线程去执行，再通过Future去控制子线程执行的过程，最后获取到计算结果。通过异步的思想，提高程序的运行效率。 Callable和Future的关系 Callable接口相比于Runnable可以通过Future类的get方法返回结果。因此，Future类相当于一个存储器，它存储了Callable的call方法的任务结果。 12345678910111213public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; get() 获取结果 获取任务执行的结果 当执行get的时候，任务已经执行完毕了。可以立刻返回，获取到任务执行的结果。 任务还未开始或任务正在执行中，调用get时，都会把当前线程阻塞，直到任务完成再把结果返回回来。 任务执行过程中抛出异常，调用get时，就会抛出ExecutionException，且无论执行call方法时里面抛出的异常类型是什么，在执行get方法时所获得的异常都是ExecutionException。 任务被取消了，如果任务被取消，调用get方法时则会抛出CancellationException。 任务超时，调用带延迟参数的get方法之后，如果call方法在规定时间内仍没有完成任务，get方法则会抛出TimeoutException，代表超时了。 123456789101112131415161718192021222324/* *一个Future的使用 */public class OneFuture &#123; static class CallableTask implements Callable&#123; @Override public Object call() throws Exception &#123; Thread.sleep(3000); return new Random().nextInt()+Thread.currentThread().getName(); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); Future future = executorService.submit(new CallableTask()); try &#123; System.out.println(future.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; executorService.shutdown(); &#125;&#125; isDone() 判断是否执行完毕 判断当前线程是否执行完毕，返回true代表已经执行完毕，返回false则代表还没完成。但这里如果返回true，并不代表这个任务是成功执行的，比如说任务执行到一半抛出了异常，仍然会返回true，所以isDone方法在返回true的时候，不代表这个任务是成功执行的，只代表它执行完毕了。 123456789101112131415161718192021222324252627282930313233public class GetException &#123; static class CallableTask implements Callable&#123; @Override public Object call() throws Exception &#123; throw new IllegalArgumentException(\"Callable抛出异常！\"); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(20); Future future = executorService.submit(new CallableTask()); try &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(i); Thread.sleep(500); &#125; System.out.println(future.isDone()); future.get(); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;01234truejava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Callable抛出异常！ at java.util.concurrent.FutureTask.report(FutureTask.java:122)...... 这段代码的运行结果证明了： 即便任务抛出异常，isDone方法依然会返回true。 虽然call方法抛出的异常是IllegalArgumentException，但对于get而言，它抛出的异常依然是ExecutionException。 虽然在任务执行一开始就抛出了异常，但真正要等到执行get的时候，才看到了异常。 cancel 取消任务的执行 任务还未执行，任务会被正常取消，未来也不会被执行，返回true。 任务已经完成或被取消过，返回false。 任务正在执行，会根据传入的参数mayInterruptIfRunning，如果传入的参数是true，执行任务的线程会收到一个中断的信号。如果传入的是false，就代表不中断正在运行的任务，同时返回false。 true：明确知道这个任务能够处理中断 false：明确知道这个任务不能处理中断；不知道这个任务是否支持取消(是否能够响应中断)；如果这个任务一旦开始运行，就希望它完全的执行完毕。 isCancelled() 判断是否被取消 用FutureTask创建Future 12345678910111213141516171819202122232425public class FutureTaskDemo &#123; public static void main(String[] args) &#123; Task task = new Task(); FutureTask futureTask = new FutureTask(task); new Thread(futureTask).start(); try &#123; System.out.println(\"task运行结果：\"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Task implements Callable&#123; @Override public Object call() throws Exception &#123; System.out.println(\"子线程\"+Thread.currentThread().getName()+\"正在计算！\"); int sum = 0; for (int i = 0; i &lt; 100; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 7.3 Future注意点 当for循环批量获取Future的结果时容易block，get方法调用时应该使用timeout限制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class FutureDemo &#123; static class SlowTask implements Callable &#123; @Override public Object call() throws Exception &#123; Thread.sleep(5000); return \"速度慢的任务\" + Thread.currentThread().getName(); &#125; &#125; static class FastTask implements Callable &#123; @Override public Object call() throws Exception &#123; return \"速度快的任务\" + Thread.currentThread().getName(); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = new ThreadPoolExecutor(10, 10, 10, TimeUnit.MICROSECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); List&lt;Future&gt; futures = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 4; i++) &#123; Future future; if (i == 0 || i == 1) &#123; future = executorService.submit(new SlowTask()); &#125; else &#123; future = executorService.submit(new FastTask()); &#125; futures.add(future); &#125; for (int i = 0; i &lt; 4; i++) &#123; Future future = futures.get(i); try &#123; String result = (String)future.get(); System.out.println(result); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; executorService.shutdown(); &#125;&#125;速度慢的任务pool-1-thread-1速度慢的任务pool-1-thread-2速度快的任务pool-1-thread-3速度快的任务pool-1-thread-4 第三个任务量比较小，可以很快返回结果，紧接着第四个任务也会返回结果。但由于前两个任务速度很慢，所以get方法执行时，会卡在第一个任务上。所以，即使第三、四个任务很早就得到结果了，但在此使用for循环的方式去获取结果，依然无法及时获取第三、四个任务的结果。直到5秒后，第一个任务出结果了，我们才能获取到，紧接着获取剩下任务的结果。 此时可以使用Future的带超时参数的get(long timeout, TimeUnit unit)方法，如果在限定时间内没能返回结果，即抛出TimeoutException。 Future的生命周期不可后退 Future的生命周期不可后退，一旦完成了任务，它就永久停在了”已完成”的状态，不能重头再来，即不能让一个已经完成计算的Future再次重新执行任务。 Future产生新的线程了吗 Callable和Future本身并不能产生新的线程，它们需要借助其它的比如Thread类或者线程池才能执行任务。例如：在把Callable提交到线程池后，真正执行Callable的其实还是线程池中的线程，而线程池中的线程是由ThreadFactory产生的。 7.4 CountDownLatch、Completable 线程池实现 12345678910111213141516171819202122232425262728293031323334public class ThreadPoolDemo &#123; ExecutorService threadPool = Executors.newFixedThreadPool(3); public static void main(String[] args) throws InterruptedException &#123; ThreadPoolDemo threadPoolDemo = new ThreadPoolDemo(); System.out.println(threadPoolDemo.getPrices()); &#125; private Set&lt;Integer&gt; getPrices() throws InterruptedException &#123; Set&lt;Integer&gt; prices = Collections.synchronizedSet(new HashSet&lt;Integer&gt;()); threadPool.submit(new Task(123, prices)); threadPool.submit(new Task(456, prices)); threadPool.submit(new Task(789, prices)); Thread.sleep(3000); return prices; &#125; private class Task implements Runnable &#123; Integer productId; Set&lt;Integer&gt; prices; public Task(Integer productId, Set&lt;Integer&gt; prices) &#123; this.productId = productId; this.prices = prices; &#125; @Override public void run() &#123; int price=0; try &#123; Thread.sleep((long) (Math.random() * 4000)); price= (int) (Math.random() * 4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; prices.add(price); &#125; &#125;&#125; CountDownLatch 1234567891011121314151617181920212223242526272829303132333435363738394041public class CountDownLatchDemo &#123; ExecutorService threadPool = Executors.newFixedThreadPool(3); public static void main(String[] args) throws InterruptedException &#123; CountDownLatchDemo countDownLatchDemo = new CountDownLatchDemo(); System.out.println(countDownLatchDemo.getPrices()); &#125; private Set&lt;Integer&gt; getPrices() throws InterruptedException &#123; Set&lt;Integer&gt; prices = Collections.synchronizedSet(new HashSet&lt;Integer&gt;()); CountDownLatch countDownLatch = new CountDownLatch(3); threadPool.submit(new Task(123, prices, countDownLatch)); threadPool.submit(new Task(456, prices, countDownLatch)); threadPool.submit(new Task(789, prices, countDownLatch)); countDownLatch.await(3, TimeUnit.SECONDS); return prices; &#125; private class Task implements Runnable &#123; Integer productId; Set&lt;Integer&gt; prices; CountDownLatch countDownLatch; public Task(Integer productId, Set&lt;Integer&gt; prices, CountDownLatch countDownLatch) &#123; this.productId = productId; this.prices = prices; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; int price = 0; try &#123; Thread.sleep((long) (Math.random() * 4000)); price = (int) (Math.random() * 4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; prices.add(price); countDownLatch.countDown(); &#125; &#125;&#125; 执行countDownLatch.await(3, TimeUnit.SECONDS)等待时，如果三个任务都非常快速得执行完毕了，那么都已经执行了countDown方法，相当于把计数减1。如果有一个线程没有执行countDown方法，来不及在3秒内执行完毕，那么这个带超时参数的await方法也会在3秒以后，及时的放弃这一次等待，于是就把prices返回了。 CompletableFuture 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CompletableFutureDemo &#123; private class Task implements Runnable &#123; Integer productId; Set&lt;Integer&gt; prices; public Task(Integer productId, Set&lt;Integer&gt; prices) &#123; this.productId = productId; this.prices = prices; &#125; @Override public void run() &#123; int price = 0; try &#123; Thread.sleep((long)(Math.random() * 4000)); price = (int)(Math.random() * 4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; prices.add(price); &#125; &#125; private Set&lt;Integer&gt; getPrices() &#123; Set&lt;Integer&gt; prices = Collections.synchronizedSet(new HashSet&lt;Integer&gt;()); CompletableFuture&lt;Void&gt; task1 = CompletableFuture.runAsync(new Task(123, prices)); CompletableFuture&lt;Void&gt; task2 = CompletableFuture.runAsync(new Task(456, prices)); CompletableFuture&lt;Void&gt; task3 = CompletableFuture.runAsync(new Task(789, prices)); CompletableFuture&lt;Void&gt; allTasks = CompletableFuture.allOf(task1, task2, task3); try &#123; allTasks.get(3, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; return prices; &#125; public static void main(String[] args) &#123; CompletableFutureDemo completableFutureDemo = new CompletableFutureDemo(); System.out.println(completableFutureDemo.getPrices()); &#125;&#125; CompletableFuture的runAsync()方法，这个方法会异步的去执行任务。 8.线程协作8.1 信号量 控制需要限制并发访问量的资源。 使用流程 初始化一个信号量，并传入许可证的数量。public Semaphore(int permits, boolean fair)，传入两个参数，第一个参数是许可证的数量，另一个参数是是否公平，如果为true，代表是公平的策略，会把之前已经在等待的线程放入到队列中，当有新的许可证时，会按照顺序发放；如果为false，则代表非公平策略，也就有可能插队。 在调用慢服务之前，线程调用acquire()或者acquireUninterruptibly()获取许可证。如果此时信号量没有剩余的许可证，那么线程会等在acquire()的这一行代码中，不会进一步执行下面调用服务的方法。 acquire()和acquireUninterruptibly()的区别：是否能够中断。acquire()支持中断，即在获取信号量期间，假如这个线程被中断了，那么它就会跳出acquire()，不再继续尝试获取了，而acquireUninterruptibly()方法是不会中断的。 任务执行完毕之后，调用release()释放许可证。 其他的主要方法 public boolean tryAcquire() 尝试获取许可证，获取不到不会阻塞，可以去做其他事。 public boolean tryAcquire(long timeout, TimeUnit unit) 超时时间到，依然获取不到许可证，认为获取失败，返回false。 availablePermits() 查询可用许可证的数量，返回一个整形的结果。 12345678910111213141516171819202122232425262728293031323334353637public class SemaphoreDemo2 &#123; static Semaphore semaphore = new Semaphore(5); static ThreadLocal&lt;StopWatch&gt; stopWatchThreadLocal = ThreadLocal.withInitial(() -&gt; new StopWatch()); private static class Task implements Runnable &#123; @Override public void run() &#123; try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"获取到许可证，开始执行任务！\"); StopWatch stopWatch = stopWatchThreadLocal.get(); stopWatch.start(); try &#123; Thread.sleep(3000); stopWatch.stop(); System.out.println(\"慢服务执行完毕，耗时：\" + stopWatch.getTotalTimeMillis() + \"---\" + Thread.currentThread().getName() + \"释放了许可证！\"); semaphore.release(); stopWatchThreadLocal.remove(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = new ThreadPoolExecutor(50, 50, 5, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 1000; i++) &#123; executorService.submit(new Task()); &#125; executorService.shutdown(); &#125;&#125; 特殊用法：一次获取或释放多个许可证 semphore.acquire(2) semaphore.release(3) 注意点 获取和释放的许可证数量尽量保持一致 在初始化时可以设置公平性，true会让它更公平，false则会让总的吞吐量更高 信号量是支持跨线程、跨线程池的，并且并不是哪个线程获得的许可证，就必须由这个线程去释放，对于获取和释放许可证的线程是没有要求的。 8.2 CountDownLatch 是如何安排线程执行顺序的？ 主要方法 构造函数 public CountDownLatch(int count){ } count是需要倒数的值 await() 调用await()方法的线程开始等待，直到倒数结束，也就是count值为0的时候才会继续执行。 await(long timeout, TimeUnit unit) 和await()类似，但这里可以设置超时时间，如果超时就不等待了。 countDown() 把数值倒数1，也就是将count值减1，直到减为0时，之前等待的线程会被唤起。 用法 12345678910111213141516171819202122232425262728293031323334public class RunDemo3 &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = new ThreadPoolExecutor(5, 5, 5, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(), new ThreadPoolExecutor.AbortPolicy()); CountDownLatch downLatch1 = new CountDownLatch(5); CountDownLatch downLatch2 = new CountDownLatch(1); for (int i = 0; i &lt; 5; i++) &#123; int finalI = i + 1; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(finalI + \"号运动员准备完毕，等待裁判员的发令枪\"); downLatch2.await(); Thread.sleep((long)(Math.random() * 10000)); System.out.println(finalI + \"号运动员完成了比赛\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; downLatch1.countDown(); &#125; &#125; &#125;; executorService.submit(runnable); &#125; Thread.sleep(5000); System.out.println(\"5秒准备时间已过，发令枪响，比赛开始！\"); downLatch2.countDown(); System.out.println(\"等待5个运动员都跑完....\"); downLatch1.await(); System.out.println(\"所有人都跑完了，比赛结束\"); executorService.shutdown(); &#125;&#125; 注意点 CountDownLatch是不能够重用的，比如已经完成了倒数，不可以在下一次继续去重新倒数。可以考虑使用CyclicBarrier或创建一个新的CountDownLatch实例。 8.3 CyclicBarrier和CountdownLatchCyclicBarrier可以构造出一个集结点，当某一个线程执行await()的时候，它就会到这个集结点开始等待，等待这个栅栏被撤销。直到预定数量的线程都到了这个集结点之后，这个栅栏就会撤销，之前等待的线程就在此刻统一出发，继续去执行剩下的任务。 12345678910111213141516171819202122232425262728293031323334353637public class CyclicBarrierDemo &#123; static class Task implements Runnable &#123; private int id; private CyclicBarrier cyclicBarrier; public Task(int id, CyclicBarrier cyclicBarrier) &#123; this.id = id; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; try &#123; System.out.println(\"同学\" + id + \"现在从大门出发，前往自行车驿站\"); Thread.sleep((long)(Math.random() * 10000)); System.out.println(\"同学\" + id + \"到了自行车驿站，开始等待其他人到达\"); cyclicBarrier.await(); System.out.println(\"同学\" + id + \"开始骑车\"); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new Runnable() &#123; // 当线程达到集结点，执行下一次动作之前，会执行一次这个动作 @Override public void run() &#123; System.out.println(\"凑齐3人了，GO！\"); &#125; &#125;); for (int i = 0; i &lt; 6; i++) &#123; new Thread(new Task(i + 1, cyclicBarrier)).start(); &#125; &#125;&#125; 执行动作barrierAction public CyclicBarrier(int parties, Runnable barrierAction): 当parties线程到达集结点时，继续往下执行前，会执行这一次这个动作。 1234567891011121314151617181920同学1现在从大门出发，前往自行车驿站同学5现在从大门出发，前往自行车驿站同学6现在从大门出发，前往自行车驿站同学4现在从大门出发，前往自行车驿站同学3现在从大门出发，前往自行车驿站同学2现在从大门出发，前往自行车驿站同学5到了自行车驿站，开始等待其他人到达同学2到了自行车驿站，开始等待其他人到达同学6到了自行车驿站，开始等待其他人到达凑齐3人了，GO！同学6开始骑车同学5开始骑车同学2开始骑车同学3到了自行车驿站，开始等待其他人到达同学4到了自行车驿站，开始等待其他人到达同学1到了自行车驿站，开始等待其他人到达凑齐3人了，GO！同学1开始骑车同学3开始骑车同学4开始骑车 CyclicBarrier和CountDownLatch的异同 相同点：都能阻塞一个或一组线程，直到某个预设条件达成，再统一出发。 不同点： 作用对象不同： CyclicBarrier要等固定数量的线程都到达了栅栏位置才能继续执行，而CountDownLatch只需等待数字到0，也就是说CountDownLatch作用于事件，但CyclicBarrier作用于线程；CountDownLatch是在调用了countDown方法之后把数字减1，而CyclicBarrier是在某线程开始等待后把计数减1。 可重用性不同： CountDownLatch在倒数0并且触发门闩打开后，就不能再次使用了，除非新建一个新的实例；而CyclicBarrier可以重复使用。CyclicBarrier还可以随时调用reset方法进行重置，如果重置时有线程已经调用了await方法并开始等待，那么这些线程则会抛出BrokenBarrierException异常。 执行动作不同： CyclicBarrier有执行动作barrierAction，而CountDownLatch没这个功能。 8.4 Condition、object都wait()何notify()的关系假设线程1需要等待某些条件满足后，才能继续运行，如等待某个时间点到达或者等待某些任务处理完毕。此时，就可以执行Condition的await方法，一旦执行了该方法，这个线程就会进入WATTING状态。通常还有另外一个线程2，它去达成对应的条件，直到这个条件达成之后，那么线程2调用signal方法或signalAll方法，代表”条件达成，之前等待这个条件的线程现在可以苏醒了“。这个时候，JVM就会找到等待该Condition的线程，并予以唤醒，线程1在此时就会被唤醒，线程状态又会回到Runnable。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ConditionDemo &#123; private ReentrantLock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); void task1() throws InterruptedException &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \":条件不满足，开始await\"); condition.await(); System.out.println(Thread.currentThread().getName() + \"条件满足了，开始执行后续的任务\"); &#125; finally &#123; lock.unlock(); &#125; &#125; void task2() throws InterruptedException &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \":需要5秒钟的准备时间\"); Thread.sleep(5000); System.out.println(Thread.currentThread().getName() + \":准备工作完成，唤醒其他的线程\"); condition.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ConditionDemo conditionDemo = new ConditionDemo(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; conditionDemo.task2(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); conditionDemo.task1(); &#125;&#125;main:条件不满足，开始awaitThread-0:需要5秒钟的准备时间Thread-0:准备工作完成，唤醒其他的线程main条件满足了，开始执行后续的任务 注意点 线程2解锁后，线程1才能获得锁并继续执行 调用signal之后，还需要等待子线程完全退出这个锁，即执行unlock之后，这个主线程才有可能去获取到这把锁，并且当获取锁成功之后才能继续执行后面的任务。 signalAll()和signal()区别 signalAll()会唤醒所有正在等待的线程，而signal()只会唤醒一个线程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/* * Condition实现简易版阻塞队列 */public class MyBlockingQueueForCondition &#123; private Queue queue; private int max = 16; private ReentrantLock lock = new ReentrantLock(); private Condition notEmpty = lock.newCondition(); private Condition notFull = lock.newCondition(); public MyBlockingQueueForCondition(int maxSize) &#123; this.max = maxSize; queue = new LinkedList(); &#125; public void put(Object object) throws InterruptedException &#123; lock.lock(); try &#123; while (queue.size() == max) &#123; notFull.await(); &#125; queue.add(object); notEmpty.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (queue.size() == 0) &#123; notEmpty.await(); &#125; Object item = queue.remove(); notFull.signalAll(); return item; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;/* * 使用wait/notify来实现简易版阻塞队列 */public class MyBlockingQueueForWaitNotify &#123; private int maxSize; private LinkedList&lt;Object&gt; queue; public MyBlockingQueueForWaitNotify(int maxSize) &#123; this.maxSize = maxSize; queue = new LinkedList&lt;&gt;(); &#125; public synchronized void put(Object object) throws InterruptedException &#123; while (queue.size() == maxSize) &#123; this.wait(); &#125; queue.add(object); this.notifyAll(); &#125; public synchronized Object take() throws InterruptedException &#123; while (queue.size() == 0) &#123; this.wait(); &#125; Object item = queue.remove(); this.notifyAll(); return item; &#125;&#125; Condition把Object的wait/notify/notifyAll转化为了一种相应的对象，其实现的效果基本一样，但是把更复杂的用法，变成了更直观可控的对象方法，是一种升级。await方法会自动释放持有的Lock锁，否则会抛出异常，和Object的wait一样，不需要自己手动释放锁。另外，调用await的时候必须持有锁，否则会抛出异常，这一点和Object的wait一样。 9.Java内存模型9.1 什么是Java内存模型？JVM内存结构 堆 堆是存放类实例和数组的，通常是内存中最大的一块。比如new Object()就会产生一个实例；而数组也是保存在堆上，因为在Java中，数组也是对象。 虚拟机栈 保存局部变量和部分结果，并在方法调用和返回中起作用。 方法区 它存储每个类的结构，例如运行时常量池、字段和方法数据，以及方法和构造函数的代码，包括用于类初始化以及接口初始化的特殊方法。 本地方法栈 与虚拟机栈类似，区别在于虚拟机栈为虚拟机执行的Java方法服务，而本地方法栈则是为Native方法服务。 程序计数器 最小的一块内存区域，它的作用通常是保存当前正在执行的JVM指令地址。 运行时常量池 是方法区的一部分，包含多种常量，范围从编译时已知的数字到必须在运行时解析的方法和字段引用。 为什么需要JMM(Java Memory Model, Java内存模型) 程序最终执行的效果依赖于具体的处理器，而不同的处理器的规则又不一样，需要一个标准，让多线程运行结果可以预期，这个标准就是JMM。 JMM是什么 JMM是规范 JMM是和多线程相关的一组规范，需要各个JVM的实现来遵守JMM规范。因此JMM与处理器、缓存、并发、编译器有关，它解决了CPU多级缓存、处理器优化、质量重排序等导致的结果不可预期的问题。 JMM是工具类和关键字的原理 如volatile、synchronized、Lock等原理都涉及JMM。重排序、原子性、内存可见性。 9.2 什么是指令重排序？为什么要进行重排序？假设我们写了一个Java程序，实际上语句的运行顺序可能可写的代码顺序不一致。编译器、JVM或者CPU都有可能出于优化等目的，对于实际指令执行的顺序进行调整。 重排序的好处：提高处理速度 重排序的3种情况 编译器优化 编译器(包括JVM、JIT编译器等)；重排序并不意味着可以任意排序，它需要保证重排序后，不改变单线程内的语义。 CPU重排序 CPU同样会有优化行为，即使之前的编译器不发生冲排，CPU也可能进行重排。 内存的”重排序” 内存系统不存在真正的重排序，但是内存会带来看上去和重排序一样的效果。由于内存有缓存的存在，在JMM里表现为主内存和本地内存，而主内存和本地内存的内容可能不一致，所以这也会导致程序表现出乱序的行为。 9.3 Java中的原子操作有哪些注意事项？原子操作指一系列操作要么全部发生，要么全部不发生，不会出现执行一半的情况。 Java中的原子操作有哪些 除了long和double之外的基本类型(int、byte、boolean、short、char、float)的读/写操作，都天然的具备原子性 所有引用reference的读/写操作 加了volatile后，所有变量的读/写操作(包含long/double) java.concurrent.Atomic包中的一部分类的一部分方法，比如AtomicInteger的incrementAndGet long和double的原子性 long和double的值需要占用64位的内存空间，而对于64位值的写入，可以分为两个32位的操作进行。因此，本来是一个整体的赋值操作，就可能被拆分为低32位和高32位两个操作。如果在这两个操作之间发生了其他线程对这个值的读操作，就可能会读到一个错误、不完整的值。 JVM的开发者可以自由选择是否把64位的long和double的读写操作作为原子操作去实现，并且规范推荐JVM将其实现为原子操作。 原子操作 + 原子操作 != 原子操作 9.4 什么是内存可见性123456789101112131415161718192021222324252627282930313233343536373839404142434445/* * 内存可见性问题 */public class VisibilityProblem &#123; int a = 10; int b = 20; private synchronized void change() &#123; a = 30; b = a; &#125; private synchronized void print() &#123; System.out.println(\"b=\" + b + \";a=\" + a); &#125; public static void main(String[] args) &#123; while (true) &#123; VisibilityProblem visibilityProblem = new VisibilityProblem(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; visibilityProblem.change(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; visibilityProblem.print(); &#125; &#125;).start(); &#125; &#125;&#125; 第1种情况：假设第1个线程，也就是执行change的线程先运行，并且运行完毕了，然后，第2个线程开始运行，打印出b=30;a=30 第2种情况：与第1种情况相反。因为线程先start，并不代表它真的先执行，所以第2种情况是第2个线程先打印b=20;a=10，然后第1个线程再去进行change 第3种情况：它们几乎同时运行，所以会出现交叉的情况。如第1个线程的change执行到一半，已经把a的值改为30了，而b的值还未来得及修改，此时第2个线程就开始打印，即打印结果为b=20;a=30 第4种情况：发生可见性问题，a的值已经被第1个线程修改了，但是其他线程却看不到，由于a的最新值没能及时同步过来，打印出b=30;a=10 volatile关键字解决可见性问题 synchronized不仅保证了原子性，还保证了可见性 synchronized不仅保证了临界区内最多同时只有一个线程执行操作，同时还保证了在前一个线程释放锁之后，之前所做的所有修改，都能被获得同一个锁的下一个线程所看到，也就是能读取到最新的值。 9.5 主内存与工作内存的关系CPU有多级缓存，导致读的数据过期 为了提高CPU的整体运行效率，减少空闲时间，在CPU和内存之间会有cache层(缓存层)。虽然缓存的容量比内存小，但是缓存的速度却比内存的速度要快得多，其中L1缓存的速度仅次于寄存器的速度。 线程间对于共享变量的可见性问题，并不是由多核引起的，而是由多级缓存引起的。每个核心在获取在获取数据时，都会将数据从内存一层层往上读取，同样，后续对于数据的修改也是先写入到自己的L1缓存中，然后等待时机再逐层往下同步，直到最终刷回内存。 假设core1修改了变量a的值，并写入到了core1的L1缓存里，但是还没来得及继续往下同步，由于core1有它自己的L1缓存，core4是无法直接获取core1的L1缓存的值，那么此时对于core4而言，变量a的值就不是core1修改后的最新的值，core4读取到的可能是一个过期的值，从而引起多线程时的可见性问题发生。 JMM的抽象：主内存和工作内存 每个线程都只能直接接触到工作内存，无法直接操作主内存，而工作内存中所保存的正是主内存的共享变量的副本，主内存和工作内存之间的通信是JMM控制的。 主内存和工作内存的关系 所有的变量都存储在主内存中，同时每个线程拥有自己独立的工作内存，而工作内存中的变量的内容内容是主内存中该变量的拷贝。 线程不能直接读/写主内存中的变量，但可以操作自己工作内存中的变量，然后再同步到主内存中，这样，其他线程就可以看到本次修改。 主内存是由多个线程所共享的，但线程之间不共享各自的工作内存，如果线程间需要通信，则必须借助主内存主内存来完成。","categories":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/categories/多线程/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/tags/多线程/"},{"name":"并发编程","slug":"并发编程","permalink":"http://tonymua.top/tags/并发编程/"}]},{"title":"Java常见小案例(不定时补充)","slug":"Java常用小案例(待补充)","date":"2021-05-08T13:19:59.133Z","updated":"2020-04-29T02:44:37.933Z","comments":true,"path":"15205/","link":"","permalink":"http://tonymua.top/15205/","excerpt":"1.不死神兔问题(斐波那契数列) 有一对兔子,从出生后第三个月起每个月都生一对兔子,小兔子长到第三个月后每个月又生一对兔子.假如兔子都不死,第N个月有多少兔子? 123456789101112131415161718//1 1 2 3 5 8 13 21 a[n]=a[n-1]+a[n-1-1]public class Test_01 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入月份:\"); Scanner scanner=new Scanner(System.in); int n=scanner.nextInt();//获取输入的整数 System.out.println(\"第\"+n+\"个月的兔子数为\"+function(n)); scanner.close(); &#125; //返回兔子数量 public static int function(int n) &#123; if (n==1||n==2) &#123; return 1; &#125; return function(n-1)+function(n-2);//递归 &#125;&#125;","text":"1.不死神兔问题(斐波那契数列) 有一对兔子,从出生后第三个月起每个月都生一对兔子,小兔子长到第三个月后每个月又生一对兔子.假如兔子都不死,第N个月有多少兔子? 123456789101112131415161718//1 1 2 3 5 8 13 21 a[n]=a[n-1]+a[n-1-1]public class Test_01 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入月份:\"); Scanner scanner=new Scanner(System.in); int n=scanner.nextInt();//获取输入的整数 System.out.println(\"第\"+n+\"个月的兔子数为\"+function(n)); scanner.close(); &#125; //返回兔子数量 public static int function(int n) &#123; if (n==1||n==2) &#123; return 1; &#125; return function(n-1)+function(n-2);//递归 &#125;&#125; 2.遍历101-200之间的所有素数123456789101112131415161718192021public class Test_02 &#123; public static void main(String[] args) &#123; int i; int j; int sum=0; boolean flag; for (i = 101; i &lt; 200; i++) &#123; flag=true; for (j = 2; j &lt;Math.sqrt(i); j++) &#123; if (i%j==0) &#123; flag=false; &#125; &#125; if (flag) &#123; System.out.println(i); sum++; &#125; &#125; System.out.println(\"共有\"+sum+\"个素数\"); &#125;&#125; 3.水仙花数问题 打印出所有的水仙花数,即一个三位数,其各位数字立方和等于该数本身.例如:153=13+53+3*3 123456789101112131415public class Test_03 &#123; public static void main(String[] args) &#123; int sum=0; for (int i = 100; i &lt; 1000; i++) &#123; int a=i%10;//求得各位 int b=i/10%10;//求得十位 int c=i/10/10%10;//求得百位 if (a*a*a+b*b*b+c*c*c==i) &#123; System.out.println(i+\" \"); sum++; &#125; &#125; System.out.println(\"共有\"+sum+\"个水仙花数\"); &#125;&#125; 4.分解质因数1234567891011121314151617181920212223//将一个正整数分解质因数 例如:输入90 打印输出90=2*3*3*5public class Test_04 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入一个正整数\"); Scanner scanner=new Scanner(System.in); int input=scanner.nextInt();//获取输入的正整数 System.out.println(input+\"=\"); if (input&lt;=1) &#123; System.out.println(input+\"是无效的分解数\"); &#125; for (int i = 2; i &lt; input+1; i++) &#123; while (input!=i) &#123; if (input%i==0) &#123; System.out.println(i+\"*\"); input=input/i; &#125;else &#123; break; &#125; &#125; &#125; System.out.println(input); &#125;&#125; 5.按分数划分等级(switch)1234567891011121314151617181920212223242526272829public class Test_05 &#123; public static void main(String[] args) &#123; System.out.println(\"请输入分数\"); Scanner scanner=new Scanner(System.in); int score=scanner.nextInt(); if (score&gt;100||score&lt;0) &#123; System.out.println(\"输入的分数有误\"); return; &#125; switch (score/10) &#123; case 10: case 9: System.out.println(\"A\"); break; case 8: System.out.println(\"B\"); break; case 7: System.out.println(\"C\"); break; case 6: System.out.println(\"D\"); break; default: System.out.println(\"E\"); break; &#125; &#125;&#125;","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"}]},{"title":"Java基础常见面试题","slug":"Java基础常见面试题","date":"2021-05-08T13:19:59.132Z","updated":"2020-04-29T02:44:38.021Z","comments":true,"path":"51576/","link":"","permalink":"http://tonymua.top/51576/","excerpt":"1.面向对象: 面向对象是一种思想，能让复杂问题简单化，程序员不需要了解具体的实现过程，只需要指挥对象去实现功能。如把需要洗的衣服交给洗衣机去洗. 多态: 允许不同类的对象对同一消息做出响应(发送消息就是函数调用) 2.封装继承多态举例: 封装：就像一个盒子，你不需要知道里面有什么东西，只知道它有那些用处就行 继承：就像父子关系，儿子是父亲的继承 多态：好比一个父亲有多个儿子，各个儿子有不同的特征 3.Array与ArrayList的区别:","text":"1.面向对象: 面向对象是一种思想，能让复杂问题简单化，程序员不需要了解具体的实现过程，只需要指挥对象去实现功能。如把需要洗的衣服交给洗衣机去洗. 多态: 允许不同类的对象对同一消息做出响应(发送消息就是函数调用) 2.封装继承多态举例: 封装：就像一个盒子，你不需要知道里面有什么东西，只知道它有那些用处就行 继承：就像父子关系，儿子是父亲的继承 多态：好比一个父亲有多个儿子，各个儿子有不同的特征 3.Array与ArrayList的区别: Array可以包含基本类型和对象类型, ArrayList只可以包含对象类型. Array大小不可改变, ArrayList的大小是可以动态变化的 ArrayList提供了更多的方法和特性, 如addAll(), removeAll() 4.ArrayList, Vector, LinkedList: ArrayList与Vector都是使用数组方式存储数据, LinkedList使用双向链表存储数据 ArrayList与Vector索引(查找)数据快插入和删除数据慢, Vector线程安全, 性能较差; LinkedList索引数据慢插入和删除数据快 注: ArrayList在并发add()时可能会出现数组下标越界 5.String, StringBuffer, StringBuilder: String: 字符串不可改变 StringBuffer: 字符串可变, 线程安全, 效率低 StringBuilder: 字符串可变, 线程不安全, 效率高 注: （1）如果要操作少量的数据用 String； ​ （2）多线程操作字符串缓冲区下操作大量数据 StringBuffer； ​ （3）单线程操作字符串缓冲区下操作大量数据 StringBuilder。 6.String为啥不可变: JDK中String被声明为一个fina类, 且内部的value字节数组也是final的; 安全, 多线程安全, 保证了hash码的唯一性 7.==比较的是什么: ‘’==’’ 对比两个对象基于内存引用, 如果两个对象的引用完全相同(指向同一个对象), ‘’==’’ 操作将返回true, 否则返回false ‘’==’’ 如果两边是基本类型, 就是比较数值是否相等 8.==与equals的区别: equals方法不能作用于基本数据类型的变量 没有重写equals方法时，是判断两个对象地址值是否相等。 重写了equals方法时，是判断两个对象所指向的内容是否相等。（如String、Date都重写了equals方法） 9.是否可以在static环境中访问非static变量: 不可以, static变量在Java中是属于类的,它在所有的实例中的值是一样的, 当类被Java虚拟机载入的时候, 会对static变量进行初始化. 如果尝试不用实例来访问非static的变量, 编译器会报错, 因为这些变量还没有被创建出来, 还没有与任何实例关联上 10.接口与抽象类的区别: 类可以实现很多个接口, 但只能继承一个抽象类 Java接口中声明的变量默认都是final的, 抽象类可以包含非final的变量 接口中所有的方法隐含的都是抽象的, 而抽象类则可以同时包含抽象和非抽象的方法 Java接口中的成员函数默认是public的, 抽象类的成员函数可以是private, protected或者public的 接口是绝对抽象的, 不可以被实例化. 抽象类页不可以被实例化, 但是, 如果它包含main()方法的话是可以被调用的 类如果要实现一个接口，它必须要实现接口声明的所有方法。但是，类可以不实现抽象类声明的所有方法，当然，在这种情况下，类也必须得声明成是抽象的。 11.Java里的final关键字怎么用: 当用final修饰一个类时, 表示这个类不能被继承 对于一个final变量, 如果是基本数据类型的变量, 则在其数值一旦在初始化之后便不能更改; 如果是引用类型的变量, 则在对其初始化之后便不能再让其指向另一个对象 注:使用final方法的原因有两个, 第一个原因是把方法锁定, 以防任何继承类修改它的含义; 第二个原因是效率, 在早期的Java实现版本中, 会将final方法转为内置方法 12.final, finally, finalize的区别: final用于声明属性, 方法和类, 分别表示属性不可改变, 方法不可覆盖, 类不可继承 finally是异常处理语句结构的一部分, 表示总是执行 finalize是Object类的一个方法, 在垃圾收集器执行的时候会调用被回收对象的此方法, 可以覆盖此方法提供垃圾收集时的其他资源回收, 例如关闭文件等 13.四种权限修饰符: 修饰符 同类中 同一个包中(子类和无关类) 不同包(子类) 不同包(无关类) public Y Y Y Y protected Y Y Y N 默认 Y Y N N private Y N N N 14.列举你所知道的Object类的方法: ​ Object()默认构造方法。 clone() 创建并返回此对象的一个副本。 equals(Object obj) 指示某个其他对象是否与此对象“相等”。 finalize()当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。getClass()返回一个对象的运行时类。 hashCode()返回该对象的哈希码值。 notify()唤醒在此对象监视器上等待的单个线程。 notifyAll()唤醒在此对象监视器上等待的所有线程。 toString()返回该对象的字符串表示。 wait()导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。 wait(long timeout)导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。 wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。 15.Java支持的数据类型有哪些? 什么是自动拆装箱? Java语言支持的8种基本数据类型是:byte short int long float double boolean char 自动装箱是Java编译器在基本数据类型和对应的对象包装数据类型之间做的一个转化, 分别对应的为: Byte Short Integer Long Float Double Boolean Character 16.Java集合类框架的基本接口有哪些? Collection: 代表一组对象, 每一个对象都是它的子元素 Set: 不包含重复元素的Collection List: 有顺序的Collection, 并可以包含重复元素 Map: 可以把键(key)映射到值(value)的对象, 键不能重复 17.Collection和Collections的区别: Collection是集合类的上级接口, 继承于它的接口主要有Set和List; Collections是针对集合类的一个帮助类, 他提供一系列静态方法实现对各种集合的搜索, 排序, 线程安全化等操作 18.List, Set, Map是否继承自Collection接口? List, Set是, Map不是 19.什么是迭代器: Iterator接口提供了很多对集合元素进行迭代的方法。每一个集合类都包含了可以返回迭代器实例的迭代方法。迭代器可以在迭代的过程中删除底层集合的元素。 20.Iterator和ListIterator的区别是什么: Iterator可用来遍历Set和List集合, 但是ListIterator只能用来遍历List Iterator对集合只能是向前遍历, ListIterator既可以向前也可以向后 ListIterator实现了iterator接口, 并包含其他功能, 比如:增加元素, 替换元素等 21.map的分类和常见的情况 Java为数据结构中的映射定义了一个接口java.util.Map;它有四个实现类,分别是HashMap Hashtable LinkedHashMap 和TreeMap Map主要用于存储健值对，根据键得到值，因此不允许键重复(重复了覆盖了),但允许值重复 Hashmap它根据键的HashCode值存储数据,根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。 HashMap最多只允许一条记录的键为Null;允许多条记录的值为 Null; HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap;可能会导致数据的不一致。如果需要同步，可以用 Collections的synchronizedMap方法使HashMap具有同步的能力，或者使用ConcurrentHashMap。 Hashtable与 HashMap类似,它继承自Dictionary类, 不同的是:它不允许记录的键或者值为空; 它支持线程的同步，即任一时刻只有一个线程能写Hashtable,因此也导致了 Hashtable在写入时会比较慢。 LinkedHashMap 是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关 TreeMap实现SortMap接口，能够把它保存的记录根据键排序, 默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的 22.为什么重写equals还要重写hashcode? 如果两个对象相同(即equals返回true)hashcode一定相等；但是hashcod相等时, 两个对象却不一定equals 为了提高程序的执行效率; 先进行hashcode比较, 如果不同, 就没有必要进行equals比较了, 这样就大大的减少了equals的使用次数, 从而效率得到提高 23.Java中的异常处理关键字是什么？ ​ try来执行一段程序，如果出现异常，系统会抛出（throws）一个异常，这时候你可以通过它的类型来捕捉（catch）它，或最后（finally）由缺省处理器来处理。用try来指定一块预防所有”异常”的程序。紧跟在try程序后面，应包含一个catch子句来指定你想要捕捉的”异常”的类型。 throw: 用来明确地抛出一个”异常”。 throws: 用来标明一个成员函数可能抛出的各种”异常”。 finally: 为确保一段代码不管发生什么”异常”都被执行一段代码。 24.请问运行时异常与受检异常有什么区别？ 运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。 25.error和exception有什么区别? error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception 表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 26.如何保证线程安全？ 通过合理的时间调度，避开共享资源的存取冲突 在并行任务设计上可以通过适当的策略，保证任务与任务之间不存在共享资源 27.举例说明同步和异步 如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。 28.请简述一下线程的sleep()方法和yield()方法有什么区别？ sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态 sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常 sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性 29.创建线程有几种不同的方式？ 继承Thread类 实现Runnable接口 30.请说明一下sleep() 和 wait() 有什么区别？ sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。wait是Object类的方法，对此对象调用wait方法导致本线程放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入对象锁定池准备获得对象锁进入运行状态。 31.请说明一下锁和同步的区别 synchronized既可以加在方法上，也可以加载特定代码块上，而lock需要显示地指定起始位置和终止位置。 synchronized是托管给JVM执行的，lock的锁定是通过代码实现的，它有比synchronized更精确的线程语义。 synchronized获取锁和释放锁的方式都是在块结构中，当获取多个锁时，必须以相反的顺序释放，并且是自动解锁。而Lock则需要开发人员手动释放，并且必须在finally中释放，否则会引起死锁。 32.请你谈谈关于Synchronized和lock synchronized是Java中的关键字，synchronized是内置的语言实现；synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；Lock是一个接口，Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁 Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"}]},{"title":"HashMap分析","slug":"HashMap分析","date":"2021-05-08T13:19:59.130Z","updated":"2020-07-05T14:21:39.646Z","comments":true,"path":"HashMap/","link":"","permalink":"http://tonymua.top/HashMap/","excerpt":"1.概述HashMap位于java.util包中，HashMap基于Map接口实现，元素以键值对的方式存储，并且允许使用null键和null值，因为key不允许重复，因此只能有一个键为null,另外HashMap不能保证放入元素的顺序，它是无序的，和放入的顺序并不能相同。HashMap是线程不安全的。它的底层为哈希表结构（链表散列：数组+链表）实现，结合数组和链表的优点。JDK1.8之后，当链表长度超过 8 时，链表转换为红黑树。","text":"1.概述HashMap位于java.util包中，HashMap基于Map接口实现，元素以键值对的方式存储，并且允许使用null键和null值，因为key不允许重复，因此只能有一个键为null,另外HashMap不能保证放入元素的顺序，它是无序的，和放入的顺序并不能相同。HashMap是线程不安全的。它的底层为哈希表结构（链表散列：数组+链表）实现，结合数组和链表的优点。JDK1.8之后，当链表长度超过 8 时，链表转换为红黑树。 HashMap主要属性： 1234567891011121314151617181920212223public class HashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable, Serializable &#123; private static final long serialVersionUID = 362498820763181265L; //HashMap的初始容量大小为16(1&lt;&lt;4)，指的是存储元素的数组大小，即桶的数量 //为啥是16呢? 因为在使用2的幂的数字的时候，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。这是为了实现均匀分布。 static final int DEFAULT_INITIAL_CAPACITY = 16; //HashMap的最大容量(1&lt;&lt;30) //使用位与运算速度更快 static final int MAXIMUM_CAPACITY = 1073741824; //默认负载因子0.75 //当HashMap中的数据量/HashMap的总容量=0.75或者指定值时，HashMap的总容量自动扩展一倍 //负载因子代表了hash表中元素的填满程度。加载因子越大，填满的元素越多，但是冲突的机会增大了，链表越来越长，查询速度会降低。反之，如果加载因子过小，冲突的机会减小了，但是hash表过于稀疏。冲突越大，查找的成本就越高。 static final float DEFAULT_LOAD_FACTOR = 0.75F; //由链表转换成树的阈值:8 //在存储数据时，当某一个桶中链表的长度&gt;=8时，链表结构会转换成红黑树结构(其实还要求桶的中数量&gt;=64) static final int TREEIFY_THRESHOLD = 8; //红黑树转为链表的阈值:6 //当在扩容(resize())时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量&lt;6时，则将红黑树转换成链表 static final int UNTREEIFY_THRESHOLD = 6; //最小树形化容量阈值:64 //当哈希表中的容量&gt;该值时，才允许链表转换成红黑树 static final int MIN_TREEIFY_CAPACITY = 64; ...... &#125; 2.NodeJDK 1.8采用的是Node数组，实质上还是Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体，以此来解决Hash冲突的问题。一个桶中链表的长度&lt;8时:一个桶中链表的长度&gt;=8时:数组存储区间是连续的，占用内存严重，故空间复杂度很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难；链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O(n)。链表的特点是：寻址困难，插入和删除容易。HashMap的设计正是分别结合了数组和链表的优点。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 3.hash算法首先获取对象的hashCode()值，然后将hashCode值右移16位，然后将右移后的值与原来的hashCode做异或(^)运算，返回结果。(其中h&gt;&gt;&gt;16，在JDK1.8中，优化了高位运算的算法，使用了零扩展，无论正数还是负数，都在高位插入0) 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 4.put()HashMap并没有直接提供putVal接口给用户调用，而是提供的put方法，而put方法就是通过putVal来插入元素的。 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向6，如果table[i]不为空，转向3； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向4，这里的相同指的是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向5； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;//put函数的核心处理函数 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //HashMap是懒加载，所有的put先检查table数组是否已经初始化，没有初始化则进行扩容数组初始化table数组，保证table数组一定初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //通过hash算法(n - 1) &amp; hash找到数组下标得到数组元素，为空则新建 //(n-1)&amp;hash就等价于hash%n。&amp;运算的效率高于%运算。 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //找到数组元素，hash相等同时key相等，则直接覆盖，执行赋值操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // hash值不相等，即key不相等 //判断链表是否是红黑树 else if (p instanceof TreeNode) //放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //遍历当前的链表，一直遍历到链表末尾 for (int binCount = 0; ; ++binCount) &#123; //到达链表的尾部 if ((e = p.next) == null) &#123; //在尾部插入结点(JDK1.8之前采用头插法，JDK1.8之后采用尾插法，使用尾插，在扩容时会保持链表元素原本的顺序，就不会出现链表成环) p.next = newNode(hash, key, value, null); //当链表长度超过8(阈值)，就会将链表便转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //记录修改次数 ++modCount; //判断是否需要扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; HashMap的数据存储实现流程 根据key计算得到key.hash = (h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)； 根据key.hash计算得到桶数组的索引index = key.hash &amp; (table.length - 1)，这样就找到该key的存放位置了 ① 如果该位置没有数据，用该数据新生成一个节点保存新数据，返回null； ② 如果该位置有数据是一个红黑树，那么执行相应的插入 / 更新操作； ③ 如果该位置有数据是一个链表，分两种情况一是该链表没有这个节点，另一个是该链表上有这个节点，注意这里判断的依据是key.hash是否一样： 如果该链表没有这个节点，那么采用尾插法新增节点保存新数据，返回null；如果该链表已经有这个节点了，那么找到该节点并更新新数据，返回老数据。 注意： HashMap的put会返回key的上一次保存的数据，比如： 1234HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();System.out.println(map.put(\"a\", \"A\")); // 打印nullSystem.out.println(map.put(\"a\", \"AA\")); // 打印ASystem.out.println(map.put(\"a\", \"AB\")); // 打印AA 5.get()HashMap同样并没有直接提供getNode接口给用户调用，而是提供的get方法，而get方法就是通过getNode来取得元素的。 123456789101112131415161718192021222324252627282930public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //若table已经初始化，长度大于0，根据hash寻找table中的项也不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //永远检查第一个node，桶中第一项(数组元素)相等 //在Hashmap1.8中，无论是存元素还是取元素，都是优先判断bucket上第一个元素是否匹配，而在1.7中则是直接遍历查找 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) //一次就匹配到了，直接返回， //否则进行搜索 return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) //红黑树搜索/查找 return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //链表搜索(查找) if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 基本流程: 根据key计算hash; 检查数组是否为空，为空返回null; 根据hash计算bucket位置，如果bucket第一个元素是目标元素，直接返回。否则执行4; 如果bucket上元素大于1并且是树结构，则执行树查找。否则执行5; 如果是链表结构，则遍历寻找目标 6.resize()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table;//定义了一个临时Node类型的数组 int oldCap = (oldTab == null) ? 0 : oldTab.length;//判断目前的table数组是否为空，记录下当前数组的大小 int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123;//如果oldCap不为空的话，就是hash桶数组不为空 //如果已达到最大容量不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //通过位运算扩容到原来的两倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold //用构造器初始化了阈值，将阈值直接赋值给容量 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) //初始化新的Node类型数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //将新数组的值复制给旧的hash桶数组 table = newTab; //当原来的table不为空，需要将数据迁移到新的数组里面去 if (oldTab != null) &#123; //开始对原table进行遍历 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //取出这个数组第一个不为空的元素 if ((e = oldTab[j]) != null) &#123; //将旧的hash桶数组在j结点处设置为空，把空间释放掉，方便gc oldTab[j] = null; //如果e后面没有Node结点 if (e.next == null) //计算相应的hash值，把节点存储到新table的对应位置处 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode)///如果e是红黑树的类型，按照红黑树的节点移动 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next;//将Node结点的next赋值给next //如果结点e的hash值与原hash桶数组的长度作与运算为0 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //如果结点e的hash值与原hash桶数组的长度作与运算不为0 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 7.面试题 Object若不重写hashcode()的话，hashcode是如何计算出来的？Object的hashcode()方法是本地方法，该方法直接返回对象的内存地址，如果不重写hashcode()，则任何对象的hashcode都不相等。(然而hashmap想让部分值的hashcoe值相等，所以需要重写) 为什么重写equals()还要重写hashcode()？HashMap中比较key先求出key的hashcode()，比较其值是否相等，相等则比较equals()，若相等则认为它们是相等的，若equals()不相等则认为它们是不相等的。如果只重写equals()不重写hashcode()，就会导致相同的key值被认为不同(如果不重写hashcode()，则任何对象的hashcode都不相等)，就会在HashMap中存储相同的key值(map中key值不能相同)。①如果两个对象相同（equals()比较返回true)，那么它们的hashcode值一定相同；②如果两个对象的hashcode值相同，它们并不一定相同(equals()比较返回false)","categories":[{"name":"源码分析","slug":"源码分析","permalink":"http://tonymua.top/categories/源码分析/"}],"tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://tonymua.top/tags/HashMap/"},{"name":"源码","slug":"源码","permalink":"http://tonymua.top/tags/源码/"},{"name":"底层","slug":"底层","permalink":"http://tonymua.top/tags/底层/"}]},{"title":"Git入门(二)","slug":"Git入门(二)","date":"2021-05-08T13:19:59.129Z","updated":"2020-04-29T02:44:38.019Z","comments":true,"path":"12318/","link":"","permalink":"http://tonymua.top/12318/","excerpt":"1.远程仓库1.1 添加远程库​ 现在我们已经在本地创建了一个Git仓库，又想让其他人来协作开发，此时就可以把本地仓库同步到远程仓库，同时还增加了本地仓库的一个备份。 常用的远程仓库就是github：https://github.com/，接下来我们演示如何将本地代码同步到github。 1.1.1 在github上创建仓库","text":"1.远程仓库1.1 添加远程库​ 现在我们已经在本地创建了一个Git仓库，又想让其他人来协作开发，此时就可以把本地仓库同步到远程仓库，同时还增加了本地仓库的一个备份。 常用的远程仓库就是github：https://github.com/，接下来我们演示如何将本地代码同步到github。 1.1.1 在github上创建仓库 ​ 点击“create repository”按钮仓库就创建成功了。 ​ Github支持两种同步方式“https”和“ssh”。如果使用https很简单基本不需要配置就可以使用，但是每次提交代码和下载代码时都需要输入用户名和密码。如果使用ssh方式就需要客户端先生成一个密钥对，即一个公钥一个私钥。然后还需要把公钥放到githib的服务器上。这两种方式在实际开发中都用应用，所以我们都需要掌握。接下来我们先看ssh方式。 1.1.2 ssh协议​ SSH 为 Secure Shell（安全外壳协议）的缩写，由 IETF 的网络小组（Network Working Group）所制定。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用SSH 协议可以有效防止远程管理过程中的信息泄露问题。 ssh密钥生成及配置 1.1.3 同步到远程仓库1.1.3.1 使用git bash在仓库所在的目录（E:\\temp\\git\\repository）点击右键选择“Git Bash Here”，启动git bash程序。 然后在git bash中执行如下语句： git remote add origin git@github.com:tonymua/mytest.git git push -u origin master 注意：其中阴影字体部分需要替换成个人的用户名。 1.1.3.2 使用TortoiseGit同步​ 1. 由于TortoiseGit使用的ssh工具是“PuTTY”git Bash使用的ssh工具是“openSSH”，如果想让TortoiseGit也使用刚才生成的密钥可以做如下配置： 同步。在本地仓库的文件夹中单击右键，选择“Git同步” 1.2 从远程仓库克隆​ 克隆远程仓库也就是从远程把仓库复制一份到本地，克隆后会创建一个新的本地仓库。选择一个任意部署仓库的目录，然后克隆远程仓库。 1.2.1 使用git bashgit clone git@github.com:tonymua/mytest.git 1.2.2 使用TortoiseGit在任意目录点击右键：”拉取” 1.3 从远程仓库取代码Git中从远程的分支获取最新的版本到本地有这样2个命令： git fetch：相当于是从远程获取最新版本到本地，不会自动merge（合并代码） git pull：相当于是从远程获取最新版本并merge到本地 上述命令其实相当于git fetch 和 git merge 在实际使用中，git fetch更安全一些 因为在merge前，我们可以查看更新情况，然后再决定是否合并 如果使用TortoiseGit的话可以从右键菜单中点击“拉取”（pull）或者“获取”（fetch） 1.4 搭建私有Git服务器1.4.1 服务器搭建​ 远程仓库实际上和本地仓库没啥不同，纯粹为了7x24小时开机并交换大家的修改。GitHub就是一个免费托管开源代码的远程仓库。但是对于某些视源代码如生命的商业公司来说，既不想公开源代码，又舍不得给GitHub交保护费，那就只能自己搭建一台Git服务器作为私有仓库使用。 搭建Git服务器需要准备一台运行Linux的机器，在此我们使用CentOS。以下为安装步骤： 安装git服务环境准备 yum -y install curl curl-devel zlib-devel openssl-devel perl cpio expat-devel gettext-devel gcc cc 下载git-2.5.0.tar.gz 1）解压缩 2）cd git-2.5.0 3）autoconf 4）./configure 5）make 6）make install 添加用户 adduser -r -c ‘git version control’ -d /home/git -m git 此命令执行后会创建/home/git目录作为git用户的主目录。 设置密码 passwd git 输入两次密码 切换到git用户 su git 创建git仓库 git –bare init /home/git/first 注意：如果不使用“–bare”参数，初始化仓库后，提交master分支时报错。这是由于git默认拒绝了push操作，需要.git/config添加如下代码： [receive] ​ denyCurrentBranch = ignore 推荐使用：git –bare init初始化仓库。 1.4.2 连接服务器私有git服务器搭建完成后就可以向连接github一样连接使用了，但是我们的git服务器并没有配置密钥登录，所以每次连接时需要输入密码。 使用命令连接： $ git remote add origin ssh://git@192.168.25.156/home/git/first 这种形式和刚才使用的形式好像不一样，前面有ssh://前缀，好吧你也可以这样写： $ git remote add origin git@192.168.25.156:first 使用TortoiseGit同步的话参考上面的使用方法。 2.分支管理2.1 建合并分支​ 在我们每次的提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD指针严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。 一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点： 每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。 当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上： Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变： 假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并： 所以Git合并分支也很快！就改改指针，工作区内容也不变！合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支： 2.2 使用TortoiseGit实现分支管理2.2.1 创建分支在本地仓库文件夹中点击右键，然后从菜单中选择“创建分支”： 如果想创建完毕后直接切换到新分支可以勾选“切换到新分支”选项或者从菜单中选择“切换/检出”来切换分支： 2.2.2 合并分支分支切换到dev后就可以对工作区的文件进行修改，然后提交到dev分支原理的master分支不受影响。例如我们修改mytest.txt中的内容，然后提交到dev分支。 切换到master分支后还是原理的内容： 将dev分支的内容合并到master分支，当前分支为master。从右键菜单中选择“合并”： 再查看mytest.txt的内容就已经更新了 2.3 解决冲突两个分支中编辑的内容都是相互独立互不干扰的，那么如果在两个分支中都对同一个文件进行编辑，然后再合并，就有可能会出现冲突。 例如在master分支中对mytest.txt进行编辑：然后提交到版本库。 切换到dev分支，对mytest.txt进行编辑：提交 最后进行分支合并，例如将dev分支合并到master分支。需要先切换到master分支然后进行分支合并。 冲突需要手动解决。 在冲突文件上单机右键选择“解决冲突”菜单项：把冲突解决完毕的文件提交到版本库就可以了。 3.在IntelliJ IDEA中使用Git3.1 在Idea中配置Git如果Git安装在默认路径下，那么idea会自动找到git的位置，如果更改了Git的安装位置则需要手动配置下Git的路径。 选择File→Settings打开设置窗口，找到Version Control下的git选项： 选择git的安装目录后可以点击“Test”按钮测试是否正确配置。 3.2 将工程添加至Git 在idea中创建一个工程，例如创建一个java工程 创建本地仓库 在菜单中选择“vcs”→Import into Version Control→Create Git Repository… 选择工程所在的上级目录。本例中应该选择idea-projects目录，然后点击“OK”按钮，在工程的上级目录创建本地仓库，那么ideaproject目录就是本地仓库的工作目录，此目录中的工程就可以添加到本地仓库中。也就是可以把idea-git-test工程添加到本地仓库中。 选择之后在工具栏上就多出了git相关工具按钮 将工程添加至本地仓库 直接点击commit按钮，将工程提交至本地仓库。 然后点击“commit”按钮，将工程添加至本地仓库。 推送到远程 在github上创建一个仓库然后将本地仓库推送到远程。 在工程上点击右键，选择git→Repository→push， 或者在菜单中选择vcs→git→push 点击“Define remote”链接，配置https形式的URL，git形式的无法通过。然后点击OK 点击“push”按钮就讲本地仓库推送到远程，如果是第一次配置推送需要输入github的用户名和密码。 3.3 从远程仓库克隆关闭工程后，在idea的欢迎页上有“Check out from version control”下拉框，选择git 此处仍然推荐使用htts形式的url，点击“test”按钮后显示连接成功。 点击OK按钮后根据提示将远程仓库克隆下来，然后倒入到idea中。 3.4 从服务端拉取代码如果需要从服务端同步代码可以使用工具条中的“update”按钮","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Git入门(一)","slug":"Git入门(一)","date":"2021-05-08T13:19:59.127Z","updated":"2020-04-29T02:44:38.018Z","comments":true,"path":"61626/","link":"","permalink":"http://tonymua.top/61626/","excerpt":"1.Git与svn对比1.1 SVN​ SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就郁闷了。下图就是标准的集中式版本控制工具管理方式：","text":"1.Git与svn对比1.1 SVN​ SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而干活的时候，用的都是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，带宽够大，速度够快，如果在互联网下，如果网速慢的话，就郁闷了。下图就是标准的集中式版本控制工具管理方式： ​ 集中管理方式在一定程度上看到其他开发人员在干什么，而管理员也可以很轻松掌握每个人的开发权限。 但是相较于其优点而言，集中式版本控制工具缺点很明显： 服务器单点故障 容错性差 2.2 Git​ Git是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。下图就是分布式版本控制工具管理方式： 2.Git工作流程一般工作流程如下： 1．从远程仓库中克隆 Git 资源作为本地仓库。 2．从本地仓库中checkout代码然后进行代码修改 3．在提交前先将代码提交到暂存区。 4．提交修改。提交到本地仓库。本地仓库中保存修改的各个历史版本。 5．在修改完成后，需要和团队成员共享代码时，可以将代码push到远程仓库。 下图展示了 Git 的工作流程： 3.使用git管理文件版本3.1 创建版本库​ 什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。由于git是分布式版本管理工具，所以git在不需要联网的情况下也具有完整的版本管理能力。 3.1.1 使用GitBash在当前目录中点击右键中选择Git Bash来启动, 或者在开始菜单中启动。 注意如果是从开始菜单启动的gitbash需要切换目录到仓库所在的目录。 创建仓库执行命令：git init 概念： 版本库：“.git”目录就是版本库，将来文件都需要保存到版本库中。 工作目录：包含“.git”目录的目录，也就是.git目录的上一级目录就是工作目录。只有工作目录中的文件才能保存到版本库中。 3.2 添加文件3.2.1 添加文件过程在E:\\temp\\git\\repository目录下创建一个mytest.txt文件 提交文件：在mytest.txt上再次点击右键选择“提交”，此时将文件保存至版本库中。 3.2.2 工作区和暂存区Git和其他版本控制系统如SVN的一个不同之处就是有暂存区的概念。 什么是工作区（Working Directory）？ 工作区就是你在电脑里能看到的目录，比如我的reporstory文件夹就是一个工作区。 有的同学可能会说repository不是版本库吗怎么是工作区了？其实repository目录是工作区，在这个目录中的“.git”隐藏文件夹才是版本库。这回概念清晰了吧。 Git的版本库里存了很多东西，其中最重要的就是称为（或者叫）的暂存区，还有为我们自动创建的第一个分支，以及指向的一个指针叫HEAD。如下图所示： 把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。 你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 3.3 修改文件3.3.1 提交修改​ 被版本库管理的文件不可避免的要发生修改，此时只需要直接对文件修改即可。修改完毕后需要将文件的修改提交到版本库。 修改test.txt文件后点击右键，然后选择“提交” 3.3.2 查看修改历史在开发过程中可能会经常查看代码的修改历史，或者叫做修改日志。来查看某个版本是谁修改的，什么时间修改的，修改了哪些内容。 可以在文件上点击右键选择“显示日志”来查看文件的修改历史。 3.3.3 差异比较当文件内容修改后，需要和修改之前对比一下修改了哪些内容此时可以使用“比较差异功能” 3.3.4 还原修改当文件修改后不想把修改的内容提交，还想还原到未修改之前的状态。此时可以使用“还原”功能 注意：此操作会撤销所有未提交的修改，所以当做还原操作是需要慎重慎重！！！ 3.4 删除文件需要删除无用的文件时可以使用git提供的删除功能直接将文件从版本库中删除。 3.5 案例：将java工程提交到版本库 第一步：将参考资料中的java工程HelloProjet复制到工作目录中 第二步：将工程添加到暂存区 ​ 点击确定完成暂存区添加 忽略文件或文件夹 ​ 在此工程中，并不是所有文件都需要保存到版本库中的例如“out”目录及目录下的文件就可以忽略。好在Git考虑到了大家的感受，这个问题解决起来也很简单，在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 如果使用TortoiseGit的话可以使用菜单项直接进行忽略 选择保留本地文件。完成后在此文件夹内会多出一个.gitignore文件，这个文件就是文件忽略文件，当然也可以手工编辑。其中的内容就是把out目录忽略掉。 提交 3.6 忽略文件语法规范空行或是以 # 开头的行即注释行将被忽略。 可以在前面添加正斜杠 / 来避免递归,下面的例子中可以很明白的看出来与下一条的区别。 可以在后面添加正斜杠 / 来忽略文件夹，例如 build/ 即忽略build文件夹。 可以使用 ! 来否定忽略，即比如在前面用了 *.apk ，然后使用 !a.apk ，则这个a.apk不会被忽略。 * 用来匹配零个或多个字符，如 *.[oa] 忽略所有以”.o”或”.a”结尾， *~ 忽略所有以 ~ 结尾的文件（这种文件通常被许多编辑器标记为临时文件）； [] 用来匹配括号内的任一字符，如 [abc] ，也可以在括号内加连接符，如 [0-9] 匹配0至9的数； ? 用来匹配单个字符。 看了这么多，还是应该来个栗子： # 忽略 .a 文件 *.a # 但否定忽略 lib.a, 尽管已经在前面忽略了 .a 文件 !lib.a # 仅在当前目录下忽略 TODO 文件， 但不包括子目录下的 subdir/TODO /TODO # 忽略 build/ 文件夹下的所有文件 build/ # 忽略 doc/notes.txt, 不包括 doc/server/arch.txt doc/*.txt # 忽略所有的 .pdf 文件 在 doc/ directory 下的 doc/*/.pdf","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]},{"title":"Git","slug":"Git","date":"2021-05-08T13:19:59.126Z","updated":"2020-08-05T07:34:41.314Z","comments":true,"path":"git_shell/","link":"","permalink":"http://tonymua.top/git_shell/","excerpt":"Git1.创建版本库 git init 把这个目录变成Git可以管理的仓库 git add readme.md 把文件添加到仓库 git commit -m “wrote a readme file” -m后面输入的是本次提交的说明","text":"Git1.创建版本库 git init 把这个目录变成Git可以管理的仓库 git add readme.md 把文件添加到仓库 git commit -m “wrote a readme file” -m后面输入的是本次提交的说明 2.版本回退 修改readme.md内容git add readme.txtgit commit -m “append GPL”ps: git log可以查看版本历史记录 git reset –hard HEAD^ps: HEAD^表示上一个版本 HEAD^表示上上个版本 HEAD~100表示往上100个版本 命令行窗口还没有被关掉时，找到某个版本的commit id，也能进行回退。git reset –hard xxxxxxxx命令行窗口被被关掉时，使用git reflog查看记录的每一次命令 3.工作区和暂存区 工作区电脑里能看到的目录，比如gittest文件夹就是一个工作区 版本库工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。git add . 添加所有数据git commit -m “understand how stage works” 4.管理修改 对readme.txt做一个修改git add readme.md再修改readme.mdgit commit -m “git tracks changes” 提交 git status然而，第二次修改并没有被提交，第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git commitGit管理的是修改，当你用git add命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，git commit只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。git diff HEAD – readme.md 查看工作区和版本库里面最新版本的区别 提交第二次修改第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commit 5.撤销修改 git checkout – readme.md 丢弃工作区的修改一种是readme.md自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；一种是readme.md已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。总之，就是让这个文件回到最近一次git commit或git add时的状态。 git add后修改git reset HEAD readme.md 把暂存区的修改撤销掉git checkout – readme.md 丢弃工作区的修改 6.删除文件 先添加一个新文件test.txt到Git并且提交git add test.txtgit commit -m “add test.txt” 直接在文件管理器中把没用的文件删了，或者用rm命令删除rm test.txt从版本库中删除该文件，那就用命令git rm删掉，并且git commitgit rm test.txtgit commit -m “remove test.txt”删错了，因为版本库里还有，所以可以把误删的文件恢复到最新版本git checkout – test.txt 7.远程仓库 添加远程库在GitHub创建一个Git仓库git remote add origin git@github.com:xxxxxxxx 关联git push -u origin master 把本地库的所有内容推送到远程库上 从远程库克隆git clone git@github.com:xxxxxxxxx 8.分支管理 创建与合并分支git switch -c dev 创建dev分支，然后切换到dev分支git branch 查看当前分支修改readme.md git add readme.md git commit -m “branch test”git switch master 切换回master分支再查看readme.md文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变。git merge dev 把dev分支的工作成果合并到master分支上git branch -d dev 删除dev分支 解决冲突git switch -c feature1 准备新的feature1分支修改readme.mdgit add readme.mdgit commit -m “AND simple” 在feature1分支上提交git switch master 切换到master分支在master分支上把readme.md进行不同修改git add readme.mdgit commit -m “&amp; simple” 在master分支上提交这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突。git status 查看冲突的文件手动修改文件解决冲突后再提交git add readme.txtgit commit -m “conflict fixed”git branch -d feature1 删除feature1分支准备合并dev分支，请注意--no-ff参数，表示禁用Fast forward Bug分支git stash 把当前工作现场“储藏”起来，等以后恢复现场后继续工作git switch -c issue-101修改Bug，然后提交git add readme.txtgit commit -m “fix bug 101”修复完成后，切换到master分支，并完成合并，最后删除issue-101分支git switch mastergit merge –no-ff -m “merged bug fix 101” issue-101git switch devgit stash pop 删除stash复制一个特定的提交到当前分支git loggit cherry-pick 4e4858db453de3da86ee2eafc2 多人协作git remote -v 查看远程库的详细信息多人协作的工作模式通常是这样： 首先，可以试图用git push origin推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin推送就能成功！如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to origin/。 忽略特殊文件在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。不需要从头写.gitignore文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：https://github.com/github/gitignore把.gitignore也提交到Git","categories":[{"name":"Git","slug":"Git","permalink":"http://tonymua.top/categories/Git/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://tonymua.top/tags/shell/"},{"name":"Git","slug":"Git","permalink":"http://tonymua.top/tags/Git/"}]},{"title":"Druid连接池的配置与使用","slug":"Druid连接池的配置与使用","date":"2021-05-08T13:19:59.124Z","updated":"2020-04-29T02:44:37.931Z","comments":true,"path":"30630/","link":"","permalink":"http://tonymua.top/30630/","excerpt":"Druid连接池的配置与使用Druid（德鲁伊）连接池 是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池(据说是目前最好的连接池)。github地址：https://github.com/alibaba/druid/ maven仓库地址：http://www.mvnrepository.com/artifact/com.alibaba/druid Druid连接池的使用步骤1.导入jar包https://pan.baidu.com/s/1jOaM-nFfxx7PcQ6_Nvu-Uw提取码: eyl0","text":"Druid连接池的配置与使用Druid（德鲁伊）连接池 是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、PROXOOL等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池(据说是目前最好的连接池)。github地址：https://github.com/alibaba/druid/ maven仓库地址：http://www.mvnrepository.com/artifact/com.alibaba/druid Druid连接池的使用步骤1.导入jar包https://pan.baidu.com/s/1jOaM-nFfxx7PcQ6_Nvu-Uw提取码: eyl0 2.配置文件 Druid.properties123456789101112131415#驱动的名字:com.mysql.jdbc.DriverdriverClassName=com.mysql.jdbc.Driver#数据库的地址:jdbc:mysql://localhost:3306/bankurl=jdbc:mysql://localhost:3306/bank#数据库管理账号和密码username=rootpassword=547717253#初始链接数:10initialSize=10#最大并行链接数:50maxActive=50#最小空闲数:5minIdle=5#最大等待时间(毫秒):60000maxWait=60000 3.DruidUtils1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class DruidUtils &#123; /** * 定义一个连接池 */ private static DataSource dataSource; /** 初始化连接池 */ static &#123; try &#123; InputStream is = DruidUtils.class.getClassLoader().getResourceAsStream(\"Druid.properties\"); Properties prop = new Properties(); prop.load(is); dataSource = DruidDataSourceFactory.createDataSource(prop); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 通过连接池获取连接 */ public static Connection getConnection() throws SQLException &#123; return dataSource.getConnection(); &#125; /** * 关闭连接，归还资源 */ public static void release(Connection conn , PreparedStatement ps , ResultSet rs)&#123; closeRs(rs); closeSt(ps); closeConn(conn); &#125; public static void release(Connection conn , PreparedStatement ps)&#123; closeSt(ps); closeConn(conn); &#125; private static void closeRs(ResultSet rs)&#123; try &#123; if(rs != null)&#123; rs.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; rs = null; &#125; &#125; private static void closeSt(PreparedStatement ps)&#123; try &#123; if(ps != null)&#123; ps.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; ps = null; &#125; &#125; private static void closeConn(Connection conn)&#123; try &#123; if(conn != null)&#123; conn.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; conn = null; &#125; &#125;&#125; 4.测试12345678910111213141516171819public class DruidDemo &#123; @Test public void testDruid() &#123; Connection conn = null; PreparedStatement ps = null; try &#123; conn = DruidUtils.getConnection(); String sql = \"insert into account values(null,?,?)\"; ps = conn.prepareStatement(sql); ps.setString(1, \"test\"); ps.setInt(2, 2000); ps.executeUpdate(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally &#123; DruidUtils.release(conn, ps); &#125; &#125;&#125;","categories":[],"tags":[{"name":"javaee","slug":"javaee","permalink":"http://tonymua.top/tags/javaee/"}]},{"title":"Docker入门","slug":"Docker入门","date":"2021-05-08T13:19:59.123Z","updated":"2020-04-29T02:44:38.067Z","comments":true,"path":"11205/","link":"","permalink":"http://tonymua.top/11205/","excerpt":"1.Docker简介1.1 什么是虚拟化​ 在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。 ​ 在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件对资源充分利用 虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。","text":"1.Docker简介1.1 什么是虚拟化​ 在计算机中，虚拟化（英语：Virtualization）是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等，予以抽象、转换后呈现出来，打破实体结构间的不可切割的障碍，使用户可以比原本的组态更好的方式来应用这些资源。这些资源的新虚拟部份是不受现有资源的架设方式，地域或物理组态所限制。一般所指的虚拟化资源包括计算能力和资料存储。 ​ 在实际的生产环境中，虚拟化技术主要用来解决高性能的物理硬件产能过剩和老的旧的硬件产能过低的重组重用，透明化底层物理硬件，从而最大化的利用物理硬件对资源充分利用 虚拟化技术种类很多，例如：软件虚拟化、硬件虚拟化、内存虚拟化、网络虚拟化(vip)、桌面虚拟化、服务虚拟化、虚拟机等等。 1.2 什么是Docker​ Docker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub 上进行维护。 ​ Docker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。 ​ 在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。 为什么选择Docker? （1）上手快 ​ 用户只需要几分钟，就可以把自己的程序“Docker化”。Docker依赖于“写时复制”（copy-on-write）模型，使修改应用程序也非常迅速，可以说达到“随心所致，代码即改”的境界。随后，就可以创建容器来运行应用程序了。大多数Docker容器只需要不到1秒中即可启动。由于去除了管理程序的开销，Docker容器拥有很高的性能，同时同一台宿主机中也可以运行更多的容器，使用户尽可能的充分利用系统资源。 （2）职责的逻辑分类 ​ 使用Docker，开发人员只需要关心容器中运行的应用程序，而运维人员只需要关心如何管理容器。Docker设计的目的就是要加强开发人员写代码的开发环境与应用程序要部署的生产环境一致性。从而降低那种“开发时一切正常，肯定是运维的问题（测试环境都是正常的，上线后出了问题就归结为肯定是运维的问题）” （3）快速高效的开发生命周期 ​ Docker的目标之一就是缩短代码从开发、测试到部署、上线运行的周期，让你的应用程序具备可移植性，易于构建，并易于协作。（通俗一点说，Docker就像一个盒子，里面可以装很多物件，如果需要这些物件的可以直接将该大盒子拿走，而不需要从该盒子中一件件的取。） （4）鼓励使用面向服务的架构 ​ Docker还鼓励面向服务的体系结构和微服务架构。Docker推荐单个容器只运行一个应用程序或进程，这样就形成了一个分布式的应用程序模型，在这种模型下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序都变得非常简单，同时也提高了程序的内省性。（当然，可以在一个容器中运行多个应用程序） 1.3 容器与虚拟机比较​ 容器是在操作系统层面上实现虚拟化，直接复用本地主机的操作系统，而传统方式则是在硬件层面实现。与传统的虚拟机相比，Docker优势体现为启动速度快、占用体积小。 1.4 Docker 组件1.4.1 Docker服务器与客户端​ Docker是一个客户端-服务器（C/S）架构程序。Docker客户端只需要向Docker服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作并返回结果。Docker提供了一个命令行工具Docker以及一整套RESTful API。你可以在同一台宿主机上运行Docker守护进程和客户端，也可以从本地的Docker客户端连接到运行在另一台宿主机上的远程Docker守护进程。 1.4.2 Docker镜像与容器​ 镜像是构建Docker的基石。用户基于镜像来运行自己的容器。镜像也是Docker生命周期中的“构建”部分。镜像是基于联合文件系统的一种层式结构，由一系列指令一步一步构建出来。例如：添加一个文件；执行一个命令；打开一个窗口。也可以将镜像当作容器的“源代码”。镜像体积很小，非常“便携”，易于分享、存储和更新。 ​ Docker可以帮助你构建和部署容器，你只需要把自己的应用程序或者服务打包放进容器即可。容器是基于镜像启动起来的，容器中可以运行一个或多个进程。我们可以认为，镜像是Docker生命周期中的构建或者打包阶段，而容器则是启动或者执行阶段。 容器基于镜像启动，一旦容器启动完成后，我们就可以登录到容器中安装自己需要的软件或者服务。所以Docker容器就是：一个镜像格式；一些列标准操作；一个执行环境。 Docker借鉴了标准集装箱的概念。标准集装箱将货物运往世界各地，Docker将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而Docker运输软件。和集装箱一样，Docker在执行上述操作时，并不关心容器中到底装了什么，它不管是web服务器，还是数据库，或者是应用程序服务器什么的。所有的容器都按照相同的方式将内容“装载”进去。 Docker也不关心你要把容器运到何方：我们可以在自己的笔记本中构建容器，上传到Registry，然后下载到一个物理的或者虚拟的服务器来测试，在把容器部署到具体的主机中。像标准集装箱一样，Docker容器方便替换，可以叠加，易于分发，并且尽量通用。 1.4.3 Registry（注册中心）​ Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker公司运营公共的Registry叫做Docker Hub。用户可以在Docker Hub注册账号，分享并保存自己的镜像（说明：在Docker Hub下载镜像巨慢，可以自己构建私有的Registry）。 2.Docker安装与启动2.1 安装Docker（1）yum 包更新到最新 1sudo yum update （2）安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 （3）设置yum源为阿里云 1sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo （4）安装docker 1sudo yum install docker-ce （5）安装后查看docker版本 1docker -v 2.2 设置ustc的镜像​ ustc是老牌的linux镜像服务提供者了，还在遥远的ubuntu 5.04版本的时候就在用。ustc的docker镜像加速器速度很快。ustc docker mirror的优势之一就是不需要注册，是真正的公共服务。 https://lug.ustc.edu.cn/wiki/mirrors/help/docker 编辑该文件： 1vi /etc/docker/daemon.json 在该文件中输入如下内容： 123&#123;\"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn\"]&#125; 2.3 Docker的启动与停止systemctl命令是系统服务管理器指令 启动docker： 1systemctl start docker 停止docker： 1systemctl stop docker 重启docker： 1systemctl restart docker 查看docker状态： 1systemctl status docker 开机启动： 1systemctl enable docker 查看docker概要信息 1docker info 查看docker帮助文档 1docker --help 3.常用命令3.1 镜像相关命令3.1.1 查看镜像1docker images REPOSITORY：镜像名称 TAG：镜像标签 IMAGE ID：镜像ID CREATED：镜像的创建日期（不是获取该镜像的日期） SIZE：镜像大小 这些镜像都是存储在Docker宿主机的/var/lib/docker目录下 3.1.2 搜索镜像如果你需要从网络中查找需要的镜像，可以通过以下命令搜索 1docker search 镜像名称 NAME：仓库名称 DESCRIPTION：镜像描述 STARS：用户评价，反应一个镜像的受欢迎程度 OFFICIAL：是否官方 AUTOMATED：自动构建，表示该镜像由Docker Hub自动构建流程创建的 3.1.3 拉取镜像拉取镜像就是从中央仓库中下载镜像到本地 1docker pull 镜像名称 例如，我要下载centos7镜像 1docker pull centos7 3.1.4 删除镜像按镜像ID删除镜像 1docker rmi 镜像ID 删除镜像时必须将里面的容器全部停掉 删除所有镜像 1docker rmi `docker images -q` 3.2 容器相关命令3.2.1 查看容器查看正在运行的容器 1docker ps 查看所有容器 1docker ps -a 查看最后一次运行的容器 1docker ps -l 查看停止的容器 1docker ps -f status=exited 3.2.2 创建与启动容器创建容器常用的参数说明： 创建容器命令：docker run -i：表示运行容器 -t：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。 –name :为创建的容器命名。 -v：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个－v做多个目录或文件映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。 -d：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t两个参数，创建后就会自动进去容器）。 -p：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射 （1）交互式方式创建容器 1docker run -it --name=容器名称 镜像名称:标签 /bin/bash 命令窗口1: 命令窗口2: 退出当前容器 1exit 以交互方式创建的容器在退出的时候容器运行就停止了。 （2）守护式方式创建容器： 1docker run -di --name=容器名称 镜像名称:标签 登录守护式容器方式： 1docker exec -it 容器名称 (或者容器ID) /bin/bash 创建守护式容器后，退出时容器继续运行 3.2.3 停止与启动容器停止容器： 1docker stop 容器名称（或者容器ID） 启动容器： 1docker start 容器名称（或者容器ID） 3.2.4 文件拷贝如果我们需要将文件拷贝到容器内可以使用cp命令 1docker cp 需要拷贝的文件或目录 容器名称:容器目录 也可以将文件从容器内拷贝出来 1docker cp 容器名称:容器目录 需要拷贝的文件或目录 3.2.5 目录挂载​ 我们可以在创建容器的时候，将宿主机的目录与容器内的目录进行映射，这样我们就可以通过修改宿主机某个目录的文件从而去影响容器。创建容器 添加-v参数 后边为 宿主机目录:容器目录，例如： 1docker run -di -v /usr/local/myhtml:/usr/local/myhtml --name=mycentos3 centos:7 如果你共享的是多级的目录，可能会出现权限不足的提示。 这是因为CentOS7中的安全模块selinux把权限禁掉了，我们需要添加参数 –privileged=true 来解决挂载的目录没有权限的问题 3.2.6 查看容器IP地址我们可以通过以下命令查看容器运行的各种数据 1docker inspect 容器名称（容器ID） 也可以直接执行下面的命令直接输出IP地址 1docker inspect --format='&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' 容器名称（容器ID） 3.2.7 删除容器删除指定的容器： 1docker rm 容器名称（容器ID） 4 应用部署4.1 MySQL部署（1）拉取mysql镜像 1docker pull centos/mysql-57-centos7 （2）创建容器 1docker run -di --name=tensquare_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=547717253 mysql -p 代表端口映射，格式为 宿主机映射端口:容器运行端口 -e 代表添加环境变量 MYSQL_ROOT_PASSWORD 是root用户的登陆密码 （3）远程登录mysql 连接宿主机的IP ,指定端口为33306 4.2 tomcat部署（1）拉取镜像 1docker pull tomcat:7-jre7 （2）创建容器 创建容器 -p表示地址映射 12docker run -di --name=mytomcat -p 9000:8080 -v /usr/local/webapps:/usr/local/tomcat/webapps tomcat:7-jre7 4.3 Nginx部署（1）拉取镜像 1docker pull nginx （2）创建Nginx容器 1docker run -di --name=mynginx -p 80:80 nginx 4.4 Redis部署（1）拉取镜像 1docker pull redis （2）创建容器 1docker run -di --name=myredis -p 6379:6379 redis 5 迁移与备份5.1 容器保存为镜像我们可以通过以下命令将容器保存为镜像 1docker commit myredis myredis_i 5.2 镜像备份我们可以通过以下命令将镜像保存为tar 文件 1docker save -o myredis.tar myredis_i 5.3 镜像恢复与迁移先删除myredis_i创建的容器myredis，然后再删除myredis_i镜像。 然后执行此命令进行恢复 1docker load -i mynginx.tar 执行后再次查看镜像，可以看到镜像已经恢复 6 Dockerfile6.1 什么是Dockerfile​ Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像（centos或者ubuntu，即操作系统级别的镜像）并最终创建一个新的镜像。 (1) 对于开发人员：可以为开发团队提供一个完全一致的开发环境；(2) 对于测试人员：可以直接拿开发时所构建的镜像或者通过Dockerfile文件构建一个新的镜像开始工作了；(3) 对于运维人员：在部署时，可以实现应用的无缝移植。 6.2 常用命令 命令 作用 FROM image_name:tag 定义了使用哪个基础镜像启动构建流程 MAINTAINER user_name 声明镜像的创建者 ENV key value 设置环境变量 (可以写多条) RUN command 是Dockerfile的核心部分(可以写多条) ADD source_dir/file dest_dir/file 将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复制后自动解压 COPY source_dir/file dest_dir/file 和ADD相似，但是如果有压缩文件并不能解压 WORKDIR path_dir 设置工作目录 6.3 使用脚本创建镜像(例:构建JDK8)步骤： （1）创建目录 1mkdir –p /usr/local/dockerjdk8 （2）下载jdk-8u171-linux-x64.tar.gz并上传到服务器（虚拟机）中的/usr/local/dockerjdk8目录 （3）创建文件Dockerfile vi Dockerfile 123456789101112131415#依赖镜像名称和IDFROM centos:7#指定镜像创建者信息MAINTAINER ITCAST#切换工作目录WORKDIR /usrRUN mkdir /usr/local/java#ADD 是相对路径jar,把java添加到容器中ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/#配置java环境变量ENV JAVA_HOME /usr/local/java/jdk1.8.0_171ENV JRE_HOME $JAVA_HOME/jreENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH $JAVA_HOME/bin:$PATH （4）执行命令构建镜像 1docker build -t='jdk1.8' . 注意后边的空格和点，不要省略 （5）查看镜像是否建立完成 1docker images 7 Docker私有仓库7.1 私有仓库搭建与配置(1) 拉取私有仓库镜像（此步省略） 1docker pull registry (2) 启动私有仓库容器 1docker run -di --name=registry -p 5000:5000 registry (3) 打开浏览器 输入地址http://192.168.179.101:5000/v2/_catalog看到`{&quot;repositories&quot;:[]}`表示私有仓库搭建成功并且内容为空 （4）修改daemon.json 1vi /etc/docker/daemon.json 添加以下内容，保存退出。 123&#123;\"insecure-registries\":[\"192.168.179.101:5000\"]&#125; 此步用于让 docker信任私有仓库地址 （5）重启docker 服务 1systemctl restart docker 7.2 镜像上传至私有仓库（1）标记此镜像为私有仓库的镜像 1docker tag redis 192.168.179.101:5000/redis 2）再次启动私服容器 1docker start registry （3）上传标记的镜像 1docker push 192.168.179.101:5000/redis","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"}]}],"categories":[{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/categories/Spring/"},{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/categories/多线程/"},{"name":"项目","slug":"项目","permalink":"http://tonymua.top/categories/项目/"},{"name":"shell","slug":"shell","permalink":"http://tonymua.top/categories/shell/"},{"name":"前端","slug":"前端","permalink":"http://tonymua.top/categories/前端/"},{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/categories/微服务/"},{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/categories/Redis/"},{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/categories/JVM/"},{"name":"源码分析","slug":"源码分析","permalink":"http://tonymua.top/categories/源码分析/"},{"name":"Git","slug":"Git","permalink":"http://tonymua.top/categories/Git/"}],"tags":[{"name":"代理模式","slug":"代理模式","permalink":"http://tonymua.top/tags/代理模式/"},{"name":"javaee","slug":"javaee","permalink":"http://tonymua.top/tags/javaee/"},{"name":"javase","slug":"javase","permalink":"http://tonymua.top/tags/javase/"},{"name":"项目","slug":"项目","permalink":"http://tonymua.top/tags/项目/"},{"name":"多线程","slug":"多线程","permalink":"http://tonymua.top/tags/多线程/"},{"name":"并发编程","slug":"并发编程","permalink":"http://tonymua.top/tags/并发编程/"},{"name":"tool","slug":"tool","permalink":"http://tonymua.top/tags/tool/"},{"name":"项目部署","slug":"项目部署","permalink":"http://tonymua.top/tags/项目部署/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://tonymua.top/tags/Spring-Boot/"},{"name":"微信公众号","slug":"微信公众号","permalink":"http://tonymua.top/tags/微信公众号/"},{"name":"HLS","slug":"HLS","permalink":"http://tonymua.top/tags/HLS/"},{"name":"文件上传","slug":"文件上传","permalink":"http://tonymua.top/tags/文件上传/"},{"name":"文件分块","slug":"文件分块","permalink":"http://tonymua.top/tags/文件分块/"},{"name":"视频处理","slug":"视频处理","permalink":"http://tonymua.top/tags/视频处理/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://tonymua.top/tags/RabbitMQ/"},{"name":"m3u8","slug":"m3u8","permalink":"http://tonymua.top/tags/m3u8/"},{"name":"面试","slug":"面试","permalink":"http://tonymua.top/tags/面试/"},{"name":"Vue","slug":"Vue","permalink":"http://tonymua.top/tags/Vue/"},{"name":"算法","slug":"算法","permalink":"http://tonymua.top/tags/算法/"},{"name":"框架","slug":"框架","permalink":"http://tonymua.top/tags/框架/"},{"name":"Spring","slug":"Spring","permalink":"http://tonymua.top/tags/Spring/"},{"name":"AOP","slug":"AOP","permalink":"http://tonymua.top/tags/AOP/"},{"name":"面向切面编程","slug":"面向切面编程","permalink":"http://tonymua.top/tags/面向切面编程/"},{"name":"微服务","slug":"微服务","permalink":"http://tonymua.top/tags/微服务/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://tonymua.top/tags/Spring-Cloud/"},{"name":"Redis","slug":"Redis","permalink":"http://tonymua.top/tags/Redis/"},{"name":"数据库","slug":"数据库","permalink":"http://tonymua.top/tags/数据库/"},{"name":"JVM","slug":"JVM","permalink":"http://tonymua.top/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://tonymua.top/tags/垃圾回收/"},{"name":"GC","slug":"GC","permalink":"http://tonymua.top/tags/GC/"},{"name":"HashMap","slug":"HashMap","permalink":"http://tonymua.top/tags/HashMap/"},{"name":"源码","slug":"源码","permalink":"http://tonymua.top/tags/源码/"},{"name":"底层","slug":"底层","permalink":"http://tonymua.top/tags/底层/"},{"name":"shell","slug":"shell","permalink":"http://tonymua.top/tags/shell/"},{"name":"Git","slug":"Git","permalink":"http://tonymua.top/tags/Git/"}]}